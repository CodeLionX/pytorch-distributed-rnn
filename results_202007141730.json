{"results": [{"command": "~/susml/jakob_torben/bin/horovodrun -np 12 --hosts 10.42.0.50:1,10.42.0.29:1,10.42.0.105:1,10.42.0.56:1,10.42.0.180:1,10.42.0.235:1,10.42.0.244:1,10.42.0.239:1,10.42.0.191:1,10.42.0.41:1,10.42.0.190:1,10.42.0.69:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 480 --epochs 1 --seed 123456789 --no-validation  horovod", "stdout": "", "stderr": "[1,6]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,6]<stderr>:INFO:root:Training set of size 6912\n[1,10]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,10]<stderr>:INFO:root:Training set of size 6912\n[1,3]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,3]<stderr>:INFO:root:Training set of size 6912\n[1,4]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,4]<stderr>:INFO:root:Training set of size 6912\n[1,5]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,5]<stderr>:INFO:root:Training set of size 6912\n[1,11]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,11]<stderr>:INFO:root:Training set of size 6912\n[1,9]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,9]<stderr>:INFO:root:Training set of size 6912\n[1,7]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,7]<stderr>:INFO:root:Training set of size 6912\n[1,2]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,2]<stderr>:INFO:root:Training set of size 6912\n[1,8]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,8]<stderr>:INFO:root:Training set of size 6912\n[1,1]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,1]<stderr>:INFO:root:Training set of size 6912\n[1,0]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,0]<stderr>:INFO:root:Training set of size 6912\n[1,7]<stderr>:INFO:root:Training model for 1 epochs...\n[1,5]<stderr>:INFO:root:Training model for 1 epochs...\n[1,6]<stderr>:INFO:root:Training model for 1 epochs...\n[1,11]<stderr>:INFO:root:Training model for 1 epochs...\n[1,4]<stderr>:INFO:root:Training model for 1 epochs...\n[1,3]<stderr>:INFO:root:Training model for 1 epochs...\n[1,1]<stderr>:INFO:root:Training model for 1 epochs...\n[1,10]<stderr>:INFO:root:Training model for 1 epochs...\n[1,2]<stderr>:INFO:root:Training model for 1 epochs...\n[1,8]<stderr>:INFO:root:Training model for 1 epochs...\n[1,9]<stderr>:INFO:root:Training model for 1 epochs...\n[1,0]<stderr>:INFO:root:Training model for 1 epochs...\n[1,11]<stderr>:INFO:root:Rank: 11   Start Epoch 0\n[1,4]<stderr>:INFO:root:Rank: 04   Start Epoch 0\n[1,5]<stderr>:INFO:root:Rank: 05   Start Epoch 0\n[1,7]<stderr>:INFO:root:Rank: 07   Start Epoch 0\n[1,3]<stderr>:INFO:root:Rank: 03   Start Epoch 0\n[1,6]<stderr>:INFO:root:Rank: 06   Start Epoch 0\n[1,10]<stderr>:INFO:root:Rank: 10   Start Epoch 0\n[1,9]<stderr>:INFO:root:Rank: 09   Start Epoch 0\n[1,0]<stderr>:INFO:root:Rank: 00   Start Epoch 0\n[1,2]<stderr>:INFO:root:Rank: 02   Start Epoch 0\n[1,1]<stderr>:INFO:root:Rank: 01   Start Epoch 0\n[1,8]<stderr>:INFO:root:Rank: 08   Start Epoch 0\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 1/15 (7%)\tLoss: 1.798443\tAcc: 5/40 (12%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 1/15 (7%)\tLoss: 1.796497\tAcc: 8/40 (20%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 1/15 (7%)\tLoss: 1.779946\tAcc: 10/40 (25%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 1/15 (7%)\tLoss: 1.805178\tAcc: 8/40 (20%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 1/15 (7%)\tLoss: 1.798122\tAcc: 8/40 (20%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 1/15 (7%)\tLoss: 1.791924\tAcc: 6/40 (15%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 1/15 (7%)\tLoss: 1.803177\tAcc: 8/40 (20%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 1/15 (7%)\tLoss: 1.772854\tAcc: 10/40 (25%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 1/15 (7%)\tLoss: 1.813990\tAcc: 7/40 (18%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 1/15 (7%)\tLoss: 1.774294\tAcc: 10/40 (25%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 1/15 (7%)\tLoss: 1.804508\tAcc: 5/40 (12%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 1/15 (7%)\tLoss: 1.820293\tAcc: 1/40 (2%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 2/15 (13%)\tLoss: 1.800625\tAcc: 5/40 (12%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 2/15 (13%)\tLoss: 1.784211\tAcc: 5/40 (12%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 2/15 (13%)\tLoss: 1.779206\tAcc: 6/40 (15%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 2/15 (13%)\tLoss: 1.799015\tAcc: 3/40 (8%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 2/15 (13%)\tLoss: 1.774449\tAcc: 10/40 (25%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 2/15 (13%)\tLoss: 1.784490\tAcc: 7/40 (18%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 2/15 (13%)\tLoss: 1.791232\tAcc: 5/40 (12%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 2/15 (13%)\tLoss: 1.796935\tAcc: 8/40 (20%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 2/15 (13%)\tLoss: 1.791208\tAcc: 6/40 (15%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 2/15 (13%)\tLoss: 1.794070\tAcc: 5/40 (12%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 2/15 (13%)\tLoss: 1.801611\tAcc: 6/40 (15%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 2/15 (13%)\tLoss: 1.800308\tAcc: 5/40 (12%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 3/15 (20%)\tLoss: 1.796351\tAcc: 5/40 (12%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 3/15 (20%)\tLoss: 1.797429\tAcc: 4/40 (10%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 3/15 (20%)\tLoss: 1.796249\tAcc: 5/40 (12%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 3/15 (20%)\tLoss: 1.795674\tAcc: 7/40 (18%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 3/15 (20%)\tLoss: 1.784643\tAcc: 7/40 (18%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 3/15 (20%)\tLoss: 1.778935\tAcc: 7/40 (18%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 3/15 (20%)\tLoss: 1.781276\tAcc: 10/40 (25%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 3/15 (20%)\tLoss: 1.784475\tAcc: 6/40 (15%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 3/15 (20%)\tLoss: 1.781636\tAcc: 8/40 (20%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 3/15 (20%)\tLoss: 1.779833\tAcc: 9/40 (22%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 3/15 (20%)\tLoss: 1.788617\tAcc: 9/40 (22%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 3/15 (20%)\tLoss: 1.776458\tAcc: 12/40 (30%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 4/15 (27%)\tLoss: 1.787030\tAcc: 5/40 (12%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 4/15 (27%)\tLoss: 1.792035\tAcc: 4/40 (10%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 4/15 (27%)\tLoss: 1.784108\tAcc: 5/40 (12%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 4/15 (27%)\tLoss: 1.783063\tAcc: 6/40 (15%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 4/15 (27%)\tLoss: 1.767022\tAcc: 10/40 (25%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 4/15 (27%)\tLoss: 1.800322\tAcc: 2/40 (5%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 4/15 (27%)\tLoss: 1.784835\tAcc: 10/40 (25%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 4/15 (27%)\tLoss: 1.783888\tAcc: 4/40 (10%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 4/15 (27%)\tLoss: 1.764290\tAcc: 14/40 (35%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 4/15 (27%)\tLoss: 1.781661\tAcc: 4/40 (10%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 4/15 (27%)\tLoss: 1.773340\tAcc: 9/40 (22%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 4/15 (27%)\tLoss: 1.782248\tAcc: 8/40 (20%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 5/15 (33%)\tLoss: 1.776353\tAcc: 8/40 (20%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 5/15 (33%)\tLoss: 1.781172\tAcc: 9/40 (22%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 5/15 (33%)\tLoss: 1.784829\tAcc: 7/40 (18%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 5/15 (33%)\tLoss: 1.795012\tAcc: 8/40 (20%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 5/15 (33%)\tLoss: 1.794169\tAcc: 5/40 (12%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 5/15 (33%)\tLoss: 1.804270\tAcc: 5/40 (12%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 5/15 (33%)\tLoss: 1.789005\tAcc: 9/40 (22%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 5/15 (33%)\tLoss: 1.773007\tAcc: 11/40 (28%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 5/15 (33%)\tLoss: 1.794024\tAcc: 6/40 (15%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 5/15 (33%)\tLoss: 1.785323\tAcc: 11/40 (28%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 5/15 (33%)\tLoss: 1.766987\tAcc: 14/40 (35%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 5/15 (33%)\tLoss: 1.757488\tAcc: 12/40 (30%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 6/15 (40%)\tLoss: 1.782206\tAcc: 10/40 (25%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 6/15 (40%)\tLoss: 1.797990\tAcc: 10/40 (25%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 6/15 (40%)\tLoss: 1.780948\tAcc: 11/40 (28%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 6/15 (40%)\tLoss: 1.788426\tAcc: 14/40 (35%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 6/15 (40%)\tLoss: 1.763002\tAcc: 16/40 (40%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 6/15 (40%)\tLoss: 1.759716\tAcc: 17/40 (42%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 6/15 (40%)\tLoss: 1.761390\tAcc: 18/40 (45%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 6/15 (40%)\tLoss: 1.771604\tAcc: 13/40 (32%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 6/15 (40%)\tLoss: 1.777434\tAcc: 15/40 (38%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 6/15 (40%)\tLoss: 1.797366\tAcc: 12/40 (30%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 6/15 (40%)\tLoss: 1.807108\tAcc: 5/40 (12%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 6/15 (40%)\tLoss: 1.773443\tAcc: 13/40 (32%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 7/15 (47%)\tLoss: 1.757135\tAcc: 15/40 (38%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 7/15 (47%)\tLoss: 1.749228\tAcc: 17/40 (42%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 7/15 (47%)\tLoss: 1.758928\tAcc: 15/40 (38%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 7/15 (47%)\tLoss: 1.760255\tAcc: 16/40 (40%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 7/15 (47%)\tLoss: 1.769178\tAcc: 13/40 (32%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 7/15 (47%)\tLoss: 1.782549\tAcc: 13/40 (32%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 7/15 (47%)\tLoss: 1.781237\tAcc: 14/40 (35%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 7/15 (47%)\tLoss: 1.765203\tAcc: 17/40 (42%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 7/15 (47%)\tLoss: 1.756216\tAcc: 17/40 (42%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 7/15 (47%)\tLoss: 1.751123\tAcc: 17/40 (42%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 7/15 (47%)\tLoss: 1.756758\tAcc: 15/40 (38%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 7/15 (47%)\tLoss: 1.786044\tAcc: 9/40 (22%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 8/15 (53%)\tLoss: 1.757513\tAcc: 14/40 (35%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 8/15 (53%)\tLoss: 1.758239\tAcc: 15/40 (38%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 8/15 (53%)\tLoss: 1.748493\tAcc: 16/40 (40%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 8/15 (53%)\tLoss: 1.788602\tAcc: 9/40 (22%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 8/15 (53%)\tLoss: 1.762403\tAcc: 14/40 (35%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 8/15 (53%)\tLoss: 1.762384\tAcc: 13/40 (32%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 8/15 (53%)\tLoss: 1.775038\tAcc: 15/40 (38%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 8/15 (53%)\tLoss: 1.766785\tAcc: 13/40 (32%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 8/15 (53%)\tLoss: 1.741822\tAcc: 18/40 (45%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 8/15 (53%)\tLoss: 1.775790\tAcc: 11/40 (28%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 8/15 (53%)\tLoss: 1.778528\tAcc: 10/40 (25%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 8/15 (53%)\tLoss: 1.734538\tAcc: 17/40 (42%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 9/15 (60%)\tLoss: 1.750196\tAcc: 13/40 (32%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 9/15 (60%)\tLoss: 1.739022\tAcc: 18/40 (45%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 9/15 (60%)\tLoss: 1.745427\tAcc: 13/40 (32%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 9/15 (60%)\tLoss: 1.773520\tAcc: 9/40 (22%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 9/15 (60%)\tLoss: 1.777621\tAcc: 8/40 (20%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 9/15 (60%)\tLoss: 1.745315\tAcc: 16/40 (40%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 9/15 (60%)\tLoss: 1.745416\tAcc: 10/40 (25%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 9/15 (60%)\tLoss: 1.750072\tAcc: 11/40 (28%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 9/15 (60%)\tLoss: 1.767559\tAcc: 14/40 (35%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 9/15 (60%)\tLoss: 1.743669\tAcc: 12/40 (30%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 9/15 (60%)\tLoss: 1.782029\tAcc: 11/40 (28%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 9/15 (60%)\tLoss: 1.751347\tAcc: 13/40 (32%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 10/15 (67%)\tLoss: 1.747152\tAcc: 8/40 (20%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 10/15 (67%)\tLoss: 1.749862\tAcc: 12/40 (30%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 10/15 (67%)\tLoss: 1.740394\tAcc: 14/40 (35%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 10/15 (67%)\tLoss: 1.759995\tAcc: 8/40 (20%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 10/15 (67%)\tLoss: 1.755953\tAcc: 8/40 (20%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 10/15 (67%)\tLoss: 1.730910\tAcc: 13/40 (32%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 10/15 (67%)\tLoss: 1.726690\tAcc: 13/40 (32%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 10/15 (67%)\tLoss: 1.749563\tAcc: 11/40 (28%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 10/15 (67%)\tLoss: 1.742392\tAcc: 9/40 (22%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 10/15 (67%)\tLoss: 1.752174\tAcc: 13/40 (32%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 10/15 (67%)\tLoss: 1.751426\tAcc: 10/40 (25%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 10/15 (67%)\tLoss: 1.748655\tAcc: 13/40 (32%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 11/15 (73%)\tLoss: 1.698152\tAcc: 15/40 (38%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 11/15 (73%)\tLoss: 1.740143\tAcc: 11/40 (28%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 11/15 (73%)\tLoss: 1.767846\tAcc: 12/40 (30%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 11/15 (73%)\tLoss: 1.752898\tAcc: 10/40 (25%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 11/15 (73%)\tLoss: 1.695564\tAcc: 16/40 (40%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 11/15 (73%)\tLoss: 1.735351\tAcc: 11/40 (28%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 11/15 (73%)\tLoss: 1.709522\tAcc: 13/40 (32%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 11/15 (73%)\tLoss: 1.714617\tAcc: 15/40 (38%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 11/15 (73%)\tLoss: 1.724076\tAcc: 16/40 (40%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 11/15 (73%)\tLoss: 1.746730\tAcc: 14/40 (35%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 11/15 (73%)\tLoss: 1.739007\tAcc: 10/40 (25%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 11/15 (73%)\tLoss: 1.766491\tAcc: 8/40 (20%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 12/15 (80%)\tLoss: 1.736638\tAcc: 12/40 (30%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 12/15 (80%)\tLoss: 1.709249\tAcc: 14/40 (35%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 12/15 (80%)\tLoss: 1.709894\tAcc: 14/40 (35%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 12/15 (80%)\tLoss: 1.742122\tAcc: 14/40 (35%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 12/15 (80%)\tLoss: 1.693290\tAcc: 16/40 (40%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 12/15 (80%)\tLoss: 1.694872\tAcc: 19/40 (48%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 12/15 (80%)\tLoss: 1.740726\tAcc: 13/40 (32%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 12/15 (80%)\tLoss: 1.712949\tAcc: 9/40 (22%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 12/15 (80%)\tLoss: 1.699079\tAcc: 17/40 (42%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 12/15 (80%)\tLoss: 1.769886\tAcc: 11/40 (28%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 12/15 (80%)\tLoss: 1.699059\tAcc: 16/40 (40%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 12/15 (80%)\tLoss: 1.694813\tAcc: 12/40 (30%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 13/15 (87%)\tLoss: 1.675880\tAcc: 18/40 (45%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 13/15 (87%)\tLoss: 1.716464\tAcc: 13/40 (32%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 13/15 (87%)\tLoss: 1.722178\tAcc: 13/40 (32%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 13/15 (87%)\tLoss: 1.709507\tAcc: 17/40 (42%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 13/15 (87%)\tLoss: 1.657071\tAcc: 16/40 (40%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 13/15 (87%)\tLoss: 1.721277\tAcc: 15/40 (38%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 13/15 (87%)\tLoss: 1.728180\tAcc: 10/40 (25%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 13/15 (87%)\tLoss: 1.660105\tAcc: 18/40 (45%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 13/15 (87%)\tLoss: 1.720785\tAcc: 9/40 (22%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 13/15 (87%)\tLoss: 1.657376\tAcc: 20/40 (50%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 13/15 (87%)\tLoss: 1.716509\tAcc: 14/40 (35%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 13/15 (87%)\tLoss: 1.683857\tAcc: 15/40 (38%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 14/15 (93%)\tLoss: 1.656380\tAcc: 20/40 (50%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 14/15 (93%)\tLoss: 1.671110\tAcc: 20/40 (50%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 14/15 (93%)\tLoss: 1.639106\tAcc: 14/40 (35%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 14/15 (93%)\tLoss: 1.701320\tAcc: 14/40 (35%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 14/15 (93%)\tLoss: 1.655311\tAcc: 11/40 (28%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 14/15 (93%)\tLoss: 1.653454\tAcc: 17/40 (42%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 14/15 (93%)\tLoss: 1.696226\tAcc: 19/40 (48%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 14/15 (93%)\tLoss: 1.693185\tAcc: 10/40 (25%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 14/15 (93%)\tLoss: 1.715732\tAcc: 14/40 (35%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 14/15 (93%)\tLoss: 1.666236\tAcc: 13/40 (32%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 14/15 (93%)\tLoss: 1.634934\tAcc: 21/40 (52%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 14/15 (93%)\tLoss: 1.661925\tAcc: 13/40 (32%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 15/15 (100%)\tLoss: 1.682908\tAcc: 4/16 (25%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 15/15 (100%)\tLoss: 1.562436\tAcc: 9/16 (56%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 15/15 (100%)\tLoss: 1.668455\tAcc: 7/16 (44%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 15/15 (100%)\tLoss: 1.718976\tAcc: 3/16 (19%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 15/15 (100%)\tLoss: 1.545304\tAcc: 7/16 (44%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 15/15 (100%)\tLoss: 1.516605\tAcc: 9/16 (56%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 15/15 (100%)\tLoss: 1.649004\tAcc: 5/16 (31%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 15/15 (100%)\tLoss: 1.633612\tAcc: 6/16 (38%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 15/15 (100%)\tLoss: 1.594221\tAcc: 7/16 (44%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 15/15 (100%)\tLoss: 1.591646\tAcc: 7/16 (44%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 15/15 (100%)\tLoss: 1.665223\tAcc: 3/16 (19%)\n[1,10]<stderr>:INFO:root:10: Memory Usage: 154.86328125, Training Duration: 29.34236177099956\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 15/15 (100%)\tLoss: 1.568134\tAcc: 7/16 (44%)\n[1,2]<stderr>:INFO:root:2: Memory Usage: 154.08203125, Training Duration: 29.363284806000593\n[1,5]<stderr>:INFO:root:5: Memory Usage: 154.32421875, Training Duration: 29.364217119000386\n[1,7]<stderr>:INFO:root:7: Memory Usage: 154.40625, Training Duration: 29.364356344001862\n[1,3]<stderr>:INFO:root:3: Memory Usage: 154.109375, Training Duration: 29.364011826000933\n[1,6]<stderr>:INFO:root:6: Memory Usage: 154.0546875, Training Duration: 29.364844413001265\n[1,9]<stderr>:INFO:root:9: Memory Usage: 154.83984375, Training Duration: 29.367948013001296\n[1,11]<stderr>:INFO:root:11: Memory Usage: 154.78125, Training Duration: 29.374853914996493\n[1,0]<stderr>:INFO:root:0: Memory Usage: 155.734375, Training Duration: 29.375928750003368\n[1,8]<stderr>:INFO:root:8: Memory Usage: 154.31640625, Training Duration: 29.37571840400051\n[1,4]<stderr>:INFO:root:4: Memory Usage: 154.26953125, Training Duration: 29.379400646997965\n[1,1]<stderr>:INFO:root:1: Memory Usage: 154.3046875, Training Duration: 29.383135353000398\n", "config": {"trainer": "horovod", "hosts": 12, "slots": 1, "parameters": {"--batch-size": 480, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 480 --epochs 1 --seed 123456789 --no-validation  local", "stdout": "", "stderr": "INFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Training model for 1 epochs...\nINFO:root:Rank: 00   Start Epoch 0\nINFO:root:Rank: 00   Train Batch: 1/15 (7%)\tLoss: 1.796602\tAcc: 86/480 (18%)\nINFO:root:Rank: 00   Train Batch: 2/15 (13%)\tLoss: 1.791447\tAcc: 71/480 (15%)\nINFO:root:Rank: 00   Train Batch: 3/15 (20%)\tLoss: 1.786798\tAcc: 89/480 (19%)\nINFO:root:Rank: 00   Train Batch: 4/15 (27%)\tLoss: 1.781988\tAcc: 81/480 (17%)\nINFO:root:Rank: 00   Train Batch: 5/15 (33%)\tLoss: 1.783470\tAcc: 105/480 (22%)\nINFO:root:Rank: 00   Train Batch: 6/15 (40%)\tLoss: 1.780052\tAcc: 154/480 (32%)\nINFO:root:Rank: 00   Train Batch: 7/15 (47%)\tLoss: 1.764488\tAcc: 178/480 (37%)\nINFO:root:Rank: 00   Train Batch: 8/15 (53%)\tLoss: 1.762511\tAcc: 165/480 (34%)\nINFO:root:Rank: 00   Train Batch: 9/15 (60%)\tLoss: 1.755932\tAcc: 148/480 (31%)\nINFO:root:Rank: 00   Train Batch: 10/15 (67%)\tLoss: 1.746263\tAcc: 132/480 (28%)\nINFO:root:Rank: 00   Train Batch: 11/15 (73%)\tLoss: 1.732533\tAcc: 151/480 (31%)\nINFO:root:Rank: 00   Train Batch: 12/15 (80%)\tLoss: 1.716881\tAcc: 167/480 (35%)\nINFO:root:Rank: 00   Train Batch: 13/15 (87%)\tLoss: 1.697432\tAcc: 178/480 (37%)\nINFO:root:Rank: 00   Train Batch: 14/15 (93%)\tLoss: 1.670410\tAcc: 186/480 (39%)\nINFO:root:Rank: 00   Train Batch: 15/15 (100%)\tLoss: 1.616377\tAcc: 74/192 (39%)\nINFO:root:0: Memory Usage: 396.28515625, Training Duration: 162.4142339459977\n", "config": {"trainer": "local", "hosts": 1, "slots": 1, "parameters": {"--batch-size": 480, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "~/susml/jakob_torben/bin/horovodrun -np 2 --hosts 10.42.0.50:1,10.42.0.29:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 480 --epochs 1 --seed 123456789 --no-validation  horovod", "stdout": "", "stderr": "[1,1]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,1]<stderr>:INFO:root:Training set of size 6912\n[1,0]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,0]<stderr>:INFO:root:Training set of size 6912\n[1,0]<stderr>:INFO:root:Training model for 1 epochs...\n[1,1]<stderr>:INFO:root:Training model for 1 epochs...\n[1,0]<stderr>:INFO:root:Rank: 00   Start Epoch 0\n[1,1]<stderr>:INFO:root:Rank: 01   Start Epoch 0\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 1/15 (7%)\tLoss: 1.799708\tAcc: 46/240 (19%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 1/15 (7%)\tLoss: 1.793498\tAcc: 40/240 (17%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 2/15 (13%)\tLoss: 1.791796\tAcc: 31/240 (13%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 2/15 (13%)\tLoss: 1.791096\tAcc: 40/240 (17%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 3/15 (20%)\tLoss: 1.792659\tAcc: 38/240 (16%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 3/15 (20%)\tLoss: 1.780936\tAcc: 51/240 (21%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 4/15 (27%)\tLoss: 1.780521\tAcc: 47/240 (20%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 4/15 (27%)\tLoss: 1.783452\tAcc: 34/240 (14%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 5/15 (33%)\tLoss: 1.781686\tAcc: 48/240 (20%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 5/15 (33%)\tLoss: 1.785253\tAcc: 57/240 (24%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 6/15 (40%)\tLoss: 1.777773\tAcc: 81/240 (34%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 6/15 (40%)\tLoss: 1.782333\tAcc: 73/240 (30%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 7/15 (47%)\tLoss: 1.763381\tAcc: 93/240 (39%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 7/15 (47%)\tLoss: 1.765595\tAcc: 85/240 (35%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 8/15 (53%)\tLoss: 1.764439\tAcc: 80/240 (33%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 8/15 (53%)\tLoss: 1.760583\tAcc: 85/240 (35%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 9/15 (60%)\tLoss: 1.751001\tAcc: 75/240 (31%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 9/15 (60%)\tLoss: 1.760864\tAcc: 73/240 (30%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 10/15 (67%)\tLoss: 1.743228\tAcc: 69/240 (29%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 10/15 (67%)\tLoss: 1.749299\tAcc: 63/240 (26%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 11/15 (73%)\tLoss: 1.740571\tAcc: 71/240 (30%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 11/15 (73%)\tLoss: 1.724495\tAcc: 80/240 (33%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 12/15 (80%)\tLoss: 1.725041\tAcc: 83/240 (35%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 12/15 (80%)\tLoss: 1.708722\tAcc: 84/240 (35%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 13/15 (87%)\tLoss: 1.698768\tAcc: 89/240 (37%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 13/15 (87%)\tLoss: 1.696097\tAcc: 89/240 (37%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 14/15 (93%)\tLoss: 1.667384\tAcc: 101/240 (42%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 14/15 (93%)\tLoss: 1.673435\tAcc: 85/240 (35%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 15/15 (100%)\tLoss: 1.617575\tAcc: 37/96 (39%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 15/15 (100%)\tLoss: 1.615178\tAcc: 37/96 (39%)\n[1,0]<stderr>:INFO:root:0: Memory Usage: 271.16796875, Training Duration: 95.84459506599887\n[1,1]<stderr>:INFO:root:1: Memory Usage: 268.38671875, Training Duration: 95.85495077399901\n", "config": {"trainer": "horovod", "hosts": 2, "slots": 1, "parameters": {"--batch-size": 480, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "mpirun --bind-to none --map-by slot -np 2 --host 10.42.0.50:1,10.42.0.29:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 960 --epochs 1 --seed 123456789 --no-validation  distributed", "stdout": "", "stderr": "INFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Rank: 00   Start Epoch 0\nINFO:root:Rank: 01   Start Epoch 0\nINFO:root:Rank: 01   Train Batch: 1/8 (12%)\tLoss: 1.797411\tAcc: 86/480 (18%)\nINFO:root:Rank: 00   Train Batch: 1/8 (12%)\tLoss: 1.794207\tAcc: 71/480 (15%)\nINFO:root:Rank: 01   Train Batch: 2/8 (25%)\tLoss: 1.791553\tAcc: 85/480 (18%)\nINFO:root:Rank: 00   Train Batch: 2/8 (25%)\tLoss: 1.787575\tAcc: 85/480 (18%)\nINFO:root:Rank: 00   Train Batch: 3/8 (38%)\tLoss: 1.790183\tAcc: 78/480 (16%)\nINFO:root:Rank: 01   Train Batch: 3/8 (38%)\tLoss: 1.789301\tAcc: 72/480 (15%)\nINFO:root:Rank: 00   Train Batch: 4/8 (50%)\tLoss: 1.781793\tAcc: 75/480 (16%)\nINFO:root:Rank: 01   Train Batch: 4/8 (50%)\tLoss: 1.778382\tAcc: 89/480 (19%)\nINFO:root:Rank: 01   Train Batch: 5/8 (62%)\tLoss: 1.775585\tAcc: 169/480 (35%)\nINFO:root:Rank: 00   Train Batch: 5/8 (62%)\tLoss: 1.780939\tAcc: 155/480 (32%)\nINFO:root:Rank: 01   Train Batch: 6/8 (75%)\tLoss: 1.772507\tAcc: 160/480 (33%)\nINFO:root:Rank: 00   Train Batch: 6/8 (75%)\tLoss: 1.770746\tAcc: 169/480 (35%)\nINFO:root:Rank: 01   Train Batch: 7/8 (88%)\tLoss: 1.768617\tAcc: 128/480 (27%)\nINFO:root:Rank: 00   Train Batch: 7/8 (88%)\tLoss: 1.767383\tAcc: 126/480 (26%)\nINFO:root:Rank: 01   Train Batch: 8/8 (100%)\tLoss: 1.760383\tAcc: 26/96 (27%)\nINFO:root:Rank: 00   Train Batch: 8/8 (100%)\tLoss: 1.756339\tAcc: 24/96 (25%)\nINFO:root:1: Memory Usage: 404.484375, Training Duration: 99.04059727899948\nINFO:root:0: Memory Usage: 404.8203125, Training Duration: 99.05082526600017\n", "config": {"trainer": "distributed", "hosts": 2, "slots": 1, "parameters": {"--batch-size": 960, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "mpirun --bind-to none --map-by slot -np 8 --host 10.42.0.50:1,10.42.0.29:1,10.42.0.105:1,10.42.0.56:1,10.42.0.180:1,10.42.0.235:1,10.42.0.244:1,10.42.0.239:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 960 --epochs 1 --seed 123456789 --no-validation  distributed", "stdout": "", "stderr": "INFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Rank: 05   Start Epoch 0\nINFO:root:Rank: 00   Start Epoch 0\nINFO:root:Rank: 07   Start Epoch 0\nINFO:root:Rank: 04   Start Epoch 0\nINFO:root:Rank: 06   Start Epoch 0\nINFO:root:Rank: 03   Start Epoch 0\nINFO:root:Rank: 02   Start Epoch 0\nINFO:root:Rank: 01   Start Epoch 0\nINFO:root:Rank: 00   Train Batch: 1/8 (12%)\tLoss: 1.792831\tAcc: 18/120 (15%)\nINFO:root:Rank: 07   Train Batch: 1/8 (12%)\tLoss: 1.795470\tAcc: 20/120 (17%)\nINFO:root:Rank: 02   Train Batch: 1/8 (12%)\tLoss: 1.788679\tAcc: 22/120 (18%)\nINFO:root:Rank: 04   Train Batch: 1/8 (12%)\tLoss: 1.800577\tAcc: 17/120 (14%)\nINFO:root:Rank: 03   Train Batch: 1/8 (12%)\tLoss: 1.793724\tAcc: 25/120 (21%)\nINFO:root:Rank: 06   Train Batch: 1/8 (12%)\tLoss: 1.794739\tAcc: 14/120 (12%)\nINFO:root:Rank: 05   Train Batch: 1/8 (12%)\tLoss: 1.791984\tAcc: 26/120 (22%)\nINFO:root:Rank: 01   Train Batch: 1/8 (12%)\tLoss: 1.808466\tAcc: 15/120 (12%)\nINFO:root:Rank: 07   Train Batch: 2/8 (25%)\tLoss: 1.781925\tAcc: 25/120 (21%)\nINFO:root:Rank: 06   Train Batch: 2/8 (25%)\tLoss: 1.786330\tAcc: 20/120 (17%)\nINFO:root:Rank: 00   Train Batch: 2/8 (25%)\tLoss: 1.785688\tAcc: 22/120 (18%)\nINFO:root:Rank: 02   Train Batch: 2/8 (25%)\tLoss: 1.793234\tAcc: 19/120 (16%)\nINFO:root:Rank: 01   Train Batch: 2/8 (25%)\tLoss: 1.788694\tAcc: 20/120 (17%)\nINFO:root:Rank: 03   Train Batch: 2/8 (25%)\tLoss: 1.793408\tAcc: 23/120 (19%)\nINFO:root:Rank: 05   Train Batch: 2/8 (25%)\tLoss: 1.802182\tAcc: 17/120 (14%)\nINFO:root:Rank: 04   Train Batch: 2/8 (25%)\tLoss: 1.785046\tAcc: 24/120 (20%)\nINFO:root:Rank: 00   Train Batch: 3/8 (38%)\tLoss: 1.797088\tAcc: 22/120 (18%)\nINFO:root:Rank: 01   Train Batch: 3/8 (38%)\tLoss: 1.790712\tAcc: 15/120 (12%)\nINFO:root:Rank: 03   Train Batch: 3/8 (38%)\tLoss: 1.789099\tAcc: 21/120 (18%)\nINFO:root:Rank: 07   Train Batch: 3/8 (38%)\tLoss: 1.787521\tAcc: 18/120 (15%)\nINFO:root:Rank: 05   Train Batch: 3/8 (38%)\tLoss: 1.789871\tAcc: 18/120 (15%)\nINFO:root:Rank: 06   Train Batch: 3/8 (38%)\tLoss: 1.796445\tAcc: 15/120 (12%)\nINFO:root:Rank: 04   Train Batch: 3/8 (38%)\tLoss: 1.778589\tAcc: 21/120 (18%)\nINFO:root:Rank: 02   Train Batch: 3/8 (38%)\tLoss: 1.788605\tAcc: 20/120 (17%)\nINFO:root:Rank: 07   Train Batch: 4/8 (50%)\tLoss: 1.784368\tAcc: 18/120 (15%)\nINFO:root:Rank: 03   Train Batch: 4/8 (50%)\tLoss: 1.768727\tAcc: 24/120 (20%)\nINFO:root:Rank: 04   Train Batch: 4/8 (50%)\tLoss: 1.781974\tAcc: 22/120 (18%)\nINFO:root:Rank: 05   Train Batch: 4/8 (50%)\tLoss: 1.782258\tAcc: 18/120 (15%)\nINFO:root:Rank: 00   Train Batch: 4/8 (50%)\tLoss: 1.781264\tAcc: 19/120 (16%)\nINFO:root:Rank: 02   Train Batch: 4/8 (50%)\tLoss: 1.783865\tAcc: 13/120 (11%)\nINFO:root:Rank: 06   Train Batch: 4/8 (50%)\tLoss: 1.780070\tAcc: 21/120 (18%)\nINFO:root:Rank: 01   Train Batch: 4/8 (50%)\tLoss: 1.778171\tAcc: 29/120 (24%)\nINFO:root:Rank: 04   Train Batch: 5/8 (62%)\tLoss: 1.787518\tAcc: 34/120 (28%)\nINFO:root:Rank: 03   Train Batch: 5/8 (62%)\tLoss: 1.774058\tAcc: 41/120 (34%)\nINFO:root:Rank: 00   Train Batch: 5/8 (62%)\tLoss: 1.779757\tAcc: 41/120 (34%)\nINFO:root:Rank: 01   Train Batch: 5/8 (62%)\tLoss: 1.787153\tAcc: 36/120 (30%)\nINFO:root:Rank: 07   Train Batch: 5/8 (62%)\tLoss: 1.773627\tAcc: 40/120 (33%)\nINFO:root:Rank: 05   Train Batch: 5/8 (62%)\tLoss: 1.767501\tAcc: 52/120 (43%)\nINFO:root:Rank: 06   Train Batch: 5/8 (62%)\tLoss: 1.777368\tAcc: 47/120 (39%)\nINFO:root:Rank: 02   Train Batch: 5/8 (62%)\tLoss: 1.779114\tAcc: 33/120 (28%)\nINFO:root:Rank: 07   Train Batch: 6/8 (75%)\tLoss: 1.772359\tAcc: 36/120 (30%)\nINFO:root:Rank: 06   Train Batch: 6/8 (75%)\tLoss: 1.777706\tAcc: 37/120 (31%)\nINFO:root:Rank: 04   Train Batch: 6/8 (75%)\tLoss: 1.767602\tAcc: 47/120 (39%)\nINFO:root:Rank: 03   Train Batch: 6/8 (75%)\tLoss: 1.775013\tAcc: 40/120 (33%)\nINFO:root:Rank: 02   Train Batch: 6/8 (75%)\tLoss: 1.779403\tAcc: 36/120 (30%)\nINFO:root:Rank: 05   Train Batch: 6/8 (75%)\tLoss: 1.764130\tAcc: 45/120 (38%)\nINFO:root:Rank: 00   Train Batch: 6/8 (75%)\tLoss: 1.758269\tAcc: 49/120 (41%)\nINFO:root:Rank: 01   Train Batch: 6/8 (75%)\tLoss: 1.778531\tAcc: 39/120 (32%)\nINFO:root:Rank: 06   Train Batch: 7/8 (88%)\tLoss: 1.765103\tAcc: 38/120 (32%)\nINFO:root:Rank: 05   Train Batch: 7/8 (88%)\tLoss: 1.768509\tAcc: 34/120 (28%)\nINFO:root:Rank: 07   Train Batch: 7/8 (88%)\tLoss: 1.773928\tAcc: 29/120 (24%)\nINFO:root:Rank: 04   Train Batch: 7/8 (88%)\tLoss: 1.777536\tAcc: 28/120 (23%)\nINFO:root:Rank: 03   Train Batch: 7/8 (88%)\tLoss: 1.765838\tAcc: 34/120 (28%)\nINFO:root:Rank: 02   Train Batch: 7/8 (88%)\tLoss: 1.765520\tAcc: 27/120 (22%)\nINFO:root:Rank: 01   Train Batch: 7/8 (88%)\tLoss: 1.766192\tAcc: 31/120 (26%)\nINFO:root:Rank: 00   Train Batch: 7/8 (88%)\tLoss: 1.761371\tAcc: 33/120 (28%)\nINFO:root:Rank: 05   Train Batch: 8/8 (100%)\tLoss: 1.770036\tAcc: 6/24 (25%)\nINFO:root:Rank: 03   Train Batch: 8/8 (100%)\tLoss: 1.741724\tAcc: 9/24 (38%)\nINFO:root:Rank: 04   Train Batch: 8/8 (100%)\tLoss: 1.731862\tAcc: 7/24 (29%)\nINFO:root:Rank: 07   Train Batch: 8/8 (100%)\tLoss: 1.764930\tAcc: 5/24 (21%)\nINFO:root:Rank: 00   Train Batch: 8/8 (100%)\tLoss: 1.763532\tAcc: 3/24 (12%)\nINFO:root:Rank: 06   Train Batch: 8/8 (100%)\tLoss: 1.756312\tAcc: 9/24 (38%)\nINFO:root:Rank: 02   Train Batch: 8/8 (100%)\tLoss: 1.773650\tAcc: 5/24 (21%)\nINFO:root:Rank: 01   Train Batch: 8/8 (100%)\tLoss: 1.764840\tAcc: 6/24 (25%)\nINFO:root:5: Memory Usage: 194.28515625, Training Duration: 37.48299208699973\nINFO:root:4: Memory Usage: 196.484375, Training Duration: 37.48155158099689\nINFO:root:7: Memory Usage: 195.49609375, Training Duration: 37.48501855699942\nINFO:root:3: Memory Usage: 192.71875, Training Duration: 37.48149021000063\nINFO:root:6: Memory Usage: 193.5078125, Training Duration: 37.48312034799892\nINFO:root:0: Memory Usage: 195.2109375, Training Duration: 37.48978493600225\nINFO:root:2: Memory Usage: 195.43359375, Training Duration: 37.48296130499875\nINFO:root:1: Memory Usage: 194.02734375, Training Duration: 37.48270004799997\n", "config": {"trainer": "distributed", "hosts": 8, "slots": 1, "parameters": {"--batch-size": 960, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "mpirun --bind-to none --map-by slot -np 12 --host 10.42.0.50:1,10.42.0.29:1,10.42.0.105:1,10.42.0.56:1,10.42.0.180:1,10.42.0.235:1,10.42.0.244:1,10.42.0.239:1,10.42.0.191:1,10.42.0.41:1,10.42.0.190:1,10.42.0.69:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 480 --epochs 1 --seed 123456789 --no-validation  distributed", "stdout": "", "stderr": "INFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Rank: 11   Start Epoch 0\nINFO:root:Rank: 00   Start Epoch 0\nINFO:root:Rank: 08   Start Epoch 0\nINFO:root:Rank: 02   Start Epoch 0\nINFO:root:Rank: 01   Start Epoch 0\nINFO:root:Rank: 06   Start Epoch 0\nINFO:root:Rank: 10   Start Epoch 0\nINFO:root:Rank: 05   Start Epoch 0\nINFO:root:Rank: 04   Start Epoch 0\nINFO:root:Rank: 07   Start Epoch 0\nINFO:root:Rank: 03   Start Epoch 0\nINFO:root:Rank: 09   Start Epoch 0\nINFO:root:Rank: 10   Train Batch: 1/15 (7%)\tLoss: 1.774294\tAcc: 10/40 (25%)\nINFO:root:Rank: 01   Train Batch: 1/15 (7%)\tLoss: 1.798122\tAcc: 8/40 (20%)\nINFO:root:Rank: 02   Train Batch: 1/15 (7%)\tLoss: 1.820293\tAcc: 1/40 (2%)\nINFO:root:Rank: 03   Train Batch: 1/15 (7%)\tLoss: 1.805178\tAcc: 8/40 (20%)\nINFO:root:Rank: 09   Train Batch: 1/15 (7%)\tLoss: 1.804508\tAcc: 5/40 (12%)\nINFO:root:Rank: 07   Train Batch: 1/15 (7%)\tLoss: 1.779946\tAcc: 10/40 (25%)\nINFO:root:Rank: 06   Train Batch: 1/15 (7%)\tLoss: 1.772854\tAcc: 10/40 (25%)\nINFO:root:Rank: 05   Train Batch: 1/15 (7%)\tLoss: 1.813990\tAcc: 7/40 (18%)\nINFO:root:Rank: 00   Train Batch: 1/15 (7%)\tLoss: 1.798443\tAcc: 5/40 (12%)\nINFO:root:Rank: 11   Train Batch: 1/15 (7%)\tLoss: 1.796497\tAcc: 8/40 (20%)\nINFO:root:Rank: 04   Train Batch: 1/15 (7%)\tLoss: 1.791924\tAcc: 6/40 (15%)\nINFO:root:Rank: 08   Train Batch: 1/15 (7%)\tLoss: 1.803177\tAcc: 8/40 (20%)\nINFO:root:Rank: 07   Train Batch: 2/15 (13%)\tLoss: 1.779206\tAcc: 6/40 (15%)\nINFO:root:Rank: 10   Train Batch: 2/15 (13%)\tLoss: 1.799015\tAcc: 3/40 (8%)\nINFO:root:Rank: 04   Train Batch: 2/15 (13%)\tLoss: 1.791208\tAcc: 6/40 (15%)\nINFO:root:Rank: 01   Train Batch: 2/15 (13%)\tLoss: 1.794070\tAcc: 5/40 (12%)\nINFO:root:Rank: 11   Train Batch: 2/15 (13%)\tLoss: 1.800308\tAcc: 5/40 (12%)\nINFO:root:Rank: 09   Train Batch: 2/15 (13%)\tLoss: 1.774449\tAcc: 10/40 (25%)\nINFO:root:Rank: 08   Train Batch: 2/15 (13%)\tLoss: 1.784211\tAcc: 5/40 (12%)\nINFO:root:Rank: 05   Train Batch: 2/15 (13%)\tLoss: 1.801611\tAcc: 6/40 (15%)\nINFO:root:Rank: 06   Train Batch: 2/15 (13%)\tLoss: 1.784490\tAcc: 7/40 (18%)\nINFO:root:Rank: 03   Train Batch: 2/15 (13%)\tLoss: 1.796935\tAcc: 8/40 (20%)\nINFO:root:Rank: 00   Train Batch: 2/15 (13%)\tLoss: 1.800625\tAcc: 5/40 (12%)\nINFO:root:Rank: 02   Train Batch: 2/15 (13%)\tLoss: 1.791232\tAcc: 5/40 (12%)\nINFO:root:Rank: 09   Train Batch: 3/15 (20%)\tLoss: 1.788617\tAcc: 9/40 (22%)\nINFO:root:Rank: 08   Train Batch: 3/15 (20%)\tLoss: 1.778935\tAcc: 7/40 (18%)\nINFO:root:Rank: 01   Train Batch: 3/15 (20%)\tLoss: 1.796351\tAcc: 5/40 (12%)\nINFO:root:Rank: 10   Train Batch: 3/15 (20%)\tLoss: 1.784475\tAcc: 6/40 (15%)\nINFO:root:Rank: 06   Train Batch: 3/15 (20%)\tLoss: 1.779833\tAcc: 9/40 (22%)\nINFO:root:Rank: 02   Train Batch: 3/15 (20%)\tLoss: 1.784643\tAcc: 7/40 (18%)\nINFO:root:Rank: 11   Train Batch: 3/15 (20%)\tLoss: 1.781636\tAcc: 8/40 (20%)\nINFO:root:Rank: 03   Train Batch: 3/15 (20%)\tLoss: 1.795674\tAcc: 7/40 (18%)\nINFO:root:Rank: 05   Train Batch: 3/15 (20%)\tLoss: 1.797429\tAcc: 4/40 (10%)\nINFO:root:Rank: 04   Train Batch: 3/15 (20%)\tLoss: 1.781276\tAcc: 10/40 (25%)\nINFO:root:Rank: 07   Train Batch: 3/15 (20%)\tLoss: 1.796249\tAcc: 5/40 (12%)\nINFO:root:Rank: 00   Train Batch: 3/15 (20%)\tLoss: 1.776458\tAcc: 12/40 (30%)\nINFO:root:Rank: 11   Train Batch: 4/15 (27%)\tLoss: 1.764290\tAcc: 14/40 (35%)\nINFO:root:Rank: 09   Train Batch: 4/15 (27%)\tLoss: 1.784835\tAcc: 10/40 (25%)\nINFO:root:Rank: 04   Train Batch: 4/15 (27%)\tLoss: 1.800322\tAcc: 2/40 (5%)\nINFO:root:Rank: 10   Train Batch: 4/15 (27%)\tLoss: 1.792035\tAcc: 4/40 (10%)\nINFO:root:Rank: 03   Train Batch: 4/15 (27%)\tLoss: 1.782248\tAcc: 8/40 (20%)\nINFO:root:Rank: 06   Train Batch: 4/15 (27%)\tLoss: 1.773340\tAcc: 9/40 (22%)\nINFO:root:Rank: 05   Train Batch: 4/15 (27%)\tLoss: 1.787031\tAcc: 5/40 (12%)\nINFO:root:Rank: 07   Train Batch: 4/15 (27%)\tLoss: 1.783063\tAcc: 6/40 (15%)\nINFO:root:Rank: 01   Train Batch: 4/15 (27%)\tLoss: 1.781661\tAcc: 4/40 (10%)\nINFO:root:Rank: 02   Train Batch: 4/15 (27%)\tLoss: 1.783888\tAcc: 4/40 (10%)\nINFO:root:Rank: 08   Train Batch: 4/15 (27%)\tLoss: 1.767022\tAcc: 10/40 (25%)\nINFO:root:Rank: 00   Train Batch: 4/15 (27%)\tLoss: 1.784108\tAcc: 5/40 (12%)\nINFO:root:Rank: 02   Train Batch: 5/15 (33%)\tLoss: 1.789005\tAcc: 9/40 (22%)\nINFO:root:Rank: 10   Train Batch: 5/15 (33%)\tLoss: 1.785323\tAcc: 11/40 (28%)\nINFO:root:Rank: 09   Train Batch: 5/15 (33%)\tLoss: 1.794169\tAcc: 5/40 (12%)\nINFO:root:Rank: 07   Train Batch: 5/15 (33%)\tLoss: 1.804270\tAcc: 5/40 (12%)\nINFO:root:Rank: 11   Train Batch: 5/15 (33%)\tLoss: 1.757488\tAcc: 12/40 (30%)\nINFO:root:Rank: 01   Train Batch: 5/15 (33%)\tLoss: 1.776353\tAcc: 8/40 (20%)\nINFO:root:Rank: 04   Train Batch: 5/15 (33%)\tLoss: 1.795012\tAcc: 8/40 (20%)\nINFO:root:Rank: 03   Train Batch: 5/15 (33%)\tLoss: 1.773007\tAcc: 11/40 (28%)\nINFO:root:Rank: 08   Train Batch: 5/15 (33%)\tLoss: 1.766987\tAcc: 14/40 (35%)\nINFO:root:Rank: 05   Train Batch: 5/15 (33%)\tLoss: 1.784829\tAcc: 7/40 (18%)\nINFO:root:Rank: 06   Train Batch: 5/15 (33%)\tLoss: 1.794024\tAcc: 6/40 (15%)\nINFO:root:Rank: 00   Train Batch: 5/15 (33%)\tLoss: 1.781172\tAcc: 9/40 (22%)\nINFO:root:Rank: 11   Train Batch: 6/15 (40%)\tLoss: 1.771604\tAcc: 13/40 (32%)\nINFO:root:Rank: 07   Train Batch: 6/15 (40%)\tLoss: 1.773443\tAcc: 13/40 (32%)\nINFO:root:Rank: 10   Train Batch: 6/15 (40%)\tLoss: 1.759716\tAcc: 17/40 (42%)\nINFO:root:Rank: 02   Train Batch: 6/15 (40%)\tLoss: 1.807108\tAcc: 5/40 (12%)\nINFO:root:Rank: 06   Train Batch: 6/15 (40%)\tLoss: 1.763002\tAcc: 16/40 (40%)\nINFO:root:Rank: 04   Train Batch: 6/15 (40%)\tLoss: 1.761390\tAcc: 18/40 (45%)\nINFO:root:Rank: 08   Train Batch: 6/15 (40%)\tLoss: 1.777434\tAcc: 15/40 (38%)\nINFO:root:Rank: 05   Train Batch: 6/15 (40%)\tLoss: 1.780948\tAcc: 11/40 (28%)\nINFO:root:Rank: 09   Train Batch: 6/15 (40%)\tLoss: 1.788426\tAcc: 14/40 (35%)\nINFO:root:Rank: 01   Train Batch: 6/15 (40%)\tLoss: 1.782206\tAcc: 10/40 (25%)\nINFO:root:Rank: 03   Train Batch: 6/15 (40%)\tLoss: 1.797366\tAcc: 12/40 (30%)\nINFO:root:Rank: 00   Train Batch: 6/15 (40%)\tLoss: 1.797990\tAcc: 10/40 (25%)\nINFO:root:Rank: 02   Train Batch: 7/15 (47%)\tLoss: 1.786044\tAcc: 9/40 (22%)\nINFO:root:Rank: 00   Train Batch: 7/15 (47%)\tLoss: 1.769178\tAcc: 13/40 (32%)\nINFO:root:Rank: 08   Train Batch: 7/15 (47%)\tLoss: 1.756758\tAcc: 15/40 (38%)\nINFO:root:Rank: 10   Train Batch: 7/15 (47%)\tLoss: 1.749228\tAcc: 17/40 (42%)\nINFO:root:Rank: 04   Train Batch: 7/15 (47%)\tLoss: 1.751123\tAcc: 17/40 (42%)\nINFO:root:Rank: 01   Train Batch: 7/15 (47%)\tLoss: 1.760255\tAcc: 16/40 (40%)\nINFO:root:Rank: 09   Train Batch: 7/15 (47%)\tLoss: 1.757135\tAcc: 15/40 (38%)\nINFO:root:Rank: 11   Train Batch: 7/15 (47%)\tLoss: 1.758928\tAcc: 15/40 (38%)\nINFO:root:Rank: 07   Train Batch: 7/15 (47%)\tLoss: 1.756216\tAcc: 17/40 (42%)\nINFO:root:Rank: 03   Train Batch: 7/15 (47%)\tLoss: 1.765203\tAcc: 17/40 (42%)\nINFO:root:Rank: 06   Train Batch: 7/15 (47%)\tLoss: 1.781237\tAcc: 14/40 (35%)\nINFO:root:Rank: 05   Train Batch: 7/15 (47%)\tLoss: 1.782549\tAcc: 13/40 (32%)\nINFO:root:Rank: 02   Train Batch: 8/15 (53%)\tLoss: 1.762403\tAcc: 14/40 (35%)\nINFO:root:Rank: 04   Train Batch: 8/15 (53%)\tLoss: 1.778528\tAcc: 10/40 (25%)\nINFO:root:Rank: 11   Train Batch: 8/15 (53%)\tLoss: 1.734538\tAcc: 17/40 (42%)\nINFO:root:Rank: 10   Train Batch: 8/15 (53%)\tLoss: 1.766785\tAcc: 13/40 (32%)\nINFO:root:Rank: 05   Train Batch: 8/15 (53%)\tLoss: 1.758239\tAcc: 15/40 (38%)\nINFO:root:Rank: 06   Train Batch: 8/15 (53%)\tLoss: 1.741822\tAcc: 18/40 (45%)\nINFO:root:Rank: 08   Train Batch: 8/15 (53%)\tLoss: 1.748493\tAcc: 16/40 (40%)\nINFO:root:Rank: 09   Train Batch: 8/15 (53%)\tLoss: 1.775790\tAcc: 11/40 (28%)\nINFO:root:Rank: 07   Train Batch: 8/15 (53%)\tLoss: 1.762384\tAcc: 13/40 (32%)\nINFO:root:Rank: 03   Train Batch: 8/15 (53%)\tLoss: 1.775038\tAcc: 15/40 (38%)\nINFO:root:Rank: 01   Train Batch: 8/15 (53%)\tLoss: 1.757513\tAcc: 14/40 (35%)\nINFO:root:Rank: 00   Train Batch: 8/15 (53%)\tLoss: 1.788602\tAcc: 9/40 (22%)\nINFO:root:Rank: 10   Train Batch: 9/15 (60%)\tLoss: 1.751347\tAcc: 13/40 (32%)\nINFO:root:Rank: 04   Train Batch: 9/15 (60%)\tLoss: 1.782029\tAcc: 11/40 (28%)\nINFO:root:Rank: 11   Train Batch: 9/15 (60%)\tLoss: 1.743669\tAcc: 12/40 (30%)\nINFO:root:Rank: 06   Train Batch: 9/15 (60%)\tLoss: 1.745315\tAcc: 16/40 (40%)\nINFO:root:Rank: 00   Train Batch: 9/15 (60%)\tLoss: 1.767559\tAcc: 14/40 (35%)\nINFO:root:Rank: 05   Train Batch: 9/15 (60%)\tLoss: 1.777621\tAcc: 8/40 (20%)\nINFO:root:Rank: 01   Train Batch: 9/15 (60%)\tLoss: 1.750196\tAcc: 13/40 (32%)\nINFO:root:Rank: 09   Train Batch: 9/15 (60%)\tLoss: 1.750072\tAcc: 11/40 (28%)\nINFO:root:Rank: 02   Train Batch: 9/15 (60%)\tLoss: 1.773520\tAcc: 9/40 (22%)\nINFO:root:Rank: 03   Train Batch: 9/15 (60%)\tLoss: 1.739022\tAcc: 18/40 (45%)\nINFO:root:Rank: 08   Train Batch: 9/15 (60%)\tLoss: 1.745416\tAcc: 10/40 (25%)\nINFO:root:Rank: 07   Train Batch: 9/15 (60%)\tLoss: 1.745427\tAcc: 13/40 (32%)\nINFO:root:Rank: 10   Train Batch: 10/15 (67%)\tLoss: 1.749563\tAcc: 11/40 (28%)\nINFO:root:Rank: 00   Train Batch: 10/15 (67%)\tLoss: 1.752174\tAcc: 13/40 (32%)\nINFO:root:Rank: 08   Train Batch: 10/15 (67%)\tLoss: 1.755953\tAcc: 8/40 (20%)\nINFO:root:Rank: 01   Train Batch: 10/15 (67%)\tLoss: 1.747152\tAcc: 8/40 (20%)\nINFO:root:Rank: 09   Train Batch: 10/15 (67%)\tLoss: 1.730910\tAcc: 13/40 (32%)\nINFO:root:Rank: 02   Train Batch: 10/15 (67%)\tLoss: 1.751426\tAcc: 10/40 (25%)\nINFO:root:Rank: 04   Train Batch: 10/15 (67%)\tLoss: 1.726690\tAcc: 13/40 (32%)\nINFO:root:Rank: 06   Train Batch: 10/15 (67%)\tLoss: 1.759995\tAcc: 8/40 (20%)\nINFO:root:Rank: 05   Train Batch: 10/15 (67%)\tLoss: 1.740394\tAcc: 14/40 (35%)\nINFO:root:Rank: 07   Train Batch: 10/15 (67%)\tLoss: 1.742392\tAcc: 9/40 (22%)\nINFO:root:Rank: 11   Train Batch: 10/15 (67%)\tLoss: 1.749862\tAcc: 12/40 (30%)\nINFO:root:Rank: 03   Train Batch: 10/15 (67%)\tLoss: 1.748655\tAcc: 13/40 (32%)\nINFO:root:Rank: 09   Train Batch: 11/15 (73%)\tLoss: 1.735351\tAcc: 11/40 (28%)\nINFO:root:Rank: 10   Train Batch: 11/15 (73%)\tLoss: 1.698152\tAcc: 15/40 (38%)\nINFO:root:Rank: 05   Train Batch: 11/15 (73%)\tLoss: 1.740143\tAcc: 11/40 (28%)\nINFO:root:Rank: 08   Train Batch: 11/15 (73%)\tLoss: 1.714617\tAcc: 15/40 (38%)\nINFO:root:Rank: 00   Train Batch: 11/15 (73%)\tLoss: 1.746730\tAcc: 14/40 (35%)\nINFO:root:Rank: 03   Train Batch: 11/15 (73%)\tLoss: 1.724076\tAcc: 16/40 (40%)\nINFO:root:Rank: 06   Train Batch: 11/15 (73%)\tLoss: 1.739007\tAcc: 10/40 (25%)\nINFO:root:Rank: 04   Train Batch: 11/15 (73%)\tLoss: 1.695564\tAcc: 16/40 (40%)\nINFO:root:Rank: 11   Train Batch: 11/15 (73%)\tLoss: 1.709522\tAcc: 13/40 (32%)\nINFO:root:Rank: 07   Train Batch: 11/15 (73%)\tLoss: 1.767846\tAcc: 12/40 (30%)\nINFO:root:Rank: 01   Train Batch: 11/15 (73%)\tLoss: 1.766491\tAcc: 8/40 (20%)\nINFO:root:Rank: 02   Train Batch: 11/15 (73%)\tLoss: 1.752898\tAcc: 10/40 (25%)\nINFO:root:Rank: 10   Train Batch: 12/15 (80%)\tLoss: 1.736638\tAcc: 12/40 (30%)\nINFO:root:Rank: 05   Train Batch: 12/15 (80%)\tLoss: 1.709894\tAcc: 14/40 (35%)\nINFO:root:Rank: 11   Train Batch: 12/15 (80%)\tLoss: 1.740726\tAcc: 13/40 (32%)\nINFO:root:Rank: 09   Train Batch: 12/15 (80%)\tLoss: 1.712949\tAcc: 9/40 (22%)\nINFO:root:Rank: 08   Train Batch: 12/15 (80%)\tLoss: 1.699059\tAcc: 16/40 (40%)\nINFO:root:Rank: 07   Train Batch: 12/15 (80%)\tLoss: 1.694872\tAcc: 19/40 (48%)\nINFO:root:Rank: 02   Train Batch: 12/15 (80%)\tLoss: 1.769886\tAcc: 11/40 (28%)\nINFO:root:Rank: 03   Train Batch: 12/15 (80%)\tLoss: 1.699079\tAcc: 17/40 (42%)\nINFO:root:Rank: 06   Train Batch: 12/15 (80%)\tLoss: 1.742122\tAcc: 14/40 (35%)\nINFO:root:Rank: 04   Train Batch: 12/15 (80%)\tLoss: 1.693290\tAcc: 16/40 (40%)\nINFO:root:Rank: 00   Train Batch: 12/15 (80%)\tLoss: 1.709249\tAcc: 14/40 (35%)\nINFO:root:Rank: 01   Train Batch: 12/15 (80%)\tLoss: 1.694813\tAcc: 12/40 (30%)\nINFO:root:Rank: 10   Train Batch: 13/15 (87%)\tLoss: 1.675880\tAcc: 18/40 (45%)\nINFO:root:Rank: 05   Train Batch: 13/15 (87%)\tLoss: 1.716464\tAcc: 13/40 (32%)\nINFO:root:Rank: 09   Train Batch: 13/15 (87%)\tLoss: 1.709507\tAcc: 17/40 (42%)\nINFO:root:Rank: 08   Train Batch: 13/15 (87%)\tLoss: 1.720785\tAcc: 9/40 (22%)\nINFO:root:Rank: 11   Train Batch: 13/15 (87%)\tLoss: 1.728180\tAcc: 10/40 (25%)\nINFO:root:Rank: 07   Train Batch: 13/15 (87%)\tLoss: 1.660105\tAcc: 18/40 (45%)\nINFO:root:Rank: 04   Train Batch: 13/15 (87%)\tLoss: 1.657376\tAcc: 20/40 (50%)\nINFO:root:Rank: 01   Train Batch: 13/15 (87%)\tLoss: 1.657071\tAcc: 16/40 (40%)\nINFO:root:Rank: 02   Train Batch: 13/15 (87%)\tLoss: 1.716509\tAcc: 14/40 (35%)\nINFO:root:Rank: 03   Train Batch: 13/15 (87%)\tLoss: 1.721277\tAcc: 15/40 (38%)\nINFO:root:Rank: 06   Train Batch: 13/15 (87%)\tLoss: 1.683857\tAcc: 15/40 (38%)\nINFO:root:Rank: 00   Train Batch: 13/15 (87%)\tLoss: 1.722178\tAcc: 13/40 (32%)\nINFO:root:Rank: 10   Train Batch: 14/15 (93%)\tLoss: 1.671110\tAcc: 20/40 (50%)\nINFO:root:Rank: 05   Train Batch: 14/15 (93%)\tLoss: 1.661925\tAcc: 13/40 (32%)\nINFO:root:Rank: 04   Train Batch: 14/15 (93%)\tLoss: 1.653454\tAcc: 17/40 (42%)\nINFO:root:Rank: 08   Train Batch: 14/15 (93%)\tLoss: 1.666236\tAcc: 13/40 (32%)\nINFO:root:Rank: 09   Train Batch: 14/15 (93%)\tLoss: 1.656380\tAcc: 20/40 (50%)\nINFO:root:Rank: 07   Train Batch: 14/15 (93%)\tLoss: 1.715732\tAcc: 14/40 (35%)\nINFO:root:Rank: 06   Train Batch: 14/15 (93%)\tLoss: 1.655311\tAcc: 11/40 (28%)\nINFO:root:Rank: 11   Train Batch: 14/15 (93%)\tLoss: 1.639106\tAcc: 14/40 (35%)\nINFO:root:Rank: 00   Train Batch: 14/15 (93%)\tLoss: 1.701320\tAcc: 14/40 (35%)\nINFO:root:Rank: 02   Train Batch: 14/15 (93%)\tLoss: 1.693185\tAcc: 10/40 (25%)\nINFO:root:Rank: 03   Train Batch: 14/15 (93%)\tLoss: 1.634934\tAcc: 21/40 (52%)\nINFO:root:Rank: 01   Train Batch: 14/15 (93%)\tLoss: 1.696226\tAcc: 19/40 (48%)\nINFO:root:Rank: 10   Train Batch: 15/15 (100%)\tLoss: 1.682908\tAcc: 4/16 (25%)\nINFO:root:Rank: 11   Train Batch: 15/15 (100%)\tLoss: 1.665223\tAcc: 3/16 (19%)\nINFO:root:Rank: 08   Train Batch: 15/15 (100%)\tLoss: 1.649004\tAcc: 5/16 (31%)\nINFO:root:Rank: 09   Train Batch: 15/15 (100%)\tLoss: 1.718976\tAcc: 3/16 (19%)\nINFO:root:Rank: 03   Train Batch: 15/15 (100%)\tLoss: 1.594221\tAcc: 7/16 (44%)\nINFO:root:Rank: 02   Train Batch: 15/15 (100%)\tLoss: 1.545304\tAcc: 7/16 (44%)\nINFO:root:Rank: 04   Train Batch: 15/15 (100%)\tLoss: 1.568134\tAcc: 7/16 (44%)\nINFO:root:Rank: 07   Train Batch: 15/15 (100%)\tLoss: 1.562436\tAcc: 9/16 (56%)\nINFO:root:Rank: 01   Train Batch: 15/15 (100%)\tLoss: 1.633612\tAcc: 6/16 (38%)\nINFO:root:Rank: 06   Train Batch: 15/15 (100%)\tLoss: 1.668455\tAcc: 7/16 (44%)\nINFO:root:Rank: 05   Train Batch: 15/15 (100%)\tLoss: 1.516605\tAcc: 9/16 (56%)\nINFO:root:Rank: 00   Train Batch: 15/15 (100%)\tLoss: 1.591646\tAcc: 7/16 (44%)\nINFO:root:10: Memory Usage: 154.703125, Training Duration: 24.125665479998133\nINFO:root:3: Memory Usage: 154.1328125, Training Duration: 24.145731623000756\nINFO:root:11: Memory Usage: 154.875, Training Duration: 24.157068024000182\nINFO:root:9: Memory Usage: 154.39453125, Training Duration: 24.14704205900125\nINFO:root:2: Memory Usage: 154.640625, Training Duration: 24.151371799998742\nINFO:root:4: Memory Usage: 154.33984375, Training Duration: 24.14724926800045\nINFO:root:8: Memory Usage: 154.81640625, Training Duration: 24.14726857700225\nINFO:root:6: Memory Usage: 153.7265625, Training Duration: 24.148994824998226\nINFO:root:7: Memory Usage: 154.31640625, Training Duration: 24.147935949000384\nINFO:root:5: Memory Usage: 154.859375, Training Duration: 24.149044280999078\nINFO:root:0: Memory Usage: 154.76171875, Training Duration: 24.160450940002193\nINFO:root:1: Memory Usage: 154.078125, Training Duration: 24.15253427800053\n", "config": {"trainer": "distributed", "hosts": 12, "slots": 1, "parameters": {"--batch-size": 480, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "~/susml/jakob_torben/bin/horovodrun -np 8 --hosts 10.42.0.50:1,10.42.0.29:1,10.42.0.105:1,10.42.0.56:1,10.42.0.180:1,10.42.0.235:1,10.42.0.244:1,10.42.0.239:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 960 --epochs 1 --seed 123456789 --no-validation  horovod", "stdout": "", "stderr": "[1,4]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,4]<stderr>:INFO:root:Training set of size 6912\n[1,7]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,7]<stderr>:INFO:root:Training set of size 6912\n[1,6]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,6]<stderr>:INFO:root:Training set of size 6912\n[1,5]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,5]<stderr>:INFO:root:Training set of size 6912\n[1,3]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,3]<stderr>:INFO:root:Training set of size 6912\n[1,1]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,1]<stderr>:INFO:root:Training set of size 6912\n[1,2]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,2]<stderr>:INFO:root:Training set of size 6912\n[1,0]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,0]<stderr>:INFO:root:Training set of size 6912\n[1,3]<stderr>:INFO:root:Training model for 1 epochs...\n[1,4]<stderr>:INFO:root:Training model for 1 epochs...\n[1,5]<stderr>:INFO:root:Training model for 1 epochs...\n[1,7]<stderr>:INFO:root:Training model for 1 epochs...\n[1,6]<stderr>:INFO:root:Training model for 1 epochs...\n[1,0]<stderr>:INFO:root:Training model for 1 epochs...\n[1,2]<stderr>:INFO:root:Training model for 1 epochs...\n[1,1]<stderr>:INFO:root:Training model for 1 epochs...\n[1,5]<stderr>:INFO:root:Rank: 05   Start Epoch 0\n[1,7]<stderr>:INFO:root:Rank: 07   Start Epoch 0\n[1,3]<stderr>:INFO:root:Rank: 03   Start Epoch 0\n[1,6]<stderr>:INFO:root:Rank: 06   Start Epoch 0\n[1,4]<stderr>:INFO:root:Rank: 04   Start Epoch 0\n[1,0]<stderr>:INFO:root:Rank: 00   Start Epoch 0\n[1,1]<stderr>:INFO:root:Rank: 01   Start Epoch 0\n[1,2]<stderr>:INFO:root:Rank: 02   Start Epoch 0\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 1/8 (12%)\tLoss: 1.788679\tAcc: 22/120 (18%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 1/8 (12%)\tLoss: 1.795470\tAcc: 20/120 (17%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 1/8 (12%)\tLoss: 1.791984\tAcc: 26/120 (22%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 1/8 (12%)\tLoss: 1.800577\tAcc: 17/120 (14%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 1/8 (12%)\tLoss: 1.793724\tAcc: 25/120 (21%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 1/8 (12%)\tLoss: 1.808466\tAcc: 15/120 (12%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 1/8 (12%)\tLoss: 1.794739\tAcc: 14/120 (12%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 1/8 (12%)\tLoss: 1.792831\tAcc: 18/120 (15%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 2/8 (25%)\tLoss: 1.793408\tAcc: 23/120 (19%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 2/8 (25%)\tLoss: 1.781925\tAcc: 25/120 (21%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 2/8 (25%)\tLoss: 1.786330\tAcc: 20/120 (17%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 2/8 (25%)\tLoss: 1.802182\tAcc: 17/120 (14%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 2/8 (25%)\tLoss: 1.785046\tAcc: 24/120 (20%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 2/8 (25%)\tLoss: 1.793234\tAcc: 19/120 (16%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 2/8 (25%)\tLoss: 1.788694\tAcc: 20/120 (17%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 2/8 (25%)\tLoss: 1.785688\tAcc: 22/120 (18%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 3/8 (38%)\tLoss: 1.778589\tAcc: 21/120 (18%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 3/8 (38%)\tLoss: 1.796445\tAcc: 15/120 (12%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 3/8 (38%)\tLoss: 1.789871\tAcc: 18/120 (15%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 3/8 (38%)\tLoss: 1.787521\tAcc: 18/120 (15%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 3/8 (38%)\tLoss: 1.788605\tAcc: 20/120 (17%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 3/8 (38%)\tLoss: 1.789099\tAcc: 21/120 (18%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 3/8 (38%)\tLoss: 1.797088\tAcc: 22/120 (18%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 3/8 (38%)\tLoss: 1.790712\tAcc: 15/120 (12%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 4/8 (50%)\tLoss: 1.781974\tAcc: 22/120 (18%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 4/8 (50%)\tLoss: 1.784368\tAcc: 18/120 (15%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 4/8 (50%)\tLoss: 1.783865\tAcc: 13/120 (11%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 4/8 (50%)\tLoss: 1.782258\tAcc: 18/120 (15%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 4/8 (50%)\tLoss: 1.768727\tAcc: 24/120 (20%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 4/8 (50%)\tLoss: 1.778171\tAcc: 29/120 (24%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 4/8 (50%)\tLoss: 1.781264\tAcc: 19/120 (16%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 4/8 (50%)\tLoss: 1.780070\tAcc: 21/120 (18%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 5/8 (62%)\tLoss: 1.779757\tAcc: 41/120 (34%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 5/8 (62%)\tLoss: 1.767501\tAcc: 52/120 (43%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 5/8 (62%)\tLoss: 1.787518\tAcc: 34/120 (28%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 5/8 (62%)\tLoss: 1.773627\tAcc: 40/120 (33%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 5/8 (62%)\tLoss: 1.777368\tAcc: 47/120 (39%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 5/8 (62%)\tLoss: 1.787153\tAcc: 36/120 (30%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 5/8 (62%)\tLoss: 1.774058\tAcc: 41/120 (34%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 5/8 (62%)\tLoss: 1.779114\tAcc: 33/120 (28%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 6/8 (75%)\tLoss: 1.764130\tAcc: 45/120 (38%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 6/8 (75%)\tLoss: 1.758269\tAcc: 49/120 (41%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 6/8 (75%)\tLoss: 1.778531\tAcc: 39/120 (32%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 6/8 (75%)\tLoss: 1.775013\tAcc: 40/120 (33%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 6/8 (75%)\tLoss: 1.772359\tAcc: 36/120 (30%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 6/8 (75%)\tLoss: 1.767602\tAcc: 47/120 (39%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 6/8 (75%)\tLoss: 1.777706\tAcc: 37/120 (31%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 6/8 (75%)\tLoss: 1.779403\tAcc: 36/120 (30%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 7/8 (88%)\tLoss: 1.765103\tAcc: 38/120 (32%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 7/8 (88%)\tLoss: 1.773928\tAcc: 29/120 (24%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 7/8 (88%)\tLoss: 1.765520\tAcc: 27/120 (22%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 7/8 (88%)\tLoss: 1.768509\tAcc: 34/120 (28%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 7/8 (88%)\tLoss: 1.766192\tAcc: 31/120 (26%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 7/8 (88%)\tLoss: 1.765838\tAcc: 34/120 (28%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 7/8 (88%)\tLoss: 1.761371\tAcc: 33/120 (28%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 7/8 (88%)\tLoss: 1.777536\tAcc: 28/120 (23%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 8/8 (100%)\tLoss: 1.773650\tAcc: 5/24 (21%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 8/8 (100%)\tLoss: 1.731862\tAcc: 7/24 (29%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 8/8 (100%)\tLoss: 1.763532\tAcc: 3/24 (12%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 8/8 (100%)\tLoss: 1.756312\tAcc: 9/24 (38%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 8/8 (100%)\tLoss: 1.741724\tAcc: 9/24 (38%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 8/8 (100%)\tLoss: 1.770036\tAcc: 6/24 (25%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 8/8 (100%)\tLoss: 1.764840\tAcc: 6/24 (25%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 8/8 (100%)\tLoss: 1.764930\tAcc: 5/24 (21%)\n[1,0]<stderr>:INFO:root:0: Memory Usage: 194.640625, Training Duration: 56.608738815000834\n[1,6]<stderr>:INFO:root:6: Memory Usage: 195.73828125, Training Duration: 56.603033030001825\n[1,4]<stderr>:INFO:root:4: Memory Usage: 196.71875, Training Duration: 56.60365882399856\n[1,5]<stderr>:INFO:root:5: Memory Usage: 196.81640625, Training Duration: 56.62030186899938\n[1,1]<stderr>:INFO:root:1: Memory Usage: 195.1015625, Training Duration: 56.625569250998524\n[1,7]<stderr>:INFO:root:7: Memory Usage: 196.24609375, Training Duration: 56.62603118300103\n[1,3]<stderr>:INFO:root:3: Memory Usage: 194.28125, Training Duration: 56.62579634099893\n[1,2]<stderr>:INFO:root:2: Memory Usage: 196.2109375, Training Duration: 56.62571278800169\n", "config": {"trainer": "horovod", "hosts": 8, "slots": 1, "parameters": {"--batch-size": 960, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "~/susml/jakob_torben/bin/horovodrun -np 2 --hosts 10.42.0.50:1,10.42.0.29:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 1440 --epochs 1 --seed 123456789 --no-validation  horovod", "stdout": "", "stderr": "[1,1]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,1]<stderr>:INFO:root:Training set of size 6912\n[1,0]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,0]<stderr>:INFO:root:Training set of size 6912\n[1,0]<stderr>:INFO:root:Training model for 1 epochs...\n[1,1]<stderr>:INFO:root:Training model for 1 epochs...\n[1,0]<stderr>:INFO:root:Rank: 00   Start Epoch 0\n[1,1]<stderr>:INFO:root:Rank: 01   Start Epoch 0\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 1/5 (20%)\tLoss: 1.798722\tAcc: 124/720 (17%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 1/5 (20%)\tLoss: 1.790705\tAcc: 122/720 (17%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 2/5 (40%)\tLoss: 1.790506\tAcc: 119/720 (17%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 2/5 (40%)\tLoss: 1.793001\tAcc: 112/720 (16%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 3/5 (60%)\tLoss: 1.783072\tAcc: 126/720 (18%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 3/5 (60%)\tLoss: 1.787134\tAcc: 110/720 (15%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 4/5 (80%)\tLoss: 1.780844\tAcc: 123/720 (17%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 4/5 (80%)\tLoss: 1.780652\tAcc: 136/720 (19%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 5/5 (100%)\tLoss: 1.777994\tAcc: 196/576 (34%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 5/5 (100%)\tLoss: 1.776130\tAcc: 201/576 (35%)\n[1,1]<stderr>:INFO:root:1: Memory Usage: 491.2890625, Training Duration: 82.31903941600103\n[1,0]<stderr>:INFO:root:0: Memory Usage: 491.14453125, Training Duration: 82.32738637700095\n", "config": {"trainer": "horovod", "hosts": 2, "slots": 1, "parameters": {"--batch-size": 1440, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "~/susml/jakob_torben/bin/horovodrun -np 2 --hosts 10.42.0.50:1,10.42.0.29:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 960 --epochs 1 --seed 123456789 --no-validation  horovod", "stdout": "", "stderr": "[1,0]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,0]<stderr>:INFO:root:Training set of size 6912\n[1,1]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,1]<stderr>:INFO:root:Training set of size 6912\n[1,1]<stderr>:INFO:root:Training model for 1 epochs...\n[1,0]<stderr>:INFO:root:Training model for 1 epochs...\n[1,1]<stderr>:INFO:root:Rank: 01   Start Epoch 0\n[1,0]<stderr>:INFO:root:Rank: 00   Start Epoch 0\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 1/8 (12%)\tLoss: 1.797411\tAcc: 86/480 (18%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 1/8 (12%)\tLoss: 1.794207\tAcc: 71/480 (15%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 2/8 (25%)\tLoss: 1.791553\tAcc: 85/480 (18%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 2/8 (25%)\tLoss: 1.787575\tAcc: 85/480 (18%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 3/8 (38%)\tLoss: 1.789301\tAcc: 72/480 (15%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 3/8 (38%)\tLoss: 1.790183\tAcc: 78/480 (16%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 4/8 (50%)\tLoss: 1.778382\tAcc: 89/480 (19%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 4/8 (50%)\tLoss: 1.781793\tAcc: 75/480 (16%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 5/8 (62%)\tLoss: 1.775585\tAcc: 169/480 (35%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 5/8 (62%)\tLoss: 1.780939\tAcc: 155/480 (32%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 6/8 (75%)\tLoss: 1.770746\tAcc: 169/480 (35%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 6/8 (75%)\tLoss: 1.772507\tAcc: 160/480 (33%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 7/8 (88%)\tLoss: 1.768617\tAcc: 128/480 (27%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 7/8 (88%)\tLoss: 1.767383\tAcc: 126/480 (26%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 8/8 (100%)\tLoss: 1.756339\tAcc: 24/96 (25%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 8/8 (100%)\tLoss: 1.760383\tAcc: 26/96 (27%)\n[1,0]<stderr>:INFO:root:0: Memory Usage: 382.5078125, Training Duration: 95.7695883760025\n[1,1]<stderr>:INFO:root:1: Memory Usage: 374.05078125, Training Duration: 95.77478998899824\n", "config": {"trainer": "horovod", "hosts": 2, "slots": 1, "parameters": {"--batch-size": 960, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "mpirun --bind-to none --map-by slot -np 2 --host 10.42.0.50:1,10.42.0.29:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 480 --epochs 1 --seed 123456789 --no-validation  distributed", "stdout": "", "stderr": "INFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Rank: 01   Start Epoch 0\nINFO:root:Rank: 00   Start Epoch 0\nINFO:root:Rank: 01   Train Batch: 1/15 (7%)\tLoss: 1.799708\tAcc: 46/240 (19%)\nINFO:root:Rank: 00   Train Batch: 1/15 (7%)\tLoss: 1.793498\tAcc: 40/240 (17%)\nINFO:root:Rank: 01   Train Batch: 2/15 (13%)\tLoss: 1.791096\tAcc: 40/240 (17%)\nINFO:root:Rank: 00   Train Batch: 2/15 (13%)\tLoss: 1.791796\tAcc: 31/240 (13%)\nINFO:root:Rank: 01   Train Batch: 3/15 (20%)\tLoss: 1.792659\tAcc: 38/240 (16%)\nINFO:root:Rank: 00   Train Batch: 3/15 (20%)\tLoss: 1.780936\tAcc: 51/240 (21%)\nINFO:root:Rank: 00   Train Batch: 4/15 (27%)\tLoss: 1.783452\tAcc: 34/240 (14%)\nINFO:root:Rank: 01   Train Batch: 4/15 (27%)\tLoss: 1.780521\tAcc: 47/240 (20%)\nINFO:root:Rank: 01   Train Batch: 5/15 (33%)\tLoss: 1.781686\tAcc: 48/240 (20%)\nINFO:root:Rank: 00   Train Batch: 5/15 (33%)\tLoss: 1.785253\tAcc: 57/240 (24%)\nINFO:root:Rank: 01   Train Batch: 6/15 (40%)\tLoss: 1.782333\tAcc: 73/240 (30%)\nINFO:root:Rank: 00   Train Batch: 6/15 (40%)\tLoss: 1.777773\tAcc: 81/240 (34%)\nINFO:root:Rank: 00   Train Batch: 7/15 (47%)\tLoss: 1.765595\tAcc: 85/240 (35%)\nINFO:root:Rank: 01   Train Batch: 7/15 (47%)\tLoss: 1.763381\tAcc: 93/240 (39%)\nINFO:root:Rank: 01   Train Batch: 8/15 (53%)\tLoss: 1.760583\tAcc: 85/240 (35%)\nINFO:root:Rank: 00   Train Batch: 8/15 (53%)\tLoss: 1.764439\tAcc: 80/240 (33%)\nINFO:root:Rank: 01   Train Batch: 9/15 (60%)\tLoss: 1.751001\tAcc: 75/240 (31%)\nINFO:root:Rank: 00   Train Batch: 9/15 (60%)\tLoss: 1.760864\tAcc: 73/240 (30%)\nINFO:root:Rank: 01   Train Batch: 10/15 (67%)\tLoss: 1.743228\tAcc: 69/240 (29%)\nINFO:root:Rank: 00   Train Batch: 10/15 (67%)\tLoss: 1.749299\tAcc: 63/240 (26%)\nINFO:root:Rank: 01   Train Batch: 11/15 (73%)\tLoss: 1.740571\tAcc: 71/240 (30%)\nINFO:root:Rank: 00   Train Batch: 11/15 (73%)\tLoss: 1.724495\tAcc: 80/240 (33%)\nINFO:root:Rank: 01   Train Batch: 12/15 (80%)\tLoss: 1.708722\tAcc: 84/240 (35%)\nINFO:root:Rank: 00   Train Batch: 12/15 (80%)\tLoss: 1.725041\tAcc: 83/240 (35%)\nINFO:root:Rank: 01   Train Batch: 13/15 (87%)\tLoss: 1.698768\tAcc: 89/240 (37%)\nINFO:root:Rank: 00   Train Batch: 13/15 (87%)\tLoss: 1.696097\tAcc: 89/240 (37%)\nINFO:root:Rank: 00   Train Batch: 14/15 (93%)\tLoss: 1.673435\tAcc: 85/240 (35%)\nINFO:root:Rank: 01   Train Batch: 14/15 (93%)\tLoss: 1.667384\tAcc: 101/240 (42%)\nINFO:root:Rank: 00   Train Batch: 15/15 (100%)\tLoss: 1.617575\tAcc: 37/96 (39%)\nINFO:root:Rank: 01   Train Batch: 15/15 (100%)\tLoss: 1.615178\tAcc: 37/96 (39%)\nINFO:root:0: Memory Usage: 270.97265625, Training Duration: 102.59824587699768\nINFO:root:1: Memory Usage: 269.24609375, Training Duration: 102.60335112799658\n", "config": {"trainer": "distributed", "hosts": 2, "slots": 1, "parameters": {"--batch-size": 480, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "~/susml/jakob_torben/bin/horovodrun -np 1 --hosts 10.42.0.50:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 1440 --epochs 1 --seed 123456789 --no-validation  horovod", "stdout": "", "stderr": "[1,0]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,0]<stderr>:INFO:root:Training set of size 6912\n[1,0]<stderr>:INFO:root:Training model for 1 epochs...\n[1,0]<stderr>:INFO:root:Rank: 00   Start Epoch 0\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 1/5 (20%)\tLoss: 1.794715\tAcc: 246/1440 (17%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 2/5 (40%)\tLoss: 1.791755\tAcc: 231/1440 (16%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 3/5 (60%)\tLoss: 1.785106\tAcc: 236/1440 (16%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 4/5 (80%)\tLoss: 1.780747\tAcc: 259/1440 (18%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 5/5 (100%)\tLoss: 1.777063\tAcc: 397/1152 (34%)\n[1,0]<stderr>:INFO:root:0: Memory Usage: 788.546875, Training Duration: 136.21731369600093\n", "config": {"trainer": "horovod", "hosts": 1, "slots": 1, "parameters": {"--batch-size": 1440, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "mpirun --bind-to none --map-by slot -np 12 --host 10.42.0.50:1,10.42.0.29:1,10.42.0.105:1,10.42.0.56:1,10.42.0.180:1,10.42.0.235:1,10.42.0.244:1,10.42.0.239:1,10.42.0.191:1,10.42.0.41:1,10.42.0.190:1,10.42.0.69:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 1440 --epochs 1 --seed 123456789 --no-validation  distributed", "stdout": "", "stderr": "INFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Rank: 07   Start Epoch 0\nINFO:root:Rank: 10   Start Epoch 0\nINFO:root:Rank: 09   Start Epoch 0\nINFO:root:Rank: 00   Start Epoch 0\nINFO:root:Rank: 11   Start Epoch 0\nINFO:root:Rank: 04   Start Epoch 0\nINFO:root:Rank: 03   Start Epoch 0\nINFO:root:Rank: 06   Start Epoch 0\nINFO:root:Rank: 08   Start Epoch 0\nINFO:root:Rank: 02   Start Epoch 0\nINFO:root:Rank: 05   Start Epoch 0\nINFO:root:Rank: 01   Start Epoch 0\nINFO:root:Rank: 09   Train Batch: 1/5 (20%)\tLoss: 1.795747\tAcc: 24/120 (20%)\nINFO:root:Rank: 11   Train Batch: 1/5 (20%)\tLoss: 1.794687\tAcc: 21/120 (18%)\nINFO:root:Rank: 10   Train Batch: 1/5 (20%)\tLoss: 1.788200\tAcc: 19/120 (16%)\nINFO:root:Rank: 07   Train Batch: 1/5 (20%)\tLoss: 1.789980\tAcc: 21/120 (18%)\nINFO:root:Rank: 04   Train Batch: 1/5 (20%)\tLoss: 1.787725\tAcc: 22/120 (18%)\nINFO:root:Rank: 05   Train Batch: 1/5 (20%)\tLoss: 1.807860\tAcc: 17/120 (14%)\nINFO:root:Rank: 06   Train Batch: 1/5 (20%)\tLoss: 1.780108\tAcc: 26/120 (22%)\nINFO:root:Rank: 03   Train Batch: 1/5 (20%)\tLoss: 1.805652\tAcc: 23/120 (19%)\nINFO:root:Rank: 08   Train Batch: 1/5 (20%)\tLoss: 1.792296\tAcc: 20/120 (17%)\nINFO:root:Rank: 02   Train Batch: 1/5 (20%)\tLoss: 1.803072\tAcc: 13/120 (11%)\nINFO:root:Rank: 01   Train Batch: 1/5 (20%)\tLoss: 1.798410\tAcc: 18/120 (15%)\nINFO:root:Rank: 00   Train Batch: 1/5 (20%)\tLoss: 1.792827\tAcc: 22/120 (18%)\nINFO:root:Rank: 09   Train Batch: 2/5 (40%)\tLoss: 1.792923\tAcc: 22/120 (18%)\nINFO:root:Rank: 10   Train Batch: 2/5 (40%)\tLoss: 1.790001\tAcc: 20/120 (17%)\nINFO:root:Rank: 11   Train Batch: 2/5 (40%)\tLoss: 1.778764\tAcc: 26/120 (22%)\nINFO:root:Rank: 06   Train Batch: 2/5 (40%)\tLoss: 1.787766\tAcc: 22/120 (18%)\nINFO:root:Rank: 01   Train Batch: 2/5 (40%)\tLoss: 1.792401\tAcc: 14/120 (12%)\nINFO:root:Rank: 07   Train Batch: 2/5 (40%)\tLoss: 1.794203\tAcc: 18/120 (15%)\nINFO:root:Rank: 04   Train Batch: 2/5 (40%)\tLoss: 1.794826\tAcc: 16/120 (13%)\nINFO:root:Rank: 05   Train Batch: 2/5 (40%)\tLoss: 1.793685\tAcc: 16/120 (13%)\nINFO:root:Rank: 03   Train Batch: 2/5 (40%)\tLoss: 1.791060\tAcc: 23/120 (19%)\nINFO:root:Rank: 02   Train Batch: 2/5 (40%)\tLoss: 1.809911\tAcc: 10/120 (8%)\nINFO:root:Rank: 08   Train Batch: 2/5 (40%)\tLoss: 1.781578\tAcc: 25/120 (21%)\nINFO:root:Rank: 00   Train Batch: 2/5 (40%)\tLoss: 1.793929\tAcc: 19/120 (16%)\nINFO:root:Rank: 10   Train Batch: 3/5 (60%)\tLoss: 1.783663\tAcc: 19/120 (16%)\nINFO:root:Rank: 08   Train Batch: 3/5 (60%)\tLoss: 1.776277\tAcc: 21/120 (18%)\nINFO:root:Rank: 09   Train Batch: 3/5 (60%)\tLoss: 1.792810\tAcc: 17/120 (14%)\nINFO:root:Rank: 05   Train Batch: 3/5 (60%)\tLoss: 1.784656\tAcc: 25/120 (21%)\nINFO:root:Rank: 00   Train Batch: 3/5 (60%)\tLoss: 1.797802\tAcc: 17/120 (14%)\nINFO:root:Rank: 02   Train Batch: 3/5 (60%)\tLoss: 1.792076\tAcc: 14/120 (12%)\nINFO:root:Rank: 11   Train Batch: 3/5 (60%)\tLoss: 1.776799\tAcc: 18/120 (15%)\nINFO:root:Rank: 03   Train Batch: 3/5 (60%)\tLoss: 1.781271\tAcc: 22/120 (18%)\nINFO:root:Rank: 06   Train Batch: 3/5 (60%)\tLoss: 1.783329\tAcc: 17/120 (14%)\nINFO:root:Rank: 04   Train Batch: 3/5 (60%)\tLoss: 1.789658\tAcc: 22/120 (18%)\nINFO:root:Rank: 01   Train Batch: 3/5 (60%)\tLoss: 1.777147\tAcc: 25/120 (21%)\nINFO:root:Rank: 07   Train Batch: 3/5 (60%)\tLoss: 1.785756\tAcc: 19/120 (16%)\nINFO:root:Rank: 10   Train Batch: 4/5 (80%)\tLoss: 1.784836\tAcc: 17/120 (14%)\nINFO:root:Rank: 11   Train Batch: 4/5 (80%)\tLoss: 1.783836\tAcc: 15/120 (12%)\nINFO:root:Rank: 02   Train Batch: 4/5 (80%)\tLoss: 1.787267\tAcc: 23/120 (19%)\nINFO:root:Rank: 01   Train Batch: 4/5 (80%)\tLoss: 1.782045\tAcc: 21/120 (18%)\nINFO:root:Rank: 00   Train Batch: 4/5 (80%)\tLoss: 1.786974\tAcc: 21/120 (18%)\nINFO:root:Rank: 03   Train Batch: 4/5 (80%)\tLoss: 1.783032\tAcc: 20/120 (17%)\nINFO:root:Rank: 04   Train Batch: 4/5 (80%)\tLoss: 1.767982\tAcc: 25/120 (21%)\nINFO:root:Rank: 05   Train Batch: 4/5 (80%)\tLoss: 1.779758\tAcc: 22/120 (18%)\nINFO:root:Rank: 08   Train Batch: 4/5 (80%)\tLoss: 1.777687\tAcc: 21/120 (18%)\nINFO:root:Rank: 09   Train Batch: 4/5 (80%)\tLoss: 1.774058\tAcc: 26/120 (22%)\nINFO:root:Rank: 07   Train Batch: 4/5 (80%)\tLoss: 1.782339\tAcc: 19/120 (16%)\nINFO:root:Rank: 06   Train Batch: 4/5 (80%)\tLoss: 1.779156\tAcc: 29/120 (24%)\nINFO:root:Rank: 11   Train Batch: 5/5 (100%)\tLoss: 1.772404\tAcc: 37/96 (39%)\nINFO:root:Rank: 09   Train Batch: 5/5 (100%)\tLoss: 1.783321\tAcc: 27/96 (28%)\nINFO:root:Rank: 10   Train Batch: 5/5 (100%)\tLoss: 1.788190\tAcc: 29/96 (30%)\nINFO:root:Rank: 04   Train Batch: 5/5 (100%)\tLoss: 1.773334\tAcc: 33/96 (34%)\nINFO:root:Rank: 02   Train Batch: 5/5 (100%)\tLoss: 1.767738\tAcc: 42/96 (44%)\nINFO:root:Rank: 05   Train Batch: 5/5 (100%)\tLoss: 1.768395\tAcc: 41/96 (43%)\nINFO:root:Rank: 08   Train Batch: 5/5 (100%)\tLoss: 1.777342\tAcc: 27/96 (28%)\nINFO:root:Rank: 00   Train Batch: 5/5 (100%)\tLoss: 1.782884\tAcc: 32/96 (33%)\nINFO:root:Rank: 01   Train Batch: 5/5 (100%)\tLoss: 1.781495\tAcc: 32/96 (33%)\nINFO:root:Rank: 07   Train Batch: 5/5 (100%)\tLoss: 1.785762\tAcc: 28/96 (29%)\nINFO:root:Rank: 03   Train Batch: 5/5 (100%)\tLoss: 1.776589\tAcc: 31/96 (32%)\nINFO:root:Rank: 06   Train Batch: 5/5 (100%)\tLoss: 1.767290\tAcc: 38/96 (40%)\nINFO:root:11: Memory Usage: 193.21875, Training Duration: 27.224049225998897\nINFO:root:9: Memory Usage: 193.515625, Training Duration: 27.228299881000567\nINFO:root:10: Memory Usage: 193.4453125, Training Duration: 27.229041833001247\nINFO:root:4: Memory Usage: 193.00390625, Training Duration: 27.244495487000677\nINFO:root:5: Memory Usage: 193.5625, Training Duration: 27.244215678001638\nINFO:root:2: Memory Usage: 193.59375, Training Duration: 27.245555310000782\nINFO:root:7: Memory Usage: 193.7109375, Training Duration: 27.24975262999942\nINFO:root:3: Memory Usage: 194.71875, Training Duration: 27.24632137899971\nINFO:root:8: Memory Usage: 193.62109375, Training Duration: 27.24588861200027\nINFO:root:1: Memory Usage: 194.640625, Training Duration: 27.24575929099956\nINFO:root:0: Memory Usage: 194.55859375, Training Duration: 27.250897023001016\nINFO:root:6: Memory Usage: 194.70703125, Training Duration: 27.248340701000416\n", "config": {"trainer": "distributed", "hosts": 12, "slots": 1, "parameters": {"--batch-size": 1440, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "~/susml/jakob_torben/bin/horovodrun -np 12 --hosts 10.42.0.50:1,10.42.0.29:1,10.42.0.105:1,10.42.0.56:1,10.42.0.180:1,10.42.0.235:1,10.42.0.244:1,10.42.0.239:1,10.42.0.191:1,10.42.0.41:1,10.42.0.190:1,10.42.0.69:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 1440 --epochs 1 --seed 123456789 --no-validation  horovod", "stdout": "", "stderr": "[1,10]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,10]<stderr>:INFO:root:Training set of size 6912\n[1,9]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,9]<stderr>:INFO:root:Training set of size 6912\n[1,5]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,5]<stderr>:INFO:root:Training set of size 6912\n[1,3]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,3]<stderr>:INFO:root:Training set of size 6912\n[1,6]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,6]<stderr>:INFO:root:Training set of size 6912\n[1,4]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,4]<stderr>:INFO:root:Training set of size 6912\n[1,11]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,11]<stderr>:INFO:root:Training set of size 6912\n[1,7]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,7]<stderr>:INFO:root:Training set of size 6912\n[1,8]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,8]<stderr>:INFO:root:Training set of size 6912\n[1,2]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,2]<stderr>:INFO:root:Training set of size 6912\n[1,1]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,1]<stderr>:INFO:root:Training set of size 6912\n[1,0]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,0]<stderr>:INFO:root:Training set of size 6912\n[1,7]<stderr>:INFO:root:Training model for 1 epochs...\n[1,10]<stderr>:INFO:root:Training model for 1 epochs...\n[1,9]<stderr>:INFO:root:Training model for 1 epochs...\n[1,4]<stderr>:INFO:root:Training model for 1 epochs...\n[1,6]<stderr>:INFO:root:Training model for 1 epochs...\n[1,11]<stderr>:INFO:root:Training model for 1 epochs...\n[1,5]<stderr>:INFO:root:Training model for 1 epochs...\n[1,3]<stderr>:INFO:root:Training model for 1 epochs...\n[1,8]<stderr>:INFO:root:Training model for 1 epochs...\n[1,1]<stderr>:INFO:root:Training model for 1 epochs...\n[1,2]<stderr>:INFO:root:Training model for 1 epochs...\n[1,0]<stderr>:INFO:root:Training model for 1 epochs...\n[1,9]<stderr>:INFO:root:Rank: 09   Start Epoch 0\n[1,4]<stderr>:INFO:root:Rank: 04   Start Epoch 0\n[1,6]<stderr>:INFO:root:Rank: 06   Start Epoch 0\n[1,3]<stderr>:INFO:root:Rank: 03   Start Epoch 0\n[1,5]<stderr>:INFO:root:Rank: 05   Start Epoch 0\n[1,10]<stderr>:INFO:root:Rank: 10   Start Epoch 0\n[1,7]<stderr>:INFO:root:Rank: 07   Start Epoch 0\n[1,11]<stderr>:INFO:root:Rank: 11   Start Epoch 0\n[1,0]<stderr>:INFO:root:Rank: 00   Start Epoch 0\n[1,2]<stderr>:INFO:root:Rank: 02   Start Epoch 0\n[1,1]<stderr>:INFO:root:Rank: 01   Start Epoch 0\n[1,8]<stderr>:INFO:root:Rank: 08   Start Epoch 0\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 1/5 (20%)\tLoss: 1.794687\tAcc: 21/120 (18%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 1/5 (20%)\tLoss: 1.789980\tAcc: 21/120 (18%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 1/5 (20%)\tLoss: 1.787725\tAcc: 22/120 (18%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 1/5 (20%)\tLoss: 1.780108\tAcc: 26/120 (22%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 1/5 (20%)\tLoss: 1.795747\tAcc: 24/120 (20%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 1/5 (20%)\tLoss: 1.798410\tAcc: 18/120 (15%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 1/5 (20%)\tLoss: 1.807860\tAcc: 17/120 (14%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 1/5 (20%)\tLoss: 1.792827\tAcc: 22/120 (18%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 1/5 (20%)\tLoss: 1.792296\tAcc: 20/120 (17%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 1/5 (20%)\tLoss: 1.788200\tAcc: 19/120 (16%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 1/5 (20%)\tLoss: 1.805652\tAcc: 23/120 (19%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 1/5 (20%)\tLoss: 1.803072\tAcc: 13/120 (11%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 2/5 (40%)\tLoss: 1.792923\tAcc: 22/120 (18%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 2/5 (40%)\tLoss: 1.778764\tAcc: 26/120 (22%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 2/5 (40%)\tLoss: 1.790001\tAcc: 20/120 (17%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 2/5 (40%)\tLoss: 1.781578\tAcc: 25/120 (21%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 2/5 (40%)\tLoss: 1.792401\tAcc: 14/120 (12%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 2/5 (40%)\tLoss: 1.793685\tAcc: 16/120 (13%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 2/5 (40%)\tLoss: 1.794826\tAcc: 16/120 (13%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 2/5 (40%)\tLoss: 1.791060\tAcc: 23/120 (19%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 2/5 (40%)\tLoss: 1.809911\tAcc: 10/120 (8%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 2/5 (40%)\tLoss: 1.787766\tAcc: 22/120 (18%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 2/5 (40%)\tLoss: 1.794203\tAcc: 18/120 (15%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 2/5 (40%)\tLoss: 1.793929\tAcc: 19/120 (16%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 3/5 (60%)\tLoss: 1.785756\tAcc: 19/120 (16%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 3/5 (60%)\tLoss: 1.789658\tAcc: 22/120 (18%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 3/5 (60%)\tLoss: 1.783329\tAcc: 17/120 (14%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 3/5 (60%)\tLoss: 1.783663\tAcc: 19/120 (16%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 3/5 (60%)\tLoss: 1.792810\tAcc: 17/120 (14%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 3/5 (60%)\tLoss: 1.792076\tAcc: 14/120 (12%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 3/5 (60%)\tLoss: 1.776277\tAcc: 21/120 (18%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 3/5 (60%)\tLoss: 1.777147\tAcc: 25/120 (21%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 3/5 (60%)\tLoss: 1.784656\tAcc: 25/120 (21%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 3/5 (60%)\tLoss: 1.776799\tAcc: 18/120 (15%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 3/5 (60%)\tLoss: 1.797802\tAcc: 17/120 (14%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 3/5 (60%)\tLoss: 1.781271\tAcc: 22/120 (18%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 4/5 (80%)\tLoss: 1.767982\tAcc: 25/120 (21%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 4/5 (80%)\tLoss: 1.783032\tAcc: 20/120 (17%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 4/5 (80%)\tLoss: 1.779758\tAcc: 22/120 (18%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 4/5 (80%)\tLoss: 1.774058\tAcc: 26/120 (22%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 4/5 (80%)\tLoss: 1.784836\tAcc: 17/120 (14%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 4/5 (80%)\tLoss: 1.779156\tAcc: 29/120 (24%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 4/5 (80%)\tLoss: 1.782339\tAcc: 19/120 (16%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 4/5 (80%)\tLoss: 1.786974\tAcc: 21/120 (18%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 4/5 (80%)\tLoss: 1.782045\tAcc: 21/120 (18%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 4/5 (80%)\tLoss: 1.783836\tAcc: 15/120 (12%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 4/5 (80%)\tLoss: 1.777687\tAcc: 21/120 (18%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 4/5 (80%)\tLoss: 1.787267\tAcc: 23/120 (19%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 5/5 (100%)\tLoss: 1.788190\tAcc: 29/96 (30%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 5/5 (100%)\tLoss: 1.772404\tAcc: 37/96 (39%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 5/5 (100%)\tLoss: 1.783321\tAcc: 27/96 (28%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 5/5 (100%)\tLoss: 1.785762\tAcc: 28/96 (29%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 5/5 (100%)\tLoss: 1.767738\tAcc: 42/96 (44%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 5/5 (100%)\tLoss: 1.777342\tAcc: 27/96 (28%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 5/5 (100%)\tLoss: 1.767290\tAcc: 38/96 (40%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 5/5 (100%)\tLoss: 1.776589\tAcc: 31/96 (32%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 5/5 (100%)\tLoss: 1.773334\tAcc: 33/96 (34%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 5/5 (100%)\tLoss: 1.781495\tAcc: 32/96 (33%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 5/5 (100%)\tLoss: 1.782884\tAcc: 32/96 (33%)\n[1,11]<stderr>:INFO:root:11: Memory Usage: 192.44140625, Training Duration: 49.31220662099804\n[1,9]<stderr>:INFO:root:9: Memory Usage: 195.10546875, Training Duration: 49.31677061500159\n[1,10]<stderr>:INFO:root:10: Memory Usage: 193.87890625, Training Duration: 49.31544198100164\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 5/5 (100%)\tLoss: 1.768395\tAcc: 41/96 (43%)\n[1,2]<stderr>:INFO:root:2: Memory Usage: 194.8359375, Training Duration: 49.337544497000636\n[1,1]<stderr>:INFO:root:1: Memory Usage: 194.1484375, Training Duration: 49.33862096899975\n[1,7]<stderr>:INFO:root:7: Memory Usage: 194.69140625, Training Duration: 49.33793364600206\n[1,4]<stderr>:INFO:root:4: Memory Usage: 194.875, Training Duration: 49.340218761997676\n[1,6]<stderr>:INFO:root:6: Memory Usage: 191.703125, Training Duration: 49.339698079998925\n[1,3]<stderr>:INFO:root:3: Memory Usage: 194.01171875, Training Duration: 49.340873818000546\n[1,8]<stderr>:INFO:root:8: Memory Usage: 193.609375, Training Duration: 49.344373763000476\n[1,5]<stderr>:INFO:root:5: Memory Usage: 193.5625, Training Duration: 49.35104327800218\n[1,0]<stderr>:INFO:root:0: Memory Usage: 194.39453125, Training Duration: 49.3561971320014\n", "config": {"trainer": "horovod", "hosts": 12, "slots": 1, "parameters": {"--batch-size": 1440, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "mpirun --bind-to none --map-by slot -np 4 --host 10.42.0.50:1,10.42.0.29:1,10.42.0.105:1,10.42.0.56:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 480 --epochs 1 --seed 123456789 --no-validation  distributed", "stdout": "", "stderr": "INFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Rank: 00   Start Epoch 0\nINFO:root:Rank: 03   Start Epoch 0\nINFO:root:Rank: 01   Start Epoch 0\nINFO:root:Rank: 02   Start Epoch 0\nINFO:root:Rank: 03   Train Batch: 1/15 (7%)\tLoss: 1.793874\tAcc: 26/120 (22%)\nINFO:root:Rank: 00   Train Batch: 1/15 (7%)\tLoss: 1.797848\tAcc: 19/120 (16%)\nINFO:root:Rank: 01   Train Batch: 1/15 (7%)\tLoss: 1.805541\tAcc: 20/120 (17%)\nINFO:root:Rank: 02   Train Batch: 1/15 (7%)\tLoss: 1.789147\tAcc: 21/120 (18%)\nINFO:root:Rank: 03   Train Batch: 2/15 (13%)\tLoss: 1.792150\tAcc: 19/120 (16%)\nINFO:root:Rank: 00   Train Batch: 2/15 (13%)\tLoss: 1.792014\tAcc: 16/120 (13%)\nINFO:root:Rank: 02   Train Batch: 2/15 (13%)\tLoss: 1.791579\tAcc: 15/120 (12%)\nINFO:root:Rank: 01   Train Batch: 2/15 (13%)\tLoss: 1.790044\tAcc: 21/120 (18%)\nINFO:root:Rank: 03   Train Batch: 3/15 (20%)\tLoss: 1.791186\tAcc: 20/120 (17%)\nINFO:root:Rank: 00   Train Batch: 3/15 (20%)\tLoss: 1.778889\tAcc: 29/120 (24%)\nINFO:root:Rank: 02   Train Batch: 3/15 (20%)\tLoss: 1.782983\tAcc: 22/120 (18%)\nINFO:root:Rank: 01   Train Batch: 3/15 (20%)\tLoss: 1.794132\tAcc: 18/120 (15%)\nINFO:root:Rank: 03   Train Batch: 4/15 (27%)\tLoss: 1.776533\tAcc: 28/120 (23%)\nINFO:root:Rank: 00   Train Batch: 4/15 (27%)\tLoss: 1.783818\tAcc: 17/120 (14%)\nINFO:root:Rank: 01   Train Batch: 4/15 (27%)\tLoss: 1.784508\tAcc: 19/120 (16%)\nINFO:root:Rank: 02   Train Batch: 4/15 (27%)\tLoss: 1.783088\tAcc: 17/120 (14%)\nINFO:root:Rank: 03   Train Batch: 5/15 (33%)\tLoss: 1.778255\tAcc: 28/120 (23%)\nINFO:root:Rank: 01   Train Batch: 5/15 (33%)\tLoss: 1.785117\tAcc: 20/120 (17%)\nINFO:root:Rank: 00   Train Batch: 5/15 (33%)\tLoss: 1.781057\tAcc: 31/120 (26%)\nINFO:root:Rank: 02   Train Batch: 5/15 (33%)\tLoss: 1.789450\tAcc: 26/120 (22%)\nINFO:root:Rank: 03   Train Batch: 6/15 (40%)\tLoss: 1.780804\tAcc: 38/120 (32%)\nINFO:root:Rank: 00   Train Batch: 6/15 (40%)\tLoss: 1.778938\tAcc: 43/120 (36%)\nINFO:root:Rank: 01   Train Batch: 6/15 (40%)\tLoss: 1.783859\tAcc: 35/120 (29%)\nINFO:root:Rank: 02   Train Batch: 6/15 (40%)\tLoss: 1.776608\tAcc: 38/120 (32%)\nINFO:root:Rank: 03   Train Batch: 7/15 (47%)\tLoss: 1.760116\tAcc: 49/120 (41%)\nINFO:root:Rank: 00   Train Batch: 7/15 (47%)\tLoss: 1.759020\tAcc: 45/120 (38%)\nINFO:root:Rank: 01   Train Batch: 7/15 (47%)\tLoss: 1.766646\tAcc: 44/120 (37%)\nINFO:root:Rank: 02   Train Batch: 7/15 (47%)\tLoss: 1.772170\tAcc: 40/120 (33%)\nINFO:root:Rank: 03   Train Batch: 8/15 (53%)\tLoss: 1.757320\tAcc: 45/120 (38%)\nINFO:root:Rank: 00   Train Batch: 8/15 (53%)\tLoss: 1.771874\tAcc: 35/120 (29%)\nINFO:root:Rank: 01   Train Batch: 8/15 (53%)\tLoss: 1.763847\tAcc: 40/120 (33%)\nINFO:root:Rank: 02   Train Batch: 8/15 (53%)\tLoss: 1.757003\tAcc: 45/120 (38%)\nINFO:root:Rank: 03   Train Batch: 9/15 (60%)\tLoss: 1.742706\tAcc: 43/120 (36%)\nINFO:root:Rank: 00   Train Batch: 9/15 (60%)\tLoss: 1.765002\tAcc: 35/120 (29%)\nINFO:root:Rank: 01   Train Batch: 9/15 (60%)\tLoss: 1.759296\tAcc: 32/120 (27%)\nINFO:root:Rank: 02   Train Batch: 9/15 (60%)\tLoss: 1.756727\tAcc: 38/120 (32%)\nINFO:root:Rank: 03   Train Batch: 10/15 (67%)\tLoss: 1.746969\tAcc: 34/120 (28%)\nINFO:root:Rank: 01   Train Batch: 10/15 (67%)\tLoss: 1.739485\tAcc: 35/120 (29%)\nINFO:root:Rank: 00   Train Batch: 10/15 (67%)\tLoss: 1.744939\tAcc: 34/120 (28%)\nINFO:root:Rank: 02   Train Batch: 10/15 (67%)\tLoss: 1.753661\tAcc: 29/120 (24%)\nINFO:root:Rank: 03   Train Batch: 11/15 (73%)\tLoss: 1.733814\tAcc: 41/120 (34%)\nINFO:root:Rank: 02   Train Batch: 11/15 (73%)\tLoss: 1.730019\tAcc: 35/120 (29%)\nINFO:root:Rank: 01   Train Batch: 11/15 (73%)\tLoss: 1.747328\tAcc: 30/120 (25%)\nINFO:root:Rank: 00   Train Batch: 11/15 (73%)\tLoss: 1.718971\tAcc: 45/120 (38%)\nINFO:root:Rank: 03   Train Batch: 12/15 (80%)\tLoss: 1.711560\tAcc: 49/120 (41%)\nINFO:root:Rank: 00   Train Batch: 12/15 (80%)\tLoss: 1.700533\tAcc: 46/120 (38%)\nINFO:root:Rank: 02   Train Batch: 12/15 (80%)\tLoss: 1.749549\tAcc: 37/120 (31%)\nINFO:root:Rank: 01   Train Batch: 12/15 (80%)\tLoss: 1.705886\tAcc: 35/120 (29%)\nINFO:root:Rank: 03   Train Batch: 13/15 (87%)\tLoss: 1.703188\tAcc: 43/120 (36%)\nINFO:root:Rank: 02   Train Batch: 13/15 (87%)\tLoss: 1.692082\tAcc: 47/120 (39%)\nINFO:root:Rank: 00   Train Batch: 13/15 (87%)\tLoss: 1.700113\tAcc: 42/120 (35%)\nINFO:root:Rank: 01   Train Batch: 13/15 (87%)\tLoss: 1.694347\tAcc: 46/120 (38%)\nINFO:root:Rank: 03   Train Batch: 14/15 (93%)\tLoss: 1.663258\tAcc: 49/120 (41%)\nINFO:root:Rank: 00   Train Batch: 14/15 (93%)\tLoss: 1.673670\tAcc: 44/120 (37%)\nINFO:root:Rank: 02   Train Batch: 14/15 (93%)\tLoss: 1.673202\tAcc: 41/120 (34%)\nINFO:root:Rank: 01   Train Batch: 14/15 (93%)\tLoss: 1.671510\tAcc: 52/120 (43%)\nINFO:root:Rank: 03   Train Batch: 15/15 (100%)\tLoss: 1.607293\tAcc: 19/48 (40%)\nINFO:root:Rank: 02   Train Batch: 15/15 (100%)\tLoss: 1.632223\tAcc: 18/48 (38%)\nINFO:root:3: Memory Usage: 195.90625, Training Duration: 67.42412328299906\nINFO:root:Rank: 01   Train Batch: 15/15 (100%)\tLoss: 1.623065\tAcc: 18/48 (38%)\nINFO:root:Rank: 00   Train Batch: 15/15 (100%)\tLoss: 1.602928\tAcc: 19/48 (40%)\nINFO:root:2: Memory Usage: 196.76171875, Training Duration: 67.44642996699986\nINFO:root:1: Memory Usage: 195.7109375, Training Duration: 67.45400645799964\nINFO:root:0: Memory Usage: 196.27734375, Training Duration: 67.4561448630011\n", "config": {"trainer": "distributed", "hosts": 4, "slots": 1, "parameters": {"--batch-size": 480, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "~/susml/jakob_torben/bin/horovodrun -np 8 --hosts 10.42.0.50:1,10.42.0.29:1,10.42.0.105:1,10.42.0.56:1,10.42.0.180:1,10.42.0.235:1,10.42.0.244:1,10.42.0.239:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 1440 --epochs 1 --seed 123456789 --no-validation  horovod", "stdout": "", "stderr": "[1,3]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,3]<stderr>:INFO:root:Training set of size 6912\n[1,6]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,6]<stderr>:INFO:root:Training set of size 6912\n[1,5]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,5]<stderr>:INFO:root:Training set of size 6912\n[1,4]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,4]<stderr>:INFO:root:Training set of size 6912\n[1,7]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,7]<stderr>:INFO:root:Training set of size 6912\n[1,2]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,2]<stderr>:INFO:root:Training set of size 6912\n[1,1]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,1]<stderr>:INFO:root:Training set of size 6912\n[1,0]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,0]<stderr>:INFO:root:Training set of size 6912\n[1,1]<stderr>:INFO:root:Training model for 1 epochs...\n[1,3]<stderr>:INFO:root:Training model for 1 epochs...\n[1,7]<stderr>:INFO:root:Training model for 1 epochs...\n[1,5]<stderr>:INFO:root:Training model for 1 epochs...\n[1,2]<stderr>:INFO:root:Training model for 1 epochs...\n[1,4]<stderr>:INFO:root:Training model for 1 epochs...\n[1,6]<stderr>:INFO:root:Training model for 1 epochs...\n[1,0]<stderr>:INFO:root:Training model for 1 epochs...\n[1,3]<stderr>:INFO:root:Rank: 03   Start Epoch 0\n[1,7]<stderr>:INFO:root:Rank: 07   Start Epoch 0\n[1,4]<stderr>:INFO:root:Rank: 04   Start Epoch 0\n[1,5]<stderr>:INFO:root:Rank: 05   Start Epoch 0\n[1,1]<stderr>:INFO:root:Rank: 01   Start Epoch 0\n[1,2]<stderr>:INFO:root:Rank: 02   Start Epoch 0\n[1,6]<stderr>:INFO:root:Rank: 06   Start Epoch 0\n[1,0]<stderr>:INFO:root:Rank: 00   Start Epoch 0\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 1/5 (20%)\tLoss: 1.790115\tAcc: 32/180 (18%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 1/5 (20%)\tLoss: 1.793342\tAcc: 32/180 (18%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 1/5 (20%)\tLoss: 1.807391\tAcc: 22/180 (12%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 1/5 (20%)\tLoss: 1.793953\tAcc: 37/180 (21%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 1/5 (20%)\tLoss: 1.790805\tAcc: 26/180 (14%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 1/5 (20%)\tLoss: 1.800205\tAcc: 33/180 (18%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 1/5 (20%)\tLoss: 1.788322\tAcc: 30/180 (17%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 1/5 (20%)\tLoss: 1.793576\tAcc: 34/180 (19%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 2/5 (40%)\tLoss: 1.795760\tAcc: 32/180 (18%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 2/5 (40%)\tLoss: 1.797570\tAcc: 23/180 (13%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 2/5 (40%)\tLoss: 1.787470\tAcc: 31/180 (17%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 2/5 (40%)\tLoss: 1.788547\tAcc: 36/180 (20%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 2/5 (40%)\tLoss: 1.797752\tAcc: 24/180 (13%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 2/5 (40%)\tLoss: 1.788255\tAcc: 28/180 (16%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 2/5 (40%)\tLoss: 1.784461\tAcc: 28/180 (16%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 2/5 (40%)\tLoss: 1.794214\tAcc: 29/180 (16%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 3/5 (60%)\tLoss: 1.783816\tAcc: 29/180 (16%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 3/5 (60%)\tLoss: 1.775926\tAcc: 33/180 (18%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 3/5 (60%)\tLoss: 1.786755\tAcc: 35/180 (19%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 3/5 (60%)\tLoss: 1.788897\tAcc: 21/180 (12%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 3/5 (60%)\tLoss: 1.786624\tAcc: 26/180 (14%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 3/5 (60%)\tLoss: 1.782987\tAcc: 32/180 (18%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 3/5 (60%)\tLoss: 1.791166\tAcc: 28/180 (16%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 3/5 (60%)\tLoss: 1.784658\tAcc: 32/180 (18%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 4/5 (80%)\tLoss: 1.783550\tAcc: 32/180 (18%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 4/5 (80%)\tLoss: 1.771866\tAcc: 35/180 (19%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 4/5 (80%)\tLoss: 1.785373\tAcc: 34/180 (19%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 4/5 (80%)\tLoss: 1.778062\tAcc: 34/180 (19%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 4/5 (80%)\tLoss: 1.784006\tAcc: 32/180 (18%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 4/5 (80%)\tLoss: 1.782588\tAcc: 22/180 (12%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 4/5 (80%)\tLoss: 1.783502\tAcc: 37/180 (21%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 4/5 (80%)\tLoss: 1.777034\tAcc: 33/180 (18%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 5/5 (100%)\tLoss: 1.782330\tAcc: 46/144 (32%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 5/5 (100%)\tLoss: 1.774174\tAcc: 50/144 (35%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 5/5 (100%)\tLoss: 1.780972\tAcc: 46/144 (32%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 5/5 (100%)\tLoss: 1.780360\tAcc: 49/144 (34%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 5/5 (100%)\tLoss: 1.775115\tAcc: 51/144 (35%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 5/5 (100%)\tLoss: 1.774766\tAcc: 48/144 (33%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 5/5 (100%)\tLoss: 1.774046\tAcc: 61/144 (42%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 5/5 (100%)\tLoss: 1.774733\tAcc: 46/144 (32%)\n[1,7]<stderr>:INFO:root:7: Memory Usage: 223.46875, Training Duration: 50.57099800500146\n[1,4]<stderr>:INFO:root:4: Memory Usage: 224.30859375, Training Duration: 50.57171876000211\n[1,5]<stderr>:INFO:root:5: Memory Usage: 223.82421875, Training Duration: 50.57163049299925\n[1,2]<stderr>:INFO:root:2: Memory Usage: 224.05859375, Training Duration: 50.572078023997165\n[1,6]<stderr>:INFO:root:6: Memory Usage: 223.90625, Training Duration: 50.57244729100057\n[1,3]<stderr>:INFO:root:3: Memory Usage: 225.22265625, Training Duration: 50.57394352499978\n[1,1]<stderr>:INFO:root:1: Memory Usage: 224.625, Training Duration: 50.57458369300002\n[1,0]<stderr>:INFO:root:0: Memory Usage: 223.34765625, Training Duration: 50.5780205580013\n", "config": {"trainer": "horovod", "hosts": 8, "slots": 1, "parameters": {"--batch-size": 1440, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "~/susml/jakob_torben/bin/horovodrun -np 8 --hosts 10.42.0.50:1,10.42.0.29:1,10.42.0.105:1,10.42.0.56:1,10.42.0.180:1,10.42.0.235:1,10.42.0.244:1,10.42.0.239:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 480 --epochs 1 --seed 123456789 --no-validation  horovod", "stdout": "", "stderr": "[1,3]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,3]<stderr>:INFO:root:Training set of size 6912\n[1,6]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,6]<stderr>:INFO:root:Training set of size 6912\n[1,4]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,4]<stderr>:INFO:root:Training set of size 6912\n[1,5]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,5]<stderr>:INFO:root:Training set of size 6912\n[1,7]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,7]<stderr>:INFO:root:Training set of size 6912\n[1,2]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,2]<stderr>:INFO:root:Training set of size 6912\n[1,1]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,1]<stderr>:INFO:root:Training set of size 6912\n[1,0]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,0]<stderr>:INFO:root:Training set of size 6912\n[1,4]<stderr>:INFO:root:Training model for 1 epochs...\n[1,7]<stderr>:INFO:root:Training model for 1 epochs...\n[1,3]<stderr>:INFO:root:Training model for 1 epochs...\n[1,5]<stderr>:INFO:root:Training model for 1 epochs...\n[1,6]<stderr>:INFO:root:Training model for 1 epochs...\n[1,1]<stderr>:INFO:root:Training model for 1 epochs...\n[1,0]<stderr>:INFO:root:Training model for 1 epochs...\n[1,2]<stderr>:INFO:root:Training model for 1 epochs...\n[1,4]<stderr>:INFO:root:Rank: 04   Start Epoch 0\n[1,5]<stderr>:INFO:root:Rank: 05   Start Epoch 0\n[1,7]<stderr>:INFO:root:Rank: 07   Start Epoch 0\n[1,3]<stderr>:INFO:root:Rank: 03   Start Epoch 0\n[1,6]<stderr>:INFO:root:Rank: 06   Start Epoch 0\n[1,0]<stderr>:INFO:root:Rank: 00   Start Epoch 0\n[1,2]<stderr>:INFO:root:Rank: 02   Start Epoch 0\n[1,1]<stderr>:INFO:root:Rank: 01   Start Epoch 0\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 1/15 (7%)\tLoss: 1.799998\tAcc: 11/60 (18%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 1/15 (7%)\tLoss: 1.791471\tAcc: 16/60 (27%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 1/15 (7%)\tLoss: 1.815445\tAcc: 7/60 (12%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 1/15 (7%)\tLoss: 1.795635\tAcc: 13/60 (22%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 1/15 (7%)\tLoss: 1.796277\tAcc: 10/60 (17%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 1/15 (7%)\tLoss: 1.783958\tAcc: 13/60 (22%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 1/15 (7%)\tLoss: 1.794336\tAcc: 8/60 (13%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 1/15 (7%)\tLoss: 1.795698\tAcc: 8/60 (13%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 2/15 (13%)\tLoss: 1.792264\tAcc: 9/60 (15%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 2/15 (13%)\tLoss: 1.792929\tAcc: 6/60 (10%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 2/15 (13%)\tLoss: 1.796502\tAcc: 8/60 (13%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 2/15 (13%)\tLoss: 1.797257\tAcc: 6/60 (10%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 2/15 (13%)\tLoss: 1.783585\tAcc: 13/60 (22%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 2/15 (13%)\tLoss: 1.790229\tAcc: 9/60 (15%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 2/15 (13%)\tLoss: 1.792036\tAcc: 10/60 (17%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 2/15 (13%)\tLoss: 1.786772\tAcc: 10/60 (17%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 3/15 (20%)\tLoss: 1.779692\tAcc: 12/60 (20%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 3/15 (20%)\tLoss: 1.781168\tAcc: 12/60 (20%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 3/15 (20%)\tLoss: 1.794055\tAcc: 7/60 (12%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 3/15 (20%)\tLoss: 1.783423\tAcc: 12/60 (20%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 3/15 (20%)\tLoss: 1.801204\tAcc: 8/60 (13%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 3/15 (20%)\tLoss: 1.774356\tAcc: 17/60 (28%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 3/15 (20%)\tLoss: 1.794210\tAcc: 11/60 (18%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 3/15 (20%)\tLoss: 1.786276\tAcc: 10/60 (17%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 4/15 (27%)\tLoss: 1.782139\tAcc: 10/60 (17%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 4/15 (27%)\tLoss: 1.779758\tAcc: 15/60 (25%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 4/15 (27%)\tLoss: 1.800813\tAcc: 6/60 (10%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 4/15 (27%)\tLoss: 1.784939\tAcc: 9/60 (15%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 4/15 (27%)\tLoss: 1.773308\tAcc: 13/60 (22%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 4/15 (27%)\tLoss: 1.785495\tAcc: 7/60 (12%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 4/15 (27%)\tLoss: 1.768205\tAcc: 13/60 (22%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 4/15 (27%)\tLoss: 1.781237\tAcc: 8/60 (13%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 5/15 (33%)\tLoss: 1.783664\tAcc: 9/60 (15%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 5/15 (33%)\tLoss: 1.789392\tAcc: 13/60 (22%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 5/15 (33%)\tLoss: 1.779097\tAcc: 14/60 (23%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 5/15 (33%)\tLoss: 1.803673\tAcc: 13/60 (22%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 5/15 (33%)\tLoss: 1.786570\tAcc: 11/60 (18%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 5/15 (33%)\tLoss: 1.777412\tAcc: 14/60 (23%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 5/15 (33%)\tLoss: 1.758441\tAcc: 18/60 (30%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 5/15 (33%)\tLoss: 1.789508\tAcc: 13/60 (22%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 6/15 (40%)\tLoss: 1.785305\tAcc: 17/60 (28%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 6/15 (40%)\tLoss: 1.788962\tAcc: 17/60 (28%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 6/15 (40%)\tLoss: 1.788276\tAcc: 15/60 (25%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 6/15 (40%)\tLoss: 1.772640\tAcc: 22/60 (37%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 6/15 (40%)\tLoss: 1.764941\tAcc: 23/60 (38%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 6/15 (40%)\tLoss: 1.776305\tAcc: 21/60 (35%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 6/15 (40%)\tLoss: 1.785236\tAcc: 21/60 (35%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 6/15 (40%)\tLoss: 1.778759\tAcc: 18/60 (30%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 7/15 (47%)\tLoss: 1.760878\tAcc: 21/60 (35%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 7/15 (47%)\tLoss: 1.757161\tAcc: 24/60 (40%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 7/15 (47%)\tLoss: 1.755203\tAcc: 25/60 (42%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 7/15 (47%)\tLoss: 1.767788\tAcc: 21/60 (35%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 7/15 (47%)\tLoss: 1.765505\tAcc: 23/60 (38%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 7/15 (47%)\tLoss: 1.770635\tAcc: 22/60 (37%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 7/15 (47%)\tLoss: 1.765027\tAcc: 24/60 (40%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 7/15 (47%)\tLoss: 1.773705\tAcc: 18/60 (30%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 8/15 (53%)\tLoss: 1.764163\tAcc: 16/60 (27%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 8/15 (53%)\tLoss: 1.765437\tAcc: 18/60 (30%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 8/15 (53%)\tLoss: 1.756754\tAcc: 21/60 (35%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 8/15 (53%)\tLoss: 1.779587\tAcc: 19/60 (32%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 8/15 (53%)\tLoss: 1.764693\tAcc: 20/60 (33%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 8/15 (53%)\tLoss: 1.757252\tAcc: 24/60 (40%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 8/15 (53%)\tLoss: 1.763002\tAcc: 20/60 (33%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 8/15 (53%)\tLoss: 1.749203\tAcc: 27/60 (45%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 9/15 (60%)\tLoss: 1.753716\tAcc: 19/60 (32%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 9/15 (60%)\tLoss: 1.737493\tAcc: 24/60 (40%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 9/15 (60%)\tLoss: 1.764877\tAcc: 13/60 (22%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 9/15 (60%)\tLoss: 1.747918\tAcc: 19/60 (32%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 9/15 (60%)\tLoss: 1.749181\tAcc: 22/60 (37%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 9/15 (60%)\tLoss: 1.773916\tAcc: 13/60 (22%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 9/15 (60%)\tLoss: 1.764273\tAcc: 16/60 (27%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 9/15 (60%)\tLoss: 1.756087\tAcc: 22/60 (37%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 10/15 (67%)\tLoss: 1.755282\tAcc: 14/60 (23%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 10/15 (67%)\tLoss: 1.744175\tAcc: 17/60 (28%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 10/15 (67%)\tLoss: 1.754338\tAcc: 14/60 (23%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 10/15 (67%)\tLoss: 1.758090\tAcc: 15/60 (25%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 10/15 (67%)\tLoss: 1.735850\tAcc: 19/60 (32%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 10/15 (67%)\tLoss: 1.752985\tAcc: 15/60 (25%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 10/15 (67%)\tLoss: 1.745704\tAcc: 17/60 (28%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 10/15 (67%)\tLoss: 1.723689\tAcc: 21/60 (35%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 11/15 (73%)\tLoss: 1.768323\tAcc: 11/60 (18%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 11/15 (73%)\tLoss: 1.708559\tAcc: 24/60 (40%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 11/15 (73%)\tLoss: 1.738776\tAcc: 16/60 (27%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 11/15 (73%)\tLoss: 1.732986\tAcc: 21/60 (35%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 11/15 (73%)\tLoss: 1.726334\tAcc: 19/60 (32%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 11/15 (73%)\tLoss: 1.721262\tAcc: 19/60 (32%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 11/15 (73%)\tLoss: 1.729381\tAcc: 21/60 (35%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 11/15 (73%)\tLoss: 1.734643\tAcc: 20/60 (33%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 12/15 (80%)\tLoss: 1.740384\tAcc: 20/60 (33%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 12/15 (80%)\tLoss: 1.705196\tAcc: 22/60 (37%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 12/15 (80%)\tLoss: 1.711430\tAcc: 18/60 (30%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 12/15 (80%)\tLoss: 1.717922\tAcc: 27/60 (45%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 12/15 (80%)\tLoss: 1.758714\tAcc: 17/60 (28%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 12/15 (80%)\tLoss: 1.706733\tAcc: 22/60 (37%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 12/15 (80%)\tLoss: 1.700341\tAcc: 17/60 (28%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 12/15 (80%)\tLoss: 1.694333\tAcc: 24/60 (40%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 13/15 (87%)\tLoss: 1.699543\tAcc: 22/60 (37%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 13/15 (87%)\tLoss: 1.689152\tAcc: 24/60 (40%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 13/15 (87%)\tLoss: 1.686165\tAcc: 24/60 (40%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 13/15 (87%)\tLoss: 1.690273\tAcc: 25/60 (42%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 13/15 (87%)\tLoss: 1.731753\tAcc: 19/60 (32%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 13/15 (87%)\tLoss: 1.720210\tAcc: 19/60 (32%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 13/15 (87%)\tLoss: 1.693890\tAcc: 22/60 (37%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 13/15 (87%)\tLoss: 1.668473\tAcc: 23/60 (38%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 14/15 (93%)\tLoss: 1.650251\tAcc: 32/60 (53%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 14/15 (93%)\tLoss: 1.692769\tAcc: 20/60 (33%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 14/15 (93%)\tLoss: 1.659278\tAcc: 23/60 (38%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 14/15 (93%)\tLoss: 1.666370\tAcc: 22/60 (37%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 14/15 (93%)\tLoss: 1.655089\tAcc: 20/60 (33%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 14/15 (93%)\tLoss: 1.660146\tAcc: 27/60 (45%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 14/15 (93%)\tLoss: 1.688062\tAcc: 21/60 (35%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 14/15 (93%)\tLoss: 1.691315\tAcc: 21/60 (35%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 15/15 (100%)\tLoss: 1.635092\tAcc: 10/24 (42%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 15/15 (100%)\tLoss: 1.611036\tAcc: 8/24 (33%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 15/15 (100%)\tLoss: 1.655223\tAcc: 9/24 (38%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 15/15 (100%)\tLoss: 1.559363\tAcc: 10/24 (42%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 15/15 (100%)\tLoss: 1.677636\tAcc: 7/24 (29%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 15/15 (100%)\tLoss: 1.677247\tAcc: 7/24 (29%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 15/15 (100%)\tLoss: 1.586809\tAcc: 11/24 (46%)\n[1,5]<stderr>:INFO:root:5: Memory Usage: 164.8984375, Training Duration: 33.93490196299899\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 15/15 (100%)\tLoss: 1.528609\tAcc: 12/24 (50%)\n[1,3]<stderr>:INFO:root:3: Memory Usage: 165.96484375, Training Duration: 33.95443379599965\n[1,1]<stderr>:INFO:root:1: Memory Usage: 166.6640625, Training Duration: 33.956044170001405\n[1,7]<stderr>:INFO:root:7: Memory Usage: 165.04296875, Training Duration: 33.956642983001075\n[1,0]<stderr>:INFO:root:0: Memory Usage: 166.4453125, Training Duration: 33.96772666099787\n[1,4]<stderr>:INFO:root:4: Memory Usage: 165.85546875, Training Duration: 33.96880518300168\n[1,2]<stderr>:INFO:root:2: Memory Usage: 165.41015625, Training Duration: 33.97558996799853\n[1,6]<stderr>:INFO:root:6: Memory Usage: 166.9296875, Training Duration: 33.976447271001234\n", "config": {"trainer": "horovod", "hosts": 8, "slots": 1, "parameters": {"--batch-size": 480, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "mpirun --bind-to none --map-by slot -np 12 --host 10.42.0.50:1,10.42.0.29:1,10.42.0.105:1,10.42.0.56:1,10.42.0.180:1,10.42.0.235:1,10.42.0.244:1,10.42.0.239:1,10.42.0.191:1,10.42.0.41:1,10.42.0.190:1,10.42.0.69:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 960 --epochs 1 --seed 123456789 --no-validation  distributed", "stdout": "", "stderr": "INFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Rank: 11   Start Epoch 0\nINFO:root:Rank: 08   Start Epoch 0\nINFO:root:Rank: 00   Start Epoch 0\nINFO:root:Rank: 04   Start Epoch 0\nINFO:root:Rank: 02   Start Epoch 0\nINFO:root:Rank: 07   Start Epoch 0\nINFO:root:Rank: 01   Start Epoch 0\nINFO:root:Rank: 03   Start Epoch 0\nINFO:root:Rank: 06   Start Epoch 0\nINFO:root:Rank: 05   Start Epoch 0\nINFO:root:Rank: 10   Start Epoch 0\nINFO:root:Rank: 09   Start Epoch 0\nINFO:root:Rank: 10   Train Batch: 1/8 (12%)\tLoss: 1.787234\tAcc: 13/80 (16%)\nINFO:root:Rank: 09   Train Batch: 1/8 (12%)\tLoss: 1.793659\tAcc: 15/80 (19%)\nINFO:root:Rank: 07   Train Batch: 1/8 (12%)\tLoss: 1.779391\tAcc: 16/80 (20%)\nINFO:root:Rank: 08   Train Batch: 1/8 (12%)\tLoss: 1.795578\tAcc: 13/80 (16%)\nINFO:root:Rank: 00   Train Batch: 1/8 (12%)\tLoss: 1.801895\tAcc: 10/80 (12%)\nINFO:root:Rank: 11   Train Batch: 1/8 (12%)\tLoss: 1.800863\tAcc: 13/80 (16%)\nINFO:root:Rank: 04   Train Batch: 1/8 (12%)\tLoss: 1.792639\tAcc: 12/80 (15%)\nINFO:root:Rank: 05   Train Batch: 1/8 (12%)\tLoss: 1.809552\tAcc: 13/80 (16%)\nINFO:root:Rank: 02   Train Batch: 1/8 (12%)\tLoss: 1.808632\tAcc: 6/80 (8%)\nINFO:root:Rank: 01   Train Batch: 1/8 (12%)\tLoss: 1.797465\tAcc: 13/80 (16%)\nINFO:root:Rank: 03   Train Batch: 1/8 (12%)\tLoss: 1.803537\tAcc: 16/80 (20%)\nINFO:root:Rank: 06   Train Batch: 1/8 (12%)\tLoss: 1.779261\tAcc: 17/80 (21%)\nINFO:root:Rank: 10   Train Batch: 2/8 (25%)\tLoss: 1.796296\tAcc: 10/80 (12%)\nINFO:root:Rank: 11   Train Batch: 2/8 (25%)\tLoss: 1.775772\tAcc: 22/80 (28%)\nINFO:root:Rank: 09   Train Batch: 2/8 (25%)\tLoss: 1.791194\tAcc: 19/80 (24%)\nINFO:root:Rank: 04   Train Batch: 2/8 (25%)\tLoss: 1.795076\tAcc: 12/80 (15%)\nINFO:root:Rank: 07   Train Batch: 2/8 (25%)\tLoss: 1.795073\tAcc: 11/80 (14%)\nINFO:root:Rank: 01   Train Batch: 2/8 (25%)\tLoss: 1.795943\tAcc: 9/80 (11%)\nINFO:root:Rank: 05   Train Batch: 2/8 (25%)\tLoss: 1.799178\tAcc: 9/80 (11%)\nINFO:root:Rank: 02   Train Batch: 2/8 (25%)\tLoss: 1.793418\tAcc: 11/80 (14%)\nINFO:root:Rank: 00   Train Batch: 2/8 (25%)\tLoss: 1.781491\tAcc: 17/80 (21%)\nINFO:root:Rank: 03   Train Batch: 2/8 (25%)\tLoss: 1.792155\tAcc: 15/80 (19%)\nINFO:root:Rank: 08   Train Batch: 2/8 (25%)\tLoss: 1.779534\tAcc: 17/80 (21%)\nINFO:root:Rank: 06   Train Batch: 2/8 (25%)\tLoss: 1.779631\tAcc: 18/80 (22%)\nINFO:root:Rank: 03   Train Batch: 3/8 (38%)\tLoss: 1.793736\tAcc: 15/80 (19%)\nINFO:root:Rank: 05   Train Batch: 3/8 (38%)\tLoss: 1.788152\tAcc: 11/80 (14%)\nINFO:root:Rank: 09   Train Batch: 3/8 (38%)\tLoss: 1.795227\tAcc: 12/80 (15%)\nINFO:root:Rank: 10   Train Batch: 3/8 (38%)\tLoss: 1.779842\tAcc: 16/80 (20%)\nINFO:root:Rank: 04   Train Batch: 3/8 (38%)\tLoss: 1.786099\tAcc: 14/80 (18%)\nINFO:root:Rank: 07   Train Batch: 3/8 (38%)\tLoss: 1.795199\tAcc: 12/80 (15%)\nINFO:root:Rank: 01   Train Batch: 3/8 (38%)\tLoss: 1.787497\tAcc: 10/80 (12%)\nINFO:root:Rank: 02   Train Batch: 3/8 (38%)\tLoss: 1.809039\tAcc: 6/80 (8%)\nINFO:root:Rank: 08   Train Batch: 3/8 (38%)\tLoss: 1.781328\tAcc: 15/80 (19%)\nINFO:root:Rank: 00   Train Batch: 3/8 (38%)\tLoss: 1.796087\tAcc: 14/80 (18%)\nINFO:root:Rank: 06   Train Batch: 3/8 (38%)\tLoss: 1.788695\tAcc: 13/80 (16%)\nINFO:root:Rank: 11   Train Batch: 3/8 (38%)\tLoss: 1.775995\tAcc: 12/80 (15%)\nINFO:root:Rank: 10   Train Batch: 4/8 (50%)\tLoss: 1.775472\tAcc: 15/80 (19%)\nINFO:root:Rank: 06   Train Batch: 4/8 (50%)\tLoss: 1.784699\tAcc: 9/80 (11%)\nINFO:root:Rank: 05   Train Batch: 4/8 (50%)\tLoss: 1.781332\tAcc: 19/80 (24%)\nINFO:root:Rank: 00   Train Batch: 4/8 (50%)\tLoss: 1.799366\tAcc: 9/80 (11%)\nINFO:root:Rank: 01   Train Batch: 4/8 (50%)\tLoss: 1.769831\tAcc: 18/80 (22%)\nINFO:root:Rank: 07   Train Batch: 4/8 (50%)\tLoss: 1.785292\tAcc: 11/80 (14%)\nINFO:root:Rank: 11   Train Batch: 4/8 (50%)\tLoss: 1.763095\tAcc: 16/80 (20%)\nINFO:root:Rank: 08   Train Batch: 4/8 (50%)\tLoss: 1.769480\tAcc: 15/80 (19%)\nINFO:root:Rank: 04   Train Batch: 4/8 (50%)\tLoss: 1.776013\tAcc: 17/80 (21%)\nINFO:root:Rank: 03   Train Batch: 4/8 (50%)\tLoss: 1.781255\tAcc: 15/80 (19%)\nINFO:root:Rank: 09   Train Batch: 4/8 (50%)\tLoss: 1.789480\tAcc: 10/80 (12%)\nINFO:root:Rank: 02   Train Batch: 4/8 (50%)\tLoss: 1.785731\tAcc: 10/80 (12%)\nINFO:root:Rank: 09   Train Batch: 5/8 (62%)\tLoss: 1.776414\tAcc: 32/80 (40%)\nINFO:root:Rank: 10   Train Batch: 5/8 (62%)\tLoss: 1.778921\tAcc: 28/80 (35%)\nINFO:root:Rank: 04   Train Batch: 5/8 (62%)\tLoss: 1.784448\tAcc: 27/80 (34%)\nINFO:root:Rank: 05   Train Batch: 5/8 (62%)\tLoss: 1.780106\tAcc: 27/80 (34%)\nINFO:root:Rank: 03   Train Batch: 5/8 (62%)\tLoss: 1.774956\tAcc: 32/80 (40%)\nINFO:root:Rank: 11   Train Batch: 5/8 (62%)\tLoss: 1.778210\tAcc: 23/80 (29%)\nINFO:root:Rank: 06   Train Batch: 5/8 (62%)\tLoss: 1.768812\tAcc: 30/80 (38%)\nINFO:root:Rank: 01   Train Batch: 5/8 (62%)\tLoss: 1.775463\tAcc: 29/80 (36%)\nINFO:root:Rank: 07   Train Batch: 5/8 (62%)\tLoss: 1.768363\tAcc: 26/80 (32%)\nINFO:root:Rank: 08   Train Batch: 5/8 (62%)\tLoss: 1.778922\tAcc: 21/80 (26%)\nINFO:root:Rank: 02   Train Batch: 5/8 (62%)\tLoss: 1.786990\tAcc: 22/80 (28%)\nINFO:root:Rank: 00   Train Batch: 5/8 (62%)\tLoss: 1.787540\tAcc: 27/80 (34%)\nINFO:root:Rank: 10   Train Batch: 6/8 (75%)\tLoss: 1.773386\tAcc: 23/80 (29%)\nINFO:root:Rank: 11   Train Batch: 6/8 (75%)\tLoss: 1.775529\tAcc: 25/80 (31%)\nINFO:root:Rank: 06   Train Batch: 6/8 (75%)\tLoss: 1.776635\tAcc: 28/80 (35%)\nINFO:root:Rank: 04   Train Batch: 6/8 (75%)\tLoss: 1.754879\tAcc: 34/80 (42%)\nINFO:root:Rank: 02   Train Batch: 6/8 (75%)\tLoss: 1.785643\tAcc: 22/80 (28%)\nINFO:root:Rank: 09   Train Batch: 6/8 (75%)\tLoss: 1.764732\tAcc: 31/80 (39%)\nINFO:root:Rank: 08   Train Batch: 6/8 (75%)\tLoss: 1.760126\tAcc: 32/80 (40%)\nINFO:root:Rank: 07   Train Batch: 6/8 (75%)\tLoss: 1.776536\tAcc: 23/80 (29%)\nINFO:root:Rank: 00   Train Batch: 6/8 (75%)\tLoss: 1.773803\tAcc: 30/80 (38%)\nINFO:root:Rank: 01   Train Batch: 6/8 (75%)\tLoss: 1.775579\tAcc: 25/80 (31%)\nINFO:root:Rank: 05   Train Batch: 6/8 (75%)\tLoss: 1.773679\tAcc: 28/80 (35%)\nINFO:root:Rank: 03   Train Batch: 6/8 (75%)\tLoss: 1.768995\tAcc: 28/80 (35%)\nINFO:root:Rank: 11   Train Batch: 7/8 (88%)\tLoss: 1.768162\tAcc: 26/80 (32%)\nINFO:root:Rank: 03   Train Batch: 7/8 (88%)\tLoss: 1.766662\tAcc: 19/80 (24%)\nINFO:root:Rank: 04   Train Batch: 7/8 (88%)\tLoss: 1.760362\tAcc: 23/80 (29%)\nINFO:root:Rank: 09   Train Batch: 7/8 (88%)\tLoss: 1.769479\tAcc: 19/80 (24%)\nINFO:root:Rank: 10   Train Batch: 7/8 (88%)\tLoss: 1.771538\tAcc: 20/80 (25%)\nINFO:root:Rank: 08   Train Batch: 7/8 (88%)\tLoss: 1.766892\tAcc: 18/80 (22%)\nINFO:root:Rank: 05   Train Batch: 7/8 (88%)\tLoss: 1.765435\tAcc: 22/80 (28%)\nINFO:root:Rank: 06   Train Batch: 7/8 (88%)\tLoss: 1.753992\tAcc: 25/80 (31%)\nINFO:root:Rank: 01   Train Batch: 7/8 (88%)\tLoss: 1.767138\tAcc: 24/80 (30%)\nINFO:root:Rank: 00   Train Batch: 7/8 (88%)\tLoss: 1.781106\tAcc: 20/80 (25%)\nINFO:root:Rank: 02   Train Batch: 7/8 (88%)\tLoss: 1.770405\tAcc: 20/80 (25%)\nINFO:root:Rank: 07   Train Batch: 7/8 (88%)\tLoss: 1.774825\tAcc: 18/80 (22%)\nINFO:root:Rank: 04   Train Batch: 8/8 (100%)\tLoss: 1.735974\tAcc: 4/16 (25%)\nINFO:root:Rank: 05   Train Batch: 8/8 (100%)\tLoss: 1.719096\tAcc: 5/16 (31%)\nINFO:root:Rank: 07   Train Batch: 8/8 (100%)\tLoss: 1.750543\tAcc: 6/16 (38%)\nINFO:root:Rank: 10   Train Batch: 8/8 (100%)\tLoss: 1.803307\tAcc: 4/16 (25%)\nINFO:root:Rank: 00   Train Batch: 8/8 (100%)\tLoss: 1.736825\tAcc: 3/16 (19%)\nINFO:root:Rank: 08   Train Batch: 8/8 (100%)\tLoss: 1.770292\tAcc: 3/16 (19%)\nINFO:root:Rank: 03   Train Batch: 8/8 (100%)\tLoss: 1.750226\tAcc: 5/16 (31%)\nINFO:root:Rank: 09   Train Batch: 8/8 (100%)\tLoss: 1.797932\tAcc: 3/16 (19%)\nINFO:root:Rank: 02   Train Batch: 8/8 (100%)\tLoss: 1.713695\tAcc: 6/16 (38%)\nINFO:root:Rank: 11   Train Batch: 8/8 (100%)\tLoss: 1.759211\tAcc: 3/16 (19%)\nINFO:root:Rank: 06   Train Batch: 8/8 (100%)\tLoss: 1.777941\tAcc: 4/16 (25%)\nINFO:root:Rank: 01   Train Batch: 8/8 (100%)\tLoss: 1.785286\tAcc: 4/16 (25%)\nINFO:root:4: Memory Usage: 173.2265625, Training Duration: 43.50375945199994\nINFO:root:5: Memory Usage: 174.12890625, Training Duration: 43.51344766699913\nINFO:root:10: Memory Usage: 173.703125, Training Duration: 43.513970914998936\nINFO:root:7: Memory Usage: 173.4609375, Training Duration: 43.51620780799931\nINFO:root:3: Memory Usage: 172.8671875, Training Duration: 43.51649674700093\nINFO:root:9: Memory Usage: 172.4453125, Training Duration: 43.51484949699807\nINFO:root:0: Memory Usage: 173.6015625, Training Duration: 43.52647609899941\nINFO:root:8: Memory Usage: 172.98828125, Training Duration: 43.52245782799946\nINFO:root:2: Memory Usage: 173.3984375, Training Duration: 43.5189649189997\nINFO:root:6: Memory Usage: 173.4453125, Training Duration: 43.51875862599991\nINFO:root:11: Memory Usage: 173.23046875, Training Duration: 43.524714361003134\nINFO:root:1: Memory Usage: 173.43359375, Training Duration: 43.52083982399927\n", "config": {"trainer": "distributed", "hosts": 12, "slots": 1, "parameters": {"--batch-size": 960, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "~/susml/jakob_torben/bin/horovodrun -np 4 --hosts 10.42.0.50:1,10.42.0.29:1,10.42.0.105:1,10.42.0.56:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 960 --epochs 1 --seed 123456789 --no-validation  horovod", "stdout": "", "stderr": "[1,3]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,3]<stderr>:INFO:root:Training set of size 6912\n[1,1]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,1]<stderr>:INFO:root:Training set of size 6912\n[1,2]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,2]<stderr>:INFO:root:Training set of size 6912\n[1,0]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,0]<stderr>:INFO:root:Training set of size 6912\n[1,1]<stderr>:INFO:root:Training model for 1 epochs...\n[1,0]<stderr>:INFO:root:Training model for 1 epochs...\n[1,2]<stderr>:INFO:root:Training model for 1 epochs...\n[1,3]<stderr>:INFO:root:Training model for 1 epochs...\n[1,3]<stderr>:INFO:root:Rank: 03   Start Epoch 0\n[1,1]<stderr>:INFO:root:Rank: 01   Start Epoch 0\n[1,0]<stderr>:INFO:root:Rank: 00   Start Epoch 0\n[1,2]<stderr>:INFO:root:Rank: 02   Start Epoch 0\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 1/8 (12%)\tLoss: 1.794597\tAcc: 45/240 (19%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 1/8 (12%)\tLoss: 1.791708\tAcc: 36/240 (15%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 1/8 (12%)\tLoss: 1.800225\tAcc: 41/240 (17%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 1/8 (12%)\tLoss: 1.796704\tAcc: 35/240 (15%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 2/8 (25%)\tLoss: 1.787668\tAcc: 48/240 (20%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 2/8 (25%)\tLoss: 1.789782\tAcc: 39/240 (16%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 2/8 (25%)\tLoss: 1.795439\tAcc: 37/240 (15%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 2/8 (25%)\tLoss: 1.785366\tAcc: 46/240 (19%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 3/8 (38%)\tLoss: 1.788311\tAcc: 39/240 (16%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 3/8 (38%)\tLoss: 1.792525\tAcc: 35/240 (15%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 3/8 (38%)\tLoss: 1.787838\tAcc: 43/240 (18%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 3/8 (38%)\tLoss: 1.790292\tAcc: 33/240 (14%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 4/8 (50%)\tLoss: 1.776548\tAcc: 42/240 (18%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 4/8 (50%)\tLoss: 1.781620\tAcc: 41/240 (17%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 4/8 (50%)\tLoss: 1.781968\tAcc: 34/240 (14%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 4/8 (50%)\tLoss: 1.780214\tAcc: 47/240 (20%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 5/8 (62%)\tLoss: 1.773842\tAcc: 81/240 (34%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 5/8 (62%)\tLoss: 1.777328\tAcc: 88/240 (37%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 5/8 (62%)\tLoss: 1.778240\tAcc: 80/240 (33%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 5/8 (62%)\tLoss: 1.783637\tAcc: 75/240 (31%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 6/8 (75%)\tLoss: 1.773687\tAcc: 76/240 (32%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 6/8 (75%)\tLoss: 1.762937\tAcc: 96/240 (40%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 6/8 (75%)\tLoss: 1.771331\tAcc: 84/240 (35%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 6/8 (75%)\tLoss: 1.778555\tAcc: 73/240 (30%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 7/8 (88%)\tLoss: 1.769883\tAcc: 63/240 (26%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 7/8 (88%)\tLoss: 1.767351\tAcc: 65/240 (27%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 7/8 (88%)\tLoss: 1.769453\tAcc: 61/240 (25%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 7/8 (88%)\tLoss: 1.765312\tAcc: 65/240 (27%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 8/8 (100%)\tLoss: 1.753327\tAcc: 14/48 (29%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 8/8 (100%)\tLoss: 1.767438\tAcc: 12/48 (25%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 8/8 (100%)\tLoss: 1.764982\tAcc: 14/48 (29%)\n[1,3]<stderr>:INFO:root:3: Memory Usage: 270.79296875, Training Duration: 58.08119380700009\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 8/8 (100%)\tLoss: 1.747697\tAcc: 10/48 (21%)\n[1,0]<stderr>:INFO:root:0: Memory Usage: 259.4453125, Training Duration: 58.11858031199881\n[1,2]<stderr>:INFO:root:2: Memory Usage: 258.27734375, Training Duration: 58.119937485000264\n[1,1]<stderr>:INFO:root:1: Memory Usage: 270.46484375, Training Duration: 58.12247213799856\n", "config": {"trainer": "horovod", "hosts": 4, "slots": 1, "parameters": {"--batch-size": 960, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "mpirun --bind-to none --map-by slot -np 4 --host 10.42.0.50:1,10.42.0.29:1,10.42.0.105:1,10.42.0.56:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 960 --epochs 1 --seed 123456789 --no-validation  distributed", "stdout": "", "stderr": "INFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Rank: 00   Start Epoch 0\nINFO:root:Rank: 03   Start Epoch 0\nINFO:root:Rank: 02   Start Epoch 0\nINFO:root:Rank: 01   Start Epoch 0\nINFO:root:Rank: 03   Train Batch: 1/8 (12%)\tLoss: 1.794597\tAcc: 45/240 (19%)\nINFO:root:Rank: 00   Train Batch: 1/8 (12%)\tLoss: 1.796704\tAcc: 35/240 (15%)\nINFO:root:Rank: 02   Train Batch: 1/8 (12%)\tLoss: 1.791708\tAcc: 36/240 (15%)\nINFO:root:Rank: 01   Train Batch: 1/8 (12%)\tLoss: 1.800225\tAcc: 41/240 (17%)\nINFO:root:Rank: 03   Train Batch: 2/8 (25%)\tLoss: 1.787668\tAcc: 48/240 (20%)\nINFO:root:Rank: 02   Train Batch: 2/8 (25%)\tLoss: 1.789782\tAcc: 39/240 (16%)\nINFO:root:Rank: 00   Train Batch: 2/8 (25%)\tLoss: 1.785366\tAcc: 46/240 (19%)\nINFO:root:Rank: 01   Train Batch: 2/8 (25%)\tLoss: 1.795439\tAcc: 37/240 (15%)\nINFO:root:Rank: 03   Train Batch: 3/8 (38%)\tLoss: 1.788311\tAcc: 39/240 (16%)\nINFO:root:Rank: 00   Train Batch: 3/8 (38%)\tLoss: 1.787838\tAcc: 43/240 (18%)\nINFO:root:Rank: 01   Train Batch: 3/8 (38%)\tLoss: 1.790292\tAcc: 33/240 (14%)\nINFO:root:Rank: 02   Train Batch: 3/8 (38%)\tLoss: 1.792525\tAcc: 35/240 (15%)\nINFO:root:Rank: 03   Train Batch: 4/8 (50%)\tLoss: 1.776548\tAcc: 42/240 (18%)\nINFO:root:Rank: 02   Train Batch: 4/8 (50%)\tLoss: 1.781968\tAcc: 34/240 (14%)\nINFO:root:Rank: 00   Train Batch: 4/8 (50%)\tLoss: 1.781620\tAcc: 41/240 (17%)\nINFO:root:Rank: 01   Train Batch: 4/8 (50%)\tLoss: 1.780214\tAcc: 47/240 (20%)\nINFO:root:Rank: 03   Train Batch: 5/8 (62%)\tLoss: 1.773842\tAcc: 81/240 (34%)\nINFO:root:Rank: 01   Train Batch: 5/8 (62%)\tLoss: 1.777328\tAcc: 88/240 (37%)\nINFO:root:Rank: 00   Train Batch: 5/8 (62%)\tLoss: 1.783637\tAcc: 75/240 (31%)\nINFO:root:Rank: 02   Train Batch: 5/8 (62%)\tLoss: 1.778240\tAcc: 80/240 (33%)\nINFO:root:Rank: 03   Train Batch: 6/8 (75%)\tLoss: 1.773687\tAcc: 76/240 (32%)\nINFO:root:Rank: 02   Train Batch: 6/8 (75%)\tLoss: 1.778555\tAcc: 73/240 (30%)\nINFO:root:Rank: 01   Train Batch: 6/8 (75%)\tLoss: 1.771331\tAcc: 84/240 (35%)\nINFO:root:Rank: 00   Train Batch: 6/8 (75%)\tLoss: 1.762937\tAcc: 96/240 (40%)\nINFO:root:Rank: 03   Train Batch: 7/8 (88%)\tLoss: 1.769883\tAcc: 63/240 (26%)\nINFO:root:Rank: 00   Train Batch: 7/8 (88%)\tLoss: 1.769453\tAcc: 61/240 (25%)\nINFO:root:Rank: 01   Train Batch: 7/8 (88%)\tLoss: 1.767351\tAcc: 65/240 (27%)\nINFO:root:Rank: 02   Train Batch: 7/8 (88%)\tLoss: 1.765312\tAcc: 65/240 (27%)\nINFO:root:Rank: 03   Train Batch: 8/8 (100%)\tLoss: 1.753327\tAcc: 14/48 (29%)\nINFO:root:Rank: 00   Train Batch: 8/8 (100%)\tLoss: 1.747697\tAcc: 10/48 (21%)\nINFO:root:3: Memory Usage: 267.0703125, Training Duration: 58.345186823000404\nINFO:root:Rank: 01   Train Batch: 8/8 (100%)\tLoss: 1.767438\tAcc: 12/48 (25%)\nINFO:root:Rank: 02   Train Batch: 8/8 (100%)\tLoss: 1.764982\tAcc: 14/48 (29%)\nINFO:root:0: Memory Usage: 270.09765625, Training Duration: 58.36983203099953\nINFO:root:2: Memory Usage: 270.109375, Training Duration: 58.376576323000336\nINFO:root:1: Memory Usage: 268.5234375, Training Duration: 58.380012142999476\n", "config": {"trainer": "distributed", "hosts": 4, "slots": 1, "parameters": {"--batch-size": 960, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "~/susml/jakob_torben/bin/horovodrun -np 1 --hosts 10.42.0.50:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 480 --epochs 1 --seed 123456789 --no-validation  horovod", "stdout": "", "stderr": "[1,0]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,0]<stderr>:INFO:root:Training set of size 6912\n[1,0]<stderr>:INFO:root:Training model for 1 epochs...\n[1,0]<stderr>:INFO:root:Rank: 00   Start Epoch 0\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 1/15 (7%)\tLoss: 1.796602\tAcc: 86/480 (18%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 2/15 (13%)\tLoss: 1.791447\tAcc: 71/480 (15%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 3/15 (20%)\tLoss: 1.786798\tAcc: 89/480 (19%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 4/15 (27%)\tLoss: 1.781988\tAcc: 81/480 (17%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 5/15 (33%)\tLoss: 1.783470\tAcc: 105/480 (22%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 6/15 (40%)\tLoss: 1.780052\tAcc: 154/480 (32%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 7/15 (47%)\tLoss: 1.764488\tAcc: 178/480 (37%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 8/15 (53%)\tLoss: 1.762511\tAcc: 165/480 (34%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 9/15 (60%)\tLoss: 1.755932\tAcc: 148/480 (31%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 10/15 (67%)\tLoss: 1.746263\tAcc: 132/480 (28%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 11/15 (73%)\tLoss: 1.732533\tAcc: 151/480 (31%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 12/15 (80%)\tLoss: 1.716881\tAcc: 167/480 (35%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 13/15 (87%)\tLoss: 1.697432\tAcc: 178/480 (37%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 14/15 (93%)\tLoss: 1.670410\tAcc: 186/480 (39%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 15/15 (100%)\tLoss: 1.616377\tAcc: 74/192 (39%)\n[1,0]<stderr>:INFO:root:0: Memory Usage: 377.58984375, Training Duration: 134.3877297809995\n", "config": {"trainer": "horovod", "hosts": 1, "slots": 1, "parameters": {"--batch-size": 480, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "~/susml/jakob_torben/bin/horovodrun -np 4 --hosts 10.42.0.50:1,10.42.0.29:1,10.42.0.105:1,10.42.0.56:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 480 --epochs 1 --seed 123456789 --no-validation  horovod", "stdout": "", "stderr": "[1,3]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,3]<stderr>:INFO:root:Training set of size 6912\n[1,1]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,1]<stderr>:INFO:root:Training set of size 6912\n[1,2]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,2]<stderr>:INFO:root:Training set of size 6912\n[1,0]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,0]<stderr>:INFO:root:Training set of size 6912\n[1,3]<stderr>:INFO:root:Training model for 1 epochs...\n[1,0]<stderr>:INFO:root:Training model for 1 epochs...\n[1,2]<stderr>:INFO:root:Training model for 1 epochs...\n[1,1]<stderr>:INFO:root:Training model for 1 epochs...\n[1,3]<stderr>:INFO:root:Rank: 03   Start Epoch 0\n[1,0]<stderr>:INFO:root:Rank: 00   Start Epoch 0\n[1,2]<stderr>:INFO:root:Rank: 02   Start Epoch 0\n[1,1]<stderr>:INFO:root:Rank: 01   Start Epoch 0\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 1/15 (7%)\tLoss: 1.793874\tAcc: 26/120 (22%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 1/15 (7%)\tLoss: 1.805541\tAcc: 20/120 (17%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 1/15 (7%)\tLoss: 1.789147\tAcc: 21/120 (18%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 1/15 (7%)\tLoss: 1.797848\tAcc: 19/120 (16%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 2/15 (13%)\tLoss: 1.792150\tAcc: 19/120 (16%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 2/15 (13%)\tLoss: 1.790044\tAcc: 21/120 (18%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 2/15 (13%)\tLoss: 1.791579\tAcc: 15/120 (12%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 2/15 (13%)\tLoss: 1.792014\tAcc: 16/120 (13%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 3/15 (20%)\tLoss: 1.791186\tAcc: 20/120 (17%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 3/15 (20%)\tLoss: 1.778889\tAcc: 29/120 (24%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 3/15 (20%)\tLoss: 1.794132\tAcc: 18/120 (15%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 3/15 (20%)\tLoss: 1.782983\tAcc: 22/120 (18%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 4/15 (27%)\tLoss: 1.776533\tAcc: 28/120 (23%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 4/15 (27%)\tLoss: 1.784508\tAcc: 19/120 (16%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 4/15 (27%)\tLoss: 1.783088\tAcc: 17/120 (14%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 4/15 (27%)\tLoss: 1.783818\tAcc: 17/120 (14%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 5/15 (33%)\tLoss: 1.781057\tAcc: 31/120 (26%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 5/15 (33%)\tLoss: 1.778255\tAcc: 28/120 (23%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 5/15 (33%)\tLoss: 1.789450\tAcc: 26/120 (22%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 5/15 (33%)\tLoss: 1.785117\tAcc: 20/120 (17%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 6/15 (40%)\tLoss: 1.780804\tAcc: 38/120 (32%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 6/15 (40%)\tLoss: 1.778938\tAcc: 43/120 (36%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 6/15 (40%)\tLoss: 1.783859\tAcc: 35/120 (29%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 6/15 (40%)\tLoss: 1.776608\tAcc: 38/120 (32%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 7/15 (47%)\tLoss: 1.760116\tAcc: 49/120 (41%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 7/15 (47%)\tLoss: 1.766646\tAcc: 44/120 (37%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 7/15 (47%)\tLoss: 1.759020\tAcc: 45/120 (38%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 7/15 (47%)\tLoss: 1.772170\tAcc: 40/120 (33%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 8/15 (53%)\tLoss: 1.757320\tAcc: 45/120 (38%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 8/15 (53%)\tLoss: 1.763847\tAcc: 40/120 (33%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 8/15 (53%)\tLoss: 1.771874\tAcc: 35/120 (29%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 8/15 (53%)\tLoss: 1.757003\tAcc: 45/120 (38%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 9/15 (60%)\tLoss: 1.742706\tAcc: 43/120 (36%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 9/15 (60%)\tLoss: 1.756727\tAcc: 38/120 (32%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 9/15 (60%)\tLoss: 1.765002\tAcc: 35/120 (29%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 9/15 (60%)\tLoss: 1.759296\tAcc: 32/120 (27%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 10/15 (67%)\tLoss: 1.746969\tAcc: 34/120 (28%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 10/15 (67%)\tLoss: 1.753661\tAcc: 29/120 (24%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 10/15 (67%)\tLoss: 1.739485\tAcc: 35/120 (29%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 10/15 (67%)\tLoss: 1.744939\tAcc: 34/120 (28%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 11/15 (73%)\tLoss: 1.733814\tAcc: 41/120 (34%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 11/15 (73%)\tLoss: 1.718971\tAcc: 45/120 (38%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 11/15 (73%)\tLoss: 1.747328\tAcc: 30/120 (25%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 11/15 (73%)\tLoss: 1.730019\tAcc: 35/120 (29%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 12/15 (80%)\tLoss: 1.711560\tAcc: 49/120 (41%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 12/15 (80%)\tLoss: 1.700533\tAcc: 46/120 (38%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 12/15 (80%)\tLoss: 1.749549\tAcc: 37/120 (31%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 12/15 (80%)\tLoss: 1.705886\tAcc: 35/120 (29%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 13/15 (87%)\tLoss: 1.703188\tAcc: 43/120 (36%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 13/15 (87%)\tLoss: 1.700113\tAcc: 42/120 (35%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 13/15 (87%)\tLoss: 1.692082\tAcc: 47/120 (39%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 13/15 (87%)\tLoss: 1.694347\tAcc: 46/120 (38%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 14/15 (93%)\tLoss: 1.663258\tAcc: 49/120 (41%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 14/15 (93%)\tLoss: 1.673202\tAcc: 41/120 (34%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 14/15 (93%)\tLoss: 1.673670\tAcc: 44/120 (37%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 14/15 (93%)\tLoss: 1.671510\tAcc: 52/120 (43%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 15/15 (100%)\tLoss: 1.607293\tAcc: 19/48 (40%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 15/15 (100%)\tLoss: 1.602928\tAcc: 19/48 (40%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 15/15 (100%)\tLoss: 1.623065\tAcc: 18/48 (38%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 15/15 (100%)\tLoss: 1.632223\tAcc: 18/48 (38%)\n[1,3]<stderr>:INFO:root:3: Memory Usage: 195.5546875, Training Duration: 75.82632003199978\n[1,0]<stderr>:INFO:root:0: Memory Usage: 194.78125, Training Duration: 75.85680683800092\n[1,1]<stderr>:INFO:root:1: Memory Usage: 194.4375, Training Duration: 75.85791183600304\n[1,2]<stderr>:INFO:root:2: Memory Usage: 196.5, Training Duration: 75.86714805700103\n", "config": {"trainer": "horovod", "hosts": 4, "slots": 1, "parameters": {"--batch-size": 480, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "mpirun --bind-to none --map-by slot -np 2 --host 10.42.0.50:1,10.42.0.29:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 1440 --epochs 1 --seed 123456789 --no-validation  distributed", "stdout": "", "stderr": "INFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Rank: 00   Start Epoch 0\nINFO:root:Rank: 01   Start Epoch 0\nINFO:root:Rank: 01   Train Batch: 1/5 (20%)\tLoss: 1.798722\tAcc: 124/720 (17%)\nINFO:root:Rank: 00   Train Batch: 1/5 (20%)\tLoss: 1.790705\tAcc: 122/720 (17%)\nINFO:root:Rank: 00   Train Batch: 2/5 (40%)\tLoss: 1.793001\tAcc: 112/720 (16%)\nINFO:root:Rank: 01   Train Batch: 2/5 (40%)\tLoss: 1.790506\tAcc: 119/720 (17%)\nINFO:root:Rank: 01   Train Batch: 3/5 (60%)\tLoss: 1.783072\tAcc: 126/720 (18%)\nINFO:root:Rank: 00   Train Batch: 3/5 (60%)\tLoss: 1.787134\tAcc: 110/720 (15%)\nINFO:root:Rank: 00   Train Batch: 4/5 (80%)\tLoss: 1.780652\tAcc: 136/720 (19%)\nINFO:root:Rank: 01   Train Batch: 4/5 (80%)\tLoss: 1.780844\tAcc: 123/720 (17%)\nINFO:root:Rank: 00   Train Batch: 5/5 (100%)\tLoss: 1.776130\tAcc: 201/576 (35%)\nINFO:root:Rank: 01   Train Batch: 5/5 (100%)\tLoss: 1.777994\tAcc: 196/576 (34%)\nINFO:root:0: Memory Usage: 493.703125, Training Duration: 78.78067585899771\nINFO:root:1: Memory Usage: 494.6640625, Training Duration: 78.78384580499915\n", "config": {"trainer": "distributed", "hosts": 2, "slots": 1, "parameters": {"--batch-size": 1440, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "mpirun --bind-to none --map-by slot -np 4 --host 10.42.0.50:1,10.42.0.29:1,10.42.0.105:1,10.42.0.56:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 1440 --epochs 1 --seed 123456789 --no-validation  distributed", "stdout": "", "stderr": "INFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Rank: 00   Start Epoch 0\nINFO:root:Rank: 02   Start Epoch 0\nINFO:root:Rank: 01   Start Epoch 0\nINFO:root:Rank: 03   Start Epoch 0\nINFO:root:Rank: 03   Train Batch: 1/5 (20%)\tLoss: 1.796772\tAcc: 65/360 (18%)\nINFO:root:Rank: 00   Train Batch: 1/5 (20%)\tLoss: 1.790949\tAcc: 64/360 (18%)\nINFO:root:Rank: 02   Train Batch: 1/5 (20%)\tLoss: 1.790460\tAcc: 58/360 (16%)\nINFO:root:Rank: 01   Train Batch: 1/5 (20%)\tLoss: 1.800672\tAcc: 59/360 (16%)\nINFO:root:Rank: 03   Train Batch: 2/5 (40%)\tLoss: 1.788009\tAcc: 67/360 (19%)\nINFO:root:Rank: 00   Train Batch: 2/5 (40%)\tLoss: 1.790112\tAcc: 60/360 (17%)\nINFO:root:Rank: 02   Train Batch: 2/5 (40%)\tLoss: 1.795892\tAcc: 52/360 (14%)\nINFO:root:Rank: 01   Train Batch: 2/5 (40%)\tLoss: 1.793004\tAcc: 52/360 (14%)\nINFO:root:Rank: 03   Train Batch: 3/5 (60%)\tLoss: 1.781274\tAcc: 59/360 (16%)\nINFO:root:Rank: 02   Train Batch: 3/5 (60%)\tLoss: 1.786356\tAcc: 50/360 (14%)\nINFO:root:Rank: 00   Train Batch: 3/5 (60%)\tLoss: 1.787912\tAcc: 60/360 (17%)\nINFO:root:Rank: 01   Train Batch: 3/5 (60%)\tLoss: 1.784872\tAcc: 67/360 (19%)\nINFO:root:Rank: 03   Train Batch: 4/5 (80%)\tLoss: 1.783068\tAcc: 54/360 (15%)\nINFO:root:Rank: 01   Train Batch: 4/5 (80%)\tLoss: 1.778621\tAcc: 69/360 (19%)\nINFO:root:Rank: 02   Train Batch: 4/5 (80%)\tLoss: 1.783753\tAcc: 69/360 (19%)\nINFO:root:Rank: 00   Train Batch: 4/5 (80%)\tLoss: 1.777548\tAcc: 67/360 (19%)\nINFO:root:Rank: 03   Train Batch: 5/5 (100%)\tLoss: 1.778251\tAcc: 96/288 (33%)\nINFO:root:Rank: 02   Train Batch: 5/5 (100%)\tLoss: 1.774406\tAcc: 109/288 (38%)\nINFO:root:Rank: 01   Train Batch: 5/5 (100%)\tLoss: 1.777737\tAcc: 100/288 (35%)\nINFO:root:3: Memory Usage: 321.30859375, Training Duration: 53.18861392599865\nINFO:root:Rank: 00   Train Batch: 5/5 (100%)\tLoss: 1.777852\tAcc: 92/288 (32%)\nINFO:root:2: Memory Usage: 319.0390625, Training Duration: 53.20863829600057\nINFO:root:1: Memory Usage: 320.625, Training Duration: 53.209471881000354\nINFO:root:0: Memory Usage: 340.12890625, Training Duration: 53.22217733799698\n", "config": {"trainer": "distributed", "hosts": 4, "slots": 1, "parameters": {"--batch-size": 1440, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "mpirun --bind-to none --map-by slot -np 1 --host 10.42.0.50:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 480 --epochs 1 --seed 123456789 --no-validation  distributed", "stdout": "", "stderr": "INFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Training model for 1 epochs...\nINFO:root:Rank: 00   Start Epoch 0\nINFO:root:Rank: 00   Train Batch: 1/15 (7%)\tLoss: 1.796602\tAcc: 86/480 (18%)\nINFO:root:Rank: 00   Train Batch: 2/15 (13%)\tLoss: 1.791447\tAcc: 71/480 (15%)\nINFO:root:Rank: 00   Train Batch: 3/15 (20%)\tLoss: 1.786798\tAcc: 89/480 (19%)\nINFO:root:Rank: 00   Train Batch: 4/15 (27%)\tLoss: 1.781988\tAcc: 81/480 (17%)\nINFO:root:Rank: 00   Train Batch: 5/15 (33%)\tLoss: 1.783470\tAcc: 105/480 (22%)\nINFO:root:Rank: 00   Train Batch: 6/15 (40%)\tLoss: 1.780052\tAcc: 154/480 (32%)\nINFO:root:Rank: 00   Train Batch: 7/15 (47%)\tLoss: 1.764488\tAcc: 178/480 (37%)\nINFO:root:Rank: 00   Train Batch: 8/15 (53%)\tLoss: 1.762511\tAcc: 165/480 (34%)\nINFO:root:Rank: 00   Train Batch: 9/15 (60%)\tLoss: 1.755932\tAcc: 148/480 (31%)\nINFO:root:Rank: 00   Train Batch: 10/15 (67%)\tLoss: 1.746263\tAcc: 132/480 (28%)\nINFO:root:Rank: 00   Train Batch: 11/15 (73%)\tLoss: 1.732533\tAcc: 151/480 (31%)\nINFO:root:Rank: 00   Train Batch: 12/15 (80%)\tLoss: 1.716881\tAcc: 167/480 (35%)\nINFO:root:Rank: 00   Train Batch: 13/15 (87%)\tLoss: 1.697432\tAcc: 178/480 (37%)\nINFO:root:Rank: 00   Train Batch: 14/15 (93%)\tLoss: 1.670410\tAcc: 186/480 (39%)\nINFO:root:Rank: 00   Train Batch: 15/15 (100%)\tLoss: 1.616377\tAcc: 74/192 (39%)\nINFO:root:0: Memory Usage: 403.26953125, Training Duration: 154.02800376899904\n", "config": {"trainer": "distributed", "hosts": 1, "slots": 1, "parameters": {"--batch-size": 480, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "mpirun --bind-to none --map-by slot -np 8 --host 10.42.0.50:1,10.42.0.29:1,10.42.0.105:1,10.42.0.56:1,10.42.0.180:1,10.42.0.235:1,10.42.0.244:1,10.42.0.239:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 480 --epochs 1 --seed 123456789 --no-validation  distributed", "stdout": "", "stderr": "INFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Rank: 00   Start Epoch 0\nINFO:root:Rank: 07   Start Epoch 0\nINFO:root:Rank: 06   Start Epoch 0\nINFO:root:Rank: 02   Start Epoch 0\nINFO:root:Rank: 01   Start Epoch 0\nINFO:root:Rank: 05   Start Epoch 0\nINFO:root:Rank: 04   Start Epoch 0\nINFO:root:Rank: 03   Start Epoch 0\nINFO:root:Rank: 03   Train Batch: 1/15 (7%)\tLoss: 1.791471\tAcc: 16/60 (27%)\nINFO:root:Rank: 04   Train Batch: 1/15 (7%)\tLoss: 1.799998\tAcc: 11/60 (18%)\nINFO:root:Rank: 05   Train Batch: 1/15 (7%)\tLoss: 1.795635\tAcc: 13/60 (22%)\nINFO:root:Rank: 06   Train Batch: 1/15 (7%)\tLoss: 1.794336\tAcc: 8/60 (13%)\nINFO:root:Rank: 02   Train Batch: 1/15 (7%)\tLoss: 1.783958\tAcc: 13/60 (22%)\nINFO:root:Rank: 07   Train Batch: 1/15 (7%)\tLoss: 1.796277\tAcc: 10/60 (17%)\nINFO:root:Rank: 00   Train Batch: 1/15 (7%)\tLoss: 1.795698\tAcc: 8/60 (13%)\nINFO:root:Rank: 01   Train Batch: 1/15 (7%)\tLoss: 1.815445\tAcc: 7/60 (12%)\nINFO:root:Rank: 04   Train Batch: 2/15 (13%)\tLoss: 1.797257\tAcc: 6/60 (10%)\nINFO:root:Rank: 05   Train Batch: 2/15 (13%)\tLoss: 1.783585\tAcc: 13/60 (22%)\nINFO:root:Rank: 01   Train Batch: 2/15 (13%)\tLoss: 1.796502\tAcc: 8/60 (13%)\nINFO:root:Rank: 03   Train Batch: 2/15 (13%)\tLoss: 1.792264\tAcc: 9/60 (15%)\nINFO:root:Rank: 00   Train Batch: 2/15 (13%)\tLoss: 1.786772\tAcc: 10/60 (17%)\nINFO:root:Rank: 02   Train Batch: 2/15 (13%)\tLoss: 1.790229\tAcc: 9/60 (15%)\nINFO:root:Rank: 07   Train Batch: 2/15 (13%)\tLoss: 1.792036\tAcc: 10/60 (17%)\nINFO:root:Rank: 06   Train Batch: 2/15 (13%)\tLoss: 1.792929\tAcc: 6/60 (10%)\nINFO:root:Rank: 04   Train Batch: 3/15 (20%)\tLoss: 1.774356\tAcc: 17/60 (28%)\nINFO:root:Rank: 03   Train Batch: 3/15 (20%)\tLoss: 1.801204\tAcc: 8/60 (13%)\nINFO:root:Rank: 05   Train Batch: 3/15 (20%)\tLoss: 1.794210\tAcc: 11/60 (18%)\nINFO:root:Rank: 01   Train Batch: 3/15 (20%)\tLoss: 1.794055\tAcc: 7/60 (12%)\nINFO:root:Rank: 07   Train Batch: 3/15 (20%)\tLoss: 1.781168\tAcc: 12/60 (20%)\nINFO:root:Rank: 06   Train Batch: 3/15 (20%)\tLoss: 1.779692\tAcc: 12/60 (20%)\nINFO:root:Rank: 02   Train Batch: 3/15 (20%)\tLoss: 1.786276\tAcc: 10/60 (17%)\nINFO:root:Rank: 00   Train Batch: 3/15 (20%)\tLoss: 1.783423\tAcc: 12/60 (20%)\nINFO:root:Rank: 00   Train Batch: 4/15 (27%)\tLoss: 1.782139\tAcc: 10/60 (17%)\nINFO:root:Rank: 05   Train Batch: 4/15 (27%)\tLoss: 1.800813\tAcc: 6/60 (10%)\nINFO:root:Rank: 03   Train Batch: 4/15 (27%)\tLoss: 1.779758\tAcc: 15/60 (25%)\nINFO:root:Rank: 02   Train Batch: 4/15 (27%)\tLoss: 1.784939\tAcc: 9/60 (15%)\nINFO:root:Rank: 06   Train Batch: 4/15 (27%)\tLoss: 1.781237\tAcc: 8/60 (13%)\nINFO:root:Rank: 07   Train Batch: 4/15 (27%)\tLoss: 1.773308\tAcc: 13/60 (22%)\nINFO:root:Rank: 04   Train Batch: 4/15 (27%)\tLoss: 1.785495\tAcc: 7/60 (12%)\nINFO:root:Rank: 01   Train Batch: 4/15 (27%)\tLoss: 1.768205\tAcc: 13/60 (22%)\nINFO:root:Rank: 05   Train Batch: 5/15 (33%)\tLoss: 1.786570\tAcc: 11/60 (18%)\nINFO:root:Rank: 03   Train Batch: 5/15 (33%)\tLoss: 1.779097\tAcc: 14/60 (23%)\nINFO:root:Rank: 02   Train Batch: 5/15 (33%)\tLoss: 1.789508\tAcc: 13/60 (22%)\nINFO:root:Rank: 06   Train Batch: 5/15 (33%)\tLoss: 1.789392\tAcc: 13/60 (22%)\nINFO:root:Rank: 00   Train Batch: 5/15 (33%)\tLoss: 1.803673\tAcc: 13/60 (22%)\nINFO:root:Rank: 04   Train Batch: 5/15 (33%)\tLoss: 1.758441\tAcc: 18/60 (30%)\nINFO:root:Rank: 07   Train Batch: 5/15 (33%)\tLoss: 1.777412\tAcc: 14/60 (23%)\nINFO:root:Rank: 01   Train Batch: 5/15 (33%)\tLoss: 1.783664\tAcc: 9/60 (15%)\nINFO:root:Rank: 05   Train Batch: 6/15 (40%)\tLoss: 1.778759\tAcc: 18/60 (30%)\nINFO:root:Rank: 03   Train Batch: 6/15 (40%)\tLoss: 1.785305\tAcc: 17/60 (28%)\nINFO:root:Rank: 02   Train Batch: 6/15 (40%)\tLoss: 1.764941\tAcc: 23/60 (38%)\nINFO:root:Rank: 06   Train Batch: 6/15 (40%)\tLoss: 1.788276\tAcc: 15/60 (25%)\nINFO:root:Rank: 01   Train Batch: 6/15 (40%)\tLoss: 1.788962\tAcc: 17/60 (28%)\nINFO:root:Rank: 00   Train Batch: 6/15 (40%)\tLoss: 1.772640\tAcc: 22/60 (37%)\nINFO:root:Rank: 07   Train Batch: 6/15 (40%)\tLoss: 1.776305\tAcc: 21/60 (35%)\nINFO:root:Rank: 04   Train Batch: 6/15 (40%)\tLoss: 1.785236\tAcc: 21/60 (35%)\nINFO:root:Rank: 05   Train Batch: 7/15 (47%)\tLoss: 1.765505\tAcc: 23/60 (38%)\nINFO:root:Rank: 01   Train Batch: 7/15 (47%)\tLoss: 1.767788\tAcc: 21/60 (35%)\nINFO:root:Rank: 03   Train Batch: 7/15 (47%)\tLoss: 1.755203\tAcc: 25/60 (42%)\nINFO:root:Rank: 07   Train Batch: 7/15 (47%)\tLoss: 1.765027\tAcc: 24/60 (40%)\nINFO:root:Rank: 04   Train Batch: 7/15 (47%)\tLoss: 1.760878\tAcc: 21/60 (35%)\nINFO:root:Rank: 06   Train Batch: 7/15 (47%)\tLoss: 1.770635\tAcc: 22/60 (37%)\nINFO:root:Rank: 00   Train Batch: 7/15 (47%)\tLoss: 1.757161\tAcc: 24/60 (40%)\nINFO:root:Rank: 02   Train Batch: 7/15 (47%)\tLoss: 1.773705\tAcc: 18/60 (30%)\nINFO:root:Rank: 02   Train Batch: 8/15 (53%)\tLoss: 1.757252\tAcc: 24/60 (40%)\nINFO:root:Rank: 05   Train Batch: 8/15 (53%)\tLoss: 1.763002\tAcc: 20/60 (33%)\nINFO:root:Rank: 06   Train Batch: 8/15 (53%)\tLoss: 1.756754\tAcc: 21/60 (35%)\nINFO:root:Rank: 01   Train Batch: 8/15 (53%)\tLoss: 1.764693\tAcc: 20/60 (33%)\nINFO:root:Rank: 07   Train Batch: 8/15 (53%)\tLoss: 1.765437\tAcc: 18/60 (30%)\nINFO:root:Rank: 04   Train Batch: 8/15 (53%)\tLoss: 1.779587\tAcc: 19/60 (32%)\nINFO:root:Rank: 00   Train Batch: 8/15 (53%)\tLoss: 1.764163\tAcc: 16/60 (27%)\nINFO:root:Rank: 03   Train Batch: 8/15 (53%)\tLoss: 1.749203\tAcc: 27/60 (45%)\nINFO:root:Rank: 06   Train Batch: 9/15 (60%)\tLoss: 1.749181\tAcc: 22/60 (37%)\nINFO:root:Rank: 05   Train Batch: 9/15 (60%)\tLoss: 1.753716\tAcc: 19/60 (32%)\nINFO:root:Rank: 01   Train Batch: 9/15 (60%)\tLoss: 1.764877\tAcc: 13/60 (22%)\nINFO:root:Rank: 07   Train Batch: 9/15 (60%)\tLoss: 1.747918\tAcc: 19/60 (32%)\nINFO:root:Rank: 02   Train Batch: 9/15 (60%)\tLoss: 1.764273\tAcc: 16/60 (27%)\nINFO:root:Rank: 04   Train Batch: 9/15 (60%)\tLoss: 1.773916\tAcc: 13/60 (22%)\nINFO:root:Rank: 03   Train Batch: 9/15 (60%)\tLoss: 1.737493\tAcc: 24/60 (40%)\nINFO:root:Rank: 00   Train Batch: 9/15 (60%)\tLoss: 1.756087\tAcc: 22/60 (37%)\nINFO:root:Rank: 05   Train Batch: 10/15 (67%)\tLoss: 1.723689\tAcc: 21/60 (35%)\nINFO:root:Rank: 04   Train Batch: 10/15 (67%)\tLoss: 1.745704\tAcc: 17/60 (28%)\nINFO:root:Rank: 02   Train Batch: 10/15 (67%)\tLoss: 1.752985\tAcc: 15/60 (25%)\nINFO:root:Rank: 03   Train Batch: 10/15 (67%)\tLoss: 1.758090\tAcc: 15/60 (25%)\nINFO:root:Rank: 01   Train Batch: 10/15 (67%)\tLoss: 1.755282\tAcc: 14/60 (23%)\nINFO:root:Rank: 06   Train Batch: 10/15 (67%)\tLoss: 1.754338\tAcc: 14/60 (23%)\nINFO:root:Rank: 07   Train Batch: 10/15 (67%)\tLoss: 1.735850\tAcc: 19/60 (32%)\nINFO:root:Rank: 00   Train Batch: 10/15 (67%)\tLoss: 1.744175\tAcc: 17/60 (28%)\nINFO:root:Rank: 04   Train Batch: 11/15 (73%)\tLoss: 1.729381\tAcc: 21/60 (35%)\nINFO:root:Rank: 01   Train Batch: 11/15 (73%)\tLoss: 1.768323\tAcc: 11/60 (18%)\nINFO:root:Rank: 03   Train Batch: 11/15 (73%)\tLoss: 1.734643\tAcc: 20/60 (33%)\nINFO:root:Rank: 05   Train Batch: 11/15 (73%)\tLoss: 1.726334\tAcc: 19/60 (32%)\nINFO:root:Rank: 02   Train Batch: 11/15 (73%)\tLoss: 1.721262\tAcc: 19/60 (32%)\nINFO:root:Rank: 07   Train Batch: 11/15 (73%)\tLoss: 1.732986\tAcc: 21/60 (35%)\nINFO:root:Rank: 06   Train Batch: 11/15 (73%)\tLoss: 1.738776\tAcc: 16/60 (27%)\nINFO:root:Rank: 00   Train Batch: 11/15 (73%)\tLoss: 1.708559\tAcc: 24/60 (40%)\nINFO:root:Rank: 05   Train Batch: 12/15 (80%)\tLoss: 1.700341\tAcc: 17/60 (28%)\nINFO:root:Rank: 03   Train Batch: 12/15 (80%)\tLoss: 1.717922\tAcc: 27/60 (45%)\nINFO:root:Rank: 04   Train Batch: 12/15 (80%)\tLoss: 1.706733\tAcc: 22/60 (37%)\nINFO:root:Rank: 06   Train Batch: 12/15 (80%)\tLoss: 1.740384\tAcc: 20/60 (33%)\nINFO:root:Rank: 01   Train Batch: 12/15 (80%)\tLoss: 1.711430\tAcc: 18/60 (30%)\nINFO:root:Rank: 07   Train Batch: 12/15 (80%)\tLoss: 1.705196\tAcc: 22/60 (37%)\nINFO:root:Rank: 02   Train Batch: 12/15 (80%)\tLoss: 1.758714\tAcc: 17/60 (28%)\nINFO:root:Rank: 00   Train Batch: 12/15 (80%)\tLoss: 1.694333\tAcc: 24/60 (40%)\nINFO:root:Rank: 03   Train Batch: 13/15 (87%)\tLoss: 1.686165\tAcc: 24/60 (40%)\nINFO:root:Rank: 04   Train Batch: 13/15 (87%)\tLoss: 1.731753\tAcc: 19/60 (32%)\nINFO:root:Rank: 01   Train Batch: 13/15 (87%)\tLoss: 1.689152\tAcc: 24/60 (40%)\nINFO:root:Rank: 07   Train Batch: 13/15 (87%)\tLoss: 1.720210\tAcc: 19/60 (32%)\nINFO:root:Rank: 06   Train Batch: 13/15 (87%)\tLoss: 1.690273\tAcc: 25/60 (42%)\nINFO:root:Rank: 02   Train Batch: 13/15 (87%)\tLoss: 1.693890\tAcc: 22/60 (37%)\nINFO:root:Rank: 00   Train Batch: 13/15 (87%)\tLoss: 1.668473\tAcc: 23/60 (38%)\nINFO:root:Rank: 05   Train Batch: 13/15 (87%)\tLoss: 1.699543\tAcc: 22/60 (37%)\nINFO:root:Rank: 05   Train Batch: 14/15 (93%)\tLoss: 1.650251\tAcc: 32/60 (53%)\nINFO:root:Rank: 04   Train Batch: 14/15 (93%)\tLoss: 1.688062\tAcc: 21/60 (35%)\nINFO:root:Rank: 01   Train Batch: 14/15 (93%)\tLoss: 1.692770\tAcc: 20/60 (33%)\nINFO:root:Rank: 03   Train Batch: 14/15 (93%)\tLoss: 1.666370\tAcc: 22/60 (37%)\nINFO:root:Rank: 07   Train Batch: 14/15 (93%)\tLoss: 1.660146\tAcc: 27/60 (45%)\nINFO:root:Rank: 00   Train Batch: 14/15 (93%)\tLoss: 1.659278\tAcc: 23/60 (38%)\nINFO:root:Rank: 02   Train Batch: 14/15 (93%)\tLoss: 1.691315\tAcc: 21/60 (35%)\nINFO:root:Rank: 06   Train Batch: 14/15 (93%)\tLoss: 1.655089\tAcc: 20/60 (33%)\nINFO:root:Rank: 04   Train Batch: 15/15 (100%)\tLoss: 1.528609\tAcc: 12/24 (50%)\nINFO:root:Rank: 00   Train Batch: 15/15 (100%)\tLoss: 1.677247\tAcc: 7/24 (29%)\nINFO:root:Rank: 03   Train Batch: 15/15 (100%)\tLoss: 1.559363\tAcc: 10/24 (42%)\nINFO:root:Rank: 07   Train Batch: 15/15 (100%)\tLoss: 1.655223\tAcc: 9/24 (38%)\nINFO:root:Rank: 05   Train Batch: 15/15 (100%)\tLoss: 1.635092\tAcc: 10/24 (42%)\nINFO:root:Rank: 01   Train Batch: 15/15 (100%)\tLoss: 1.611036\tAcc: 8/24 (33%)\nINFO:root:Rank: 02   Train Batch: 15/15 (100%)\tLoss: 1.677636\tAcc: 7/24 (29%)\nINFO:root:Rank: 06   Train Batch: 15/15 (100%)\tLoss: 1.586809\tAcc: 11/24 (46%)\nINFO:root:4: Memory Usage: 166.7265625, Training Duration: 30.47149076200003\nINFO:root:1: Memory Usage: 166.82421875, Training Duration: 30.49317678999796\nINFO:root:2: Memory Usage: 165.84375, Training Duration: 30.49422316500204\nINFO:root:7: Memory Usage: 165.4609375, Training Duration: 30.496024731000944\nINFO:root:6: Memory Usage: 166.44140625, Training Duration: 30.49353926099866\nINFO:root:5: Memory Usage: 165.15625, Training Duration: 30.493328589000157\nINFO:root:3: Memory Usage: 166.6171875, Training Duration: 30.49328403400068\nINFO:root:0: Memory Usage: 167.80078125, Training Duration: 30.500788301000284\n", "config": {"trainer": "distributed", "hosts": 8, "slots": 1, "parameters": {"--batch-size": 480, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "~/susml/jakob_torben/bin/horovodrun -np 12 --hosts 10.42.0.50:1,10.42.0.29:1,10.42.0.105:1,10.42.0.56:1,10.42.0.180:1,10.42.0.235:1,10.42.0.244:1,10.42.0.239:1,10.42.0.191:1,10.42.0.41:1,10.42.0.190:1,10.42.0.69:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 960 --epochs 1 --seed 123456789 --no-validation  horovod", "stdout": "", "stderr": "[1,10]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,10]<stderr>:INFO:root:Training set of size 6912\n[1,9]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,9]<stderr>:INFO:root:Training set of size 6912\n[1,5]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,5]<stderr>:INFO:root:Training set of size 6912\n[1,4]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,4]<stderr>:INFO:root:Training set of size 6912\n[1,7]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,7]<stderr>:INFO:root:Training set of size 6912\n[1,3]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,3]<stderr>:INFO:root:Training set of size 6912\n[1,6]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,6]<stderr>:INFO:root:Training set of size 6912\n[1,11]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,11]<stderr>:INFO:root:Training set of size 6912\n[1,1]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,1]<stderr>:INFO:root:Training set of size 6912\n[1,8]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,8]<stderr>:INFO:root:Training set of size 6912\n[1,2]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,2]<stderr>:INFO:root:Training set of size 6912\n[1,0]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,0]<stderr>:INFO:root:Training set of size 6912\n[1,6]<stderr>:INFO:root:Training model for 1 epochs...\n[1,3]<stderr>:INFO:root:Training model for 1 epochs...\n[1,9]<stderr>:INFO:root:Training model for 1 epochs...\n[1,11]<stderr>:INFO:root:Training model for 1 epochs...\n[1,7]<stderr>:INFO:root:Training model for 1 epochs...\n[1,5]<stderr>:INFO:root:Training model for 1 epochs...\n[1,10]<stderr>:INFO:root:Training model for 1 epochs...\n[1,4]<stderr>:INFO:root:Training model for 1 epochs...\n[1,1]<stderr>:INFO:root:Training model for 1 epochs...\n[1,2]<stderr>:INFO:root:Training model for 1 epochs...\n[1,8]<stderr>:INFO:root:Training model for 1 epochs...\n[1,0]<stderr>:INFO:root:Training model for 1 epochs...\n[1,4]<stderr>:INFO:root:Rank: 04   Start Epoch 0\n[1,9]<stderr>:INFO:root:Rank: 09   Start Epoch 0\n[1,10]<stderr>:INFO:root:Rank: 10   Start Epoch 0\n[1,7]<stderr>:INFO:root:Rank: 07   Start Epoch 0\n[1,5]<stderr>:INFO:root:Rank: 05   Start Epoch 0\n[1,3]<stderr>:INFO:root:Rank: 03   Start Epoch 0\n[1,6]<stderr>:INFO:root:Rank: 06   Start Epoch 0\n[1,0]<stderr>:INFO:root:Rank: 00   Start Epoch 0\n[1,1]<stderr>:INFO:root:Rank: 01   Start Epoch 0\n[1,11]<stderr>:INFO:root:Rank: 11   Start Epoch 0\n[1,8]<stderr>:INFO:root:Rank: 08   Start Epoch 0\n[1,2]<stderr>:INFO:root:Rank: 02   Start Epoch 0\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 1/8 (12%)\tLoss: 1.800863\tAcc: 13/80 (16%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 1/8 (12%)\tLoss: 1.797465\tAcc: 13/80 (16%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 1/8 (12%)\tLoss: 1.779391\tAcc: 16/80 (20%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 1/8 (12%)\tLoss: 1.787234\tAcc: 13/80 (16%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 1/8 (12%)\tLoss: 1.793659\tAcc: 15/80 (19%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 1/8 (12%)\tLoss: 1.792639\tAcc: 12/80 (15%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 1/8 (12%)\tLoss: 1.779261\tAcc: 17/80 (21%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 1/8 (12%)\tLoss: 1.809552\tAcc: 13/80 (16%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 1/8 (12%)\tLoss: 1.795578\tAcc: 13/80 (16%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 1/8 (12%)\tLoss: 1.808632\tAcc: 6/80 (8%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 1/8 (12%)\tLoss: 1.803537\tAcc: 16/80 (20%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 1/8 (12%)\tLoss: 1.801895\tAcc: 10/80 (12%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 2/8 (25%)\tLoss: 1.792155\tAcc: 15/80 (19%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 2/8 (25%)\tLoss: 1.795076\tAcc: 12/80 (15%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 2/8 (25%)\tLoss: 1.796296\tAcc: 10/80 (12%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 2/8 (25%)\tLoss: 1.791194\tAcc: 19/80 (24%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 2/8 (25%)\tLoss: 1.799178\tAcc: 9/80 (11%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 2/8 (25%)\tLoss: 1.779631\tAcc: 18/80 (22%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 2/8 (25%)\tLoss: 1.793418\tAcc: 11/80 (14%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 2/8 (25%)\tLoss: 1.795073\tAcc: 11/80 (14%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 2/8 (25%)\tLoss: 1.779534\tAcc: 17/80 (21%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 2/8 (25%)\tLoss: 1.781491\tAcc: 17/80 (21%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 2/8 (25%)\tLoss: 1.775772\tAcc: 22/80 (28%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 2/8 (25%)\tLoss: 1.795943\tAcc: 9/80 (11%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 3/8 (38%)\tLoss: 1.788152\tAcc: 11/80 (14%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 3/8 (38%)\tLoss: 1.795199\tAcc: 12/80 (15%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 3/8 (38%)\tLoss: 1.796087\tAcc: 14/80 (18%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 3/8 (38%)\tLoss: 1.788695\tAcc: 13/80 (16%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 3/8 (38%)\tLoss: 1.787497\tAcc: 10/80 (12%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 3/8 (38%)\tLoss: 1.795227\tAcc: 12/80 (15%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 3/8 (38%)\tLoss: 1.809039\tAcc: 6/80 (8%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 3/8 (38%)\tLoss: 1.781328\tAcc: 15/80 (19%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 3/8 (38%)\tLoss: 1.793736\tAcc: 15/80 (19%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 3/8 (38%)\tLoss: 1.779842\tAcc: 16/80 (20%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 3/8 (38%)\tLoss: 1.786099\tAcc: 14/80 (18%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 3/8 (38%)\tLoss: 1.775995\tAcc: 12/80 (15%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 4/8 (50%)\tLoss: 1.781332\tAcc: 19/80 (24%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 4/8 (50%)\tLoss: 1.785292\tAcc: 11/80 (14%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 4/8 (50%)\tLoss: 1.781255\tAcc: 15/80 (19%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 4/8 (50%)\tLoss: 1.776013\tAcc: 17/80 (21%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 4/8 (50%)\tLoss: 1.784699\tAcc: 9/80 (11%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 4/8 (50%)\tLoss: 1.769831\tAcc: 18/80 (22%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 4/8 (50%)\tLoss: 1.799366\tAcc: 9/80 (11%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 4/8 (50%)\tLoss: 1.769480\tAcc: 15/80 (19%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 4/8 (50%)\tLoss: 1.785731\tAcc: 10/80 (12%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 4/8 (50%)\tLoss: 1.775472\tAcc: 15/80 (19%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 4/8 (50%)\tLoss: 1.763095\tAcc: 16/80 (20%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 4/8 (50%)\tLoss: 1.789480\tAcc: 10/80 (12%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 5/8 (62%)\tLoss: 1.776414\tAcc: 32/80 (40%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 5/8 (62%)\tLoss: 1.768812\tAcc: 30/80 (38%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 5/8 (62%)\tLoss: 1.786990\tAcc: 22/80 (28%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 5/8 (62%)\tLoss: 1.784448\tAcc: 27/80 (34%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 5/8 (62%)\tLoss: 1.768363\tAcc: 26/80 (32%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 5/8 (62%)\tLoss: 1.775463\tAcc: 29/80 (36%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 5/8 (62%)\tLoss: 1.778921\tAcc: 28/80 (35%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 5/8 (62%)\tLoss: 1.774956\tAcc: 32/80 (40%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 5/8 (62%)\tLoss: 1.780106\tAcc: 27/80 (34%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 5/8 (62%)\tLoss: 1.787540\tAcc: 27/80 (34%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 5/8 (62%)\tLoss: 1.778210\tAcc: 23/80 (29%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 5/8 (62%)\tLoss: 1.778922\tAcc: 21/80 (26%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 6/8 (75%)\tLoss: 1.776635\tAcc: 28/80 (35%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 6/8 (75%)\tLoss: 1.754879\tAcc: 34/80 (42%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 6/8 (75%)\tLoss: 1.776536\tAcc: 23/80 (29%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 6/8 (75%)\tLoss: 1.773679\tAcc: 28/80 (35%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 6/8 (75%)\tLoss: 1.768995\tAcc: 28/80 (35%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 6/8 (75%)\tLoss: 1.760126\tAcc: 32/80 (40%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 6/8 (75%)\tLoss: 1.775579\tAcc: 25/80 (31%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 6/8 (75%)\tLoss: 1.764732\tAcc: 31/80 (39%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 6/8 (75%)\tLoss: 1.773803\tAcc: 30/80 (38%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 6/8 (75%)\tLoss: 1.773386\tAcc: 23/80 (29%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 6/8 (75%)\tLoss: 1.775529\tAcc: 25/80 (31%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 6/8 (75%)\tLoss: 1.785643\tAcc: 22/80 (28%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 7/8 (88%)\tLoss: 1.771538\tAcc: 20/80 (25%)\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 7/8 (88%)\tLoss: 1.769479\tAcc: 19/80 (24%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 7/8 (88%)\tLoss: 1.770405\tAcc: 20/80 (25%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 7/8 (88%)\tLoss: 1.767138\tAcc: 24/80 (30%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 7/8 (88%)\tLoss: 1.766892\tAcc: 18/80 (22%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 7/8 (88%)\tLoss: 1.765435\tAcc: 22/80 (28%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 7/8 (88%)\tLoss: 1.766662\tAcc: 19/80 (24%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 7/8 (88%)\tLoss: 1.781106\tAcc: 20/80 (25%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 7/8 (88%)\tLoss: 1.774825\tAcc: 18/80 (22%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 7/8 (88%)\tLoss: 1.760362\tAcc: 23/80 (29%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 7/8 (88%)\tLoss: 1.768162\tAcc: 26/80 (32%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 7/8 (88%)\tLoss: 1.753992\tAcc: 25/80 (31%)\n[1,10]<stderr>:INFO:root:Rank: 10   Train Batch: 8/8 (100%)\tLoss: 1.803307\tAcc: 4/16 (25%)\n[1,4]<stderr>:INFO:root:Rank: 04   Train Batch: 8/8 (100%)\tLoss: 1.735974\tAcc: 4/16 (25%)\n[1,7]<stderr>:INFO:root:Rank: 07   Train Batch: 8/8 (100%)\tLoss: 1.750543\tAcc: 6/16 (38%)\n[1,11]<stderr>:INFO:root:Rank: 11   Train Batch: 8/8 (100%)\tLoss: 1.759211\tAcc: 3/16 (19%)\n[1,5]<stderr>:INFO:root:Rank: 05   Train Batch: 8/8 (100%)\tLoss: 1.719096\tAcc: 5/16 (31%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 8/8 (100%)\tLoss: 1.713695\tAcc: 6/16 (38%)\n[1,6]<stderr>:INFO:root:Rank: 06   Train Batch: 8/8 (100%)\tLoss: 1.777941\tAcc: 4/16 (25%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 8/8 (100%)\tLoss: 1.736825\tAcc: 3/16 (19%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 8/8 (100%)\tLoss: 1.750226\tAcc: 5/16 (31%)\n[1,8]<stderr>:INFO:root:Rank: 08   Train Batch: 8/8 (100%)\tLoss: 1.770292\tAcc: 3/16 (19%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 8/8 (100%)\tLoss: 1.785286\tAcc: 4/16 (25%)\n[1,10]<stderr>:INFO:root:10: Memory Usage: 173.96875, Training Duration: 63.47649234900018\n[1,9]<stderr>:INFO:root:Rank: 09   Train Batch: 8/8 (100%)\tLoss: 1.797932\tAcc: 3/16 (19%)\n[1,11]<stderr>:INFO:root:11: Memory Usage: 174.0234375, Training Duration: 63.49902283800111\n[1,7]<stderr>:INFO:root:7: Memory Usage: 173.59375, Training Duration: 63.50029974399877\n[1,2]<stderr>:INFO:root:2: Memory Usage: 173.31640625, Training Duration: 63.50050910900245\n[1,0]<stderr>:INFO:root:0: Memory Usage: 173.79296875, Training Duration: 63.510115967001184\n[1,5]<stderr>:INFO:root:5: Memory Usage: 173.83203125, Training Duration: 63.50771037799859\n[1,9]<stderr>:INFO:root:9: Memory Usage: 173.3359375, Training Duration: 63.50881029000084\n[1,1]<stderr>:INFO:root:1: Memory Usage: 173.81640625, Training Duration: 63.51764144399931\n[1,4]<stderr>:INFO:root:4: Memory Usage: 173.21875, Training Duration: 63.51884475899715\n[1,8]<stderr>:INFO:root:8: Memory Usage: 174.27734375, Training Duration: 63.51940340799774\n[1,3]<stderr>:INFO:root:3: Memory Usage: 175.015625, Training Duration: 63.52016133200232\n[1,6]<stderr>:INFO:root:6: Memory Usage: 173.73046875, Training Duration: 63.521368997000536\n", "config": {"trainer": "horovod", "hosts": 12, "slots": 1, "parameters": {"--batch-size": 960, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "mpirun --bind-to none --map-by slot -np 1 --host 10.42.0.50:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 960 --epochs 1 --seed 123456789 --no-validation  distributed", "stdout": "", "stderr": "INFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Training model for 1 epochs...\nINFO:root:Rank: 00   Start Epoch 0\nINFO:root:Rank: 00   Train Batch: 1/8 (12%)\tLoss: 1.795809\tAcc: 157/960 (16%)\nINFO:root:Rank: 00   Train Batch: 2/8 (25%)\tLoss: 1.789564\tAcc: 170/960 (18%)\nINFO:root:Rank: 00   Train Batch: 3/8 (38%)\tLoss: 1.789741\tAcc: 150/960 (16%)\nINFO:root:Rank: 00   Train Batch: 4/8 (50%)\tLoss: 1.780087\tAcc: 164/960 (17%)\nINFO:root:Rank: 00   Train Batch: 5/8 (62%)\tLoss: 1.778262\tAcc: 324/960 (34%)\nINFO:root:Rank: 00   Train Batch: 6/8 (75%)\tLoss: 1.771628\tAcc: 329/960 (34%)\nINFO:root:Rank: 00   Train Batch: 7/8 (88%)\tLoss: 1.768000\tAcc: 254/960 (26%)\nINFO:root:Rank: 00   Train Batch: 8/8 (100%)\tLoss: 1.758361\tAcc: 50/192 (26%)\nINFO:root:0: Memory Usage: 602.8828125, Training Duration: 128.89368049199766\n", "config": {"trainer": "distributed", "hosts": 1, "slots": 1, "parameters": {"--batch-size": 960, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "~/susml/jakob_torben/bin/horovodrun -np 4 --hosts 10.42.0.50:1,10.42.0.29:1,10.42.0.105:1,10.42.0.56:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 1440 --epochs 1 --seed 123456789 --no-validation  horovod", "stdout": "", "stderr": "[1,3]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,3]<stderr>:INFO:root:Training set of size 6912\n[1,1]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,1]<stderr>:INFO:root:Training set of size 6912\n[1,2]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,2]<stderr>:INFO:root:Training set of size 6912\n[1,0]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,0]<stderr>:INFO:root:Training set of size 6912\n[1,2]<stderr>:INFO:root:Training model for 1 epochs...\n[1,3]<stderr>:INFO:root:Training model for 1 epochs...\n[1,1]<stderr>:INFO:root:Training model for 1 epochs...\n[1,0]<stderr>:INFO:root:Training model for 1 epochs...\n[1,3]<stderr>:INFO:root:Rank: 03   Start Epoch 0\n[1,2]<stderr>:INFO:root:Rank: 02   Start Epoch 0\n[1,0]<stderr>:INFO:root:Rank: 00   Start Epoch 0\n[1,1]<stderr>:INFO:root:Rank: 01   Start Epoch 0\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 1/5 (20%)\tLoss: 1.796772\tAcc: 65/360 (18%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 1/5 (20%)\tLoss: 1.800672\tAcc: 59/360 (16%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 1/5 (20%)\tLoss: 1.790949\tAcc: 64/360 (18%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 1/5 (20%)\tLoss: 1.790460\tAcc: 58/360 (16%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 2/5 (40%)\tLoss: 1.788009\tAcc: 67/360 (19%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 2/5 (40%)\tLoss: 1.795892\tAcc: 52/360 (14%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 2/5 (40%)\tLoss: 1.790112\tAcc: 60/360 (17%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 2/5 (40%)\tLoss: 1.793004\tAcc: 52/360 (14%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 3/5 (60%)\tLoss: 1.781274\tAcc: 59/360 (16%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 3/5 (60%)\tLoss: 1.784872\tAcc: 67/360 (19%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 3/5 (60%)\tLoss: 1.787912\tAcc: 60/360 (17%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 3/5 (60%)\tLoss: 1.786356\tAcc: 50/360 (14%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 4/5 (80%)\tLoss: 1.783068\tAcc: 54/360 (15%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 4/5 (80%)\tLoss: 1.777548\tAcc: 67/360 (19%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 4/5 (80%)\tLoss: 1.778621\tAcc: 69/360 (19%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 4/5 (80%)\tLoss: 1.783753\tAcc: 69/360 (19%)\n[1,3]<stderr>:INFO:root:Rank: 03   Train Batch: 5/5 (100%)\tLoss: 1.778251\tAcc: 96/288 (33%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 5/5 (100%)\tLoss: 1.777852\tAcc: 92/288 (32%)\n[1,2]<stderr>:INFO:root:Rank: 02   Train Batch: 5/5 (100%)\tLoss: 1.774406\tAcc: 109/288 (38%)\n[1,1]<stderr>:INFO:root:Rank: 01   Train Batch: 5/5 (100%)\tLoss: 1.777737\tAcc: 100/288 (35%)\n[1,3]<stderr>:INFO:root:3: Memory Usage: 319.5703125, Training Duration: 64.94517960300072\n[1,0]<stderr>:INFO:root:0: Memory Usage: 320.21875, Training Duration: 64.97295075500006\n[1,1]<stderr>:INFO:root:1: Memory Usage: 340.70703125, Training Duration: 64.97587651800131\n[1,2]<stderr>:INFO:root:2: Memory Usage: 318.78125, Training Duration: 64.97949041200263\n", "config": {"trainer": "horovod", "hosts": 4, "slots": 1, "parameters": {"--batch-size": 1440, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 960 --epochs 1 --seed 123456789 --no-validation  local", "stdout": "", "stderr": "INFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Training model for 1 epochs...\nINFO:root:Rank: 00   Start Epoch 0\nINFO:root:Rank: 00   Train Batch: 1/8 (12%)\tLoss: 1.795809\tAcc: 157/960 (16%)\nINFO:root:Rank: 00   Train Batch: 2/8 (25%)\tLoss: 1.789564\tAcc: 170/960 (18%)\nINFO:root:Rank: 00   Train Batch: 3/8 (38%)\tLoss: 1.789741\tAcc: 150/960 (16%)\nINFO:root:Rank: 00   Train Batch: 4/8 (50%)\tLoss: 1.780087\tAcc: 164/960 (17%)\nINFO:root:Rank: 00   Train Batch: 5/8 (62%)\tLoss: 1.778262\tAcc: 324/960 (34%)\nINFO:root:Rank: 00   Train Batch: 6/8 (75%)\tLoss: 1.771628\tAcc: 329/960 (34%)\nINFO:root:Rank: 00   Train Batch: 7/8 (88%)\tLoss: 1.768000\tAcc: 254/960 (26%)\nINFO:root:Rank: 00   Train Batch: 8/8 (100%)\tLoss: 1.758361\tAcc: 50/192 (26%)\nINFO:root:0: Memory Usage: 603.48828125, Training Duration: 130.74582523500067\n", "config": {"trainer": "local", "hosts": 1, "slots": 1, "parameters": {"--batch-size": 960, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 1440 --epochs 1 --seed 123456789 --no-validation  local", "stdout": "", "stderr": "INFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Training model for 1 epochs...\nINFO:root:Rank: 00   Start Epoch 0\nINFO:root:Rank: 00   Train Batch: 1/5 (20%)\tLoss: 1.794715\tAcc: 246/1440 (17%)\nINFO:root:Rank: 00   Train Batch: 2/5 (40%)\tLoss: 1.791755\tAcc: 231/1440 (16%)\nINFO:root:Rank: 00   Train Batch: 3/5 (60%)\tLoss: 1.785106\tAcc: 236/1440 (16%)\nINFO:root:Rank: 00   Train Batch: 4/5 (80%)\tLoss: 1.780747\tAcc: 259/1440 (18%)\nINFO:root:Rank: 00   Train Batch: 5/5 (100%)\tLoss: 1.777063\tAcc: 397/1152 (34%)\nINFO:root:0: Memory Usage: 729.734375, Training Duration: 148.89455551599895\n", "config": {"trainer": "local", "hosts": 1, "slots": 1, "parameters": {"--batch-size": 1440, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "~/susml/jakob_torben/bin/horovodrun -np 1 --hosts 10.42.0.50:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 960 --epochs 1 --seed 123456789 --no-validation  horovod", "stdout": "", "stderr": "[1,0]<stderr>:INFO:root:Preprocessed data found. Skip preprocessing.\n[1,0]<stderr>:INFO:root:Training set of size 6912\n[1,0]<stderr>:INFO:root:Training model for 1 epochs...\n[1,0]<stderr>:INFO:root:Rank: 00   Start Epoch 0\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 1/8 (12%)\tLoss: 1.795809\tAcc: 157/960 (16%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 2/8 (25%)\tLoss: 1.789564\tAcc: 170/960 (18%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 3/8 (38%)\tLoss: 1.789741\tAcc: 150/960 (16%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 4/8 (50%)\tLoss: 1.780087\tAcc: 164/960 (17%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 5/8 (62%)\tLoss: 1.778262\tAcc: 324/960 (34%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 6/8 (75%)\tLoss: 1.771628\tAcc: 329/960 (34%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 7/8 (88%)\tLoss: 1.768000\tAcc: 254/960 (26%)\n[1,0]<stderr>:INFO:root:Rank: 00   Train Batch: 8/8 (100%)\tLoss: 1.758361\tAcc: 50/192 (26%)\n[1,0]<stderr>:INFO:root:0: Memory Usage: 605.77734375, Training Duration: 120.77529701000094\n", "config": {"trainer": "horovod", "hosts": 1, "slots": 1, "parameters": {"--batch-size": 960, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "mpirun --bind-to none --map-by slot -np 8 --host 10.42.0.50:1,10.42.0.29:1,10.42.0.105:1,10.42.0.56:1,10.42.0.180:1,10.42.0.235:1,10.42.0.244:1,10.42.0.239:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 1440 --epochs 1 --seed 123456789 --no-validation  distributed", "stdout": "", "stderr": "INFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Training model for 1 epochs...\nINFO:root:Rank: 00   Start Epoch 0\nINFO:root:Rank: 07   Start Epoch 0\nINFO:root:Rank: 02   Start Epoch 0\nINFO:root:Rank: 06   Start Epoch 0\nINFO:root:Rank: 04   Start Epoch 0\nINFO:root:Rank: 05   Start Epoch 0\nINFO:root:Rank: 03   Start Epoch 0\nINFO:root:Rank: 01   Start Epoch 0\nINFO:root:Rank: 05   Train Batch: 1/5 (20%)\tLoss: 1.793953\tAcc: 37/180 (21%)\nINFO:root:Rank: 07   Train Batch: 1/5 (20%)\tLoss: 1.793342\tAcc: 32/180 (18%)\nINFO:root:Rank: 04   Train Batch: 1/5 (20%)\tLoss: 1.793576\tAcc: 34/180 (19%)\nINFO:root:Rank: 06   Train Batch: 1/5 (20%)\tLoss: 1.790805\tAcc: 26/180 (14%)\nINFO:root:Rank: 03   Train Batch: 1/5 (20%)\tLoss: 1.800205\tAcc: 33/180 (18%)\nINFO:root:Rank: 00   Train Batch: 1/5 (20%)\tLoss: 1.788322\tAcc: 30/180 (17%)\nINFO:root:Rank: 02   Train Batch: 1/5 (20%)\tLoss: 1.790115\tAcc: 32/180 (18%)\nINFO:root:Rank: 01   Train Batch: 1/5 (20%)\tLoss: 1.807391\tAcc: 22/180 (12%)\nINFO:root:Rank: 02   Train Batch: 2/5 (40%)\tLoss: 1.794214\tAcc: 29/180 (16%)\nINFO:root:Rank: 03   Train Batch: 2/5 (40%)\tLoss: 1.788547\tAcc: 36/180 (20%)\nINFO:root:Rank: 04   Train Batch: 2/5 (40%)\tLoss: 1.784461\tAcc: 28/180 (16%)\nINFO:root:Rank: 05   Train Batch: 2/5 (40%)\tLoss: 1.797752\tAcc: 24/180 (13%)\nINFO:root:Rank: 01   Train Batch: 2/5 (40%)\tLoss: 1.788255\tAcc: 28/180 (16%)\nINFO:root:Rank: 06   Train Batch: 2/5 (40%)\tLoss: 1.797570\tAcc: 23/180 (13%)\nINFO:root:Rank: 07   Train Batch: 2/5 (40%)\tLoss: 1.787470\tAcc: 31/180 (17%)\nINFO:root:Rank: 00   Train Batch: 2/5 (40%)\tLoss: 1.795760\tAcc: 32/180 (18%)\nINFO:root:Rank: 00   Train Batch: 3/5 (60%)\tLoss: 1.784658\tAcc: 32/180 (18%)\nINFO:root:Rank: 02   Train Batch: 3/5 (60%)\tLoss: 1.788897\tAcc: 21/180 (12%)\nINFO:root:Rank: 01   Train Batch: 3/5 (60%)\tLoss: 1.786755\tAcc: 35/180 (19%)\nINFO:root:Rank: 03   Train Batch: 3/5 (60%)\tLoss: 1.775926\tAcc: 33/180 (18%)\nINFO:root:Rank: 04   Train Batch: 3/5 (60%)\tLoss: 1.791166\tAcc: 28/180 (16%)\nINFO:root:Rank: 05   Train Batch: 3/5 (60%)\tLoss: 1.782987\tAcc: 32/180 (18%)\nINFO:root:Rank: 06   Train Batch: 3/5 (60%)\tLoss: 1.783816\tAcc: 29/180 (16%)\nINFO:root:Rank: 07   Train Batch: 3/5 (60%)\tLoss: 1.786624\tAcc: 26/180 (14%)\nINFO:root:Rank: 04   Train Batch: 4/5 (80%)\tLoss: 1.778062\tAcc: 34/180 (19%)\nINFO:root:Rank: 03   Train Batch: 4/5 (80%)\tLoss: 1.783550\tAcc: 32/180 (18%)\nINFO:root:Rank: 05   Train Batch: 4/5 (80%)\tLoss: 1.771866\tAcc: 35/180 (19%)\nINFO:root:Rank: 06   Train Batch: 4/5 (80%)\tLoss: 1.783502\tAcc: 37/180 (21%)\nINFO:root:Rank: 07   Train Batch: 4/5 (80%)\tLoss: 1.782588\tAcc: 22/180 (12%)\nINFO:root:Rank: 02   Train Batch: 4/5 (80%)\tLoss: 1.784006\tAcc: 32/180 (18%)\nINFO:root:Rank: 01   Train Batch: 4/5 (80%)\tLoss: 1.785373\tAcc: 34/180 (19%)\nINFO:root:Rank: 00   Train Batch: 4/5 (80%)\tLoss: 1.777034\tAcc: 33/180 (18%)\nINFO:root:Rank: 02   Train Batch: 5/5 (100%)\tLoss: 1.774766\tAcc: 48/144 (33%)\nINFO:root:Rank: 03   Train Batch: 5/5 (100%)\tLoss: 1.774174\tAcc: 50/144 (35%)\nINFO:root:Rank: 06   Train Batch: 5/5 (100%)\tLoss: 1.774046\tAcc: 61/144 (42%)\nINFO:root:Rank: 05   Train Batch: 5/5 (100%)\tLoss: 1.780360\tAcc: 49/144 (34%)\nINFO:root:Rank: 00   Train Batch: 5/5 (100%)\tLoss: 1.774733\tAcc: 46/144 (32%)\nINFO:root:Rank: 07   Train Batch: 5/5 (100%)\tLoss: 1.782330\tAcc: 46/144 (32%)\nINFO:root:Rank: 01   Train Batch: 5/5 (100%)\tLoss: 1.775115\tAcc: 51/144 (35%)\nINFO:root:Rank: 04   Train Batch: 5/5 (100%)\tLoss: 1.780972\tAcc: 46/144 (32%)\nINFO:root:3: Memory Usage: 223.875, Training Duration: 29.705289325997\nINFO:root:2: Memory Usage: 223.7890625, Training Duration: 29.707064381000237\nINFO:root:6: Memory Usage: 224.73046875, Training Duration: 29.70723379899937\nINFO:root:5: Memory Usage: 224.171875, Training Duration: 29.70812445899719\nINFO:root:7: Memory Usage: 223.25390625, Training Duration: 29.713173068001197\nINFO:root:0: Memory Usage: 222.8125, Training Duration: 29.716609064002114\nINFO:root:4: Memory Usage: 223.8984375, Training Duration: 29.709692959000677\nINFO:root:1: Memory Usage: 224.16796875, Training Duration: 29.70949430899782\n", "config": {"trainer": "distributed", "hosts": 8, "slots": 1, "parameters": {"--batch-size": 1440, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}, {"command": "mpirun --bind-to none --map-by slot -np 1 --host 10.42.0.50:1 ~/susml/jakob_torben/bin/python ~/susml/jakob_torben/src/motion/main.py --batch-size 1440 --epochs 1 --seed 123456789 --no-validation  distributed", "stdout": "", "stderr": "INFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Training set of size 6912\nINFO:root:Training model for 1 epochs...\nINFO:root:Rank: 00   Start Epoch 0\nINFO:root:Rank: 00   Train Batch: 1/5 (20%)\tLoss: 1.794715\tAcc: 246/1440 (17%)\nINFO:root:Rank: 00   Train Batch: 2/5 (40%)\tLoss: 1.791755\tAcc: 231/1440 (16%)\nINFO:root:Rank: 00   Train Batch: 3/5 (60%)\tLoss: 1.785106\tAcc: 236/1440 (16%)\nINFO:root:Rank: 00   Train Batch: 4/5 (80%)\tLoss: 1.780747\tAcc: 259/1440 (18%)\nINFO:root:Rank: 00   Train Batch: 5/5 (100%)\tLoss: 1.777063\tAcc: 397/1152 (34%)\nINFO:root:0: Memory Usage: 737.59765625, Training Duration: 152.21903855100027\n", "config": {"trainer": "distributed", "hosts": 1, "slots": 1, "parameters": {"--batch-size": 1440, "--epochs": 1, "--seed": 123456789, "--no-validation": ""}}}]}