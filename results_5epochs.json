{"results": [{"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 93 batches\n0 Start Epoch 1\n0: 93 batches\n0 Start Epoch 2\n0: 93 batches\n0 Start Epoch 3\n0: 93 batches\n0 Start Epoch 4\n0: 93 batches\n0 Start Epoch 5\n0: 93 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 666289.7694833663\nINFO:root:0: Epoch 0 validation loss: 378005.0230418012\nINFO:root:0: Epoch 1 train loss: 659805.720530028\nINFO:root:0: Epoch 1 validation loss: 377258.4818098134\nINFO:root:0: Epoch 2 train loss: 659561.0322505581\nINFO:root:0: Epoch 2 validation loss: 376758.5363716257\nINFO:root:0: Epoch 3 train loss: 659641.8384163969\nINFO:root:0: Epoch 3 validation loss: 376323.22803905094\nINFO:root:0: Epoch 4 train loss: 666043.0371387851\nINFO:root:0: Epoch 4 validation loss: 375908.4734585203\nINFO:root:0: Epoch 5 train loss: 659425.1437392902\nINFO:root:0: Epoch 5 validation loss: 375539.953857093\n", "seconds": 13.493376970291138, "batch_size": 32, "nodes": 1, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 47 batches\n1 Start Epoch 0\n1: 47 batches\n1 Start Epoch 1\n1: 47 batches\n0 Start Epoch 1\n0: 47 batches\n1 Start Epoch 2\n1: 47 batches\n0 Start Epoch 2\n0: 47 batches\n1 Start Epoch 3\n1: 47 batches\n0 Start Epoch 3\n0: 47 batches\n1 Start Epoch 4\n1: 47 batches\n0 Start Epoch 4\n0: 47 batches\n1 Start Epoch 5\n1: 47 batches\n0 Start Epoch 5\n0: 47 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 325510.0482864177\nINFO:root:1: Epoch 0 train loss: 900103.0998557882\nINFO:root:0: Epoch 0 validation loss: 63826.31001178488\nINFO:root:0: Epoch 1 train loss: 903609.9745747992\nINFO:root:1: Epoch 1 train loss: 931147.8120577387\nINFO:root:0: Epoch 1 validation loss: 63311.98995716818\nINFO:root:0: Epoch 2 train loss: 593464.5675721676\nINFO:root:1: Epoch 2 train loss: 739487.9442860015\nINFO:root:0: Epoch 2 validation loss: 62965.831104845834\nINFO:root:0: Epoch 3 train loss: 354229.47623597813\nINFO:root:1: Epoch 3 train loss: 392767.29073772026\nINFO:root:0: Epoch 3 validation loss: 62782.18713154053\nINFO:root:0: Epoch 4 train loss: 1064275.8678131104\nINFO:root:1: Epoch 4 train loss: 777005.7534918278\nINFO:root:0: Epoch 4 validation loss: 62543.08721022973\nINFO:root:0: Epoch 5 train loss: 564910.6780875388\nINFO:root:1: Epoch 5 train loss: 636982.293158024\nINFO:root:0: Epoch 5 validation loss: 62337.51389156128\n", "seconds": 8.483833074569702, "batch_size": 32, "nodes": 2, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 31 batches\n2 Start Epoch 0\n1 Start Epoch 0\n2: 31 batches\n1: 31 batches\n2 Start Epoch 1\n2: 31 batches\n1 Start Epoch 1\n1: 31 batches\n0 Start Epoch 1\n0: 31 batches\n1 Start Epoch 2\n2 Start Epoch 2\n1: 31 batches\n2: 31 batches\n0 Start Epoch 2\n0: 31 batches\n2 Start Epoch 3\n1 Start Epoch 3\n2: 31 batches\n1: 31 batches\n0 Start Epoch 3\n0: 31 batches\n1 Start Epoch 4\n2 Start Epoch 4\n2: 31 batches\n1: 31 batches\n0 Start Epoch 4\n0: 31 batches\n2 Start Epoch 5\n1 Start Epoch 5\n2: 31 batches\n1: 31 batches\n0 Start Epoch 5\n0: 31 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 812584.1644831011\nINFO:root:2: Epoch 0 train loss: 544364.7965284778\nINFO:root:1: Epoch 0 train loss: 1061047.9056896088\nINFO:root:0: Epoch 0 validation loss: 131698.04459805068\nINFO:root:0: Epoch 1 train loss: 264578.15452378796\nINFO:root:1: Epoch 1 train loss: 603572.3090008612\nINFO:root:2: Epoch 1 train loss: 560828.6360997846\nINFO:root:0: Epoch 1 validation loss: 131422.90757959516\nINFO:root:0: Epoch 2 train loss: 589265.2563346125\nINFO:root:1: Epoch 2 train loss: 757448.6095563828\nINFO:root:2: Epoch 2 train loss: 856110.4758179572\nINFO:root:0: Epoch 2 validation loss: 131037.17566624848\nINFO:root:0: Epoch 3 train loss: 379381.48470257176\nINFO:root:2: Epoch 3 train loss: 554749.8132786904\nINFO:root:1: Epoch 3 train loss: 1210914.106480014\nINFO:root:0: Epoch 3 validation loss: 130701.68702326973\nINFO:root:0: Epoch 4 train loss: 296187.04222943704\nINFO:root:1: Epoch 4 train loss: 615281.2426464942\nINFO:root:2: Epoch 4 train loss: 1012512.4607388896\nINFO:root:0: Epoch 4 validation loss: 130466.06515528211\nINFO:root:0: Epoch 5 train loss: 339508.70344715734\nINFO:root:1: Epoch 5 train loss: 373586.49747503956\nINFO:root:2: Epoch 5 train loss: 311232.49853404873\nINFO:root:0: Epoch 5 validation loss: 130284.4050196846\n", "seconds": 6.98858904838562, "batch_size": 32, "nodes": 3, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n3 Start Epoch 0\n3: 24 batches\n0: 24 batches\n1 Start Epoch 0\n2 Start Epoch 0\n2: 24 batches\n1: 24 batches\n1 Start Epoch 1\n1: 24 batches\n3 Start Epoch 1\n2 Start Epoch 1\n3: 24 batches\n2: 24 batches\n0 Start Epoch 1\n0: 24 batches\n3 Start Epoch 2\n2 Start Epoch 2\n3: 24 batches\n2: 24 batches\n1 Start Epoch 2\n1: 24 batches\n0 Start Epoch 2\n0: 24 batches\n2 Start Epoch 3\n1 Start Epoch 3\n2: 24 batches\n3 Start Epoch 3\n1: 24 batches\n3: 24 batches\n0 Start Epoch 3\n0: 24 batches\n3 Start Epoch 4\n3: 24 batches\n1 Start Epoch 4\n2 Start Epoch 4\n1: 24 batches\n2: 24 batches\n0 Start Epoch 4\n0: 24 batches\n3 Start Epoch 5\n3: 24 batches\n1 Start Epoch 5\n1: 24 batches\n2 Start Epoch 5\n2: 24 batches\n0 Start Epoch 5\n0: 24 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 670427.213636828\nINFO:root:1: Epoch 0 train loss: 28327.030690193176\nINFO:root:3: Epoch 0 train loss: 682253.5949781735\nINFO:root:2: Epoch 0 train loss: 27054.77068742116\nINFO:root:0: Epoch 0 validation loss: 1801049.1368165507\nINFO:root:0: Epoch 1 train loss: 130037.27887471516\nINFO:root:2: Epoch 1 train loss: 373795.5209485649\nINFO:root:3: Epoch 1 train loss: 1133860.835015456\nINFO:root:1: Epoch 1 train loss: 140840.3462750117\nINFO:root:0: Epoch 1 validation loss: 1800183.1493351152\nINFO:root:0: Epoch 2 train loss: 294627.9569377899\nINFO:root:2: Epoch 2 train loss: 1336727.2253886461\nINFO:root:1: Epoch 2 train loss: 282539.6923357646\nINFO:root:3: Epoch 2 train loss: 59876.57323201498\nINFO:root:0: Epoch 2 validation loss: 1798736.3264708025\nINFO:root:0: Epoch 3 train loss: 378482.65900608647\nINFO:root:3: Epoch 3 train loss: 302365.60565884906\nINFO:root:2: Epoch 3 train loss: 786209.471154213\nINFO:root:1: Epoch 3 train loss: 28016.116875688236\nINFO:root:0: Epoch 3 validation loss: 1797732.6650368427\nINFO:root:0: Epoch 4 train loss: 957096.9865579953\nINFO:root:3: Epoch 4 train loss: 20458.74041112264\nINFO:root:1: Epoch 4 train loss: 434891.4983567645\nINFO:root:2: Epoch 4 train loss: 410410.0641199748\nINFO:root:0: Epoch 4 validation loss: 1796989.3075118805\nINFO:root:0: Epoch 5 train loss: 793107.2666228017\nINFO:root:3: Epoch 5 train loss: 540820.7530030608\nINFO:root:2: Epoch 5 train loss: 801964.9719626108\nINFO:root:1: Epoch 5 train loss: 284677.47218779725\nINFO:root:0: Epoch 5 validation loss: 1796324.8910892843\n", "seconds": 6.481727123260498, "batch_size": 32, "nodes": 4, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 19 batches\n2 Start Epoch 0\n2: 19 batches\n1 Start Epoch 0\n4 Start Epoch 0\n1: 19 batches\n3 Start Epoch 0\n4: 19 batches\n3: 19 batches\n2 Start Epoch 1\n2: 19 batches\n1 Start Epoch 1\n4 Start Epoch 1\n1: 19 batches\n3 Start Epoch 1\n3: 19 batches\n4: 19 batches\n0 Start Epoch 1\n0: 19 batches\n2 Start Epoch 2\n1 Start Epoch 2\n2: 19 batches\n1: 19 batches\n4 Start Epoch 2\n3 Start Epoch 2\n4: 19 batches\n3: 19 batches\n0 Start Epoch 2\n0: 19 batches\n2 Start Epoch 3\n1 Start Epoch 3\n2: 19 batches\n1: 19 batches\n3 Start Epoch 3\n3: 19 batches\n4 Start Epoch 3\n4: 19 batches\n0 Start Epoch 3\n0: 19 batches\n4 Start Epoch 4\n3 Start Epoch 4\n2 Start Epoch 4\n4: 19 batches\n3: 19 batches\n2: 19 batches\n1 Start Epoch 4\n1: 19 batches\n0 Start Epoch 4\n0: 19 batches\n3 Start Epoch 5\n2 Start Epoch 5\n1 Start Epoch 5\n3: 19 batches\n2: 19 batches\n4 Start Epoch 5\n1: 19 batches\n4: 19 batches\n0 Start Epoch 5\n0: 19 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 47187.647172727084\nINFO:root:2: Epoch 0 train loss: 1802423.1378430817\nINFO:root:1: Epoch 0 train loss: 14854.870840574566\nINFO:root:4: Epoch 0 train loss: 374828.4667756934\nINFO:root:3: Epoch 0 train loss: 799971.1926394011\nINFO:root:0: Epoch 0 validation loss: 1090884.6668293523\nINFO:root:1: Epoch 1 train loss: 425167.10026469984\nINFO:root:2: Epoch 1 train loss: 1018171.4415829307\nINFO:root:0: Epoch 1 train loss: 489412.63027673017\nINFO:root:4: Epoch 1 train loss: 430713.0646567721\nINFO:root:3: Epoch 1 train loss: 25815.677701448138\nINFO:root:0: Epoch 1 validation loss: 1090604.3615509132\nINFO:root:2: Epoch 2 train loss: 486862.12765878125\nINFO:root:1: Epoch 2 train loss: 689932.9168966193\nINFO:root:0: Epoch 2 train loss: 13007.970108835321\nINFO:root:3: Epoch 2 train loss: 1177479.7870110963\nINFO:root:4: Epoch 2 train loss: 432508.19939543074\nINFO:root:0: Epoch 2 validation loss: 1090065.2908431469\nINFO:root:4: Epoch 3 train loss: 882267.7577619553\nINFO:root:3: Epoch 3 train loss: 429000.7915912427\nINFO:root:2: Epoch 3 train loss: 769136.2896009746\nINFO:root:1: Epoch 3 train loss: 513500.956416883\nINFO:root:0: Epoch 3 train loss: 70510.83263035824\nINFO:root:0: Epoch 3 validation loss: 1089501.7086156525\nINFO:root:0: Epoch 4 train loss: 169128.86144939222\nINFO:root:2: Epoch 4 train loss: 805782.457875302\nINFO:root:3: Epoch 4 train loss: 19227.82801838925\nINFO:root:1: Epoch 4 train loss: 434010.9731256585\nINFO:root:4: Epoch 4 train loss: 923774.7021145067\nINFO:root:0: Epoch 4 validation loss: 1089086.0531180257\nINFO:root:1: Epoch 5 train loss: 760686.8099650333\nINFO:root:0: Epoch 5 train loss: 524047.4475752178\nINFO:root:2: Epoch 5 train loss: 22488.754271657843\nINFO:root:3: Epoch 5 train loss: 1389982.015255175\nINFO:root:4: Epoch 5 train loss: 451143.39120804635\nINFO:root:0: Epoch 5 validation loss: 1088729.7744311332\n", "seconds": 5.960143089294434, "batch_size": 32, "nodes": 5, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 16 batches\n5 Start Epoch 0\n3 Start Epoch 0\n4 Start Epoch 0\n5: 16 batches\n3: 16 batches\n4: 16 batches\n1 Start Epoch 0\n1: 16 batches\n2 Start Epoch 0\n2: 16 batches\n1 Start Epoch 1\n5 Start Epoch 1\n1: 16 batches\n2 Start Epoch 1\n3 Start Epoch 1\n5: 16 batches\n2: 16 batches\n3: 16 batches\n4 Start Epoch 1\n4: 16 batches\n0 Start Epoch 1\n0: 16 batches\n5 Start Epoch 2\n1 Start Epoch 2\n4 Start Epoch 2\n5: 16 batches\n1: 16 batches\n3 Start Epoch 2\n4: 16 batches\n3: 16 batches\n2 Start Epoch 2\n2: 16 batches\n0 Start Epoch 2\n0: 16 batches\n3 Start Epoch 3\n1 Start Epoch 3\n2 Start Epoch 3\n5 Start Epoch 3\n1: 16 batches\n2: 16 batches\n3: 16 batches\n5: 16 batches\n4 Start Epoch 3\n4: 16 batches\n0 Start Epoch 3\n0: 16 batches\n1 Start Epoch 4\n2 Start Epoch 4\n3 Start Epoch 4\n4 Start Epoch 4\n5 Start Epoch 4\n2: 16 batches\n3: 16 batches\n4: 16 batches\n5: 16 batches\n1: 16 batches\n0 Start Epoch 4\n0: 16 batches\n3 Start Epoch 5\n4 Start Epoch 5\n5 Start Epoch 5\n1 Start Epoch 5\n2 Start Epoch 5\n2: 16 batches\n3: 16 batches\n4: 16 batches\n5: 16 batches\n1: 16 batches\n0 Start Epoch 5\n0: 16 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 457736.14323425293\nINFO:root:1: Epoch 0 train loss: 1457764.319749117\nINFO:root:5: Epoch 0 train loss: 968680.2691497803\nINFO:root:2: Epoch 0 train loss: 948920.670486927\nINFO:root:3: Epoch 0 train loss: 523913.1845817566\nINFO:root:4: Epoch 0 train loss: 22805.136939525604\nINFO:root:0: Epoch 0 validation loss: 48111.711030820574\nINFO:root:0: Epoch 1 train loss: 185968.82628297806\nINFO:root:5: Epoch 1 train loss: 77667.04216051102\nINFO:root:1: Epoch 1 train loss: 796369.7453136444\nINFO:root:4: Epoch 1 train loss: 2288106.3284459114\nINFO:root:3: Epoch 1 train loss: 30822.606595993042\nINFO:root:2: Epoch 1 train loss: 508072.7155241966\nINFO:root:0: Epoch 1 validation loss: 48069.85660888409\nINFO:root:1: Epoch 2 train loss: 518076.16905879974\nINFO:root:2: Epoch 2 train loss: 451242.9726524353\nINFO:root:3: Epoch 2 train loss: 1023321.8977491856\nINFO:root:5: Epoch 2 train loss: 1093181.3183765411\nINFO:root:0: Epoch 2 train loss: 856313.5729288161\nINFO:root:4: Epoch 2 train loss: 20062.888203144073\nINFO:root:0: Epoch 2 validation loss: 47992.134398772796\nINFO:root:0: Epoch 3 train loss: 1023356.9079744816\nINFO:root:2: Epoch 3 train loss: 1205482.3287143707\nINFO:root:3: Epoch 3 train loss: 668807.7280216217\nINFO:root:4: Epoch 3 train loss: 36036.116426467896\nINFO:root:5: Epoch 3 train loss: 509498.6127510071\nINFO:root:1: Epoch 3 train loss: 541066.0946629047\nINFO:root:0: Epoch 3 validation loss: 47886.24591777843\nINFO:root:0: Epoch 4 train loss: 570644.6199785471\nINFO:root:3: Epoch 4 train loss: 552603.7227840424\nINFO:root:4: Epoch 4 train loss: 1605062.455530405\nINFO:root:5: Epoch 4 train loss: 221530.34070444107\nINFO:root:1: Epoch 4 train loss: 183679.4317202568\nINFO:root:2: Epoch 4 train loss: 244341.57199573517\nINFO:root:0: Epoch 4 validation loss: 47788.48500158663\nINFO:root:0: Epoch 5 train loss: 1030885.9504704475\nINFO:root:5: Epoch 5 train loss: 501005.1088690758\nINFO:root:3: Epoch 5 train loss: 463692.16077041626\nINFO:root:4: Epoch 5 train loss: 1900466.594263792\nINFO:root:2: Epoch 5 train loss: 956129.8426132202\nINFO:root:1: Epoch 5 train loss: 447652.8344371915\nINFO:root:0: Epoch 5 validation loss: 47707.51045912706\n", "seconds": 5.390408039093018, "batch_size": 32, "nodes": 6, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 14 batches\n3 Start Epoch 0\n4 Start Epoch 0\n6 Start Epoch 0\n1 Start Epoch 0\n2 Start Epoch 0\n2: 14 batches\n3: 14 batches\n4: 14 batches\n6: 14 batches\n1: 14 batches\n5 Start Epoch 0\n5: 14 batches\n6 Start Epoch 1\n1 Start Epoch 1\n5 Start Epoch 1\n2 Start Epoch 1\n3 Start Epoch 1\n4 Start Epoch 1\n6: 14 batches\n3: 14 batches\n4: 14 batches\n1: 14 batches\n5: 14 batches\n2: 14 batches\n0 Start Epoch 1\n0: 14 batches\n3 Start Epoch 2\n4 Start Epoch 2\n6 Start Epoch 2\n1 Start Epoch 2\n5 Start Epoch 2\n2 Start Epoch 2\n5: 14 batches\n2: 14 batches\n3: 14 batches\n4: 14 batches\n6: 14 batches\n1: 14 batches\n0 Start Epoch 2\n0: 14 batches\n6 Start Epoch 3\n1 Start Epoch 3\n5 Start Epoch 3\n2 Start Epoch 3\n3 Start Epoch 3\n4 Start Epoch 3\n6: 14 batches\n3: 14 batches\n4: 14 batches\n1: 14 batches\n5: 14 batches\n2: 14 batches\n0 Start Epoch 3\n0: 14 batches\n6 Start Epoch 4\n5 Start Epoch 4\n2 Start Epoch 4\n1 Start Epoch 4\n5: 14 batches\n2: 14 batches\n3 Start Epoch 4\n4 Start Epoch 4\n6: 14 batches\n1: 14 batches\n3: 14 batches\n4: 14 batches\n0 Start Epoch 4\n0: 14 batches\n6 Start Epoch 5\n4 Start Epoch 5\n6: 14 batches\n1 Start Epoch 5\n5 Start Epoch 5\n2 Start Epoch 5\n3 Start Epoch 5\n5: 14 batches\n2: 14 batches\n3: 14 batches\n4: 14 batches\n1: 14 batches\n0 Start Epoch 5\n0: 14 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 18416.109715325492\nINFO:root:6: Epoch 0 train loss: 17425.39882496425\nINFO:root:1: Epoch 0 train loss: 14002.518312726703\nINFO:root:5: Epoch 0 train loss: 516569.80985695974\nINFO:root:2: Epoch 0 train loss: 543003.5182119097\nINFO:root:3: Epoch 0 train loss: 1820555.9134303501\nINFO:root:4: Epoch 0 train loss: 1299975.7348349434\nINFO:root:0: Epoch 0 validation loss: 5387081.333521316\nINFO:root:2: Epoch 1 train loss: 95391.24913314411\nINFO:root:3: Epoch 1 train loss: 621870.4409979284\nINFO:root:4: Epoch 1 train loss: 16443.3762997474\nINFO:root:6: Epoch 1 train loss: 628250.1564044952\nINFO:root:1: Epoch 1 train loss: 1188180.3098482403\nINFO:root:5: Epoch 1 train loss: 671242.5263791765\nINFO:root:0: Epoch 1 train loss: 634319.5925990513\nINFO:root:0: Epoch 1 validation loss: 5386651.364217572\nINFO:root:6: Epoch 2 train loss: 1262308.5299134122\nINFO:root:1: Epoch 2 train loss: 26289.71622140067\nINFO:root:5: Epoch 2 train loss: 1329303.4891514096\nINFO:root:2: Epoch 2 train loss: 14805.477242606026\nINFO:root:3: Epoch 2 train loss: 32160.67588697161\nINFO:root:4: Epoch 2 train loss: 781638.3917409693\nINFO:root:0: Epoch 2 train loss: 503161.02211805753\nINFO:root:0: Epoch 2 validation loss: 5385895.7111783745\nINFO:root:6: Epoch 3 train loss: 971041.0908442906\nINFO:root:5: Epoch 3 train loss: 81462.83291952951\nINFO:root:2: Epoch 3 train loss: 273812.94408307754\nINFO:root:1: Epoch 3 train loss: 12933.042718069893\nINFO:root:3: Epoch 3 train loss: 1179451.071623666\nINFO:root:4: Epoch 3 train loss: 1284719.8718414307\nINFO:root:0: Epoch 3 train loss: 1168207.4558830261\nINFO:root:0: Epoch 3 validation loss: 5384920.122042624\nINFO:root:6: Epoch 4 train loss: 701620.6152439459\nINFO:root:2: Epoch 4 train loss: 1080090.4470032284\nINFO:root:3: Epoch 4 train loss: 29352.809143883842\nINFO:root:4: Epoch 4 train loss: 486718.0070125035\nINFO:root:1: Epoch 4 train loss: 35864.91693450936\nINFO:root:5: Epoch 4 train loss: 2313327.820879732\nINFO:root:0: Epoch 4 train loss: 20551.39377485003\nINFO:root:0: Epoch 4 validation loss: 5383872.377195898\nINFO:root:0: Epoch 5 train loss: 1290055.4000707355\nINFO:root:4: Epoch 5 train loss: 20695.78985228283\nINFO:root:6: Epoch 5 train loss: 280460.6980547224\nINFO:root:1: Epoch 5 train loss: 726197.301670347\nINFO:root:5: Epoch 5 train loss: 514203.88713846885\nINFO:root:2: Epoch 5 train loss: 2277501.0995908463\nINFO:root:3: Epoch 5 train loss: 559453.9528548036\nINFO:root:0: Epoch 5 validation loss: 5382849.04540917\n", "seconds": 6.060359954833984, "batch_size": 32, "nodes": 7, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 12 batches\n7 Start Epoch 0\n7: 12 batches\n3 Start Epoch 0\n3: 12 batches\n2 Start Epoch 0\n4 Start Epoch 0\n4: 12 batches\n6 Start Epoch 0\n2: 12 batches\n1 Start Epoch 0\n1: 12 batches\n5 Start Epoch 0\n6: 12 batches\n5: 12 batches\n3 Start Epoch 1\n3: 12 batches\n2 Start Epoch 1\n1 Start Epoch 1\n5 Start Epoch 1\n6 Start Epoch 1\n7 Start Epoch 1\n6: 12 batches\n7: 12 batches\n2: 12 batches\n1: 12 batches\n5: 12 batches\n4 Start Epoch 1\n4: 12 batches\n0 Start Epoch 1\n0: 12 batches\n3 Start Epoch 2\n3: 12 batches\n5 Start Epoch 2\n6 Start Epoch 2\n5: 12 batches\n6: 12 batches\n7 Start Epoch 2\n1 Start Epoch 2\n7: 12 batches\n2 Start Epoch 2\n1: 12 batches\n2: 12 batches\n4 Start Epoch 2\n4: 12 batches\n0 Start Epoch 2\n0: 12 batches\n7 Start Epoch 3\n2 Start Epoch 3\n1 Start Epoch 3\n5 Start Epoch 3\n4 Start Epoch 3\n6 Start Epoch 3\n7: 12 batches\n3 Start Epoch 3\n5: 12 batches\n4: 12 batches\n6: 12 batches\n3: 12 batches\n2: 12 batches\n1: 12 batches\n0 Start Epoch 3\n0: 12 batches\n6 Start Epoch 4\n7 Start Epoch 4\n6: 12 batches\n7: 12 batches\n1 Start Epoch 4\n1: 12 batches\n4 Start Epoch 4\n3 Start Epoch 4\n2 Start Epoch 4\n2: 12 batches\n5 Start Epoch 4\n4: 12 batches\n3: 12 batches\n5: 12 batches\n0 Start Epoch 4\n0: 12 batches\n2 Start Epoch 5\n1 Start Epoch 5\n4 Start Epoch 5\n3 Start Epoch 5\n4: 12 batches\n6 Start Epoch 5\n7 Start Epoch 5\n3: 12 batches\n2: 12 batches\n1: 12 batches\n5 Start Epoch 5\n5: 12 batches\n6: 12 batches\n7: 12 batches\n0 Start Epoch 5\n0: 12 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:3: Epoch 0 train loss: 660457.5404713949\nINFO:root:2: Epoch 0 train loss: 653922.9826132456\nINFO:root:0: Epoch 0 train loss: 572691.2773278555\nINFO:root:1: Epoch 0 train loss: 663479.2455647787\nINFO:root:5: Epoch 0 train loss: 2119273.7595062256\nINFO:root:6: Epoch 0 train loss: 1483846.0817222595\nINFO:root:7: Epoch 0 train loss: 46160.72292550405\nINFO:root:4: Epoch 0 train loss: 931580.3196734587\nINFO:root:0: Epoch 0 validation loss: 6540.160418932398\nINFO:root:3: Epoch 1 train loss: 689852.3611475626\nINFO:root:6: Epoch 1 train loss: 21212.949495951336\nINFO:root:5: Epoch 1 train loss: 2047207.6471853256\nINFO:root:1: Epoch 1 train loss: 671097.9269425074\nINFO:root:7: Epoch 1 train loss: 772471.1861607233\nINFO:root:2: Epoch 1 train loss: 11997.348262786865\nINFO:root:0: Epoch 1 train loss: 659100.7978897095\nINFO:root:4: Epoch 1 train loss: 705270.4165407816\nINFO:root:0: Epoch 1 validation loss: 6515.426763081474\nINFO:root:7: Epoch 2 train loss: 32977.691413879395\nINFO:root:3: Epoch 2 train loss: 750116.4822495779\nINFO:root:2: Epoch 2 train loss: 36284.585037231445\nINFO:root:1: Epoch 2 train loss: 1439395.2614034016\nINFO:root:5: Epoch 2 train loss: 93152.13231595357\nINFO:root:4: Epoch 2 train loss: 607242.3962287903\nINFO:root:6: Epoch 2 train loss: 759397.1760648092\nINFO:root:0: Epoch 2 train loss: 714371.6205088297\nINFO:root:0: Epoch 2 validation loss: 6470.051386468369\nINFO:root:0: Epoch 3 train loss: 1291299.5861902237\nINFO:root:6: Epoch 3 train loss: 775705.7091051737\nINFO:root:7: Epoch 3 train loss: 29937.622449239094\nINFO:root:1: Epoch 3 train loss: 46199.383283933006\nINFO:root:4: Epoch 3 train loss: 737594.8970492681\nINFO:root:3: Epoch 3 train loss: 809347.4407265981\nINFO:root:2: Epoch 3 train loss: 859067.975924174\nINFO:root:5: Epoch 3 train loss: 1427513.7630678813\nINFO:root:0: Epoch 3 validation loss: 6391.009429132887\nINFO:root:0: Epoch 4 train loss: 13639.520818074545\nINFO:root:3: Epoch 4 train loss: 723643.3524068197\nINFO:root:2: Epoch 4 train loss: 567736.8088169098\nINFO:root:1: Epoch 4 train loss: 696896.3914254507\nINFO:root:4: Epoch 4 train loss: 779643.0722249349\nINFO:root:5: Epoch 4 train loss: 17467.997637351353\nINFO:root:6: Epoch 4 train loss: 829798.4463130633\nINFO:root:7: Epoch 4 train loss: 696741.0042317709\nINFO:root:0: Epoch 4 validation loss: 6325.291069818982\nINFO:root:0: Epoch 5 train loss: 878680.4159151713\nINFO:root:6: Epoch 5 train loss: 97874.96414142847\nINFO:root:7: Epoch 5 train loss: 106212.55880864461\nINFO:root:3: Epoch 5 train loss: 5660.874403635661\nINFO:root:2: Epoch 5 train loss: 1490345.9293311436\nINFO:root:1: Epoch 5 train loss: 13139.08718585968\nINFO:root:5: Epoch 5 train loss: 577270.5070800781\nINFO:root:4: Epoch 5 train loss: 731951.9148127238\nINFO:root:0: Epoch 5 validation loss: 6274.590468715491\n", "seconds": 5.9342100620269775, "batch_size": 32, "nodes": 8, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 11 batches\n2 Start Epoch 0\n2: 11 batches\n3 Start Epoch 0\n1 Start Epoch 0\n4 Start Epoch 0\n5 Start Epoch 0\n6 Start Epoch 0\n8 Start Epoch 0\n1: 11 batches\n7 Start Epoch 0\n4: 11 batches\n3: 11 batches\n7: 11 batches\n5: 11 batches\n6: 11 batches\n8: 11 batches\n3 Start Epoch 1\n1 Start Epoch 1\n7 Start Epoch 1\n3: 11 batches\n1: 11 batches\n7: 11 batches\n5 Start Epoch 1\n6 Start Epoch 1\n8 Start Epoch 1\n4 Start Epoch 1\n4: 11 batches\n2 Start Epoch 1\n5: 11 batches\n6: 11 batches\n8: 11 batches\n2: 11 batches\n0 Start Epoch 1\n0: 11 batches\n3 Start Epoch 2\n3: 11 batches\n1 Start Epoch 2\n7 Start Epoch 2\n1: 11 batches\n7: 11 batches\n4 Start Epoch 2\n5 Start Epoch 2\n8 Start Epoch 2\n4: 11 batches\n2 Start Epoch 2\n5: 11 batches\n6 Start Epoch 2\n6: 11 batches\n8: 11 batches\n2: 11 batches\n0 Start Epoch 2\n0: 11 batches\n7 Start Epoch 3\n4 Start Epoch 3\n2 Start Epoch 3\n3 Start Epoch 3\n5 Start Epoch 3\n6 Start Epoch 3\n8 Start Epoch 3\n1 Start Epoch 3\n1: 11 batches\n7: 11 batches\n4: 11 batches\n2: 11 batches\n3: 11 batches\n5: 11 batches\n6: 11 batches\n8: 11 batches\n0 Start Epoch 3\n0: 11 batches\n6 Start Epoch 4\n5 Start Epoch 4\n6: 11 batches\n8 Start Epoch 4\n4 Start Epoch 4\n8: 11 batches\n4: 11 batches\n5: 11 batches\n2 Start Epoch 4\n3 Start Epoch 4\n2: 11 batches\n3: 11 batches\n7 Start Epoch 4\n1 Start Epoch 4\n1: 11 batches\n7: 11 batches\n0 Start Epoch 4\n0: 11 batches\n3 Start Epoch 5\n3: 11 batches\n5 Start Epoch 5\n6 Start Epoch 5\n4 Start Epoch 5\n6: 11 batches\n8 Start Epoch 5\n1 Start Epoch 5\n7 Start Epoch 5\n4: 11 batches\n2 Start Epoch 5\n5: 11 batches\n8: 11 batches\n1: 11 batches\n7: 11 batches\n2: 11 batches\n0 Start Epoch 5\n0: 11 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:3: Epoch 0 train loss: 27341.55475919897\nINFO:root:1: Epoch 0 train loss: 612386.2778847434\nINFO:root:7: Epoch 0 train loss: 27167.818771990864\nINFO:root:0: Epoch 0 train loss: 1516942.462269176\nINFO:root:4: Epoch 0 train loss: 1364501.8136208274\nINFO:root:5: Epoch 0 train loss: 17407.276910955257\nINFO:root:6: Epoch 0 train loss: 743373.6928502863\nINFO:root:8: Epoch 0 train loss: 1061427.4366344104\nINFO:root:2: Epoch 0 train loss: 43586.20108587092\nINFO:root:0: Epoch 0 validation loss: 35225.22146412684\nINFO:root:3: Epoch 1 train loss: 878777.0311459628\nINFO:root:7: Epoch 1 train loss: 642323.3007791693\nINFO:root:1: Epoch 1 train loss: 16664.078525543213\nINFO:root:4: Epoch 1 train loss: 1506635.4152387164\nINFO:root:0: Epoch 1 train loss: 9912.111218539152\nINFO:root:5: Epoch 1 train loss: 21335.8837538199\nINFO:root:8: Epoch 1 train loss: 598619.7371044159\nINFO:root:2: Epoch 1 train loss: 7299.536272569137\nINFO:root:6: Epoch 1 train loss: 889851.9549172141\nINFO:root:0: Epoch 1 validation loss: 35197.41150134288\nINFO:root:0: Epoch 2 train loss: 873107.499108748\nINFO:root:1: Epoch 2 train loss: 11503.69677734375\nINFO:root:7: Epoch 2 train loss: 3572286.473322088\nINFO:root:4: Epoch 2 train loss: 1626592.6273498535\nINFO:root:2: Epoch 2 train loss: 1489815.8936132952\nINFO:root:3: Epoch 2 train loss: 265716.7434109775\nINFO:root:5: Epoch 2 train loss: 86894.62004228072\nINFO:root:6: Epoch 2 train loss: 881135.9320983887\nINFO:root:8: Epoch 2 train loss: 615143.548092582\nINFO:root:0: Epoch 2 validation loss: 35155.244208701726\nINFO:root:6: Epoch 3 train loss: 814188.8288740679\nINFO:root:5: Epoch 3 train loss: 2063570.7318108298\nINFO:root:8: Epoch 3 train loss: 814260.9595725536\nINFO:root:4: Epoch 3 train loss: 888037.8889285001\nINFO:root:2: Epoch 3 train loss: 89154.33048248291\nINFO:root:3: Epoch 3 train loss: 37321.73405456543\nINFO:root:7: Epoch 3 train loss: 766311.9792258523\nINFO:root:1: Epoch 3 train loss: 1398574.6087050005\nINFO:root:0: Epoch 3 train loss: 613462.3434614702\nINFO:root:0: Epoch 3 validation loss: 35082.39783627154\nINFO:root:3: Epoch 4 train loss: 13206.646660891447\nINFO:root:5: Epoch 4 train loss: 744098.1207608309\nINFO:root:6: Epoch 4 train loss: 21516.70281982422\nINFO:root:4: Epoch 4 train loss: 2251868.254110163\nINFO:root:8: Epoch 4 train loss: 885827.7587890625\nINFO:root:1: Epoch 4 train loss: 46793.48583013361\nINFO:root:7: Epoch 4 train loss: 6409.807087984952\nINFO:root:2: Epoch 4 train loss: 655849.6440339522\nINFO:root:0: Epoch 4 train loss: 252248.35726612265\nINFO:root:0: Epoch 4 validation loss: 34980.40946645234\nINFO:root:0: Epoch 5 train loss: 37746.7216796875\nINFO:root:4: Epoch 5 train loss: 10670.104822137138\nINFO:root:2: Epoch 5 train loss: 1042474.065715443\nINFO:root:3: Epoch 5 train loss: 260226.81961530718\nINFO:root:5: Epoch 5 train loss: 644873.5198350386\nINFO:root:7: Epoch 5 train loss: 962273.2992609198\nINFO:root:8: Epoch 5 train loss: 813680.4813336459\nINFO:root:1: Epoch 5 train loss: 272273.52511081914\nINFO:root:6: Epoch 5 train loss: 19604.06086926027\nINFO:root:0: Epoch 5 validation loss: 34877.671216855786\n", "seconds": 6.297267913818359, "batch_size": 32, "nodes": 9, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 10 batches\n9 Start Epoch 0\n9: 10 batches\n8 Start Epoch 0\n2 Start Epoch 0\n4 Start Epoch 0\n7 Start Epoch 0\n8: 10 batches\n4: 10 batches\n1 Start Epoch 0\n1: 10 batches\n2: 10 batches\n3 Start Epoch 0\n6 Start Epoch 0\n7: 10 batches\n3: 10 batches\n6: 10 batches\n5 Start Epoch 0\n5: 10 batches\n3 Start Epoch 1\n3: 10 batches\n5 Start Epoch 1\n6 Start Epoch 1\n5: 10 batches\n2 Start Epoch 1\n9 Start Epoch 1\n8 Start Epoch 1\n6: 10 batches\n2: 10 batches\n8: 10 batches\n1 Start Epoch 1\n9: 10 batches\n1: 10 batches\n4 Start Epoch 1\n4: 10 batches\n7 Start Epoch 1\n7: 10 batches\n0 Start Epoch 1\n0: 10 batches\n8 Start Epoch 2\n6 Start Epoch 2\n8: 10 batches\n1 Start Epoch 2\n6: 10 batches\n5 Start Epoch 2\n2 Start Epoch 2\n3 Start Epoch 2\n1: 10 batches\n5: 10 batches\n2: 10 batches\n3: 10 batches\n9 Start Epoch 2\n9: 10 batches\n4 Start Epoch 2\n4: 10 batches\n7 Start Epoch 2\n7: 10 batches\n0 Start Epoch 2\n0: 10 batches\n3 Start Epoch 3\n3: 10 batches\n9 Start Epoch 3\n9: 10 batches\n8 Start Epoch 3\n1 Start Epoch 3\n6 Start Epoch 3\n5 Start Epoch 3\n7 Start Epoch 3\n6: 10 batches\n5: 10 batches\n2 Start Epoch 3\n7: 10 batches\n8: 10 batches\n1: 10 batches\n2: 10 batches\n4 Start Epoch 3\n4: 10 batches\n0 Start Epoch 3\n0: 10 batches\n6 Start Epoch 4\n8 Start Epoch 4\n1 Start Epoch 4\n6: 10 batches\n2 Start Epoch 4\n3 Start Epoch 4\n9 Start Epoch 4\n4 Start Epoch 4\n1: 10 batches\n5 Start Epoch 4\n2: 10 batches\n3: 10 batches\n9: 10 batches\n8: 10 batches\n4: 10 batches\n5: 10 batches\n7 Start Epoch 4\n7: 10 batches\n0 Start Epoch 4\n0: 10 batches\n2 Start Epoch 5\n3 Start Epoch 5\n9 Start Epoch 5\n8 Start Epoch 5\n7 Start Epoch 5\n3: 10 batches\n9: 10 batches\n8: 10 batches\n4 Start Epoch 5\n1 Start Epoch 5\n6 Start Epoch 5\n5 Start Epoch 5\n2: 10 batches\n6: 10 batches\n5: 10 batches\n7: 10 batches\n4: 10 batches\n1: 10 batches\n0 Start Epoch 5\n0: 10 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:3: Epoch 0 train loss: 32927.14603099823\nINFO:root:5: Epoch 0 train loss: 11424.363480591774\nINFO:root:6: Epoch 0 train loss: 2022669.2972335815\nINFO:root:2: Epoch 0 train loss: 1077629.184475708\nINFO:root:9: Epoch 0 train loss: 114961.95538139343\nINFO:root:8: Epoch 0 train loss: 808118.4888946533\nINFO:root:1: Epoch 0 train loss: 1523705.0606404394\nINFO:root:4: Epoch 0 train loss: 850766.4101269364\nINFO:root:7: Epoch 0 train loss: 701385.192238617\nINFO:root:0: Epoch 0 train loss: 884260.8196567536\nINFO:root:0: Epoch 0 validation loss: 13530.635989029795\nINFO:root:8: Epoch 1 train loss: 882089.9628463745\nINFO:root:6: Epoch 1 train loss: 664418.0887966513\nINFO:root:1: Epoch 1 train loss: 942817.8187225342\nINFO:root:5: Epoch 1 train loss: 656864.7479736328\nINFO:root:2: Epoch 1 train loss: 63762.86021118164\nINFO:root:3: Epoch 1 train loss: 8875.846229171753\nINFO:root:9: Epoch 1 train loss: 805202.4365127564\nINFO:root:4: Epoch 1 train loss: 40122.63115692139\nINFO:root:7: Epoch 1 train loss: 5899.864078617096\nINFO:root:0: Epoch 1 train loss: 119549.43743591309\nINFO:root:0: Epoch 1 validation loss: 13510.997580130937\nINFO:root:0: Epoch 2 train loss: 51019.97158050537\nINFO:root:3: Epoch 2 train loss: 835549.2998900652\nINFO:root:9: Epoch 2 train loss: 830543.3243797303\nINFO:root:6: Epoch 2 train loss: 818196.5296051025\nINFO:root:5: Epoch 2 train loss: 28355.702571105958\nINFO:root:7: Epoch 2 train loss: 302632.9938468933\nINFO:root:8: Epoch 2 train loss: 1529205.68857193\nINFO:root:1: Epoch 2 train loss: 974366.4775512696\nINFO:root:2: Epoch 2 train loss: 15328.099474906921\nINFO:root:4: Epoch 2 train loss: 875349.4352783203\nINFO:root:0: Epoch 2 validation loss: 13478.109329946083\nINFO:root:0: Epoch 3 train loss: 7813.532568359375\nINFO:root:6: Epoch 3 train loss: 11646.907427215576\nINFO:root:9: Epoch 3 train loss: 851854.8466201782\nINFO:root:8: Epoch 3 train loss: 778165.1193367004\nINFO:root:1: Epoch 3 train loss: 294100.1035463333\nINFO:root:2: Epoch 3 train loss: 3254.6713333129883\nINFO:root:3: Epoch 3 train loss: 1178169.2713066102\nINFO:root:4: Epoch 3 train loss: 2492030.4895477295\nINFO:root:5: Epoch 3 train loss: 47375.86110534668\nINFO:root:7: Epoch 3 train loss: 988759.0853454589\nINFO:root:0: Epoch 3 validation loss: 13426.973631591633\nINFO:root:0: Epoch 4 train loss: 838684.0227416992\nINFO:root:2: Epoch 4 train loss: 968725.0140185833\nINFO:root:3: Epoch 4 train loss: 24118.645416259766\nINFO:root:9: Epoch 4 train loss: 891380.9136154174\nINFO:root:8: Epoch 4 train loss: 2463900.89095459\nINFO:root:4: Epoch 4 train loss: 995667.2880432128\nINFO:root:1: Epoch 4 train loss: 307050.9474180698\nINFO:root:6: Epoch 4 train loss: 107367.24121704101\nINFO:root:5: Epoch 4 train loss: 890120.557416749\nINFO:root:7: Epoch 4 train loss: 8259.758334350587\nINFO:root:0: Epoch 4 validation loss: 13358.035740918127\nINFO:root:0: Epoch 5 train loss: 784855.2583618164\nINFO:root:2: Epoch 5 train loss: 107209.79616165161\nINFO:root:7: Epoch 5 train loss: 1740926.3788884461\nINFO:root:3: Epoch 5 train loss: 1527346.8211624145\nINFO:root:9: Epoch 5 train loss: 785284.268724823\nINFO:root:8: Epoch 5 train loss: 20941.608868408202\nINFO:root:4: Epoch 5 train loss: 5790.157684898377\nINFO:root:1: Epoch 5 train loss: 25598.488089752198\nINFO:root:6: Epoch 5 train loss: 898247.470703125\nINFO:root:5: Epoch 5 train loss: 835831.7051177978\nINFO:root:0: Epoch 5 validation loss: 13289.628114586247\n", "seconds": 5.962201118469238, "batch_size": 32, "nodes": 10, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 9 batches\n2 Start Epoch 0\n4 Start Epoch 0\n2: 9 batches\n4: 9 batches\n7 Start Epoch 0\n1 Start Epoch 0\n3 Start Epoch 0\n8 Start Epoch 0\n8: 9 batches\n7: 9 batches\n1: 9 batches\n3: 9 batches\n6 Start Epoch 0\n5 Start Epoch 0\n5: 9 batches\n10 Start Epoch 0\n6: 9 batches\n9 Start Epoch 0\n10: 9 batches\n9: 9 batches\n9 Start Epoch 1\n9: 9 batches\n1 Start Epoch 1\n1: 9 batches\n3 Start Epoch 1\n7 Start Epoch 1\n7: 9 batches\n3: 9 batches\n10 Start Epoch 1\n10: 9 batches\n4 Start Epoch 1\n2 Start Epoch 1\n4: 9 batches\n8 Start Epoch 1\n6 Start Epoch 1\n2: 9 batches\n5 Start Epoch 1\n8: 9 batches\n6: 9 batches\n5: 9 batches\n0 Start Epoch 1\n0: 9 batches\n1 Start Epoch 2\n9 Start Epoch 2\n1: 9 batches\n3 Start Epoch 2\n9: 9 batches\n7 Start Epoch 2\n3: 9 batches\n7: 9 batches\n10 Start Epoch 2\n10: 9 batches\n4 Start Epoch 2\n6 Start Epoch 2\n2 Start Epoch 2\n8 Start Epoch 2\n6: 9 batches\n2: 9 batches\n5 Start Epoch 2\n4: 9 batches\n5: 9 batches\n8: 9 batches\n0 Start Epoch 2\n0: 9 batches\n1 Start Epoch 3\n1: 9 batches\n10 Start Epoch 3\n9 Start Epoch 3\n10: 9 batches\n9: 9 batches\n5 Start Epoch 3\n4 Start Epoch 3\n3 Start Epoch 3\n6 Start Epoch 3\n3: 9 batches\n8 Start Epoch 3\n6: 9 batches\n7 Start Epoch 3\n5: 9 batches\n4: 9 batches\n7: 9 batches\n8: 9 batches\n2 Start Epoch 3\n2: 9 batches\n0 Start Epoch 3\n0: 9 batches\n10 Start Epoch 4\n10: 9 batches\n1 Start Epoch 4\n2 Start Epoch 4\n2: 9 batches\n4 Start Epoch 4\n1: 9 batches\n3 Start Epoch 4\n3: 9 batches\n8 Start Epoch 4\n6 Start Epoch 4\n7 Start Epoch 4\n5 Start Epoch 4\n4: 9 batches\n5: 9 batches\n8: 9 batches\n6: 9 batches\n9 Start Epoch 4\n7: 9 batches\n9: 9 batches\n0 Start Epoch 4\n0: 9 batches\n9 Start Epoch 5\n7 Start Epoch 5\n9: 9 batches\n7: 9 batches\n1 Start Epoch 5\n1: 9 batches\n3 Start Epoch 5\n2 Start Epoch 5\n3: 9 batches\n6 Start Epoch 5\n2: 9 batches\n6: 9 batches\n10 Start Epoch 5\n8 Start Epoch 5\n8: 9 batches\n10: 9 batches\n4 Start Epoch 5\n5 Start Epoch 5\n4: 9 batches\n5: 9 batches\n0 Start Epoch 5\n0: 9 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:9: Epoch 0 train loss: 1085915.4682244195\nINFO:root:1: Epoch 0 train loss: 891588.0588794284\nINFO:root:7: Epoch 0 train loss: 22816.14116414388\nINFO:root:3: Epoch 0 train loss: 744442.1731296115\nINFO:root:10: Epoch 0 train loss: 49272.22260877821\nINFO:root:2: Epoch 0 train loss: 2328242.878645155\nINFO:root:4: Epoch 0 train loss: 39994.47157202827\nINFO:root:5: Epoch 0 train loss: 43235.33179145389\nINFO:root:8: Epoch 0 train loss: 1234896.3834025066\nINFO:root:6: Epoch 0 train loss: 1694130.977227105\nINFO:root:0: Epoch 0 train loss: 22595.916449652777\nINFO:root:0: Epoch 0 validation loss: 282247311.1279909\nINFO:root:1: Epoch 1 train loss: 922679.9326477051\nINFO:root:9: Epoch 1 train loss: 13954.350240071615\nINFO:root:3: Epoch 1 train loss: 732475.1009148492\nINFO:root:7: Epoch 1 train loss: 19055.81103515625\nINFO:root:10: Epoch 1 train loss: 45638.08827073044\nINFO:root:2: Epoch 1 train loss: 9566.434205796984\nINFO:root:4: Epoch 1 train loss: 7781.820668538411\nINFO:root:6: Epoch 1 train loss: 1090653.3617062038\nINFO:root:5: Epoch 1 train loss: 8906.039148542615\nINFO:root:8: Epoch 1 train loss: 16554.377034505207\nINFO:root:0: Epoch 1 train loss: 50477.81826570299\nINFO:root:0: Epoch 1 validation loss: 282246176.6026553\nINFO:root:0: Epoch 2 train loss: 993867.4114176432\nINFO:root:1: Epoch 2 train loss: 737563.2191704644\nINFO:root:10: Epoch 2 train loss: 3126564.5215013293\nINFO:root:9: Epoch 2 train loss: 44684.29386054145\nINFO:root:3: Epoch 2 train loss: 20968.920076158312\nINFO:root:6: Epoch 2 train loss: 6661.166758219401\nINFO:root:5: Epoch 2 train loss: 995859.5849270291\nINFO:root:4: Epoch 2 train loss: 315178.0463731554\nINFO:root:7: Epoch 2 train loss: 964565.5201178656\nINFO:root:8: Epoch 2 train loss: 20538.25494172838\nINFO:root:2: Epoch 2 train loss: 5709.031989203559\nINFO:root:0: Epoch 2 validation loss: 282244510.57528013\nINFO:root:0: Epoch 3 train loss: 6938.676996866862\nINFO:root:10: Epoch 3 train loss: 8014.9803596072725\nINFO:root:1: Epoch 3 train loss: 120878.36839463975\nINFO:root:2: Epoch 3 train loss: 2729498.237223307\nINFO:root:4: Epoch 3 train loss: 917445.436577691\nINFO:root:3: Epoch 3 train loss: 15518.437201605902\nINFO:root:7: Epoch 3 train loss: 1074782.463663737\nINFO:root:5: Epoch 3 train loss: 5275.092902130551\nINFO:root:8: Epoch 3 train loss: 23276.589488771227\nINFO:root:6: Epoch 3 train loss: 312060.3160925971\nINFO:root:9: Epoch 3 train loss: 774934.9741821289\nINFO:root:0: Epoch 3 validation loss: 282241533.97460353\nINFO:root:0: Epoch 4 train loss: 52549.814746432836\nINFO:root:9: Epoch 4 train loss: 13073.363326178656\nINFO:root:7: Epoch 4 train loss: 982165.6441514757\nINFO:root:1: Epoch 4 train loss: 1915893.964369032\nINFO:root:2: Epoch 4 train loss: 989189.6630520291\nINFO:root:3: Epoch 4 train loss: 5394.929731580946\nINFO:root:6: Epoch 4 train loss: 9152.949703640408\nINFO:root:10: Epoch 4 train loss: 19822.040303548176\nINFO:root:8: Epoch 4 train loss: 788385.9240247938\nINFO:root:4: Epoch 4 train loss: 903688.4788089328\nINFO:root:5: Epoch 4 train loss: 983439.9590877957\nINFO:root:0: Epoch 4 validation loss: 282236646.7070488\nINFO:root:4: Epoch 5 train loss: 7432.354281107585\nINFO:root:8: Epoch 5 train loss: 65263.41399870979\nINFO:root:7: Epoch 5 train loss: 751927.2603386773\nINFO:root:6: Epoch 5 train loss: 20666.608164469402\nINFO:root:5: Epoch 5 train loss: 1383110.747501797\nINFO:root:0: Epoch 5 train loss: 993375.6821831597\nINFO:root:9: Epoch 5 train loss: 15357.128173828125\nINFO:root:10: Epoch 5 train loss: 775860.9182421366\nINFO:root:1: Epoch 5 train loss: 938396.4381290012\nINFO:root:2: Epoch 5 train loss: 21013.892681121826\nINFO:root:3: Epoch 5 train loss: 2583727.037006802\nINFO:root:0: Epoch 5 validation loss: 282231513.4942186\n", "seconds": 5.902501106262207, "batch_size": 32, "nodes": 11, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 8 batches\n11 Start Epoch 0\n11: 8 batches\n2 Start Epoch 0\n3 Start Epoch 0\n4 Start Epoch 0\n1 Start Epoch 0\n2: 8 batches\n4: 8 batches\n8 Start Epoch 0\n8: 8 batches\n7 Start Epoch 0\n3: 8 batches\n1: 8 batches\n7: 8 batches\n6 Start Epoch 0\n5 Start Epoch 0\n6: 8 batches\n10 Start Epoch 0\n9 Start Epoch 0\n5: 8 batches\n9: 8 batches\n10: 8 batches\n9 Start Epoch 1\n7 Start Epoch 1\n9: 8 batches\n7: 8 batches\n3 Start Epoch 1\n1 Start Epoch 1\n1: 8 batches\n3: 8 batches\n10 Start Epoch 1\n8 Start Epoch 1\n5 Start Epoch 1\n8: 8 batches\n10: 8 batches\n6 Start Epoch 1\n2 Start Epoch 1\n4 Start Epoch 1\n5: 8 batches\n11 Start Epoch 1\n6: 8 batches\n2: 8 batches\n4: 8 batches\n11: 8 batches\n0 Start Epoch 1\n0: 8 batches\n3 Start Epoch 2\n3: 8 batches\n1 Start Epoch 2\n7 Start Epoch 2\n9 Start Epoch 2\n1: 8 batches\n7: 8 batches\n9: 8 batches\n2 Start Epoch 2\n4 Start Epoch 2\n5 Start Epoch 2\n11 Start Epoch 2\n6 Start Epoch 2\n8 Start Epoch 2\n10 Start Epoch 2\n8: 8 batches\n10: 8 batches\n2: 8 batches\n4: 8 batches\n5: 8 batches\n11: 8 batches\n6: 8 batches\n0 Start Epoch 2\n0: 8 batches\n3 Start Epoch 3\n2 Start Epoch 3\n5 Start Epoch 3\n11 Start Epoch 3\n6 Start Epoch 3\n1 Start Epoch 3\n8 Start Epoch 3\n5: 8 batches\n11: 8 batches\n6: 8 batches\n1: 8 batches\n8: 8 batches\n7 Start Epoch 3\n10 Start Epoch 3\n9 Start Epoch 3\n3: 8 batches\n2: 8 batches\n4 Start Epoch 3\n7: 8 batches\n10: 8 batches\n9: 8 batches\n4: 8 batches\n0 Start Epoch 3\n0: 8 batches\n10 Start Epoch 4\n9 Start Epoch 4\n9: 8 batches\n10: 8 batches\n11 Start Epoch 4\n2 Start Epoch 4\n11: 8 batches\n1 Start Epoch 4\n3 Start Epoch 4\n2: 8 batches\n4 Start Epoch 4\n5 Start Epoch 4\n6 Start Epoch 4\n1: 8 batches\n8 Start Epoch 4\n7 Start Epoch 4\n3: 8 batches\n4: 8 batches\n5: 8 batches\n6: 8 batches\n8: 8 batches\n7: 8 batches\n0 Start Epoch 4\n0: 8 batches\n10 Start Epoch 5\n9 Start Epoch 5\n1 Start Epoch 5\n10: 8 batches\n9: 8 batches\n2 Start Epoch 5\n4 Start Epoch 5\n2: 8 batches\n4: 8 batches\n5 Start Epoch 5\n1: 8 batches\n5: 8 batches\n8 Start Epoch 5\n6 Start Epoch 5\n8: 8 batches\n7 Start Epoch 5\n3 Start Epoch 5\n11 Start Epoch 5\n6: 8 batches\n11: 8 batches\n7: 8 batches\n3: 8 batches\n0 Start Epoch 5\n0: 8 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:9: Epoch 0 train loss: 14659.281829833984\nINFO:root:7: Epoch 0 train loss: 1162761.870027542\nINFO:root:3: Epoch 0 train loss: 32136.974271774292\nINFO:root:1: Epoch 0 train loss: 1071758.5052261353\nINFO:root:10: Epoch 0 train loss: 1047463.2599778175\nINFO:root:8: Epoch 0 train loss: 1207786.1402549744\nINFO:root:5: Epoch 0 train loss: 1099225.4669952393\nINFO:root:6: Epoch 0 train loss: 60567.2666015625\nINFO:root:2: Epoch 0 train loss: 1057883.7534942627\nINFO:root:4: Epoch 0 train loss: 1072545.0565414429\nINFO:root:11: Epoch 0 train loss: 129213.79443359375\nINFO:root:0: Epoch 0 train loss: 37670.21838378906\nINFO:root:0: Epoch 0 validation loss: 232424609.95775864\nINFO:root:3: Epoch 1 train loss: 2396783.5419311523\nINFO:root:1: Epoch 1 train loss: 866409.7426662445\nINFO:root:7: Epoch 1 train loss: 1106671.458923459\nINFO:root:9: Epoch 1 train loss: 1048391.1452102661\nINFO:root:0: Epoch 1 train loss: 1203280.4314188957\nINFO:root:2: Epoch 1 train loss: 827736.7180347443\nINFO:root:4: Epoch 1 train loss: 1222408.1596450806\nINFO:root:5: Epoch 1 train loss: 855540.1237030029\nINFO:root:11: Epoch 1 train loss: 12178.456272125244\nINFO:root:6: Epoch 1 train loss: 362656.09507369995\nINFO:root:8: Epoch 1 train loss: 11213.48954963684\nINFO:root:10: Epoch 1 train loss: 1957582.4234580994\nINFO:root:0: Epoch 1 validation loss: 232423971.60229394\nINFO:root:0: Epoch 2 train loss: 971657.978439331\nINFO:root:5: Epoch 2 train loss: 3173579.3638153076\nINFO:root:11: Epoch 2 train loss: 3252949.9470214844\nINFO:root:6: Epoch 2 train loss: 67764.40019226074\nINFO:root:1: Epoch 2 train loss: 1467764.4044950008\nINFO:root:8: Epoch 2 train loss: 131820.72981643677\nINFO:root:3: Epoch 2 train loss: 876862.0908660889\nINFO:root:2: Epoch 2 train loss: 12048.927619934082\nINFO:root:4: Epoch 2 train loss: 891520.1819152832\nINFO:root:7: Epoch 2 train loss: 8801.367343902588\nINFO:root:10: Epoch 2 train loss: 1391401.2373232841\nINFO:root:9: Epoch 2 train loss: 39059.170337677\nINFO:root:0: Epoch 2 validation loss: 232423073.10461137\nINFO:root:0: Epoch 3 train loss: 1957625.8192558289\nINFO:root:10: Epoch 3 train loss: 14146.859848022461\nINFO:root:9: Epoch 3 train loss: 27463.83079147339\nINFO:root:11: Epoch 3 train loss: 59526.20917892456\nINFO:root:2: Epoch 3 train loss: 23649.208954811096\nINFO:root:1: Epoch 3 train loss: 2195915.392490387\nINFO:root:4: Epoch 3 train loss: 1055584.1459121704\nINFO:root:5: Epoch 3 train loss: 851399.8180770874\nINFO:root:6: Epoch 3 train loss: 37830.52626800537\nINFO:root:8: Epoch 3 train loss: 384711.29993724823\nINFO:root:7: Epoch 3 train loss: 2088961.1245422363\nINFO:root:3: Epoch 3 train loss: 2459420.9276885986\nINFO:root:0: Epoch 3 validation loss: 232421763.66090086\nINFO:root:10: Epoch 4 train loss: 826894.0002346039\nINFO:root:9: Epoch 4 train loss: 26125.24761581421\nINFO:root:0: Epoch 4 train loss: 1023869.7321624756\nINFO:root:1: Epoch 4 train loss: 825328.004951477\nINFO:root:2: Epoch 4 train loss: 35473.121128082275\nINFO:root:4: Epoch 4 train loss: 1075550.924129486\nINFO:root:5: Epoch 4 train loss: 875726.6906738281\nINFO:root:8: Epoch 4 train loss: 2397744.809764862\nINFO:root:6: Epoch 4 train loss: 66172.86566925049\nINFO:root:7: Epoch 4 train loss: 903433.5266265869\nINFO:root:11: Epoch 4 train loss: 2141171.8179855347\nINFO:root:3: Epoch 4 train loss: 8532.720680236816\nINFO:root:0: Epoch 4 validation loss: 232419706.81431475\nINFO:root:0: Epoch 5 train loss: 2962.022813796997\nINFO:root:10: Epoch 5 train loss: 1829546.974023819\nINFO:root:9: Epoch 5 train loss: 54022.10657119751\nINFO:root:11: Epoch 5 train loss: 29668.786094665527\nINFO:root:1: Epoch 5 train loss: 18814.39223384857\nINFO:root:2: Epoch 5 train loss: 1021037.1163601652\nINFO:root:3: Epoch 5 train loss: 2367129.6485061646\nINFO:root:4: Epoch 5 train loss: 355861.28885650635\nINFO:root:5: Epoch 5 train loss: 372810.6614112854\nINFO:root:6: Epoch 5 train loss: 52341.39242362976\nINFO:root:7: Epoch 5 train loss: 908321.9900512695\nINFO:root:8: Epoch 5 train loss: 1044697.3369350433\nINFO:root:0: Epoch 5 validation loss: 232416536.34459674\n", "seconds": 5.755454063415527, "batch_size": 32, "nodes": 12, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.15 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "1 Start Epoch 0\n1: 47 batches\n0 Start Epoch 0\n0: 47 batches\n1 Start Epoch 1\n1: 47 batches\n0 Start Epoch 1\n0: 47 batches\n1 Start Epoch 2\n1: 47 batches\n0 Start Epoch 2\n0: 47 batches\n1 Start Epoch 3\n1: 47 batches\n0 Start Epoch 3\n0: 47 batches\n1 Start Epoch 4\n1: 47 batches\n0 Start Epoch 4\n0: 47 batches\n1 Start Epoch 5\n1: 47 batches\n0 Start Epoch 5\n0: 47 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:1: Epoch 0 train loss: 552414.536506247\nINFO:root:0: Epoch 0 train loss: 722207.4024049474\nINFO:root:0: Epoch 0 validation loss: 283041098.8767109\nINFO:root:0: Epoch 1 train loss: 882267.6782895148\nINFO:root:1: Epoch 1 train loss: 578515.5389500071\nINFO:root:0: Epoch 1 validation loss: 283015495.5902701\nINFO:root:1: Epoch 2 train loss: 751505.437462827\nINFO:root:0: Epoch 2 train loss: 502046.09739198076\nINFO:root:0: Epoch 2 validation loss: 283002641.7566269\nINFO:root:0: Epoch 3 train loss: 388459.29416928394\nINFO:root:1: Epoch 3 train loss: 655676.227710521\nINFO:root:0: Epoch 3 validation loss: 282995285.6110335\nINFO:root:0: Epoch 4 train loss: 295897.5067852913\nINFO:root:1: Epoch 4 train loss: 1327563.6886195731\nINFO:root:0: Epoch 4 validation loss: 282986923.2400577\nINFO:root:1: Epoch 5 train loss: 593141.857655302\nINFO:root:0: Epoch 5 train loss: 675750.5517587864\nINFO:root:0: Epoch 5 validation loss: 282978810.0939699\n", "seconds": 10.140625, "batch_size": 32, "nodes": 1, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.15,192.168.2.2 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n1 Start Epoch 0\n1: 24 batches\n0: 24 batches\n3 Start Epoch 0\n2 Start Epoch 0\n3: 24 batches\n2: 24 batches\n1 Start Epoch 1\n2 Start Epoch 1\n3 Start Epoch 1\n2: 24 batches\n3: 24 batches\n1: 24 batches\n0 Start Epoch 1\n0: 24 batches\n1 Start Epoch 2\n2 Start Epoch 2\n3 Start Epoch 2\n3: 24 batches\n1: 24 batches\n2: 24 batches\n0 Start Epoch 2\n0: 24 batches\n3 Start Epoch 3\n3: 24 batches\n2 Start Epoch 3\n2: 24 batches\n1 Start Epoch 3\n1: 24 batches\n0 Start Epoch 3\n0: 24 batches\n1 Start Epoch 4\n1: 24 batches\n3 Start Epoch 4\n3: 24 batches\n2 Start Epoch 4\n2: 24 batches\n0 Start Epoch 4\n0: 24 batches\n2 Start Epoch 5\n2: 24 batches\n3 Start Epoch 5\n3: 24 batches\n1 Start Epoch 5\n1: 24 batches\n0 Start Epoch 5\n0: 24 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:1: Epoch 0 train loss: 171702.3880780538\nINFO:root:0: Epoch 0 train loss: 964275.9198525747\nINFO:root:3: Epoch 0 train loss: 165746.8113708496\nINFO:root:2: Epoch 0 train loss: 379122.7653541565\nINFO:root:0: Epoch 0 validation loss: 912074.7748822236\nINFO:root:0: Epoch 1 train loss: 421380.41118804616\nINFO:root:1: Epoch 1 train loss: 615257.6445687612\nINFO:root:3: Epoch 1 train loss: 1703944.5835844676\nINFO:root:2: Epoch 1 train loss: 15460.112595558167\nINFO:root:0: Epoch 1 validation loss: 911124.1535891007\nINFO:root:0: Epoch 2 train loss: 371617.25901095074\nINFO:root:1: Epoch 2 train loss: 729351.9049435457\nINFO:root:2: Epoch 2 train loss: 398923.1231821378\nINFO:root:3: Epoch 2 train loss: 473039.18737125397\nINFO:root:0: Epoch 2 validation loss: 910035.9968051391\nINFO:root:1: Epoch 3 train loss: 339058.02078443766\nINFO:root:0: Epoch 3 train loss: 853130.1071020762\nINFO:root:2: Epoch 3 train loss: 405844.1456873417\nINFO:root:3: Epoch 3 train loss: 340809.2797913353\nINFO:root:0: Epoch 3 validation loss: 909093.0833052684\nINFO:root:1: Epoch 4 train loss: 1050309.6699797313\nINFO:root:0: Epoch 4 train loss: 2729388.2558424077\nINFO:root:3: Epoch 4 train loss: 659134.8567962149\nINFO:root:2: Epoch 4 train loss: 427358.2688032712\nINFO:root:0: Epoch 4 validation loss: 908285.5257321132\nINFO:root:0: Epoch 5 train loss: 312301.71850077313\nINFO:root:1: Epoch 5 train loss: 36551.630983004965\nINFO:root:3: Epoch 5 train loss: 984467.1451663971\nINFO:root:2: Epoch 5 train loss: 323806.51563390094\nINFO:root:0: Epoch 5 validation loss: 907752.1463030607\n", "seconds": 6.298757791519165, "batch_size": 32, "nodes": 2, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.15,192.168.2.2,192.168.2.3 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 16 batches\n5 Start Epoch 0\n5: 16 batches\n2 Start Epoch 0\n2: 16 batches\n1 Start Epoch 0\n1: 16 batches\n3 Start Epoch 0\n4 Start Epoch 0\n3: 16 batches\n4: 16 batches\n1 Start Epoch 1\n1: 16 batches\n3 Start Epoch 1\n5 Start Epoch 1\n2 Start Epoch 1\n4 Start Epoch 1\n5: 16 batches\n3: 16 batches\n4: 16 batches\n2: 16 batches\n0 Start Epoch 1\n0: 16 batches\n1 Start Epoch 2\n3 Start Epoch 2\n4 Start Epoch 2\n3: 16 batches\n5 Start Epoch 2\n2 Start Epoch 2\n4: 16 batches\n2: 16 batches\n5: 16 batches\n1: 16 batches\n0 Start Epoch 2\n0: 16 batches\n1 Start Epoch 3\n1: 16 batches\n5 Start Epoch 3\n2 Start Epoch 3\n4 Start Epoch 3\n3 Start Epoch 3\n5: 16 batches\n2: 16 batches\n4: 16 batches\n3: 16 batches\n0 Start Epoch 3\n0: 16 batches\n1 Start Epoch 4\n1: 16 batches\n4 Start Epoch 4\n2 Start Epoch 4\n2: 16 batches\n4: 16 batches\n3 Start Epoch 4\n5 Start Epoch 4\n3: 16 batches\n5: 16 batches\n0 Start Epoch 4\n0: 16 batches\n1 Start Epoch 5\n1: 16 batches\n2 Start Epoch 5\n5 Start Epoch 5\n2: 16 batches\n4 Start Epoch 5\n3 Start Epoch 5\n5: 16 batches\n3: 16 batches\n4: 16 batches\n0 Start Epoch 5\n0: 16 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 1146545.9798597097\nINFO:root:1: Epoch 0 train loss: 519622.815230608\nINFO:root:2: Epoch 0 train loss: 579428.7115063667\nINFO:root:5: Epoch 0 train loss: 618134.9339790344\nINFO:root:3: Epoch 0 train loss: 14821.689098358154\nINFO:root:4: Epoch 0 train loss: 450569.0536079407\nINFO:root:0: Epoch 0 validation loss: 292322498.84260976\nINFO:root:1: Epoch 1 train loss: 501004.37861061096\nINFO:root:0: Epoch 1 train loss: 34611.38385428488\nINFO:root:2: Epoch 1 train loss: 616396.1940546334\nINFO:root:5: Epoch 1 train loss: 71435.9764328003\nINFO:root:3: Epoch 1 train loss: 419872.3840522766\nINFO:root:4: Epoch 1 train loss: 1156569.6156842709\nINFO:root:0: Epoch 1 validation loss: 292321201.37278825\nINFO:root:1: Epoch 2 train loss: 17902.0389816761\nINFO:root:0: Epoch 2 train loss: 24719.99061012268\nINFO:root:3: Epoch 2 train loss: 435583.72023773193\nINFO:root:4: Epoch 2 train loss: 619301.8072271347\nINFO:root:2: Epoch 2 train loss: 614820.4821338654\nINFO:root:5: Epoch 2 train loss: 525466.3121900558\nINFO:root:0: Epoch 2 validation loss: 292318275.44877446\nINFO:root:1: Epoch 3 train loss: 1088539.6650514603\nINFO:root:0: Epoch 3 train loss: 1175698.88060534\nINFO:root:3: Epoch 3 train loss: 1894582.0466690063\nINFO:root:5: Epoch 3 train loss: 714473.0893702507\nINFO:root:4: Epoch 3 train loss: 422787.69847106934\nINFO:root:2: Epoch 3 train loss: 4804.804480075836\nINFO:root:0: Epoch 3 validation loss: 292309103.4614082\nINFO:root:0: Epoch 4 train loss: 496577.90251135826\nINFO:root:1: Epoch 4 train loss: 509781.4206149578\nINFO:root:3: Epoch 4 train loss: 1030538.7260470986\nINFO:root:4: Epoch 4 train loss: 612202.387465477\nINFO:root:5: Epoch 4 train loss: 788535.243171215\nINFO:root:2: Epoch 4 train loss: 33742.881345272064\nINFO:root:0: Epoch 4 validation loss: 292298970.66827273\nINFO:root:0: Epoch 5 train loss: 515216.09846019745\nINFO:root:1: Epoch 5 train loss: 1517750.2971801758\nINFO:root:5: Epoch 5 train loss: 780137.1773681641\nINFO:root:3: Epoch 5 train loss: 428914.0105919838\nINFO:root:4: Epoch 5 train loss: 795116.7946848869\nINFO:root:2: Epoch 5 train loss: 501949.18085289\nINFO:root:0: Epoch 5 validation loss: 292291574.88677907\n", "seconds": 5.024904727935791, "batch_size": 32, "nodes": 3, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 12 batches\n1 Start Epoch 0\n1: 12 batches\n2 Start Epoch 0\n5 Start Epoch 0\n5: 12 batches\n7 Start Epoch 0\n2: 12 batches\n6 Start Epoch 0\n7: 12 batches\n3 Start Epoch 0\n4 Start Epoch 0\n4: 12 batches\n6: 12 batches\n3: 12 batches\n1 Start Epoch 1\n1: 12 batches\n3 Start Epoch 1\n5 Start Epoch 1\n7 Start Epoch 1\n4 Start Epoch 1\n6 Start Epoch 1\n6: 12 batches\n2 Start Epoch 1\n3: 12 batches\n4: 12 batches\n7: 12 batches\n2: 12 batches\n5: 12 batches\n0 Start Epoch 1\n0: 12 batches\n1 Start Epoch 2\n1: 12 batches\n4 Start Epoch 2\n6 Start Epoch 2\n3 Start Epoch 2\n5 Start Epoch 2\n7 Start Epoch 2\n3: 12 batches\n2 Start Epoch 2\n5: 12 batches\n6: 12 batches\n2: 12 batches\n4: 12 batches\n7: 12 batches\n0 Start Epoch 2\n0: 12 batches\n1 Start Epoch 3\n1: 12 batches\n3 Start Epoch 3\n4 Start Epoch 3\n6 Start Epoch 3\n2 Start Epoch 3\n4: 12 batches\n7 Start Epoch 3\n2: 12 batches\n5 Start Epoch 3\n7: 12 batches\n6: 12 batches\n3: 12 batches\n5: 12 batches\n0 Start Epoch 3\n0: 12 batches\n1 Start Epoch 4\n1: 12 batches\n3 Start Epoch 4\n4 Start Epoch 4\n7 Start Epoch 4\n6 Start Epoch 4\n2 Start Epoch 4\n5 Start Epoch 4\n6: 12 batches\n3: 12 batches\n4: 12 batches\n2: 12 batches\n5: 12 batches\n7: 12 batches\n0 Start Epoch 4\n0: 12 batches\n1 Start Epoch 5\n5 Start Epoch 5\n6 Start Epoch 5\n3 Start Epoch 5\n6: 12 batches\n2 Start Epoch 5\n5: 12 batches\n7 Start Epoch 5\n2: 12 batches\n4 Start Epoch 5\n7: 12 batches\n3: 12 batches\n4: 12 batches\n1: 12 batches\n0 Start Epoch 5\n0: 12 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 11568.5870997111\nINFO:root:1: Epoch 0 train loss: 37368.70980834961\nINFO:root:2: Epoch 0 train loss: 1541176.3885437648\nINFO:root:4: Epoch 0 train loss: 80908.53442001343\nINFO:root:6: Epoch 0 train loss: 601157.8824361166\nINFO:root:3: Epoch 0 train loss: 2435243.320526123\nINFO:root:5: Epoch 0 train loss: 1497248.44489034\nINFO:root:7: Epoch 0 train loss: 552805.1821293831\nINFO:root:0: Epoch 0 validation loss: 167006.1828638774\nINFO:root:1: Epoch 1 train loss: 14021.200414657593\nINFO:root:0: Epoch 1 train loss: 1757883.709312439\nINFO:root:5: Epoch 1 train loss: 673897.6240971884\nINFO:root:7: Epoch 1 train loss: 50334.393853505455\nINFO:root:3: Epoch 1 train loss: 15231.939589182535\nINFO:root:2: Epoch 1 train loss: 1290519.0449701946\nINFO:root:4: Epoch 1 train loss: 22247.966178894043\nINFO:root:6: Epoch 1 train loss: 48894.844538370766\nINFO:root:0: Epoch 1 validation loss: 166942.03068708704\nINFO:root:0: Epoch 2 train loss: 581248.2534891764\nINFO:root:1: Epoch 2 train loss: 655437.2186032931\nINFO:root:6: Epoch 2 train loss: 38039.814399401344\nINFO:root:3: Epoch 2 train loss: 24361.26968383789\nINFO:root:4: Epoch 2 train loss: 936930.4800720215\nINFO:root:5: Epoch 2 train loss: 38876.1624323527\nINFO:root:7: Epoch 2 train loss: 788313.7346668243\nINFO:root:2: Epoch 2 train loss: 30868.187746683758\nINFO:root:0: Epoch 2 validation loss: 166823.78340974965\nINFO:root:0: Epoch 3 train loss: 22449.1004002889\nINFO:root:1: Epoch 3 train loss: 81717.35026168823\nINFO:root:2: Epoch 3 train loss: 92805.90347798665\nINFO:root:5: Epoch 3 train loss: 233233.17258580527\nINFO:root:7: Epoch 3 train loss: 1285243.0641085308\nINFO:root:3: Epoch 3 train loss: 678753.8485368093\nINFO:root:4: Epoch 3 train loss: 2044782.7889811199\nINFO:root:6: Epoch 3 train loss: 1338425.8299570878\nINFO:root:0: Epoch 3 validation loss: 166649.72643478162\nINFO:root:0: Epoch 4 train loss: 9214.506401697794\nINFO:root:1: Epoch 4 train loss: 18541.950896581013\nINFO:root:4: Epoch 4 train loss: 570210.4667650858\nINFO:root:6: Epoch 4 train loss: 20195.862782160442\nINFO:root:2: Epoch 4 train loss: 857728.0611623129\nINFO:root:7: Epoch 4 train loss: 7463.1291879018145\nINFO:root:3: Epoch 4 train loss: 21020.44553375244\nINFO:root:5: Epoch 4 train loss: 16165.519817272821\nINFO:root:0: Epoch 4 validation loss: 166486.7525816786\nINFO:root:1: Epoch 5 train loss: 699584.1725823084\nINFO:root:0: Epoch 5 train loss: 71132.76773071289\nINFO:root:7: Epoch 5 train loss: 119974.56398773193\nINFO:root:2: Epoch 5 train loss: 642863.7592728933\nINFO:root:5: Epoch 5 train loss: 25741.911769866943\nINFO:root:3: Epoch 5 train loss: 733180.9464276632\nINFO:root:4: Epoch 5 train loss: 1270886.5980122883\nINFO:root:6: Epoch 5 train loss: 11065.92513847351\nINFO:root:0: Epoch 5 validation loss: 166325.44068651364\n", "seconds": 4.600442886352539, "batch_size": 32, "nodes": 4, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 10 batches\n1 Start Epoch 0\n1: 10 batches\n4 Start Epoch 0\n5 Start Epoch 0\n5: 10 batches\n4: 10 batches\n7 Start Epoch 0\n2 Start Epoch 0\n3 Start Epoch 0\n7: 10 batches\n2: 10 batches\n3: 10 batches\n8 Start Epoch 0\n9 Start Epoch 0\n9: 10 batches\n8: 10 batches\n6 Start Epoch 0\n6: 10 batches\n1 Start Epoch 1\n1: 10 batches\n4 Start Epoch 1\n3 Start Epoch 1\n6 Start Epoch 1\n4: 10 batches\n2 Start Epoch 1\n7 Start Epoch 1\n5 Start Epoch 1\n6: 10 batches\n5: 10 batches\n2: 10 batches\n3: 10 batches\n7: 10 batches\n8 Start Epoch 1\n8: 10 batches\n9 Start Epoch 1\n9: 10 batches\n0 Start Epoch 1\n0: 10 batches\n1 Start Epoch 2\n1: 10 batches\n4 Start Epoch 2\n6 Start Epoch 2\n2 Start Epoch 2\n6: 10 batches\n5 Start Epoch 2\n3 Start Epoch 2\n5: 10 batches\n2: 10 batches\n7 Start Epoch 2\n3: 10 batches\n7: 10 batches\n4: 10 batches\n9 Start Epoch 2\n9: 10 batches\n8 Start Epoch 2\n8: 10 batches\n0 Start Epoch 2\n0: 10 batches\n1 Start Epoch 3\n1: 10 batches\n5 Start Epoch 3\n2 Start Epoch 3\n6 Start Epoch 3\n5: 10 batches\n3 Start Epoch 3\n8 Start Epoch 3\n4 Start Epoch 3\n3: 10 batches\n9 Start Epoch 3\n7 Start Epoch 3\n6: 10 batches\n4: 10 batches\n9: 10 batches\n7: 10 batches\n2: 10 batches\n8: 10 batches\n0 Start Epoch 3\n0: 10 batches\n5 Start Epoch 4\n3 Start Epoch 4\n3: 10 batches\n4 Start Epoch 4\n7 Start Epoch 4\n2 Start Epoch 4\n8 Start Epoch 4\n6 Start Epoch 4\n9 Start Epoch 4\n7: 10 batches\n4: 10 batches\n5: 10 batches\n2: 10 batches\n8: 10 batches\n6: 10 batches\n9: 10 batches\n1 Start Epoch 4\n1: 10 batches\n0 Start Epoch 4\n0: 10 batches\n1 Start Epoch 5\n6 Start Epoch 5\n5 Start Epoch 5\n5: 10 batches\n2 Start Epoch 5\n8 Start Epoch 5\n7 Start Epoch 5\n7: 10 batches\n4 Start Epoch 5\n3 Start Epoch 5\n9 Start Epoch 5\n1: 10 batches\n6: 10 batches\n2: 10 batches\n8: 10 batches\n9: 10 batches\n3: 10 batches\n4: 10 batches\n0 Start Epoch 5\n0: 10 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:1: Epoch 0 train loss: 17816.662707519532\nINFO:root:0: Epoch 0 train loss: 795510.4397972107\nINFO:root:4: Epoch 0 train loss: 1648999.4257476807\nINFO:root:6: Epoch 0 train loss: 894722.2825170517\nINFO:root:5: Epoch 0 train loss: 920994.9565032959\nINFO:root:2: Epoch 0 train loss: 20441.969160461427\nINFO:root:7: Epoch 0 train loss: 38502.261868286136\nINFO:root:3: Epoch 0 train loss: 20490.868518066407\nINFO:root:8: Epoch 0 train loss: 2597224.989501953\nINFO:root:9: Epoch 0 train loss: 712002.5495300293\nINFO:root:0: Epoch 0 validation loss: 5877569.030620569\nINFO:root:1: Epoch 1 train loss: 22046.86806640625\nINFO:root:7: Epoch 1 train loss: 1997232.8050247193\nINFO:root:5: Epoch 1 train loss: 23417.397351074218\nINFO:root:6: Epoch 1 train loss: 20323.297579956055\nINFO:root:4: Epoch 1 train loss: 41376.304703235626\nINFO:root:2: Epoch 1 train loss: 32361.671127700807\nINFO:root:3: Epoch 1 train loss: 13991.684123229981\nINFO:root:0: Epoch 1 train loss: 786497.3656448364\nINFO:root:9: Epoch 1 train loss: 23711.370202636717\nINFO:root:8: Epoch 1 train loss: 1674562.6005515098\nINFO:root:0: Epoch 1 validation loss: 5877350.174698794\nINFO:root:1: Epoch 2 train loss: 15274.773072814942\nINFO:root:0: Epoch 2 train loss: 18200.204837036134\nINFO:root:4: Epoch 2 train loss: 18806.322704315186\nINFO:root:3: Epoch 2 train loss: 19511.082836468144\nINFO:root:8: Epoch 2 train loss: 866508.5997634887\nINFO:root:6: Epoch 2 train loss: 693832.8696289062\nINFO:root:5: Epoch 2 train loss: 1061493.6190292358\nINFO:root:2: Epoch 2 train loss: 1132633.846088171\nINFO:root:9: Epoch 2 train loss: 891488.9269050121\nINFO:root:7: Epoch 2 train loss: 663664.8220430792\nINFO:root:0: Epoch 2 validation loss: 5877059.611152871\nINFO:root:3: Epoch 3 train loss: 38987.432169723514\nINFO:root:1: Epoch 3 train loss: 42563.3378616333\nINFO:root:7: Epoch 3 train loss: 758763.2877502441\nINFO:root:6: Epoch 3 train loss: 368972.6901977539\nINFO:root:2: Epoch 3 train loss: 105059.96964838504\nINFO:root:9: Epoch 3 train loss: 1153195.3134310856\nINFO:root:5: Epoch 3 train loss: 1655725.2841796875\nINFO:root:8: Epoch 3 train loss: 14860.462771606446\nINFO:root:4: Epoch 3 train loss: 788663.086454773\nINFO:root:0: Epoch 3 train loss: 16272.929144539685\nINFO:root:0: Epoch 3 validation loss: 5876586.735860381\nINFO:root:0: Epoch 4 train loss: 10187.387786865234\nINFO:root:1: Epoch 4 train loss: 25258.663557434083\nINFO:root:6: Epoch 4 train loss: 1154854.3298095702\nINFO:root:4: Epoch 4 train loss: 790331.364636898\nINFO:root:7: Epoch 4 train loss: 1822183.1927368164\nINFO:root:5: Epoch 4 train loss: 16354.349310684203\nINFO:root:2: Epoch 4 train loss: 668488.108581543\nINFO:root:8: Epoch 4 train loss: 13608.369348144532\nINFO:root:3: Epoch 4 train loss: 33060.61528244019\nINFO:root:9: Epoch 4 train loss: 23652.355755233766\nINFO:root:0: Epoch 4 validation loss: 5875752.764460874\nINFO:root:5: Epoch 5 train loss: 46009.36243057251\nINFO:root:1: Epoch 5 train loss: 285744.0092750549\nINFO:root:3: Epoch 5 train loss: 1609674.818234253\nINFO:root:6: Epoch 5 train loss: 95419.8028793335\nINFO:root:4: Epoch 5 train loss: 38982.73471846581\nINFO:root:7: Epoch 5 train loss: 869403.5599024773\nINFO:root:2: Epoch 5 train loss: 981784.3702514649\nINFO:root:8: Epoch 5 train loss: 4596752.621386719\nINFO:root:9: Epoch 5 train loss: 20312.51544957161\nINFO:root:0: Epoch 5 train loss: 834606.6364562989\nINFO:root:0: Epoch 5 validation loss: 5874506.767633298\n", "seconds": 5.746233940124512, "batch_size": 32, "nodes": 5, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 8 batches\n11 Start Epoch 0\n11: 8 batches\n8 Start Epoch 0\n7 Start Epoch 0\n4 Start Epoch 0\n4: 8 batches\n2 Start Epoch 0\n7: 8 batches\n8: 8 batches\n5 Start Epoch 0\n3 Start Epoch 0\n5: 8 batches\n10 Start Epoch 0\n2: 8 batches\n3: 8 batches\n10: 8 batches\n1 Start Epoch 0\n1: 8 batches\n9 Start Epoch 0\n9: 8 batches\n6 Start Epoch 0\n6: 8 batches\n1 Start Epoch 1\n11 Start Epoch 1\n11: 8 batches\n3 Start Epoch 1\n6 Start Epoch 1\n3: 8 batches\n2 Start Epoch 1\n5 Start Epoch 1\n6: 8 batches\n10 Start Epoch 1\n4 Start Epoch 1\n2: 8 batches\n5: 8 batches\n4: 8 batches\n1: 8 batches\n10: 8 batches\n7 Start Epoch 1\n7: 8 batches\n8 Start Epoch 1\n9 Start Epoch 1\n9: 8 batches\n8: 8 batches\n0 Start Epoch 1\n0: 8 batches\n1 Start Epoch 2\n1: 8 batches\n11 Start Epoch 2\n3 Start Epoch 2\n6 Start Epoch 2\n11: 8 batches\n6: 8 batches\n2 Start Epoch 2\n3: 8 batches\n2: 8 batches\n7 Start Epoch 2\n7: 8 batches\n10 Start Epoch 2\n10: 8 batches\n8 Start Epoch 2\n9 Start Epoch 2\n9: 8 batches\n8: 8 batches\n4 Start Epoch 2\n4: 8 batches\n5 Start Epoch 2\n5: 8 batches\n0 Start Epoch 2\n0: 8 batches\n1 Start Epoch 3\n1: 8 batches\n10 Start Epoch 3\n3 Start Epoch 3\n6 Start Epoch 3\n4 Start Epoch 3\n3: 8 batches\n7 Start Epoch 3\n4: 8 batches\n11 Start Epoch 3\n11: 8 batches\n2 Start Epoch 3\n6: 8 batches\n5 Start Epoch 3\n2: 8 batches\n7: 8 batches\n10: 8 batches\n5: 8 batches\n8 Start Epoch 3\n8: 8 batches\n9 Start Epoch 3\n9: 8 batches\n0 Start Epoch 3\n0: 8 batches\n1 Start Epoch 4\n1: 8 batches\n2 Start Epoch 4\n6 Start Epoch 4\n4 Start Epoch 4\n2: 8 batches\n6: 8 batches\n4: 8 batches\n11 Start Epoch 4\n11: 8 batches\n3 Start Epoch 4\n5 Start Epoch 4\n7 Start Epoch 4\n10 Start Epoch 4\n10: 8 batches\n3: 8 batches\n5: 8 batches\n7: 8 batches\n9 Start Epoch 4\n8 Start Epoch 4\n8: 8 batches\n9: 8 batches\n0 Start Epoch 4\n0: 8 batches\n1 Start Epoch 5\n10 Start Epoch 5\n2 Start Epoch 5\n4 Start Epoch 5\n6 Start Epoch 5\n4: 8 batches\n10: 8 batches\n2: 8 batches\n3 Start Epoch 5\n6: 8 batches\n5 Start Epoch 5\n11 Start Epoch 5\n11: 8 batches\n3: 8 batches\n7 Start Epoch 5\n1: 8 batches\n7: 8 batches\n5: 8 batches\n8 Start Epoch 5\n9 Start Epoch 5\n9: 8 batches\n8: 8 batches\n0 Start Epoch 5\n0: 8 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 4129.374263763428\nINFO:root:1: Epoch 0 train loss: 2242229.4843444824\nINFO:root:11: Epoch 0 train loss: 1980313.015247345\nINFO:root:6: Epoch 0 train loss: 24470.242831349373\nINFO:root:3: Epoch 0 train loss: 1217325.9407470226\nINFO:root:2: Epoch 0 train loss: 11283.854969024658\nINFO:root:7: Epoch 0 train loss: 10665.069425463676\nINFO:root:4: Epoch 0 train loss: 37973.36263656616\nINFO:root:10: Epoch 0 train loss: 365033.87523651123\nINFO:root:5: Epoch 0 train loss: 1227178.2026672363\nINFO:root:8: Epoch 0 train loss: 16862.6649017334\nINFO:root:9: Epoch 0 train loss: 823446.2808532715\nINFO:root:0: Epoch 0 validation loss: 5854258.623938601\nINFO:root:0: Epoch 1 train loss: 32976.31440734863\nINFO:root:1: Epoch 1 train loss: 23999.951791763306\nINFO:root:2: Epoch 1 train loss: 345787.3640499115\nINFO:root:7: Epoch 1 train loss: 1158798.8485546112\nINFO:root:11: Epoch 1 train loss: 1332923.2442855835\nINFO:root:3: Epoch 1 train loss: 129744.47914600372\nINFO:root:6: Epoch 1 train loss: 1548170.4260250926\nINFO:root:10: Epoch 1 train loss: 1101156.0827095509\nINFO:root:9: Epoch 1 train loss: 818879.771730423\nINFO:root:8: Epoch 1 train loss: 42682.20199203491\nINFO:root:4: Epoch 1 train loss: 1014434.9685277939\nINFO:root:5: Epoch 1 train loss: 1097054.8500404358\nINFO:root:0: Epoch 1 validation loss: 5854094.889410092\nINFO:root:1: Epoch 2 train loss: 2013932.5929050446\nINFO:root:0: Epoch 2 train loss: 1824447.961517334\nINFO:root:6: Epoch 2 train loss: 1225449.3388590813\nINFO:root:5: Epoch 2 train loss: 2063581.5134334564\nINFO:root:10: Epoch 2 train loss: 37998.158699035645\nINFO:root:2: Epoch 2 train loss: 26618.40031528473\nINFO:root:11: Epoch 2 train loss: 24545.803747177124\nINFO:root:3: Epoch 2 train loss: 21804.533151626587\nINFO:root:7: Epoch 2 train loss: 1689659.8762073517\nINFO:root:4: Epoch 2 train loss: 64475.413440704346\nINFO:root:8: Epoch 2 train loss: 1876020.2476730347\nINFO:root:9: Epoch 2 train loss: 968741.2564437389\nINFO:root:0: Epoch 2 validation loss: 5853886.763795083\nINFO:root:0: Epoch 3 train loss: 13143.996612548828\nINFO:root:1: Epoch 3 train loss: 981260.6937942505\nINFO:root:7: Epoch 3 train loss: 18489.998092651367\nINFO:root:4: Epoch 3 train loss: 1024254.3096265793\nINFO:root:3: Epoch 3 train loss: 17625.486640930176\nINFO:root:2: Epoch 3 train loss: 45554.98989868164\nINFO:root:6: Epoch 3 train loss: 13143.98046875\nINFO:root:5: Epoch 3 train loss: 22670.409149169922\nINFO:root:11: Epoch 3 train loss: 993526.4360046387\nINFO:root:10: Epoch 3 train loss: 23251.159576416016\nINFO:root:9: Epoch 3 train loss: 16291.48099899292\nINFO:root:8: Epoch 3 train loss: 28413.278228759766\nINFO:root:0: Epoch 3 validation loss: 5853590.995348951\nINFO:root:0: Epoch 4 train loss: 26573.271865844727\nINFO:root:1: Epoch 4 train loss: 1056894.6897029877\nINFO:root:5: Epoch 4 train loss: 10033.097480773926\nINFO:root:10: Epoch 4 train loss: 1220439.478515625\nINFO:root:3: Epoch 4 train loss: 1092440.163356781\nINFO:root:11: Epoch 4 train loss: 1017096.7943730354\nINFO:root:2: Epoch 4 train loss: 10055.71131515503\nINFO:root:7: Epoch 4 train loss: 1000130.7806396484\nINFO:root:4: Epoch 4 train loss: 19898.45379638672\nINFO:root:6: Epoch 4 train loss: 45078.905811309814\nINFO:root:8: Epoch 4 train loss: 28338.149866104126\nINFO:root:9: Epoch 4 train loss: 976775.2007293701\nINFO:root:0: Epoch 4 validation loss: 5853152.022734722\nINFO:root:1: Epoch 5 train loss: 3096920.3160362244\nINFO:root:0: Epoch 5 train loss: 11110.446649551392\nINFO:root:3: Epoch 5 train loss: 1218132.6427612305\nINFO:root:6: Epoch 5 train loss: 1536157.8697662354\nINFO:root:10: Epoch 5 train loss: 22333.587285995483\nINFO:root:2: Epoch 5 train loss: 1087591.2422943115\nINFO:root:7: Epoch 5 train loss: 31755.579119101167\nINFO:root:4: Epoch 5 train loss: 20629.01760339737\nINFO:root:11: Epoch 5 train loss: 25216.702505111694\nINFO:root:5: Epoch 5 train loss: 2392386.4423980713\nINFO:root:8: Epoch 5 train loss: 19819.782508850098\nINFO:root:9: Epoch 5 train loss: 33435.51589202881\nINFO:root:0: Epoch 5 validation loss: 5852599.157643417\n", "seconds": 5.180124282836914, "batch_size": 32, "nodes": 6, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 7 batches\n13 Start Epoch 0\n13: 7 batches\n1 Start Epoch 0\n4 Start Epoch 0\n2 Start Epoch 0\n4: 7 batches\n8 Start Epoch 0\n12 Start Epoch 0\n3 Start Epoch 0\n5 Start Epoch 0\n12: 7 batches\n2: 7 batches\n7 Start Epoch 0\n11 Start Epoch 0\n5: 7 batches\n3: 7 batches\n6 Start Epoch 0\n11: 7 batches\n8: 7 batches\n6: 7 batches\n7: 7 batches\n10 Start Epoch 0\n9 Start Epoch 0\n9: 7 batches\n1: 7 batches\n10: 7 batches\n6 Start Epoch 1\n7 Start Epoch 1\n6: 7 batches\n7: 7 batches\n3 Start Epoch 1\n11 Start Epoch 1\n10 Start Epoch 1\n5 Start Epoch 1\n3: 7 batches\n10: 7 batches\n4 Start Epoch 1\n11: 7 batches\n5: 7 batches\n4: 7 batches\n2 Start Epoch 1\n2: 7 batches\n9 Start Epoch 1\n13 Start Epoch 1\n12 Start Epoch 1\n8 Start Epoch 1\n9: 7 batches\n13: 7 batches\n12: 7 batches\n8: 7 batches\n1 Start Epoch 1\n1: 7 batches\n0 Start Epoch 1\n0: 7 batches\n7 Start Epoch 2\n6 Start Epoch 2\n6: 7 batches\n7: 7 batches\n11 Start Epoch 2\n4 Start Epoch 2\n10 Start Epoch 2\n3 Start Epoch 2\n10: 7 batches\n5 Start Epoch 2\n11: 7 batches\n4: 7 batches\n3: 7 batches\n5: 7 batches\n2 Start Epoch 2\n2: 7 batches\n8 Start Epoch 2\n12 Start Epoch 2\n9 Start Epoch 2\n8: 7 batches\n12: 7 batches\n9: 7 batches\n13 Start Epoch 2\n13: 7 batches\n1 Start Epoch 2\n1: 7 batches\n0 Start Epoch 2\n0: 7 batches\n11 Start Epoch 3\n10 Start Epoch 3\n10: 7 batches\n11: 7 batches\n3 Start Epoch 3\n6 Start Epoch 3\n3: 7 batches\n7 Start Epoch 3\n5 Start Epoch 3\n2 Start Epoch 3\n6: 7 batches\n4 Start Epoch 3\n2: 7 batches\n7: 7 batches\n4: 7 batches\n5: 7 batches\n9 Start Epoch 3\n9: 7 batches\n8 Start Epoch 3\n8: 7 batches\n12 Start Epoch 3\n13 Start Epoch 3\n12: 7 batches\n13: 7 batches\n1 Start Epoch 3\n1: 7 batches\n0 Start Epoch 3\n0: 7 batches\n11 Start Epoch 4\n10 Start Epoch 4\n10: 7 batches\n11: 7 batches\n5 Start Epoch 4\n5: 7 batches\n2 Start Epoch 4\n6 Start Epoch 4\n2: 7 batches\n7 Start Epoch 4\n3 Start Epoch 4\n6: 7 batches\n3: 7 batches\n7: 7 batches\n4 Start Epoch 4\n4: 7 batches\n12 Start Epoch 4\n13 Start Epoch 4\n13: 7 batches\n9 Start Epoch 4\n12: 7 batches\n8 Start Epoch 4\n8: 7 batches\n9: 7 batches\n1 Start Epoch 4\n1: 7 batches\n0 Start Epoch 4\n0: 7 batches\n2 Start Epoch 5\n6 Start Epoch 5\n11 Start Epoch 5\n4 Start Epoch 5\n4: 7 batches\n2: 7 batches\n6: 7 batches\n10 Start Epoch 5\n10: 7 batches\n5 Start Epoch 5\n3 Start Epoch 5\n7 Start Epoch 5\n11: 7 batches\n5: 7 batches\n3: 7 batches\n7: 7 batches\n9 Start Epoch 5\n8 Start Epoch 5\n13 Start Epoch 5\n9: 7 batches\n12 Start Epoch 5\n8: 7 batches\n12: 7 batches\n13: 7 batches\n1 Start Epoch 5\n1: 7 batches\n0 Start Epoch 5\n0: 7 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:6: Epoch 0 train loss: 8994.041813441685\nINFO:root:7: Epoch 0 train loss: 11950.862269129071\nINFO:root:11: Epoch 0 train loss: 936661.555494036\nINFO:root:4: Epoch 0 train loss: 414802.63361467636\nINFO:root:10: Epoch 0 train loss: 19641.10448864528\nINFO:root:5: Epoch 0 train loss: 1106575.9551228115\nINFO:root:3: Epoch 0 train loss: 1635289.9809570312\nINFO:root:0: Epoch 0 train loss: 1255833.1165030343\nINFO:root:8: Epoch 0 train loss: 16498.165531703406\nINFO:root:12: Epoch 0 train loss: 52046.1137738909\nINFO:root:2: Epoch 0 train loss: 3369.250693184989\nINFO:root:9: Epoch 0 train loss: 2194661.128642491\nINFO:root:13: Epoch 0 train loss: 146233.23844800677\nINFO:root:1: Epoch 0 train loss: 987339.0205208914\nINFO:root:0: Epoch 0 validation loss: 21681.70951836325\nINFO:root:7: Epoch 1 train loss: 20694.96084158761\nINFO:root:6: Epoch 1 train loss: 953751.5012468611\nINFO:root:11: Epoch 1 train loss: 1404339.4110281807\nINFO:root:5: Epoch 1 train loss: 3994.634982517787\nINFO:root:10: Epoch 1 train loss: 31480.172389439173\nINFO:root:4: Epoch 1 train loss: 1204268.037764413\nINFO:root:2: Epoch 1 train loss: 14675.737692696708\nINFO:root:3: Epoch 1 train loss: 10734.663979666573\nINFO:root:9: Epoch 1 train loss: 2329035.496494838\nINFO:root:13: Epoch 1 train loss: 22197.892580441065\nINFO:root:8: Epoch 1 train loss: 1584633.0757010323\nINFO:root:12: Epoch 1 train loss: 2206121.0110691614\nINFO:root:1: Epoch 1 train loss: 4451.968444824219\nINFO:root:0: Epoch 1 train loss: 3328367.2165178573\nINFO:root:0: Epoch 1 validation loss: 21667.09710761134\nINFO:root:11: Epoch 2 train loss: 1842000.7789791652\nINFO:root:10: Epoch 2 train loss: 26098.905790601457\nINFO:root:2: Epoch 2 train loss: 2101511.99785505\nINFO:root:6: Epoch 2 train loss: 1410543.612688337\nINFO:root:3: Epoch 2 train loss: 74443.29849243164\nINFO:root:7: Epoch 2 train loss: 1169096.2940499443\nINFO:root:4: Epoch 2 train loss: 1253135.3714239937\nINFO:root:5: Epoch 2 train loss: 16245.088001796177\nINFO:root:9: Epoch 2 train loss: 2524531.800807408\nINFO:root:8: Epoch 2 train loss: 30780.90691266741\nINFO:root:12: Epoch 2 train loss: 1384373.5283521924\nINFO:root:13: Epoch 2 train loss: 1183717.6821725029\nINFO:root:0: Epoch 2 train loss: 6272.078673226492\nINFO:root:1: Epoch 2 train loss: 6676668.344274248\nINFO:root:0: Epoch 2 validation loss: 21648.439960575823\nINFO:root:11: Epoch 3 train loss: 1189510.969822475\nINFO:root:10: Epoch 3 train loss: 145275.09914725166\nINFO:root:5: Epoch 3 train loss: 2390316.9562290735\nINFO:root:2: Epoch 3 train loss: 22000.33980015346\nINFO:root:6: Epoch 3 train loss: 13400.34479522705\nINFO:root:3: Epoch 3 train loss: 30474.50069754464\nINFO:root:7: Epoch 3 train loss: 400557.7021135603\nINFO:root:4: Epoch 3 train loss: 1130048.330592564\nINFO:root:12: Epoch 3 train loss: 18128.371534075057\nINFO:root:13: Epoch 3 train loss: 17787.121599469865\nINFO:root:9: Epoch 3 train loss: 28550.534358433313\nINFO:root:8: Epoch 3 train loss: 1101893.5152446202\nINFO:root:1: Epoch 3 train loss: 13065.493161882672\nINFO:root:0: Epoch 3 train loss: 1190339.8394949776\nINFO:root:0: Epoch 3 validation loss: 21622.600477829063\nINFO:root:3: Epoch 4 train loss: 2764.0712280273438\nINFO:root:7: Epoch 4 train loss: 1248041.8408203125\nINFO:root:10: Epoch 4 train loss: 1178722.265562875\nINFO:root:5: Epoch 4 train loss: 23960.116040910994\nINFO:root:2: Epoch 4 train loss: 1209153.5925249371\nINFO:root:6: Epoch 4 train loss: 2071847.845790318\nINFO:root:11: Epoch 4 train loss: 443096.70154680527\nINFO:root:4: Epoch 4 train loss: 1608484.3108836582\nINFO:root:8: Epoch 4 train loss: 1282748.2018465314\nINFO:root:9: Epoch 4 train loss: 19046.085736955916\nINFO:root:12: Epoch 4 train loss: 138565.09055001396\nINFO:root:13: Epoch 4 train loss: 25556.542951311385\nINFO:root:1: Epoch 4 train loss: 6942.510784694126\nINFO:root:0: Epoch 4 train loss: 1241054.8778163365\nINFO:root:0: Epoch 4 validation loss: 21583.565963151126\nINFO:root:1: Epoch 5 train loss: 136577.88365827288\nINFO:root:0: Epoch 5 train loss: 1155242.9981570926\nINFO:root:12: Epoch 5 train loss: 17107.375938415527\nINFO:root:3: Epoch 5 train loss: 27454.982299804688\nINFO:root:13: Epoch 5 train loss: 21852.49114227295\nINFO:root:2: Epoch 5 train loss: 61485.37051827567\nINFO:root:6: Epoch 5 train loss: 1106215.9224967957\nINFO:root:11: Epoch 5 train loss: 398490.4997427804\nINFO:root:9: Epoch 5 train loss: 1060282.4476100376\nINFO:root:4: Epoch 5 train loss: 2158633.4817330497\nINFO:root:5: Epoch 5 train loss: 1197734.4430847168\nINFO:root:7: Epoch 5 train loss: 51642.97307477678\nINFO:root:10: Epoch 5 train loss: 1207631.7670767647\nINFO:root:8: Epoch 5 train loss: 8596.324390411377\nINFO:root:0: Epoch 5 validation loss: 21528.482221603394\n", "seconds": 5.6133692264556885, "batch_size": 32, "nodes": 7, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 6 batches\n1 Start Epoch 0\n1: 6 batches\n2 Start Epoch 0\n2: 6 batches\n15 Start Epoch 0\n7 Start Epoch 0\n15: 6 batches\n7: 6 batches\n11 Start Epoch 0\n11: 6 batches\n4 Start Epoch 0\n4: 6 batches\n3 Start Epoch 0\n8 Start Epoch 0\n3: 6 batches\n12 Start Epoch 0\n12: 6 batches\n8: 6 batches\n13 Start Epoch 0\n13: 6 batches\n6 Start Epoch 0\n14 Start Epoch 0\n5 Start Epoch 0\n9 Start Epoch 0\n10 Start Epoch 0\n10: 6 batches\n6: 6 batches\n14: 6 batches\n5: 6 batches\n9: 6 batches\n6 Start Epoch 1\n7 Start Epoch 1\n11 Start Epoch 1\n5 Start Epoch 1\n3 Start Epoch 1\n10 Start Epoch 1\n6: 6 batches\n7: 6 batches\n15 Start Epoch 1\n4 Start Epoch 1\n2 Start Epoch 1\n10: 6 batches\n3: 6 batches\n11: 6 batches\n15: 6 batches\n4: 6 batches\n1 Start Epoch 1\n1: 6 batches\n2: 6 batches\n5: 6 batches\n14 Start Epoch 1\n8 Start Epoch 1\n13 Start Epoch 1\n14: 6 batches\n9 Start Epoch 1\n13: 6 batches\n9: 6 batches\n8: 6 batches\n12 Start Epoch 1\n12: 6 batches\n0 Start Epoch 1\n0: 6 batches\n6 Start Epoch 2\n7 Start Epoch 2\n5 Start Epoch 2\n6: 6 batches\n7: 6 batches\n5: 6 batches\n11 Start Epoch 2\n10 Start Epoch 2\n14 Start Epoch 2\n14: 6 batches\n4 Start Epoch 2\n2 Start Epoch 2\n10: 6 batches\n3 Start Epoch 2\n3: 6 batches\n11: 6 batches\n15 Start Epoch 2\n4: 6 batches\n2: 6 batches\n15: 6 batches\n9 Start Epoch 2\n8 Start Epoch 2\n8: 6 batches\n1 Start Epoch 2\n1: 6 batches\n9: 6 batches\n13 Start Epoch 2\n12 Start Epoch 2\n13: 6 batches\n12: 6 batches\n0 Start Epoch 2\n0: 6 batches\n1 Start Epoch 3\n1: 6 batches\n14 Start Epoch 3\n14: 6 batches\n7 Start Epoch 3\n2 Start Epoch 3\n11 Start Epoch 3\n15 Start Epoch 3\n5 Start Epoch 3\n9 Start Epoch 3\n3 Start Epoch 3\n10 Start Epoch 3\n13 Start Epoch 3\n6 Start Epoch 3\n12 Start Epoch 3\n7: 6 batches\n15: 6 batches\n4 Start Epoch 3\n8 Start Epoch 3\n3: 6 batches\n10: 6 batches\n4: 6 batches\n8: 6 batches\n2: 6 batches\n11: 6 batches\n12: 6 batches\n6: 6 batches\n9: 6 batches\n13: 6 batches\n5: 6 batches\n0 Start Epoch 3\n0: 6 batches\n1 Start Epoch 4\n1: 6 batches\n8 Start Epoch 4\n6 Start Epoch 4\n12 Start Epoch 4\n7 Start Epoch 4\n15 Start Epoch 4\n8: 6 batches\n11 Start Epoch 4\n9 Start Epoch 4\n2 Start Epoch 4\n10 Start Epoch 4\n13 Start Epoch 4\n6: 6 batches\n14 Start Epoch 4\n14: 6 batches\n4 Start Epoch 4\n9: 6 batches\n3 Start Epoch 4\n10: 6 batches\n12: 6 batches\n7: 6 batches\n3: 6 batches\n11: 6 batches\n13: 6 batches\n15: 6 batches\n5 Start Epoch 4\n4: 6 batches\n2: 6 batches\n5: 6 batches\n0 Start Epoch 4\n0: 6 batches\n1 Start Epoch 5\n6 Start Epoch 5\n7 Start Epoch 5\n4 Start Epoch 5\n2 Start Epoch 5\n6: 6 batches\n4: 6 batches\n3 Start Epoch 5\n3: 6 batches\n1: 6 batches\n5 Start Epoch 5\n2: 6 batches\n11 Start Epoch 5\n7: 6 batches\n10 Start Epoch 5\n13 Start Epoch 5\n14 Start Epoch 5\n5: 6 batches\n15 Start Epoch 5\n11: 6 batches\n12 Start Epoch 5\n10: 6 batches\n13: 6 batches\n14: 6 batches\n12: 6 batches\n15: 6 batches\n9 Start Epoch 5\n9: 6 batches\n8 Start Epoch 5\n8: 6 batches\n0 Start Epoch 5\n0: 6 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:6: Epoch 0 train loss: 12839.095761617025\nINFO:root:7: Epoch 0 train loss: 13102.156331380209\nINFO:root:11: Epoch 0 train loss: 9124.307353973389\nINFO:root:4: Epoch 0 train loss: 15892.68423461914\nINFO:root:2: Epoch 0 train loss: 1342143.235768636\nINFO:root:10: Epoch 0 train loss: 1383569.1068077087\nINFO:root:5: Epoch 0 train loss: 66092.65120442708\nINFO:root:3: Epoch 0 train loss: 1340879.5228271484\nINFO:root:15: Epoch 0 train loss: 10318.5880762736\nINFO:root:1: Epoch 0 train loss: 1133082.7201334636\nINFO:root:8: Epoch 0 train loss: 1967701.9273732502\nINFO:root:9: Epoch 0 train loss: 468384.42527770996\nINFO:root:13: Epoch 0 train loss: 18607.464513142902\nINFO:root:14: Epoch 0 train loss: 18937.1739692688\nINFO:root:12: Epoch 0 train loss: 65769.27870210011\nINFO:root:0: Epoch 0 train loss: 1391030.60546875\nINFO:root:0: Epoch 0 validation loss: 9323.337976016537\nINFO:root:7: Epoch 1 train loss: 562069.1434783936\nINFO:root:6: Epoch 1 train loss: 1459849.4443918865\nINFO:root:5: Epoch 1 train loss: 18617.469716389973\nINFO:root:11: Epoch 1 train loss: 1098038.9799601238\nINFO:root:10: Epoch 1 train loss: 4289.484375\nINFO:root:15: Epoch 1 train loss: 5256.497528076172\nINFO:root:14: Epoch 1 train loss: 58522.81797281901\nINFO:root:2: Epoch 1 train loss: 6876.362080891927\nINFO:root:3: Epoch 1 train loss: 1465305.6974690754\nINFO:root:4: Epoch 1 train loss: 1087926.654373169\nINFO:root:9: Epoch 1 train loss: 26267.676060994465\nINFO:root:8: Epoch 1 train loss: 12263.098121643066\nINFO:root:12: Epoch 1 train loss: 17624.38032023112\nINFO:root:1: Epoch 1 train loss: 1297114.6745808918\nINFO:root:13: Epoch 1 train loss: 32520.769185384113\nINFO:root:0: Epoch 1 train loss: 3852673.5394763947\nINFO:root:0: Epoch 1 validation loss: 9312.603177480143\nINFO:root:1: Epoch 2 train loss: 1355264.9663899739\nINFO:root:0: Epoch 2 train loss: 1293516.5846895378\nINFO:root:14: Epoch 2 train loss: 18372.13170115153\nINFO:root:15: Epoch 2 train loss: 3410047.4989446006\nINFO:root:2: Epoch 2 train loss: 472672.48328653973\nINFO:root:12: Epoch 2 train loss: 1455921.2376403809\nINFO:root:6: Epoch 2 train loss: 1986.8826497395833\nINFO:root:10: Epoch 2 train loss: 5886.342048724492\nINFO:root:11: Epoch 2 train loss: 469158.53280528384\nINFO:root:13: Epoch 2 train loss: 1591941.3801879883\nINFO:root:7: Epoch 2 train loss: 34034.45708719889\nINFO:root:5: Epoch 2 train loss: 50887.2960764567\nINFO:root:9: Epoch 2 train loss: 31667.683919270832\nINFO:root:3: Epoch 2 train loss: 33109.661376953125\nINFO:root:4: Epoch 2 train loss: 1313450.7485148113\nINFO:root:8: Epoch 2 train loss: 3290.4492495854697\nINFO:root:0: Epoch 2 validation loss: 9298.237194670686\nINFO:root:0: Epoch 3 train loss: 1367682.9207967122\nINFO:root:1: Epoch 3 train loss: 5925.508539835612\nINFO:root:7: Epoch 3 train loss: 1338109.5700709026\nINFO:root:8: Epoch 3 train loss: 1360998.335074107\nINFO:root:11: Epoch 3 train loss: 6489.964889526367\nINFO:root:12: Epoch 3 train loss: 24880.088053385418\nINFO:root:6: Epoch 3 train loss: 9445.096666653952\nINFO:root:15: Epoch 3 train loss: 13778.964335123697\nINFO:root:9: Epoch 3 train loss: 14307.003580729166\nINFO:root:14: Epoch 3 train loss: 4762.464182535808\nINFO:root:3: Epoch 3 train loss: 19868.697387695312\nINFO:root:10: Epoch 3 train loss: 31451.02843983968\nINFO:root:13: Epoch 3 train loss: 1349869.0146077473\nINFO:root:5: Epoch 3 train loss: 2002188.1005859375\nINFO:root:2: Epoch 3 train loss: 38546.29987080892\nINFO:root:4: Epoch 3 train loss: 42632.669189453125\nINFO:root:0: Epoch 3 validation loss: 9278.838735392706\nINFO:root:0: Epoch 4 train loss: 1175683.7443847656\nINFO:root:1: Epoch 4 train loss: 1415420.7142181396\nINFO:root:6: Epoch 4 train loss: 13158.373901367188\nINFO:root:7: Epoch 4 train loss: 1385585.8389495213\nINFO:root:5: Epoch 4 train loss: 176903.5545654297\nINFO:root:2: Epoch 4 train loss: 1402974.9724826813\nINFO:root:4: Epoch 4 train loss: 1382637.6555474598\nINFO:root:3: Epoch 4 train loss: 7278.0997314453125\nINFO:root:10: Epoch 4 train loss: 1479600.1605059307\nINFO:root:13: Epoch 4 train loss: 22745.57958984375\nINFO:root:15: Epoch 4 train loss: 11918.795776367188\nINFO:root:11: Epoch 4 train loss: 34410.618352254234\nINFO:root:12: Epoch 4 train loss: 1400455.0567525227\nINFO:root:14: Epoch 4 train loss: 1446068.9554341633\nINFO:root:9: Epoch 4 train loss: 1902607.0560099285\nINFO:root:8: Epoch 4 train loss: 7353.172190348308\nINFO:root:0: Epoch 4 validation loss: 9252.666391669676\nINFO:root:0: Epoch 5 train loss: 1613764.6524658203\nINFO:root:1: Epoch 5 train loss: 14254.280888875326\nINFO:root:7: Epoch 5 train loss: 189925.2088216146\nINFO:root:2: Epoch 5 train loss: 1083317.60614268\nINFO:root:3: Epoch 5 train loss: 5092.783680597941\nINFO:root:12: Epoch 5 train loss: 52896.10768636068\nINFO:root:6: Epoch 5 train loss: 1432927.4867045085\nINFO:root:15: Epoch 5 train loss: 13027.780212402344\nINFO:root:4: Epoch 5 train loss: 1289887.8661702473\nINFO:root:5: Epoch 5 train loss: 1350131.466790517\nINFO:root:11: Epoch 5 train loss: 13960.8247756958\nINFO:root:13: Epoch 5 train loss: 27606.533650716145\nINFO:root:14: Epoch 5 train loss: 4783.462767283122\nINFO:root:10: Epoch 5 train loss: 2752659.1386388144\nINFO:root:9: Epoch 5 train loss: 457807.2417399089\nINFO:root:8: Epoch 5 train loss: 2045525.9055989583\nINFO:root:0: Epoch 5 validation loss: 9219.44971191472\n", "seconds": 5.858547925949097, "batch_size": 32, "nodes": 8, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 6 batches\n1 Start Epoch 0\n2 Start Epoch 0\n2: 6 batches\n1: 6 batches\n17 Start Epoch 0\n17: 6 batches\n9 Start Epoch 0\n9: 6 batches\n10 Start Epoch 0\n6 Start Epoch 0\n5 Start Epoch 0\n6: 6 batches\n5: 6 batches\n14 Start Epoch 0\n14: 6 batches\n10: 6 batches\n13 Start Epoch 0\n13: 6 batches\n8 Start Epoch 0\n8: 6 batches\n3 Start Epoch 0\n4 Start Epoch 0\n3: 6 batches\n4: 6 batches\n11 Start Epoch 0\n11: 6 batches\n12 Start Epoch 0\n7 Start Epoch 0\n15 Start Epoch 0\n16 Start Epoch 0\n12: 6 batches\n7: 6 batches\n16: 6 batches\n15: 6 batches\n9 Start Epoch 1\n6 Start Epoch 1\n8 Start Epoch 1\n7 Start Epoch 1\n5 Start Epoch 1\n6: 6 batches\n4 Start Epoch 1\n3 Start Epoch 1\n8: 6 batches\n9: 6 batches\n7: 6 batches\n4: 6 batches\n16 Start Epoch 1\n2 Start Epoch 1\n5: 6 batches\n14 Start Epoch 1\n17 Start Epoch 1\n3: 6 batches\n13 Start Epoch 1\n2: 6 batches\n12 Start Epoch 1\n15 Start Epoch 1\n16: 6 batches\n14: 6 batches\n17: 6 batches\n12: 6 batches\n13: 6 batches\n15: 6 batches\n10 Start Epoch 1\n11 Start Epoch 1\n11: 6 batches\n10: 6 batches\n1 Start Epoch 1\n1: 6 batches\n0 Start Epoch 1\n0: 6 batches\n6 Start Epoch 2\n7 Start Epoch 2\n5 Start Epoch 2\n6: 6 batches\n4 Start Epoch 2\n2 Start Epoch 2\n7: 6 batches\n4: 6 batches\n5: 6 batches\n14 Start Epoch 2\n17 Start Epoch 2\n3 Start Epoch 2\n13 Start Epoch 2\n15 Start Epoch 2\n16 Start Epoch 2\n2: 6 batches\n12 Start Epoch 2\n15: 6 batches\n17: 6 batches\n3: 6 batches\n12: 6 batches\n14: 6 batches\n16: 6 batches\n13: 6 batches\n10 Start Epoch 2\n9 Start Epoch 2\n11 Start Epoch 2\n8 Start Epoch 2\n8: 6 batches\n11: 6 batches\n10: 6 batches\n9: 6 batches\n1 Start Epoch 2\n1: 6 batches\n0 Start Epoch 2\n0: 6 batches\n6 Start Epoch 3\n7 Start Epoch 3\n5 Start Epoch 3\n3 Start Epoch 3\n6: 6 batches\n4 Start Epoch 3\n7: 6 batches\n4: 6 batches\n16 Start Epoch 3\n2 Start Epoch 3\n5: 6 batches\n14 Start Epoch 3\n17 Start Epoch 3\n2: 6 batches\n15 Start Epoch 3\n16: 6 batches\n3: 6 batches\n12 Start Epoch 3\n15: 6 batches\n17: 6 batches\n13 Start Epoch 3\n14: 6 batches\n12: 6 batches\n13: 6 batches\n11 Start Epoch 3\n10 Start Epoch 3\n11: 6 batches\n10: 6 batches\n8 Start Epoch 3\n9 Start Epoch 3\n9: 6 batches\n1 Start Epoch 3\n1: 6 batches\n8: 6 batches\n0 Start Epoch 3\n0: 6 batches\n6 Start Epoch 4\n6: 6 batches\n7 Start Epoch 4\n7: 6 batches\n4 Start Epoch 4\n2 Start Epoch 4\n4: 6 batches\n2: 6 batches\n3 Start Epoch 4\n12 Start Epoch 4\n5 Start Epoch 4\n14 Start Epoch 4\n17 Start Epoch 4\n13 Start Epoch 4\n5: 6 batches\n15 Start Epoch 4\n17: 6 batches\n3: 6 batches\n15: 6 batches\n16 Start Epoch 4\n11 Start Epoch 4\n13: 6 batches\n10 Start Epoch 4\n14: 6 batches\n10: 6 batches\n11: 6 batches\n16: 6 batches\n12: 6 batches\n1 Start Epoch 4\n1: 6 batches\n8 Start Epoch 4\n8: 6 batches\n9 Start Epoch 4\n9: 6 batches\n0 Start Epoch 4\n0: 6 batches\n4 Start Epoch 5\n6 Start Epoch 5\n7 Start Epoch 5\n5 Start Epoch 5\n6: 6 batches\n5: 6 batches\n2 Start Epoch 5\n3 Start Epoch 5\n7: 6 batches\n3: 6 batches\n16 Start Epoch 5\n14 Start Epoch 5\n17 Start Epoch 5\n12 Start Epoch 5\n4: 6 batches\n15 Start Epoch 5\n16: 6 batches\n15: 6 batches\n17: 6 batches\n2: 6 batches\n11 Start Epoch 5\n13 Start Epoch 5\n10 Start Epoch 5\n13: 6 batches\n11: 6 batches\n10: 6 batches\n14: 6 batches\n12: 6 batches\n1 Start Epoch 5\n1: 6 batches\n8 Start Epoch 5\n8: 6 batches\n9 Start Epoch 5\n9: 6 batches\n0 Start Epoch 5\n0: 6 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:7: Epoch 0 train loss: 1341598.5637616958\nINFO:root:9: Epoch 0 train loss: 14798.948278069496\nINFO:root:8: Epoch 0 train loss: 8411.66423288981\nINFO:root:6: Epoch 0 train loss: 69144.99858856201\nINFO:root:4: Epoch 0 train loss: 2915.8092041015625\nINFO:root:5: Epoch 0 train loss: 15316.831726074219\nINFO:root:2: Epoch 0 train loss: 3567808.317021688\nINFO:root:16: Epoch 0 train loss: 34477.46444193522\nINFO:root:3: Epoch 0 train loss: 989306.1477661133\nINFO:root:12: Epoch 0 train loss: 40177.060872395836\nINFO:root:14: Epoch 0 train loss: 1351349.2034404252\nINFO:root:17: Epoch 0 train loss: 5816.589125315349\nINFO:root:13: Epoch 0 train loss: 37678.284940719604\nINFO:root:15: Epoch 0 train loss: 38712.50207519531\nINFO:root:10: Epoch 0 train loss: 9746.854512532553\nINFO:root:11: Epoch 0 train loss: 25722.649068196613\nINFO:root:0: Epoch 0 train loss: 9611.773964568521\nINFO:root:1: Epoch 0 train loss: 10206.099457740784\nINFO:root:0: Epoch 0 validation loss: 1048029.6319696745\nINFO:root:7: Epoch 1 train loss: 1493809.315851206\nINFO:root:6: Epoch 1 train loss: 1285945.3422838848\nINFO:root:5: Epoch 1 train loss: 1327771.5824782054\nINFO:root:4: Epoch 1 train loss: 20109.53029235204\nINFO:root:3: Epoch 1 train loss: 15606.622721354166\nINFO:root:15: Epoch 1 train loss: 496007.79380289715\nINFO:root:17: Epoch 1 train loss: 47830.6796468099\nINFO:root:2: Epoch 1 train loss: 50855.72446695963\nINFO:root:13: Epoch 1 train loss: 25087.04397837321\nINFO:root:14: Epoch 1 train loss: 1099191.548268636\nINFO:root:16: Epoch 1 train loss: 1605730.274379258\nINFO:root:12: Epoch 1 train loss: 1607566.9122517903\nINFO:root:11: Epoch 1 train loss: 12379.13818438848\nINFO:root:9: Epoch 1 train loss: 26344.197732051212\nINFO:root:10: Epoch 1 train loss: 3046796.4538879395\nINFO:root:8: Epoch 1 train loss: 14977.959812164307\nINFO:root:1: Epoch 1 train loss: 9602.968943913778\nINFO:root:0: Epoch 1 train loss: 49218.986554940544\nINFO:root:0: Epoch 1 validation loss: 1047948.363864876\nINFO:root:7: Epoch 2 train loss: 12945.405306498209\nINFO:root:4: Epoch 2 train loss: 2697022.8679097495\nINFO:root:6: Epoch 2 train loss: 39193.68594588836\nINFO:root:5: Epoch 2 train loss: 1801922.1389988859\nINFO:root:2: Epoch 2 train loss: 13229.80336602529\nINFO:root:16: Epoch 2 train loss: 27122.004725138348\nINFO:root:3: Epoch 2 train loss: 15683.198264027635\nINFO:root:17: Epoch 2 train loss: 73836.13814914227\nINFO:root:14: Epoch 2 train loss: 9488.642436981201\nINFO:root:15: Epoch 2 train loss: 461342.3876139323\nINFO:root:12: Epoch 2 train loss: 1105715.86744107\nINFO:root:13: Epoch 2 train loss: 4653.824218923847\nINFO:root:10: Epoch 2 train loss: 1174281.5905847822\nINFO:root:11: Epoch 2 train loss: 1619204.6469726562\nINFO:root:8: Epoch 2 train loss: 18842.27267710368\nINFO:root:9: Epoch 2 train loss: 7344.4655838012695\nINFO:root:1: Epoch 2 train loss: 1298705.7868843079\nINFO:root:0: Epoch 2 train loss: 1102968.0676778157\nINFO:root:0: Epoch 2 validation loss: 1047856.4513820122\nINFO:root:0: Epoch 3 train loss: 1286139.8508524895\nINFO:root:1: Epoch 3 train loss: 505542.88169352215\nINFO:root:6: Epoch 3 train loss: 2595708.142186483\nINFO:root:7: Epoch 3 train loss: 44086.736572265625\nINFO:root:5: Epoch 3 train loss: 5610.224569956462\nINFO:root:2: Epoch 3 train loss: 6355.268066724141\nINFO:root:3: Epoch 3 train loss: 1192721.2428385417\nINFO:root:4: Epoch 3 train loss: 38598.37237596512\nINFO:root:12: Epoch 3 train loss: 1308865.285194397\nINFO:root:14: Epoch 3 train loss: 17906.139306352783\nINFO:root:16: Epoch 3 train loss: 2491680.4961868324\nINFO:root:13: Epoch 3 train loss: 1388480.823659266\nINFO:root:15: Epoch 3 train loss: 16500.631624857586\nINFO:root:17: Epoch 3 train loss: 24405.622464497883\nINFO:root:11: Epoch 3 train loss: 32597.17473053327\nINFO:root:10: Epoch 3 train loss: 6761.030530929565\nINFO:root:8: Epoch 3 train loss: 1096857.4541625977\nINFO:root:9: Epoch 3 train loss: 36533.72798665365\nINFO:root:0: Epoch 3 validation loss: 1047744.648980017\nINFO:root:1: Epoch 4 train loss: 76160.56828022003\nINFO:root:0: Epoch 4 train loss: 1615469.2681355476\nINFO:root:7: Epoch 4 train loss: 2738081.110850016\nINFO:root:4: Epoch 4 train loss: 14989.16186618805\nINFO:root:6: Epoch 4 train loss: 32711.458587646484\nINFO:root:5: Epoch 4 train loss: 3460.643753051758\nINFO:root:2: Epoch 4 train loss: 10632207.18572998\nINFO:root:3: Epoch 4 train loss: 4237.5449778238935\nINFO:root:16: Epoch 4 train loss: 46720.263836871985\nINFO:root:14: Epoch 4 train loss: 1159524.1176406543\nINFO:root:17: Epoch 4 train loss: 19285.322713216145\nINFO:root:12: Epoch 4 train loss: 9557.90609741211\nINFO:root:15: Epoch 4 train loss: 44271.14691293255\nINFO:root:11: Epoch 4 train loss: 24379.703699747723\nINFO:root:13: Epoch 4 train loss: 1341934.1883214314\nINFO:root:10: Epoch 4 train loss: 17725.78040568034\nINFO:root:9: Epoch 4 train loss: 17045.94955952962\nINFO:root:8: Epoch 4 train loss: 48884.91017929713\nINFO:root:0: Epoch 4 validation loss: 1047595.5144418163\nINFO:root:1: Epoch 5 train loss: 8614.351036111513\nINFO:root:0: Epoch 5 train loss: 1169633.9064534504\nINFO:root:2: Epoch 5 train loss: 180278.15922927856\nINFO:root:6: Epoch 5 train loss: 10929.423290252686\nINFO:root:5: Epoch 5 train loss: 29454.995559692383\nINFO:root:7: Epoch 5 train loss: 226747.93513997397\nINFO:root:4: Epoch 5 train loss: 35915.160513559975\nINFO:root:3: Epoch 5 train loss: 48922.770508491434\nINFO:root:16: Epoch 5 train loss: 464931.7279785474\nINFO:root:15: Epoch 5 train loss: 12710.05286916097\nINFO:root:17: Epoch 5 train loss: 2845549.6544659934\nINFO:root:13: Epoch 5 train loss: 1121958.886774699\nINFO:root:12: Epoch 5 train loss: 21850.435029347736\nINFO:root:14: Epoch 5 train loss: 29246.508463541668\nINFO:root:10: Epoch 5 train loss: 1462368.6283162434\nINFO:root:11: Epoch 5 train loss: 1623218.4024836223\nINFO:root:8: Epoch 5 train loss: 48449.194595336914\nINFO:root:9: Epoch 5 train loss: 16779.807334899902\nINFO:root:0: Epoch 5 validation loss: 1047398.9364134864\n", "seconds": 5.987298965454102, "batch_size": 32, "nodes": 9, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 5 batches\n1 Start Epoch 0\n2 Start Epoch 0\n2: 5 batches\n1: 5 batches\n19 Start Epoch 0\n19: 5 batches\n4 Start Epoch 0\n4: 5 batches\n3 Start Epoch 0\n3: 5 batches\n11 Start Epoch 0\n12 Start Epoch 0\n11: 5 batches\n14 Start Epoch 0\n6 Start Epoch 0\n12: 5 batches\n14: 5 batches\n13 Start Epoch 0\n6: 5 batches\n13: 5 batches\n5 Start Epoch 0\n5: 5 batches\n7 Start Epoch 0\n7: 5 batches\n10 Start Epoch 0\n9 Start Epoch 0\n8 Start Epoch 0\n10: 5 batches\n18 Start Epoch 0\n8: 5 batches\n18: 5 batches\n9: 5 batches\n17 Start Epoch 0\n16 Start Epoch 0\n15 Start Epoch 0\n17: 5 batches\n15: 5 batches\n16: 5 batches\n3 Start Epoch 1\n7 Start Epoch 1\n2 Start Epoch 1\n2: 5 batches\n18 Start Epoch 1\n6 Start Epoch 1\n19 Start Epoch 1\n7: 5 batches\n3: 5 batches\n15 Start Epoch 1\n6: 5 batches\n14 Start Epoch 1\n19: 5 batches\n15: 5 batches\n18: 5 batches\n14: 5 batches\n8 Start Epoch 1\n17 Start Epoch 1\n10 Start Epoch 1\n5 Start Epoch 1\n11 Start Epoch 1\n12 Start Epoch 1\n9 Start Epoch 1\n16 Start Epoch 1\n5: 5 batches\n11: 5 batches\n13 Start Epoch 1\n9: 5 batches\n16: 5 batches\n10: 5 batches\n12: 5 batches\n8: 5 batches\n17: 5 batches\n4 Start Epoch 1\n4: 5 batches\n13: 5 batches\n1 Start Epoch 1\n1: 5 batches\n0 Start Epoch 1\n0: 5 batches\n10 Start Epoch 2\n18 Start Epoch 2\n19 Start Epoch 2\n17 Start Epoch 2\n16 Start Epoch 2\n10: 5 batches\n19: 5 batches\n17: 5 batches\n7 Start Epoch 2\n15 Start Epoch 2\n18: 5 batches\n16: 5 batches\n6 Start Epoch 2\n2 Start Epoch 2\n14 Start Epoch 2\n7: 5 batches\n3 Start Epoch 2\n15: 5 batches\n6: 5 batches\n2: 5 batches\n14: 5 batches\n3: 5 batches\n11 Start Epoch 2\n9 Start Epoch 2\n11: 5 batches\n13 Start Epoch 2\n9: 5 batches\n12 Start Epoch 2\n5 Start Epoch 2\n4 Start Epoch 2\n13: 5 batches\n12: 5 batches\n4: 5 batches\n5: 5 batches\n8 Start Epoch 2\n8: 5 batches\n1 Start Epoch 2\n1: 5 batches\n0 Start Epoch 2\n0: 5 batches\n1 Start Epoch 3\n1: 5 batches\n6 Start Epoch 3\n7 Start Epoch 3\n5 Start Epoch 3\n3 Start Epoch 3\n2 Start Epoch 3\n7: 5 batches\n5: 5 batches\n18 Start Epoch 3\n17 Start Epoch 3\n6: 5 batches\n4 Start Epoch 3\n2: 5 batches\n15 Start Epoch 3\n4: 5 batches\n3: 5 batches\n14 Start Epoch 3\n11 Start Epoch 3\n19 Start Epoch 3\n13 Start Epoch 3\n16 Start Epoch 3\n15: 5 batches\n11: 5 batches\n19: 5 batches\n13: 5 batches\n16: 5 batches\n12 Start Epoch 3\n17: 5 batches\n14: 5 batches\n10 Start Epoch 3\n18: 5 batches\n10: 5 batches\n12: 5 batches\n9 Start Epoch 3\n8 Start Epoch 3\n9: 5 batches\n8: 5 batches\n0 Start Epoch 3\n0: 5 batches\n1 Start Epoch 4\n6 Start Epoch 4\n7 Start Epoch 4\n1: 5 batches\n7: 5 batches\n6: 5 batches\n5 Start Epoch 4\n4 Start Epoch 4\n3 Start Epoch 4\n5: 5 batches\n2 Start Epoch 4\n18 Start Epoch 4\n15 Start Epoch 4\n19 Start Epoch 4\n13 Start Epoch 4\n16 Start Epoch 4\n4: 5 batches\n2: 5 batches\n3: 5 batches\n14 Start Epoch 4\n11 Start Epoch 4\n19: 5 batches\n13: 5 batches\n17 Start Epoch 4\n15: 5 batches\n11: 5 batches\n18: 5 batches\n12 Start Epoch 4\n16: 5 batches\n17: 5 batches\n14: 5 batches\n10 Start Epoch 4\n12: 5 batches\n10: 5 batches\n9 Start Epoch 4\n9: 5 batches\n8 Start Epoch 4\n8: 5 batches\n0 Start Epoch 4\n0: 5 batches\n5 Start Epoch 5\n5: 5 batches\n3 Start Epoch 5\n2 Start Epoch 5\n7 Start Epoch 5\n6 Start Epoch 5\n7: 5 batches\n17 Start Epoch 5\n2: 5 batches\n3: 5 batches\n16 Start Epoch 5\n19 Start Epoch 5\n17: 5 batches\n6: 5 batches\n14 Start Epoch 5\n18 Start Epoch 5\n11 Start Epoch 5\n19: 5 batches\n13 Start Epoch 5\n16: 5 batches\n15 Start Epoch 5\n14: 5 batches\n11: 5 batches\n18: 5 batches\n13: 5 batches\n10 Start Epoch 5\n12 Start Epoch 5\n15: 5 batches\n12: 5 batches\n1 Start Epoch 5\n10: 5 batches\n1: 5 batches\n8 Start Epoch 5\n8: 5 batches\n9 Start Epoch 5\n9: 5 batches\n4 Start Epoch 5\n4: 5 batches\n0 Start Epoch 5\n0: 5 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:3: Epoch 0 train loss: 3269110.402194214\nINFO:root:6: Epoch 0 train loss: 9243.024298095703\nINFO:root:2: Epoch 0 train loss: 1660734.2616577148\nINFO:root:7: Epoch 0 train loss: 52550.252285766604\nINFO:root:14: Epoch 0 train loss: 116015.86960449218\nINFO:root:18: Epoch 0 train loss: 10313.279779052735\nINFO:root:19: Epoch 0 train loss: 1667388.5157348632\nINFO:root:15: Epoch 0 train loss: 2655870.7689453126\nINFO:root:16: Epoch 0 train loss: 1928.508154296875\nINFO:root:9: Epoch 0 train loss: 30843.256981182098\nINFO:root:4: Epoch 0 train loss: 9823.19165649414\nINFO:root:10: Epoch 0 train loss: 245153.04544067383\nINFO:root:11: Epoch 0 train loss: 48900.12587890625\nINFO:root:12: Epoch 0 train loss: 32649.956982421874\nINFO:root:8: Epoch 0 train loss: 1320402.909375\nINFO:root:17: Epoch 0 train loss: 1684534.0994140625\nINFO:root:13: Epoch 0 train loss: 26842.41602783203\nINFO:root:5: Epoch 0 train loss: 1382718.2372894287\nINFO:root:0: Epoch 0 train loss: 9827.330212402343\nINFO:root:1: Epoch 0 train loss: 1989067.4430664063\nINFO:root:0: Epoch 0 validation loss: 7289.884739315362\nINFO:root:19: Epoch 1 train loss: 2929.0523895263673\nINFO:root:17: Epoch 1 train loss: 1935806.9056343078\nINFO:root:18: Epoch 1 train loss: 26270.25510177612\nINFO:root:16: Epoch 1 train loss: 1720708.208354187\nINFO:root:15: Epoch 1 train loss: 5793.008020019532\nINFO:root:10: Epoch 1 train loss: 19741.71633300781\nINFO:root:6: Epoch 1 train loss: 9375.208520507813\nINFO:root:7: Epoch 1 train loss: 4476.9075355529785\nINFO:root:2: Epoch 1 train loss: 2919990.906188965\nINFO:root:14: Epoch 1 train loss: 1393760.9625976563\nINFO:root:3: Epoch 1 train loss: 5655.764248657227\nINFO:root:11: Epoch 1 train loss: 185080.37572021486\nINFO:root:9: Epoch 1 train loss: 2429716.4186401367\nINFO:root:13: Epoch 1 train loss: 1396.9244453430176\nINFO:root:12: Epoch 1 train loss: 185239.27812271117\nINFO:root:5: Epoch 1 train loss: 9257.440312194823\nINFO:root:4: Epoch 1 train loss: 7526.997845458985\nINFO:root:8: Epoch 1 train loss: 60933.2925201416\nINFO:root:0: Epoch 1 train loss: 2444865.947918701\nINFO:root:1: Epoch 1 train loss: 1608896.9765090942\nINFO:root:0: Epoch 1 validation loss: 7283.9672315696835\nINFO:root:0: Epoch 2 train loss: 2412641.88795166\nINFO:root:1: Epoch 2 train loss: 6012.276696777344\nINFO:root:6: Epoch 2 train loss: 1561527.0791992187\nINFO:root:7: Epoch 2 train loss: 34650.50341796875\nINFO:root:4: Epoch 2 train loss: 12131.884033203125\nINFO:root:2: Epoch 2 train loss: 37099.49549560547\nINFO:root:3: Epoch 2 train loss: 100744.72534179688\nINFO:root:5: Epoch 2 train loss: 48460.942370605466\nINFO:root:17: Epoch 2 train loss: 15975.961143493652\nINFO:root:14: Epoch 2 train loss: 75931.07680664063\nINFO:root:18: Epoch 2 train loss: 65085.7123046875\nINFO:root:15: Epoch 2 train loss: 578703.6098999024\nINFO:root:10: Epoch 2 train loss: 20055.67744140625\nINFO:root:19: Epoch 2 train loss: 15749.44287109375\nINFO:root:12: Epoch 2 train loss: 295157.97384643555\nINFO:root:16: Epoch 2 train loss: 28079.117578125\nINFO:root:13: Epoch 2 train loss: 11666.906921386719\nINFO:root:11: Epoch 2 train loss: 1581335.771887207\nINFO:root:9: Epoch 2 train loss: 61242.618872070314\nINFO:root:8: Epoch 2 train loss: 39418.983642578125\nINFO:root:0: Epoch 2 validation loss: 7277.229010130568\nINFO:root:0: Epoch 3 train loss: 10453.055654907226\nINFO:root:1: Epoch 3 train loss: 1795.7084411621095\nINFO:root:7: Epoch 3 train loss: 10558.547412109376\nINFO:root:6: Epoch 3 train loss: 2400480.2677490236\nINFO:root:5: Epoch 3 train loss: 6983.763696289063\nINFO:root:3: Epoch 3 train loss: 1724826.676623535\nINFO:root:4: Epoch 3 train loss: 35785.7173828125\nINFO:root:2: Epoch 3 train loss: 1643700.9620300294\nINFO:root:18: Epoch 3 train loss: 9638.7390625\nINFO:root:17: Epoch 3 train loss: 1306307.371875\nINFO:root:14: Epoch 3 train loss: 2016966.5433408737\nINFO:root:19: Epoch 3 train loss: 15403.21728515625\nINFO:root:13: Epoch 3 train loss: 7705.51064453125\nINFO:root:15: Epoch 3 train loss: 37235.52487792969\nINFO:root:10: Epoch 3 train loss: 8032.101171875\nINFO:root:12: Epoch 3 train loss: 2145322.3534118654\nINFO:root:16: Epoch 3 train loss: 5617.313293457031\nINFO:root:11: Epoch 3 train loss: 20937.219580078126\nINFO:root:8: Epoch 3 train loss: 3105168.9516479494\nINFO:root:9: Epoch 3 train loss: 122439.00737304687\nINFO:root:0: Epoch 3 validation loss: 7269.266640946013\nINFO:root:1: Epoch 4 train loss: 8822.12001953125\nINFO:root:0: Epoch 4 train loss: 754.3372619628906\nINFO:root:5: Epoch 4 train loss: 9878.446963500977\nINFO:root:2: Epoch 4 train loss: 32495.422512817382\nINFO:root:3: Epoch 4 train loss: 24055.634197998046\nINFO:root:6: Epoch 4 train loss: 74096.54135742187\nINFO:root:7: Epoch 4 train loss: 19038.1292175293\nINFO:root:17: Epoch 4 train loss: 9017.015982055664\nINFO:root:19: Epoch 4 train loss: 9476.44296875\nINFO:root:16: Epoch 4 train loss: 281775.2828979492\nINFO:root:14: Epoch 4 train loss: 2309.3512641906736\nINFO:root:18: Epoch 4 train loss: 1990399.567163086\nINFO:root:15: Epoch 4 train loss: 36640.8828125\nINFO:root:10: Epoch 4 train loss: 1660470.6353027343\nINFO:root:12: Epoch 4 train loss: 1654438.4584182738\nINFO:root:11: Epoch 4 train loss: 23953.558715820312\nINFO:root:13: Epoch 4 train loss: 1541775.3753204346\nINFO:root:8: Epoch 4 train loss: 1304531.5219909668\nINFO:root:9: Epoch 4 train loss: 8283.794958496093\nINFO:root:4: Epoch 4 train loss: 1738822.8869140625\nINFO:root:0: Epoch 4 validation loss: 7259.834161261546\nINFO:root:6: Epoch 5 train loss: 3532206.5751220705\nINFO:root:7: Epoch 5 train loss: 19467.378125\nINFO:root:5: Epoch 5 train loss: 543232.0039535522\nINFO:root:4: Epoch 5 train loss: 1314541.4447601319\nINFO:root:3: Epoch 5 train loss: 23753.910122680663\nINFO:root:2: Epoch 5 train loss: 51084.66350097656\nINFO:root:0: Epoch 5 train loss: 8681.304884338379\nINFO:root:1: Epoch 5 train loss: 1961335.3771240234\nINFO:root:19: Epoch 5 train loss: 1604878.6701553345\nINFO:root:16: Epoch 5 train loss: 1382184.2399230958\nINFO:root:18: Epoch 5 train loss: 1613203.6435592652\nINFO:root:17: Epoch 5 train loss: 14750.487521362305\nINFO:root:14: Epoch 5 train loss: 14540.309838867188\nINFO:root:15: Epoch 5 train loss: 1379333.1625854492\nINFO:root:13: Epoch 5 train loss: 1600325.9189971923\nINFO:root:12: Epoch 5 train loss: 35667.73125\nINFO:root:11: Epoch 5 train loss: 33928.49893798828\nINFO:root:10: Epoch 5 train loss: 1863794.411119014\nINFO:root:8: Epoch 5 train loss: 24006.863842773437\nINFO:root:9: Epoch 5 train loss: 42394.34416503906\nINFO:root:0: Epoch 5 validation loss: 7247.496909291387\n", "seconds": 5.92479681968689, "batch_size": 32, "nodes": 10, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 5 batches\n2 Start Epoch 0\n1 Start Epoch 0\n2: 5 batches\n21 Start Epoch 0\n1: 5 batches\n21: 5 batches\n6 Start Epoch 0\n6: 5 batches\n7 Start Epoch 0\n7: 5 batches\n5 Start Epoch 0\n5: 5 batches\n13 Start Epoch 0\n10 Start Epoch 0\n18 Start Epoch 0\n14 Start Epoch 0\n4 Start Epoch 0\n8 Start Epoch 0\n4: 5 batches\n13: 5 batches\n3 Start Epoch 0\n10: 5 batches\n18: 5 batches\n17 Start Epoch 0\n16 Start Epoch 0\n15 Start Epoch 0\n9 Start Epoch 0\n3: 5 batches\n17: 5 batches\n14: 5 batches\n8: 5 batches\n16: 5 batches\n15: 5 batches\n9: 5 batches\n20 Start Epoch 0\n12 Start Epoch 0\n11 Start Epoch 0\n12: 5 batches\n11: 5 batches\n19 Start Epoch 0\n20: 5 batches\n19: 5 batches\n19 Start Epoch 1\n13 Start Epoch 1\n3 Start Epoch 1\n18 Start Epoch 1\n14 Start Epoch 1\n1 Start Epoch 1\n1: 5 batches\n12 Start Epoch 1\n2 Start Epoch 1\n6 Start Epoch 1\n18: 5 batches\n15 Start Epoch 1\n13: 5 batches\n2: 5 batches\n7 Start Epoch 1\n19: 5 batches\n17 Start Epoch 1\n14: 5 batches\n6: 5 batches\n15: 5 batches\n20 Start Epoch 1\n12: 5 batches\n3: 5 batches\n11 Start Epoch 1\n7: 5 batches\n16 Start Epoch 1\n21 Start Epoch 1\n8 Start Epoch 1\n4 Start Epoch 1\n10 Start Epoch 1\n11: 5 batches\n17: 5 batches\n21: 5 batches\n8: 5 batches\n4: 5 batches\n9 Start Epoch 1\n5 Start Epoch 1\n10: 5 batches\n16: 5 batches\n20: 5 batches\n9: 5 batches\n5: 5 batches\n0 Start Epoch 1\n0: 5 batches\n1 Start Epoch 2\n1: 5 batches\n14 Start Epoch 2\n4 Start Epoch 2\n12 Start Epoch 2\n2 Start Epoch 2\n7 Start Epoch 2\n19 Start Epoch 2\n17 Start Epoch 2\n12: 5 batches\n3 Start Epoch 2\n6 Start Epoch 2\n18 Start Epoch 2\n16 Start Epoch 2\n14: 5 batches\n5 Start Epoch 2\n10 Start Epoch 2\n7: 5 batches\n18: 5 batches\n17: 5 batches\n15 Start Epoch 2\n21 Start Epoch 2\n8 Start Epoch 2\n5: 5 batches\n13 Start Epoch 2\n2: 5 batches\n19: 5 batches\n16: 5 batches\n15: 5 batches\n20 Start Epoch 2\n9 Start Epoch 2\n4: 5 batches\n13: 5 batches\n3: 5 batches\n11 Start Epoch 2\n6: 5 batches\n11: 5 batches\n21: 5 batches\n8: 5 batches\n10: 5 batches\n20: 5 batches\n9: 5 batches\n0 Start Epoch 2\n0: 5 batches\n11 Start Epoch 3\n11: 5 batches\n1 Start Epoch 3\n1: 5 batches\n4 Start Epoch 3\n3 Start Epoch 3\n10 Start Epoch 3\n7 Start Epoch 3\n19 Start Epoch 3\n17 Start Epoch 3\n14 Start Epoch 3\n20 Start Epoch 3\n9 Start Epoch 3\n21 Start Epoch 3\n8 Start Epoch 3\n5 Start Epoch 3\n2 Start Epoch 3\n10: 5 batches\n6 Start Epoch 3\n18 Start Epoch 3\n17: 5 batches\n14: 5 batches\n15 Start Epoch 3\n20: 5 batches\n8: 5 batches\n4: 5 batches\n12 Start Epoch 3\n2: 5 batches\n7: 5 batches\n18: 5 batches\n16 Start Epoch 3\n5: 5 batches\n12: 5 batches\n3: 5 batches\n6: 5 batches\n19: 5 batches\n16: 5 batches\n15: 5 batches\n21: 5 batches\n9: 5 batches\n13 Start Epoch 3\n13: 5 batches\n0 Start Epoch 3\n0: 5 batches\n20 Start Epoch 4\n1 Start Epoch 4\n17 Start Epoch 4\n14 Start Epoch 4\n1: 5 batches\n4 Start Epoch 4\n3 Start Epoch 4\n11 Start Epoch 4\n6 Start Epoch 4\n18 Start Epoch 4\n5 Start Epoch 4\n2 Start Epoch 4\n10 Start Epoch 4\n7 Start Epoch 4\n19 Start Epoch 4\n16 Start Epoch 4\n15 Start Epoch 4\n21 Start Epoch 4\n7: 5 batches\n18: 5 batches\n17: 5 batches\n14: 5 batches\n20: 5 batches\n8 Start Epoch 4\n5: 5 batches\n13 Start Epoch 4\n2: 5 batches\n11: 5 batches\n10: 5 batches\n6: 5 batches\n19: 5 batches\n16: 5 batches\n15: 5 batches\n21: 5 batches\n9 Start Epoch 4\n4: 5 batches\n12 Start Epoch 4\n3: 5 batches\n12: 5 batches\n8: 5 batches\n13: 5 batches\n9: 5 batches\n0 Start Epoch 4\n0: 5 batches\n1 Start Epoch 5\n1: 5 batches\n5 Start Epoch 5\n3 Start Epoch 5\n10 Start Epoch 5\n7 Start Epoch 5\n19 Start Epoch 5\n16 Start Epoch 5\n14 Start Epoch 5\n20 Start Epoch 5\n14: 5 batches\n21 Start Epoch 5\n4 Start Epoch 5\n2 Start Epoch 5\n11 Start Epoch 5\n6 Start Epoch 5\n18 Start Epoch 5\n17 Start Epoch 5\n11: 5 batches\n7: 5 batches\n18: 5 batches\n17: 5 batches\n15 Start Epoch 5\n21: 5 batches\n9 Start Epoch 5\n5: 5 batches\n12 Start Epoch 5\n2: 5 batches\n15: 5 batches\n20: 5 batches\n8 Start Epoch 5\n4: 5 batches\n13 Start Epoch 5\n3: 5 batches\n10: 5 batches\n6: 5 batches\n19: 5 batches\n16: 5 batches\n8: 5 batches\n13: 5 batches\n12: 5 batches\n9: 5 batches\n0 Start Epoch 5\n0: 5 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:18: Epoch 0 train loss: 17945.37832813263\nINFO:root:15: Epoch 0 train loss: 1931737.3715515137\nINFO:root:13: Epoch 0 train loss: 198384.66883621216\nINFO:root:3: Epoch 0 train loss: 13572.21360321045\nINFO:root:19: Epoch 0 train loss: 8502.444207763672\nINFO:root:2: Epoch 0 train loss: 66647.76015625\nINFO:root:7: Epoch 0 train loss: 12789.494592285157\nINFO:root:14: Epoch 0 train loss: 2763.977149963379\nINFO:root:12: Epoch 0 train loss: 28552.02988548279\nINFO:root:6: Epoch 0 train loss: 186927.15404052736\nINFO:root:1: Epoch 0 train loss: 1924066.4564819336\nINFO:root:11: Epoch 0 train loss: 6530.161006164551\nINFO:root:17: Epoch 0 train loss: 1737641.490045166\nINFO:root:20: Epoch 0 train loss: 245614.483203125\nINFO:root:4: Epoch 0 train loss: 20225.829443359376\nINFO:root:10: Epoch 0 train loss: 17927.168695068358\nINFO:root:0: Epoch 0 train loss: 10382.097125077247\nINFO:root:21: Epoch 0 train loss: 1580519.1321744919\nINFO:root:8: Epoch 0 train loss: 16311.707177734375\nINFO:root:16: Epoch 0 train loss: 1654525.0575439453\nINFO:root:9: Epoch 0 train loss: 3907.048811340332\nINFO:root:5: Epoch 0 train loss: 37667.993965148926\nINFO:root:0: Epoch 0 validation loss: 9315357.043846907\nINFO:root:4: Epoch 1 train loss: 3147788.15806427\nINFO:root:12: Epoch 1 train loss: 1780.708122253418\nINFO:root:2: Epoch 1 train loss: 555909.4765895844\nINFO:root:7: Epoch 1 train loss: 20894.59514465332\nINFO:root:19: Epoch 1 train loss: 5651.9414753770925\nINFO:root:16: Epoch 1 train loss: 16847.91053619385\nINFO:root:15: Epoch 1 train loss: 50308.45517501831\nINFO:root:5: Epoch 1 train loss: 6465.59696480115\nINFO:root:13: Epoch 1 train loss: 10724.633905029297\nINFO:root:3: Epoch 1 train loss: 545589.8182373047\nINFO:root:6: Epoch 1 train loss: 81230.112890625\nINFO:root:1: Epoch 1 train loss: 1946225.5027388572\nINFO:root:18: Epoch 1 train loss: 551454.6611328125\nINFO:root:17: Epoch 1 train loss: 1733425.1064439951\nINFO:root:14: Epoch 1 train loss: 1991.5309783935547\nINFO:root:20: Epoch 1 train loss: 14818.88045654297\nINFO:root:8: Epoch 1 train loss: 1542215.3156799315\nINFO:root:0: Epoch 1 train loss: 12042.78800354004\nINFO:root:11: Epoch 1 train loss: 19000.008403015137\nINFO:root:10: Epoch 1 train loss: 15554.046173983812\nINFO:root:21: Epoch 1 train loss: 8702.934527587891\nINFO:root:9: Epoch 1 train loss: 12675.990686798095\nINFO:root:0: Epoch 1 validation loss: 9315236.466349088\nINFO:root:11: Epoch 2 train loss: 1380049.3000835986\nINFO:root:20: Epoch 2 train loss: 28701.473146057127\nINFO:root:9: Epoch 2 train loss: 568878.7679813385\nINFO:root:4: Epoch 2 train loss: 16889.539719963075\nINFO:root:3: Epoch 2 train loss: 7923.760324174165\nINFO:root:6: Epoch 2 train loss: 22521.533866930007\nINFO:root:18: Epoch 2 train loss: 4455.014697265625\nINFO:root:16: Epoch 2 train loss: 1737454.2404942513\nINFO:root:15: Epoch 2 train loss: 91053.62984275818\nINFO:root:2: Epoch 2 train loss: 566379.3971305847\nINFO:root:10: Epoch 2 train loss: 51837.82170410156\nINFO:root:1: Epoch 2 train loss: 3863.6271911621093\nINFO:root:7: Epoch 2 train loss: 35104.40762939453\nINFO:root:19: Epoch 2 train loss: 18591.535009765626\nINFO:root:17: Epoch 2 train loss: 6659.075378417969\nINFO:root:14: Epoch 2 train loss: 4111.369933319092\nINFO:root:21: Epoch 2 train loss: 1385695.413238667\nINFO:root:8: Epoch 2 train loss: 1728.5475078582763\nINFO:root:5: Epoch 2 train loss: 2982313.1103759767\nINFO:root:12: Epoch 2 train loss: 73809.97329101563\nINFO:root:0: Epoch 2 train loss: 6936.384302520752\nINFO:root:13: Epoch 2 train loss: 1736896.2205055715\nINFO:root:0: Epoch 2 validation loss: 9315098.184482714\nINFO:root:10: Epoch 3 train loss: 583718.9890136719\nINFO:root:6: Epoch 3 train loss: 578812.7452758789\nINFO:root:18: Epoch 3 train loss: 20323.563134765624\nINFO:root:16: Epoch 3 train loss: 7961.430169677735\nINFO:root:14: Epoch 3 train loss: 19007.929110431673\nINFO:root:20: Epoch 3 train loss: 7371.772802734375\nINFO:root:5: Epoch 3 train loss: 1189.8812088012696\nINFO:root:3: Epoch 3 train loss: 5858.714122009277\nINFO:root:11: Epoch 3 train loss: 1772547.3845214844\nINFO:root:7: Epoch 3 train loss: 13262.623153686523\nINFO:root:19: Epoch 3 train loss: 53207.67522277832\nINFO:root:17: Epoch 3 train loss: 198883.62869873046\nINFO:root:15: Epoch 3 train loss: 53892.30255813598\nINFO:root:4: Epoch 3 train loss: 1664716.270388031\nINFO:root:2: Epoch 3 train loss: 3854.8567504882812\nINFO:root:1: Epoch 3 train loss: 56969.45861816406\nINFO:root:21: Epoch 3 train loss: 19497.9070356369\nINFO:root:8: Epoch 3 train loss: 6628.61372013092\nINFO:root:13: Epoch 3 train loss: 16334.11541442871\nINFO:root:9: Epoch 3 train loss: 37505.23754377365\nINFO:root:0: Epoch 3 train loss: 9154.189752030372\nINFO:root:12: Epoch 3 train loss: 40213.678234863284\nINFO:root:0: Epoch 3 validation loss: 9314923.597661136\nINFO:root:5: Epoch 4 train loss: 4473.622215270996\nINFO:root:2: Epoch 4 train loss: 29338.899279785157\nINFO:root:11: Epoch 4 train loss: 21673.995495605468\nINFO:root:6: Epoch 4 train loss: 6358.773089599609\nINFO:root:18: Epoch 4 train loss: 6636.998941040039\nINFO:root:17: Epoch 4 train loss: 37419.15571899414\nINFO:root:15: Epoch 4 train loss: 1576.8649597167969\nINFO:root:21: Epoch 4 train loss: 3503380.5079833986\nINFO:root:4: Epoch 4 train loss: 1688694.8547733307\nINFO:root:3: Epoch 4 train loss: 6385.112392923236\nINFO:root:1: Epoch 4 train loss: 1038.1633529663086\nINFO:root:10: Epoch 4 train loss: 561050.4438232422\nINFO:root:7: Epoch 4 train loss: 47669.052795410156\nINFO:root:19: Epoch 4 train loss: 195130.0901260376\nINFO:root:16: Epoch 4 train loss: 9347874.56171875\nINFO:root:14: Epoch 4 train loss: 41449.16929168701\nINFO:root:20: Epoch 4 train loss: 200436.66368522643\nINFO:root:12: Epoch 4 train loss: 17859.245239257812\nINFO:root:0: Epoch 4 train loss: 11875.935595703126\nINFO:root:8: Epoch 4 train loss: 11123047.993270874\nINFO:root:9: Epoch 4 train loss: 15701.665620589256\nINFO:root:13: Epoch 4 train loss: 3841.9954767227173\nINFO:root:0: Epoch 4 validation loss: 9314700.889863085\nINFO:root:4: Epoch 5 train loss: 9964.313671875\nINFO:root:3: Epoch 5 train loss: 573092.0151611328\nINFO:root:10: Epoch 5 train loss: 2092.2991035461428\nINFO:root:7: Epoch 5 train loss: 18053.48599014282\nINFO:root:19: Epoch 5 train loss: 52218.116174316405\nINFO:root:16: Epoch 5 train loss: 1658668.694140625\nINFO:root:14: Epoch 5 train loss: 33786.59946289063\nINFO:root:20: Epoch 5 train loss: 1874.780519580841\nINFO:root:17: Epoch 5 train loss: 22211.95902404785\nINFO:root:15: Epoch 5 train loss: 3521412.717242432\nINFO:root:21: Epoch 5 train loss: 1549835.9715957642\nINFO:root:5: Epoch 5 train loss: 17629.84557495117\nINFO:root:2: Epoch 5 train loss: 1606260.6590566635\nINFO:root:11: Epoch 5 train loss: 1326301.9047821045\nINFO:root:6: Epoch 5 train loss: 85723.03959350586\nINFO:root:18: Epoch 5 train loss: 1744313.0124053955\nINFO:root:0: Epoch 5 train loss: 16875.025722646715\nINFO:root:1: Epoch 5 train loss: 5424.2802588634195\nINFO:root:8: Epoch 5 train loss: 29248.44638671875\nINFO:root:13: Epoch 5 train loss: 36472.03210906983\nINFO:root:12: Epoch 5 train loss: 1555586.9399536133\nINFO:root:9: Epoch 5 train loss: 33612.13754882813\nINFO:root:0: Epoch 5 validation loss: 9314416.41061316\n", "seconds": 6.5969557762146, "batch_size": 32, "nodes": 11, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 4 batches\n23 Start Epoch 0\n23: 4 batches\n1 Start Epoch 0\n2 Start Epoch 0\n7 Start Epoch 0\n7: 4 batches\n2: 4 batches\n1: 4 batches\n4 Start Epoch 0\n4: 4 batches\n8 Start Epoch 0\n8: 4 batches\n16 Start Epoch 0\n16: 4 batches\n15 Start Epoch 0\n15: 4 batches\n3 Start Epoch 0\n3: 4 batches\n6 Start Epoch 0\n6: 4 batches\n12 Start Epoch 0\n12: 4 batches\n11 Start Epoch 0\n19 Start Epoch 0\n20 Start Epoch 0\n11: 4 batches\n19: 4 batches\n20: 4 batches\n18 Start Epoch 0\n18: 4 batches\n5 Start Epoch 0\n5: 4 batches\n22 Start Epoch 0\n22: 4 batches\n13 Start Epoch 0\n14 Start Epoch 0\n9 Start Epoch 0\n14: 4 batches\n21 Start Epoch 0\n10 Start Epoch 0\n17 Start Epoch 0\n13: 4 batches\n21: 4 batches\n10: 4 batches\n17: 4 batches\n9: 4 batches\n18 Start Epoch 1\n6 Start Epoch 1\n19 Start Epoch 1\n7 Start Epoch 1\n19: 4 batches\n6: 4 batches\n18: 4 batches\n7: 4 batches\n2 Start Epoch 1\n20 Start Epoch 1\n11 Start Epoch 1\n12 Start Epoch 1\n22 Start Epoch 1\n12: 4 batches\n9 Start Epoch 1\n2: 4 batches\n15 Start Epoch 1\n20: 4 batches\n11: 4 batches\n16 Start Epoch 1\n21 Start Epoch 1\n10 Start Epoch 1\n17 Start Epoch 1\n23 Start Epoch 1\n13 Start Epoch 1\n8 Start Epoch 1\n4 Start Epoch 1\n14 Start Epoch 1\n21: 4 batches\n10: 4 batches\n17: 4 batches\n22: 4 batches\n13: 4 batches\n9: 4 batches\n5 Start Epoch 1\n15: 4 batches\n8: 4 batches\n4: 4 batches\n14: 4 batches\n16: 4 batches\n23: 4 batches\n5: 4 batches\n1 Start Epoch 1\n1: 4 batches\n3 Start Epoch 1\n3: 4 batches\n0 Start Epoch 1\n0: 4 batches\n20 Start Epoch 2\n19 Start Epoch 2\n20: 4 batches\n18 Start Epoch 2\n21 Start Epoch 2\n10 Start Epoch 2\n15 Start Epoch 2\n19: 4 batches\n21: 4 batches\n11 Start Epoch 2\n16 Start Epoch 2\n3 Start Epoch 2\n4 Start Epoch 2\n15: 4 batches\n6 Start Epoch 2\n18: 4 batches\n11: 4 batches\n16: 4 batches\n10: 4 batches\n17 Start Epoch 2\n2 Start Epoch 2\n5 Start Epoch 2\n14 Start Epoch 2\n7 Start Epoch 2\n5: 4 batches\n14: 4 batches\n6: 4 batches\n17: 4 batches\n2: 4 batches\n3: 4 batches\n4: 4 batches\n7: 4 batches\n23 Start Epoch 2\n12 Start Epoch 2\n8 Start Epoch 2\n22 Start Epoch 2\n13 Start Epoch 2\n9 Start Epoch 2\n12: 4 batches\n9: 4 batches\n22: 4 batches\n23: 4 batches\n13: 4 batches\n8: 4 batches\n1 Start Epoch 2\n1: 4 batches\n0 Start Epoch 2\n0: 4 batches\n11 Start Epoch 3\n7 Start Epoch 3\n11: 4 batches\n6 Start Epoch 3\n10 Start Epoch 3\n4 Start Epoch 3\n6: 4 batches\n10: 4 batches\n2 Start Epoch 3\n5 Start Epoch 3\n7: 4 batches\n23 Start Epoch 3\n3 Start Epoch 3\n5: 4 batches\n16 Start Epoch 3\n22 Start Epoch 3\n2: 4 batches\n4: 4 batches\n17 Start Epoch 3\n22: 4 batches\n3: 4 batches\n17: 4 batches\n23: 4 batches\n16: 4 batches\n1 Start Epoch 3\n1: 4 batches\n18 Start Epoch 3\n9 Start Epoch 3\n15 Start Epoch 3\n18: 4 batches\n21 Start Epoch 3\n13 Start Epoch 3\n12 Start Epoch 3\n8 Start Epoch 3\n14 Start Epoch 3\n21: 4 batches\n14: 4 batches\n20 Start Epoch 3\n12: 4 batches\n8: 4 batches\n15: 4 batches\n20: 4 batches\n13: 4 batches\n9: 4 batches\n19 Start Epoch 3\n19: 4 batches\n0 Start Epoch 3\n0: 4 batches\n10 Start Epoch 4\n11 Start Epoch 4\n7 Start Epoch 4\n11: 4 batches\n4 Start Epoch 4\n6 Start Epoch 4\n10: 4 batches\n6: 4 batches\n23 Start Epoch 4\n3 Start Epoch 4\n5 Start Epoch 4\n2 Start Epoch 4\n5: 4 batches\n7: 4 batches\n16 Start Epoch 4\n22 Start Epoch 4\n4: 4 batches\n17 Start Epoch 4\n22: 4 batches\n2: 4 batches\n3: 4 batches\n17: 4 batches\n23: 4 batches\n16: 4 batches\n8 Start Epoch 4\n9 Start Epoch 4\n13 Start Epoch 4\n8: 4 batches\n19 Start Epoch 4\n21 Start Epoch 4\n12 Start Epoch 4\n9: 4 batches\n13: 4 batches\n18 Start Epoch 4\n21: 4 batches\n1 Start Epoch 4\n1: 4 batches\n20 Start Epoch 4\n12: 4 batches\n14 Start Epoch 4\n18: 4 batches\n14: 4 batches\n19: 4 batches\n20: 4 batches\n15 Start Epoch 4\n15: 4 batches\n0 Start Epoch 4\n0: 4 batches\n10 Start Epoch 5\n11 Start Epoch 5\n5 Start Epoch 5\n5: 4 batches\n6 Start Epoch 5\n7 Start Epoch 5\n11: 4 batches\n3 Start Epoch 5\n4 Start Epoch 5\n4: 4 batches\n6: 4 batches\n10: 4 batches\n7: 4 batches\n16 Start Epoch 5\n2 Start Epoch 5\n17 Start Epoch 5\n23 Start Epoch 5\n2: 4 batches\n3: 4 batches\n17: 4 batches\n22 Start Epoch 5\n23: 4 batches\n16: 4 batches\n22: 4 batches\n9 Start Epoch 5\n8 Start Epoch 5\n8: 4 batches\n14 Start Epoch 5\n1 Start Epoch 5\n1: 4 batches\n18 Start Epoch 5\n20 Start Epoch 5\n13 Start Epoch 5\n9: 4 batches\n21 Start Epoch 5\n12 Start Epoch 5\n14: 4 batches\n18: 4 batches\n15 Start Epoch 5\n21: 4 batches\n12: 4 batches\n19 Start Epoch 5\n20: 4 batches\n13: 4 batches\n15: 4 batches\n19: 4 batches\n0 Start Epoch 5\n0: 4 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:18: Epoch 0 train loss: 36322.8837890625\nINFO:root:6: Epoch 0 train loss: 32674.554794311523\nINFO:root:19: Epoch 0 train loss: 2192.419273376465\nINFO:root:7: Epoch 0 train loss: 8172.493362426758\nINFO:root:20: Epoch 0 train loss: 1543.6133079528809\nINFO:root:10: Epoch 0 train loss: 11263.865936279297\nINFO:root:12: Epoch 0 train loss: 6346.113430976868\nINFO:root:2: Epoch 0 train loss: 23772.391077041626\nINFO:root:15: Epoch 0 train loss: 2187598.9943847656\nINFO:root:21: Epoch 0 train loss: 19198.508419036865\nINFO:root:11: Epoch 0 train loss: 7352.5006103515625\nINFO:root:16: Epoch 0 train loss: 2011670.1850585938\nINFO:root:22: Epoch 0 train loss: 5412.143531799316\nINFO:root:13: Epoch 0 train loss: 22014.49729156494\nINFO:root:9: Epoch 0 train loss: 30514.984741210938\nINFO:root:4: Epoch 0 train loss: 2182.826591491699\nINFO:root:14: Epoch 0 train loss: 19317.523193359375\nINFO:root:17: Epoch 0 train loss: 47562.81147766113\nINFO:root:23: Epoch 0 train loss: 15066.682939052582\nINFO:root:8: Epoch 0 train loss: 27128.878997802734\nINFO:root:5: Epoch 0 train loss: 73614.58386230469\nINFO:root:1: Epoch 0 train loss: 9742.536346435547\nINFO:root:0: Epoch 0 train loss: 52852.48876953125\nINFO:root:3: Epoch 0 train loss: 3931.6569213867188\nINFO:root:0: Epoch 0 validation loss: 291752493.96128803\nINFO:root:21: Epoch 1 train loss: 245519.85314941406\nINFO:root:19: Epoch 1 train loss: 2183796.5540008545\nINFO:root:20: Epoch 1 train loss: 19317.100692749023\nINFO:root:18: Epoch 1 train loss: 24058.000122070312\nINFO:root:11: Epoch 1 train loss: 26905.71868133545\nINFO:root:15: Epoch 1 train loss: 21203.496994018555\nINFO:root:10: Epoch 1 train loss: 16918.768394470215\nINFO:root:17: Epoch 1 train loss: 27928.08612060547\nINFO:root:5: Epoch 1 train loss: 50651.58251953125\nINFO:root:14: Epoch 1 train loss: 43500.15118408203\nINFO:root:6: Epoch 1 train loss: 3834535.4068603516\nINFO:root:16: Epoch 1 train loss: 14745.472793579102\nINFO:root:3: Epoch 1 train loss: 8457.720329284668\nINFO:root:2: Epoch 1 train loss: 11846.329345703125\nINFO:root:4: Epoch 1 train loss: 20745.439170837402\nINFO:root:7: Epoch 1 train loss: 2166492.2980041504\nINFO:root:0: Epoch 1 train loss: 1927397.049111843\nINFO:root:23: Epoch 1 train loss: 3676383.8333740234\nINFO:root:13: Epoch 1 train loss: 100860.4255065918\nINFO:root:9: Epoch 1 train loss: 2404417.4128780365\nINFO:root:22: Epoch 1 train loss: 24375.779846191406\nINFO:root:12: Epoch 1 train loss: 32655.913818359375\nINFO:root:8: Epoch 1 train loss: 4564477.759155273\nINFO:root:1: Epoch 1 train loss: 2077.724578857422\nINFO:root:0: Epoch 1 validation loss: 291752233.92557156\nINFO:root:10: Epoch 2 train loss: 42702.11309814453\nINFO:root:6: Epoch 2 train loss: 2416068.9321289062\nINFO:root:11: Epoch 2 train loss: 53203.24758148193\nINFO:root:7: Epoch 2 train loss: 1637438.9939422607\nINFO:root:4: Epoch 2 train loss: 21672.032348632812\nINFO:root:5: Epoch 2 train loss: 17887.34179878235\nINFO:root:2: Epoch 2 train loss: 1633445.5249328613\nINFO:root:3: Epoch 2 train loss: 14646.998840332031\nINFO:root:22: Epoch 2 train loss: 11963.553001403809\nINFO:root:16: Epoch 2 train loss: 688916.0207519531\nINFO:root:23: Epoch 2 train loss: 1967467.075012207\nINFO:root:17: Epoch 2 train loss: 265108.5166320801\nINFO:root:1: Epoch 2 train loss: 77616.60961914062\nINFO:root:12: Epoch 2 train loss: 252271.03369140625\nINFO:root:8: Epoch 2 train loss: 2068115.338546753\nINFO:root:15: Epoch 2 train loss: 17145.16323852539\nINFO:root:18: Epoch 2 train loss: 27380.746757507324\nINFO:root:20: Epoch 2 train loss: 93775.17422485352\nINFO:root:14: Epoch 2 train loss: 5955.605575561523\nINFO:root:21: Epoch 2 train loss: 2161.4110260009766\nINFO:root:13: Epoch 2 train loss: 10924.199111938477\nINFO:root:9: Epoch 2 train loss: 11525.818645238876\nINFO:root:19: Epoch 2 train loss: 266326.1210632324\nINFO:root:0: Epoch 2 train loss: 23705.054138183594\nINFO:root:0: Epoch 2 validation loss: 291752027.24857193\nINFO:root:11: Epoch 3 train loss: 24932.10000228882\nINFO:root:10: Epoch 3 train loss: 6841.506332397461\nINFO:root:7: Epoch 3 train loss: 2742105.6290893555\nINFO:root:5: Epoch 3 train loss: 14344.826126098633\nINFO:root:6: Epoch 3 train loss: 21590.166246414185\nINFO:root:4: Epoch 3 train loss: 10986.24038696289\nINFO:root:23: Epoch 3 train loss: 65703.4105834961\nINFO:root:2: Epoch 3 train loss: 1940741.1667480469\nINFO:root:17: Epoch 3 train loss: 39770.21095275879\nINFO:root:22: Epoch 3 train loss: 108614.50009918213\nINFO:root:3: Epoch 3 train loss: 6241.013359069824\nINFO:root:16: Epoch 3 train loss: 5337.683102607727\nINFO:root:8: Epoch 3 train loss: 233586.6238746643\nINFO:root:9: Epoch 3 train loss: 27380.736740112305\nINFO:root:13: Epoch 3 train loss: 2181.6127166748047\nINFO:root:18: Epoch 3 train loss: 2153475.5225219727\nINFO:root:20: Epoch 3 train loss: 5135.571601867676\nINFO:root:12: Epoch 3 train loss: 1746903.9150390625\nINFO:root:14: Epoch 3 train loss: 11401.139137268066\nINFO:root:19: Epoch 3 train loss: 1627317.3779449463\nINFO:root:21: Epoch 3 train loss: 25594.106117248535\nINFO:root:15: Epoch 3 train loss: 1932707.747467041\nINFO:root:0: Epoch 3 train loss: 30984.140502929688\nINFO:root:1: Epoch 3 train loss: 10175.320434570312\nINFO:root:0: Epoch 3 validation loss: 291751766.79716885\nINFO:root:11: Epoch 4 train loss: 49533.381286621094\nINFO:root:6: Epoch 4 train loss: 8437.833984375\nINFO:root:10: Epoch 4 train loss: 1536.3165130615234\nINFO:root:4: Epoch 4 train loss: 25279.55029296875\nINFO:root:7: Epoch 4 train loss: 4831.394311904907\nINFO:root:3: Epoch 4 train loss: 79065.833984375\nINFO:root:16: Epoch 4 train loss: 15376.237915039062\nINFO:root:2: Epoch 4 train loss: 24152.860229492188\nINFO:root:5: Epoch 4 train loss: 6288.462257385254\nINFO:root:17: Epoch 4 train loss: 9801.02564239502\nINFO:root:23: Epoch 4 train loss: 683696.9227294922\nINFO:root:22: Epoch 4 train loss: 19199.390426635742\nINFO:root:9: Epoch 4 train loss: 72096.93162536621\nINFO:root:8: Epoch 4 train loss: 11943.087854385376\nINFO:root:14: Epoch 4 train loss: 9726.634490966797\nINFO:root:18: Epoch 4 train loss: 285.6124382019043\nINFO:root:20: Epoch 4 train loss: 24350.942138671875\nINFO:root:12: Epoch 4 train loss: 8964.136764526367\nINFO:root:13: Epoch 4 train loss: 10737.38314819336\nINFO:root:15: Epoch 4 train loss: 62109.76151275635\nINFO:root:1: Epoch 4 train loss: 2019870.9232254028\nINFO:root:21: Epoch 4 train loss: 1808138.3576507568\nINFO:root:19: Epoch 4 train loss: 9736.60238647461\nINFO:root:0: Epoch 4 train loss: 73648.48093795776\nINFO:root:0: Epoch 4 validation loss: 291751504.8545767\nINFO:root:11: Epoch 5 train loss: 12441.959247589111\nINFO:root:6: Epoch 5 train loss: 7323.635440826416\nINFO:root:10: Epoch 5 train loss: 1673092.596069336\nINFO:root:5: Epoch 5 train loss: 2211679.5263824463\nINFO:root:7: Epoch 5 train loss: 2299315.132803917\nINFO:root:4: Epoch 5 train loss: 3797.0900230407715\nINFO:root:2: Epoch 5 train loss: 13546.09177017212\nINFO:root:16: Epoch 5 train loss: 56031.703857421875\nINFO:root:23: Epoch 5 train loss: 1555.0564041137695\nINFO:root:3: Epoch 5 train loss: 2177936.8845672607\nINFO:root:17: Epoch 5 train loss: 1941632.3690414429\nINFO:root:22: Epoch 5 train loss: 2021145.5993556976\nINFO:root:9: Epoch 5 train loss: 16429.440799713135\nINFO:root:8: Epoch 5 train loss: 11406.974048614502\nINFO:root:13: Epoch 5 train loss: 12340.229278564453\nINFO:root:1: Epoch 5 train loss: 8862.924446105957\nINFO:root:12: Epoch 5 train loss: 2068188.9871635437\nINFO:root:19: Epoch 5 train loss: 98769.95558166504\nINFO:root:20: Epoch 5 train loss: 774918.3916015625\nINFO:root:15: Epoch 5 train loss: 2322787.0677490234\nINFO:root:14: Epoch 5 train loss: 41791.83349609375\nINFO:root:18: Epoch 5 train loss: 62739.0754699707\nINFO:root:21: Epoch 5 train loss: 2748358.597427368\nINFO:root:0: Epoch 5 train loss: 42880.57021522522\nINFO:root:0: Epoch 5 validation loss: 291751240.20626795\n", "seconds": 6.696290969848633, "batch_size": 32, "nodes": 12, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.15,192.168.2.15 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "1 Start Epoch 0\n2 Start Epoch 0\n0 Start Epoch 0\n0: 31 batches\n1: 31 batches\n2: 31 batches\n1 Start Epoch 1\n2 Start Epoch 1\n1: 31 batches\n2: 31 batches\n0 Start Epoch 1\n0: 31 batches\n1 Start Epoch 2\n2 Start Epoch 2\n1: 31 batches\n2: 31 batches\n0 Start Epoch 2\n0: 31 batches\n1 Start Epoch 3\n1: 31 batches\n2 Start Epoch 3\n2: 31 batches\n0 Start Epoch 3\n0: 31 batches\n2 Start Epoch 4\n1 Start Epoch 4\n2: 31 batches\n1: 31 batches\n0 Start Epoch 4\n0: 31 batches\n2 Start Epoch 5\n2: 31 batches\n1 Start Epoch 5\n1: 31 batches\n0 Start Epoch 5\n0: 31 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:1: Epoch 0 train loss: 1054214.809843002\nINFO:root:0: Epoch 0 train loss: 623849.3383418976\nINFO:root:2: Epoch 0 train loss: 544753.195694585\nINFO:root:0: Epoch 0 validation loss: 750549.8625529776\nINFO:root:1: Epoch 1 train loss: 889198.6241430467\nINFO:root:0: Epoch 1 train loss: 1064743.6316474176\nINFO:root:2: Epoch 1 train loss: 247762.99125345293\nINFO:root:0: Epoch 1 validation loss: 750003.0243326857\nINFO:root:2: Epoch 2 train loss: 276110.19116866204\nINFO:root:0: Epoch 2 train loss: 330344.2366233641\nINFO:root:1: Epoch 2 train loss: 438611.37867982924\nINFO:root:0: Epoch 2 validation loss: 749336.5091171986\nINFO:root:1: Epoch 3 train loss: 581739.6151708787\nINFO:root:0: Epoch 3 train loss: 353782.5491096743\nINFO:root:2: Epoch 3 train loss: 901740.3358563454\nINFO:root:0: Epoch 3 validation loss: 748893.1783245966\nINFO:root:1: Epoch 4 train loss: 868762.06675631\nINFO:root:2: Epoch 4 train loss: 1119422.0365916837\nINFO:root:0: Epoch 4 train loss: 835280.4920607536\nINFO:root:0: Epoch 4 validation loss: 748465.6410120438\nINFO:root:0: Epoch 5 train loss: 796213.6668196648\nINFO:root:1: Epoch 5 train loss: 1149197.0218024869\nINFO:root:2: Epoch 5 train loss: 937462.5598154375\nINFO:root:0: Epoch 5 validation loss: 748092.0929961698\n", "seconds": 10.133860111236572, "batch_size": 32, "nodes": 1, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.15,192.168.2.2,192.168.2.15,192.168.2.2 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 16 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 16 batches\n5 Start Epoch 0\n5: 16 batches\n2: 16 batches\n4 Start Epoch 0\n3 Start Epoch 0\n4: 16 batches\n3: 16 batches\n3 Start Epoch 1\n3: 16 batches\n1 Start Epoch 1\n2 Start Epoch 1\n1: 16 batches\n2: 16 batches\n4 Start Epoch 1\n5 Start Epoch 1\n4: 16 batches\n5: 16 batches\n0 Start Epoch 1\n0: 16 batches\n2 Start Epoch 2\n1 Start Epoch 2\n1: 16 batches\n5 Start Epoch 2\n4 Start Epoch 2\n5: 16 batches\n4: 16 batches\n3 Start Epoch 2\n3: 16 batches\n2: 16 batches\n0 Start Epoch 2\n0: 16 batches\n2 Start Epoch 3\n2: 16 batches\n1 Start Epoch 3\n1: 16 batches\n3 Start Epoch 3\n4 Start Epoch 3\n5 Start Epoch 3\n3: 16 batches\n5: 16 batches\n4: 16 batches\n0 Start Epoch 3\n0: 16 batches\n5 Start Epoch 4\n5: 16 batches\n3 Start Epoch 4\n3: 16 batches\n4 Start Epoch 4\n4: 16 batches\n1 Start Epoch 4\n1: 16 batches\n2 Start Epoch 4\n2: 16 batches\n0 Start Epoch 4\n0: 16 batches\n3 Start Epoch 5\n1 Start Epoch 5\n2 Start Epoch 5\n1: 16 batches\n3: 16 batches\n2: 16 batches\n5 Start Epoch 5\n5: 16 batches\n4 Start Epoch 5\n4: 16 batches\n0 Start Epoch 5\n0: 16 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:3: Epoch 0 train loss: 22159.076743125916\nINFO:root:0: Epoch 0 train loss: 453110.5872268677\nINFO:root:2: Epoch 0 train loss: 51618.6035900116\nINFO:root:1: Epoch 0 train loss: 963936.2036044002\nINFO:root:4: Epoch 0 train loss: 1448133.4739305973\nINFO:root:5: Epoch 0 train loss: 30842.28762292862\nINFO:root:0: Epoch 0 validation loss: 434656.32752283226\nINFO:root:0: Epoch 1 train loss: 23373.31007385254\nINFO:root:1: Epoch 1 train loss: 471180.3441224098\nINFO:root:2: Epoch 1 train loss: 635098.7913942337\nINFO:root:4: Epoch 1 train loss: 543630.1785033345\nINFO:root:5: Epoch 1 train loss: 930793.83897686\nINFO:root:3: Epoch 1 train loss: 1585491.164909482\nINFO:root:0: Epoch 1 validation loss: 434512.7450609169\nINFO:root:1: Epoch 2 train loss: 15265.987678050995\nINFO:root:0: Epoch 2 train loss: 940719.4781575203\nINFO:root:2: Epoch 2 train loss: 1578227.494464159\nINFO:root:4: Epoch 2 train loss: 23765.723365664482\nINFO:root:3: Epoch 2 train loss: 1034321.7206401825\nINFO:root:5: Epoch 2 train loss: 84648.20488500595\nINFO:root:0: Epoch 2 validation loss: 434202.01780852984\nINFO:root:5: Epoch 3 train loss: 1194697.3821809292\nINFO:root:0: Epoch 3 train loss: 1639373.1461808681\nINFO:root:3: Epoch 3 train loss: 893719.7170038223\nINFO:root:4: Epoch 3 train loss: 614638.5708736181\nINFO:root:1: Epoch 3 train loss: 31123.187609672546\nINFO:root:2: Epoch 3 train loss: 596167.8253233433\nINFO:root:0: Epoch 3 validation loss: 433713.0540516767\nINFO:root:3: Epoch 4 train loss: 1542488.1113548279\nINFO:root:2: Epoch 4 train loss: 942087.7368001938\nINFO:root:0: Epoch 4 train loss: 462371.3243370056\nINFO:root:1: Epoch 4 train loss: 534442.3949241638\nINFO:root:5: Epoch 4 train loss: 1457675.2237119675\nINFO:root:4: Epoch 4 train loss: 911411.1535043716\nINFO:root:0: Epoch 4 validation loss: 433294.4721011658\nINFO:root:1: Epoch 5 train loss: 724243.1878175735\nINFO:root:5: Epoch 5 train loss: 21385.84904193878\nINFO:root:4: Epoch 5 train loss: 30864.505317926407\nINFO:root:3: Epoch 5 train loss: 523575.0265688896\nINFO:root:2: Epoch 5 train loss: 503012.22093200684\nINFO:root:0: Epoch 5 train loss: 619867.082326889\nINFO:root:0: Epoch 5 validation loss: 433034.3564293426\n", "seconds": 7.121990919113159, "batch_size": 32, "nodes": 2, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.15,192.168.2.2,192.168.2.3 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 11 batches\n6 Start Epoch 0\n2 Start Epoch 0\n2: 11 batches\n5 Start Epoch 0\n5: 11 batches\n6: 11 batches\n7 Start Epoch 0\n7: 11 batches\n3 Start Epoch 0\n8 Start Epoch 0\n8: 11 batches\n1 Start Epoch 0\n1: 11 batches\n4 Start Epoch 0\n4: 11 batches\n3: 11 batches\n2 Start Epoch 1\n2: 11 batches\n5 Start Epoch 1\n4 Start Epoch 1\n5: 11 batches\n4: 11 batches\n6 Start Epoch 1\n7 Start Epoch 1\n6: 11 batches\n7: 11 batches\n8 Start Epoch 1\n8: 11 batches\n1 Start Epoch 1\n1: 11 batches\n3 Start Epoch 1\n3: 11 batches\n0 Start Epoch 1\n0: 11 batches\n7 Start Epoch 2\n7: 11 batches\n5 Start Epoch 2\n4 Start Epoch 2\n3 Start Epoch 2\n5: 11 batches\n4: 11 batches\n2 Start Epoch 2\n3: 11 batches\n6 Start Epoch 2\n6: 11 batches\n8 Start Epoch 2\n8: 11 batches\n1 Start Epoch 2\n1: 11 batches\n2: 11 batches\n0 Start Epoch 2\n0: 11 batches\n2 Start Epoch 3\n2: 11 batches\n6 Start Epoch 3\n5 Start Epoch 3\n7 Start Epoch 3\n3 Start Epoch 3\n7: 11 batches\n6: 11 batches\n5: 11 batches\n8 Start Epoch 3\n4 Start Epoch 3\n8: 11 batches\n3: 11 batches\n4: 11 batches\n1 Start Epoch 3\n1: 11 batches\n0 Start Epoch 3\n0: 11 batches\n8 Start Epoch 4\n8: 11 batches\n1 Start Epoch 4\n1: 11 batches\n5 Start Epoch 4\n3 Start Epoch 4\n3: 11 batches\n5: 11 batches\n2 Start Epoch 4\n2: 11 batches\n7 Start Epoch 4\n7: 11 batches\n6 Start Epoch 4\n6: 11 batches\n4 Start Epoch 4\n4: 11 batches\n0 Start Epoch 4\n0: 11 batches\n1 Start Epoch 5\n2 Start Epoch 5\n2: 11 batches\n8 Start Epoch 5\n8: 11 batches\n6 Start Epoch 5\n6: 11 batches\n5 Start Epoch 5\n4 Start Epoch 5\n3 Start Epoch 5\n4: 11 batches\n1: 11 batches\n3: 11 batches\n5: 11 batches\n7 Start Epoch 5\n7: 11 batches\n0 Start Epoch 5\n0: 11 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:1: Epoch 0 train loss: 2474539.9006725224\nINFO:root:2: Epoch 0 train loss: 1577763.182187167\nINFO:root:4: Epoch 0 train loss: 641739.7900118828\nINFO:root:5: Epoch 0 train loss: 1928063.188165578\nINFO:root:8: Epoch 0 train loss: 105109.10505260121\nINFO:root:6: Epoch 0 train loss: 759775.6726892645\nINFO:root:7: Epoch 0 train loss: 811686.314146562\nINFO:root:0: Epoch 0 train loss: 21150.469754305752\nINFO:root:3: Epoch 0 train loss: 88613.1789335771\nINFO:root:0: Epoch 0 validation loss: 920574.3336684199\nINFO:root:0: Epoch 1 train loss: 6244.731223076878\nINFO:root:7: Epoch 1 train loss: 1375504.880473397\nINFO:root:3: Epoch 1 train loss: 29788.697688709606\nINFO:root:5: Epoch 1 train loss: 1526750.2209472656\nINFO:root:4: Epoch 1 train loss: 11181.93152288957\nINFO:root:2: Epoch 1 train loss: 103169.47593827681\nINFO:root:6: Epoch 1 train loss: 15686.225960471413\nINFO:root:8: Epoch 1 train loss: 4233.52777931907\nINFO:root:1: Epoch 1 train loss: 36194.44467163086\nINFO:root:0: Epoch 1 validation loss: 920459.7742419245\nINFO:root:1: Epoch 2 train loss: 35207.91751098633\nINFO:root:0: Epoch 2 train loss: 706509.3675314296\nINFO:root:2: Epoch 2 train loss: 758683.6150880293\nINFO:root:6: Epoch 2 train loss: 658575.2695661024\nINFO:root:4: Epoch 2 train loss: 285532.6859103116\nINFO:root:8: Epoch 2 train loss: 812374.8737612638\nINFO:root:7: Epoch 2 train loss: 10746.469544844194\nINFO:root:5: Epoch 2 train loss: 22620.15529641238\nINFO:root:3: Epoch 2 train loss: 352969.27770163794\nINFO:root:0: Epoch 2 validation loss: 920294.843262107\nINFO:root:8: Epoch 3 train loss: 751188.7844543457\nINFO:root:1: Epoch 3 train loss: 1708277.7602539062\nINFO:root:0: Epoch 3 train loss: 719359.0346568715\nINFO:root:3: Epoch 3 train loss: 23770.179337935013\nINFO:root:5: Epoch 3 train loss: 847341.3330064253\nINFO:root:2: Epoch 3 train loss: 87559.80246803978\nINFO:root:7: Epoch 3 train loss: 798401.5279611241\nINFO:root:6: Epoch 3 train loss: 1396042.8680482344\nINFO:root:4: Epoch 3 train loss: 608993.1454114047\nINFO:root:0: Epoch 3 validation loss: 920000.7273594976\nINFO:root:1: Epoch 4 train loss: 1472920.2065583712\nINFO:root:2: Epoch 4 train loss: 711544.1548295454\nINFO:root:0: Epoch 4 train loss: 174047.13957907938\nINFO:root:8: Epoch 4 train loss: 31743.221518776634\nINFO:root:4: Epoch 4 train loss: 746355.3755455017\nINFO:root:3: Epoch 4 train loss: 20345.6025390625\nINFO:root:6: Epoch 4 train loss: 10147.231117942116\nINFO:root:5: Epoch 4 train loss: 784796.131772128\nINFO:root:7: Epoch 4 train loss: 9085.55763799494\nINFO:root:0: Epoch 4 validation loss: 919594.3703139569\nINFO:root:2: Epoch 5 train loss: 11064.183907330036\nINFO:root:0: Epoch 5 train loss: 33764.15281042186\nINFO:root:1: Epoch 5 train loss: 764438.9995006215\nINFO:root:3: Epoch 5 train loss: 753724.9097151323\nINFO:root:7: Epoch 5 train loss: 1572890.8953954524\nINFO:root:4: Epoch 5 train loss: 109003.6904389208\nINFO:root:6: Epoch 5 train loss: 746041.6032437411\nINFO:root:8: Epoch 5 train loss: 9392.006755308672\nINFO:root:5: Epoch 5 train loss: 16759.16384571249\nINFO:root:0: Epoch 5 validation loss: 919095.3371024214\n", "seconds": 6.114987850189209, "batch_size": 32, "nodes": 3, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 8 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 8 batches\n11 Start Epoch 0\n11: 8 batches\n3 Start Epoch 0\n4 Start Epoch 0\n7 Start Epoch 0\n8 Start Epoch 0\n4: 8 batches\n8: 8 batches\n3: 8 batches\n7: 8 batches\n2: 8 batches\n10 Start Epoch 0\n9 Start Epoch 0\n9: 8 batches\n5 Start Epoch 0\n6 Start Epoch 0\n10: 8 batches\n5: 8 batches\n6: 8 batches\n1 Start Epoch 1\n1: 8 batches\n6 Start Epoch 1\n6: 8 batches\n10 Start Epoch 1\n2 Start Epoch 1\n2: 8 batches\n4 Start Epoch 1\n10: 8 batches\n3 Start Epoch 1\n7 Start Epoch 1\n11 Start Epoch 1\n4: 8 batches\n3: 8 batches\n7: 8 batches\n11: 8 batches\n8 Start Epoch 1\n8: 8 batches\n9 Start Epoch 1\n9: 8 batches\n5 Start Epoch 1\n5: 8 batches\n0 Start Epoch 1\n0: 8 batches\n1 Start Epoch 2\n2 Start Epoch 2\n2: 8 batches\n1: 8 batches\n9 Start Epoch 2\n3 Start Epoch 2\n3: 8 batches\n9: 8 batches\n8 Start Epoch 2\n6 Start Epoch 2\n7 Start Epoch 2\n7: 8 batches\n6: 8 batches\n8: 8 batches\n5 Start Epoch 2\n11 Start Epoch 2\n4 Start Epoch 2\n10 Start Epoch 2\n5: 8 batches\n11: 8 batches\n4: 8 batches\n10: 8 batches\n0 Start Epoch 2\n0: 8 batches\n6 Start Epoch 3\n1 Start Epoch 3\n2 Start Epoch 3\n2: 8 batches\n1: 8 batches\n4 Start Epoch 3\n4: 8 batches\n6: 8 batches\n5 Start Epoch 3\n10 Start Epoch 3\n5: 8 batches\n10: 8 batches\n11 Start Epoch 3\n11: 8 batches\n8 Start Epoch 3\n8: 8 batches\n7 Start Epoch 3\n7: 8 batches\n9 Start Epoch 3\n9: 8 batches\n3 Start Epoch 3\n3: 8 batches\n0 Start Epoch 3\n0: 8 batches\n5 Start Epoch 4\n5: 8 batches\n10 Start Epoch 4\n6 Start Epoch 4\n7 Start Epoch 4\n10: 8 batches\n7: 8 batches\n6: 8 batches\n8 Start Epoch 4\n8: 8 batches\n9 Start Epoch 4\n9: 8 batches\n1 Start Epoch 4\n1: 8 batches\n2 Start Epoch 4\n2: 8 batches\n11 Start Epoch 4\n3 Start Epoch 4\n11: 8 batches\n3: 8 batches\n4 Start Epoch 4\n4: 8 batches\n0 Start Epoch 4\n0: 8 batches\n1 Start Epoch 5\n2 Start Epoch 5\n10 Start Epoch 5\n11 Start Epoch 5\n10: 8 batches\n4 Start Epoch 5\n8 Start Epoch 5\n7 Start Epoch 5\n11: 8 batches\n3 Start Epoch 5\n7: 8 batches\n8: 8 batches\n6 Start Epoch 5\n4: 8 batches\n6: 8 batches\n3: 8 batches\n9 Start Epoch 5\n1: 8 batches\n2: 8 batches\n9: 8 batches\n5 Start Epoch 5\n5: 8 batches\n0 Start Epoch 5\n0: 8 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 1319554.786653757\nINFO:root:1: Epoch 0 train loss: 1347765.1797485352\nINFO:root:2: Epoch 0 train loss: 1203638.1504154205\nINFO:root:6: Epoch 0 train loss: 1014844.0053100586\nINFO:root:10: Epoch 0 train loss: 1220746.6568832397\nINFO:root:4: Epoch 0 train loss: 1045109.6392822266\nINFO:root:11: Epoch 0 train loss: 11842.597466468811\nINFO:root:3: Epoch 0 train loss: 1162475.4133358002\nINFO:root:7: Epoch 0 train loss: 20303.409215927124\nINFO:root:8: Epoch 0 train loss: 36856.684494018555\nINFO:root:9: Epoch 0 train loss: 1341520.728668213\nINFO:root:5: Epoch 0 train loss: 873133.8824653625\nINFO:root:0: Epoch 0 validation loss: 3159.4571842375244\nINFO:root:3: Epoch 1 train loss: 508620.3748369217\nINFO:root:9: Epoch 1 train loss: 43900.54867553711\nINFO:root:0: Epoch 1 train loss: 897210.6300086975\nINFO:root:1: Epoch 1 train loss: 24578.29502761364\nINFO:root:2: Epoch 1 train loss: 985242.0990638733\nINFO:root:6: Epoch 1 train loss: 1058967.0198669434\nINFO:root:7: Epoch 1 train loss: 391473.46013736725\nINFO:root:8: Epoch 1 train loss: 875771.3590545654\nINFO:root:5: Epoch 1 train loss: 1253.1795053482056\nINFO:root:11: Epoch 1 train loss: 12214.898807883263\nINFO:root:4: Epoch 1 train loss: 9817.86385345459\nINFO:root:10: Epoch 1 train loss: 888947.1480712891\nINFO:root:0: Epoch 1 validation loss: 3148.927299625401\nINFO:root:6: Epoch 2 train loss: 16513.409839630127\nINFO:root:5: Epoch 2 train loss: 30040.363392829895\nINFO:root:4: Epoch 2 train loss: 1230250.328414917\nINFO:root:2: Epoch 2 train loss: 1091838.3630638123\nINFO:root:1: Epoch 2 train loss: 17369.683546066284\nINFO:root:0: Epoch 2 train loss: 15722.547443389893\nINFO:root:11: Epoch 2 train loss: 1904002.2178554535\nINFO:root:10: Epoch 2 train loss: 2404898.081132889\nINFO:root:8: Epoch 2 train loss: 37816.25741767883\nINFO:root:7: Epoch 2 train loss: 7222.887985229492\nINFO:root:9: Epoch 2 train loss: 10303.67786026001\nINFO:root:3: Epoch 2 train loss: 23962.945263028145\nINFO:root:0: Epoch 2 validation loss: 3132.688719046013\nINFO:root:5: Epoch 3 train loss: 31036.587310791016\nINFO:root:10: Epoch 3 train loss: 11809.530757904053\nINFO:root:6: Epoch 3 train loss: 1023301.2031860352\nINFO:root:7: Epoch 3 train loss: 121844.1282043457\nINFO:root:8: Epoch 3 train loss: 17451.782039642334\nINFO:root:9: Epoch 3 train loss: 992375.0861415863\nINFO:root:0: Epoch 3 train loss: 16951.507553100586\nINFO:root:2: Epoch 3 train loss: 381438.1125116348\nINFO:root:1: Epoch 3 train loss: 1691412.5305480957\nINFO:root:11: Epoch 3 train loss: 50447.2181892395\nINFO:root:3: Epoch 3 train loss: 1230406.1547546387\nINFO:root:4: Epoch 3 train loss: 10387.361442565918\nINFO:root:0: Epoch 3 validation loss: 3107.325638413895\nINFO:root:0: Epoch 4 train loss: 11235.858192443848\nINFO:root:2: Epoch 4 train loss: 7348.264362335205\nINFO:root:1: Epoch 4 train loss: 2211878.433616638\nINFO:root:10: Epoch 4 train loss: 55196.570278167725\nINFO:root:11: Epoch 4 train loss: 7942.680134773254\nINFO:root:5: Epoch 4 train loss: 1396712.4319496155\nINFO:root:3: Epoch 4 train loss: 469822.6444015503\nINFO:root:8: Epoch 4 train loss: 876684.0840950012\nINFO:root:6: Epoch 4 train loss: 13546.233472824097\nINFO:root:4: Epoch 4 train loss: 1117302.606765747\nINFO:root:7: Epoch 4 train loss: 363838.600982666\nINFO:root:9: Epoch 4 train loss: 1202568.6986427307\nINFO:root:0: Epoch 4 validation loss: 3075.3338282348523\nINFO:root:2: Epoch 5 train loss: 30659.28977394104\nINFO:root:0: Epoch 5 train loss: 132339.12841033936\nINFO:root:1: Epoch 5 train loss: 6252.648066520691\nINFO:root:3: Epoch 5 train loss: 5607.577667236328\nINFO:root:10: Epoch 5 train loss: 2699821.9303131104\nINFO:root:5: Epoch 5 train loss: 350597.5349216461\nINFO:root:8: Epoch 5 train loss: 350132.2144918442\nINFO:root:6: Epoch 5 train loss: 1252136.7197332382\nINFO:root:7: Epoch 5 train loss: 33848.24264526367\nINFO:root:4: Epoch 5 train loss: 23559.021186828613\nINFO:root:9: Epoch 5 train loss: 1211747.4643859863\nINFO:root:11: Epoch 5 train loss: 39922.43374443054\nINFO:root:0: Epoch 5 validation loss: 3043.1262432305975\n", "seconds": 5.7148730754852295, "batch_size": 32, "nodes": 4, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 7 batches\n1 Start Epoch 0\n2 Start Epoch 0\n2: 7 batches\n1: 7 batches\n14 Start Epoch 0\n10 Start Epoch 0\n13 Start Epoch 0\n9 Start Epoch 0\n10: 7 batches\n9: 7 batches\n5 Start Epoch 0\n5: 7 batches\n13: 7 batches\n14: 7 batches\n3 Start Epoch 0\n4 Start Epoch 0\n3: 7 batches\n4: 7 batches\n7 Start Epoch 0\n7: 7 batches\n8 Start Epoch 0\n8: 7 batches\n6 Start Epoch 0\n6: 7 batches\n12 Start Epoch 0\n12: 7 batches\n11 Start Epoch 0\n11: 7 batches\n9 Start Epoch 1\n9: 7 batches\n3 Start Epoch 1\n3: 7 batches\n1 Start Epoch 1\n1: 7 batches\n4 Start Epoch 1\n4: 7 batches\n2 Start Epoch 1\n2: 7 batches\n14 Start Epoch 1\n13 Start Epoch 1\n14: 7 batches\n5 Start Epoch 1\n13: 7 batches\n5: 7 batches\n12 Start Epoch 1\n12: 7 batches\n6 Start Epoch 1\n6: 7 batches\n8 Start Epoch 1\n8: 7 batches\n10 Start Epoch 1\n10: 7 batches\n11 Start Epoch 1\n11: 7 batches\n7 Start Epoch 1\n7: 7 batches\n0 Start Epoch 1\n0: 7 batches\n1 Start Epoch 2\n8 Start Epoch 2\n3 Start Epoch 2\n1: 7 batches\n8: 7 batches\n3: 7 batches\n12 Start Epoch 2\n11 Start Epoch 2\n10 Start Epoch 2\n11: 7 batches\n12: 7 batches\n10: 7 batches\n13 Start Epoch 2\n13: 7 batches\n2 Start Epoch 2\n2: 7 batches\n9 Start Epoch 2\n9: 7 batches\n7 Start Epoch 2\n6 Start Epoch 2\n5 Start Epoch 2\n4 Start Epoch 2\n4: 7 batches\n5: 7 batches\n6: 7 batches\n7: 7 batches\n14 Start Epoch 2\n14: 7 batches\n0 Start Epoch 2\n0: 7 batches\n8 Start Epoch 3\n11 Start Epoch 3\n7 Start Epoch 3\n10 Start Epoch 3\n8: 7 batches\n7: 7 batches\n9 Start Epoch 3\n11: 7 batches\n10: 7 batches\n9: 7 batches\n14 Start Epoch 3\n14: 7 batches\n2 Start Epoch 3\n4 Start Epoch 3\n4: 7 batches\n6 Start Epoch 3\n6: 7 batches\n2: 7 batches\n1 Start Epoch 3\n3 Start Epoch 3\n13 Start Epoch 3\n3: 7 batches\n13: 7 batches\n12 Start Epoch 3\n12: 7 batches\n1: 7 batches\n5 Start Epoch 3\n5: 7 batches\n0 Start Epoch 3\n0: 7 batches\n1 Start Epoch 4\n3 Start Epoch 4\n1: 7 batches\n5 Start Epoch 4\n6 Start Epoch 4\n6: 7 batches\n14 Start Epoch 4\n9 Start Epoch 4\n12 Start Epoch 4\n10 Start Epoch 4\n14: 7 batches\n9: 7 batches\n12: 7 batches\n10: 7 batches\n13 Start Epoch 4\n11 Start Epoch 4\n13: 7 batches\n11: 7 batches\n5: 7 batches\n3: 7 batches\n8 Start Epoch 4\n2 Start Epoch 4\n2: 7 batches\n8: 7 batches\n7 Start Epoch 4\n7: 7 batches\n4 Start Epoch 4\n4: 7 batches\n0 Start Epoch 4\n0: 7 batches\n14 Start Epoch 5\n7 Start Epoch 5\n7: 7 batches\n4 Start Epoch 5\n6 Start Epoch 5\n4: 7 batches\n6: 7 batches\n14: 7 batches\n9 Start Epoch 5\n11 Start Epoch 5\n9: 7 batches\n10 Start Epoch 5\n10: 7 batches\n1 Start Epoch 5\n11: 7 batches\n13 Start Epoch 5\n13: 7 batches\n1: 7 batches\n12 Start Epoch 5\n12: 7 batches\n3 Start Epoch 5\n8 Start Epoch 5\n5 Start Epoch 5\n3: 7 batches\n8: 7 batches\n5: 7 batches\n2 Start Epoch 5\n2: 7 batches\n0 Start Epoch 5\n0: 7 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:9: Epoch 0 train loss: 13949.682365826198\nINFO:root:3: Epoch 0 train loss: 5351.897670200893\nINFO:root:1: Epoch 0 train loss: 14145.78578404018\nINFO:root:4: Epoch 0 train loss: 8580.465338570732\nINFO:root:2: Epoch 0 train loss: 13097.623151506696\nINFO:root:13: Epoch 0 train loss: 1070968.3561793736\nINFO:root:14: Epoch 0 train loss: 6738.175166538784\nINFO:root:5: Epoch 0 train loss: 2421011.0522896904\nINFO:root:12: Epoch 0 train loss: 1385177.426111017\nINFO:root:8: Epoch 0 train loss: 32267.963989257812\nINFO:root:6: Epoch 0 train loss: 20384.77407155718\nINFO:root:0: Epoch 0 train loss: 58689.63967854636\nINFO:root:10: Epoch 0 train loss: 1198756.9626552036\nINFO:root:11: Epoch 0 train loss: 13411.852099827358\nINFO:root:7: Epoch 0 train loss: 20715.215205601282\nINFO:root:0: Epoch 0 validation loss: 911109.9053632919\nINFO:root:2: Epoch 1 train loss: 1388995.5932190418\nINFO:root:1: Epoch 1 train loss: 1131314.1848874774\nINFO:root:3: Epoch 1 train loss: 5224.285518101284\nINFO:root:8: Epoch 1 train loss: 2121910.5652640206\nINFO:root:12: Epoch 1 train loss: 12026.674681391034\nINFO:root:10: Epoch 1 train loss: 410042.52049527847\nINFO:root:11: Epoch 1 train loss: 1148755.9239501953\nINFO:root:13: Epoch 1 train loss: 436206.6179591588\nINFO:root:9: Epoch 1 train loss: 43961.41724068778\nINFO:root:7: Epoch 1 train loss: 3280065.480844051\nINFO:root:6: Epoch 1 train loss: 16369.82530622743\nINFO:root:5: Epoch 1 train loss: 7817.539582388742\nINFO:root:4: Epoch 1 train loss: 19410.60523223877\nINFO:root:0: Epoch 1 train loss: 1488818.6981282043\nINFO:root:14: Epoch 1 train loss: 390619.7784031459\nINFO:root:0: Epoch 1 validation loss: 911035.3772813485\nINFO:root:0: Epoch 2 train loss: 43746.89302280971\nINFO:root:10: Epoch 2 train loss: 56321.398525290824\nINFO:root:7: Epoch 2 train loss: 8919.358189174107\nINFO:root:9: Epoch 2 train loss: 24369.787689208984\nINFO:root:8: Epoch 2 train loss: 30925.812824249268\nINFO:root:11: Epoch 2 train loss: 91211.79715401786\nINFO:root:14: Epoch 2 train loss: 2288651.3170963014\nINFO:root:2: Epoch 2 train loss: 42504.285702637266\nINFO:root:4: Epoch 2 train loss: 17838.241874422347\nINFO:root:6: Epoch 2 train loss: 949697.1625279018\nINFO:root:1: Epoch 2 train loss: 2074293.6641671318\nINFO:root:3: Epoch 2 train loss: 66316.97453144619\nINFO:root:12: Epoch 2 train loss: 2400827.5002359664\nINFO:root:13: Epoch 2 train loss: 12643.804668877807\nINFO:root:5: Epoch 2 train loss: 1200768.2031947544\nINFO:root:0: Epoch 2 validation loss: 910941.34476693\nINFO:root:2: Epoch 3 train loss: 19257.455531529016\nINFO:root:1: Epoch 3 train loss: 26894.88621575492\nINFO:root:0: Epoch 3 train loss: 16999.199342455184\nINFO:root:3: Epoch 3 train loss: 31975.849931989396\nINFO:root:5: Epoch 3 train loss: 24413.955440793718\nINFO:root:6: Epoch 3 train loss: 1758826.354675293\nINFO:root:13: Epoch 3 train loss: 22551.78129686628\nINFO:root:10: Epoch 3 train loss: 22461.37369935853\nINFO:root:14: Epoch 3 train loss: 19444.237254551477\nINFO:root:11: Epoch 3 train loss: 32803.97306698694\nINFO:root:9: Epoch 3 train loss: 43283.1334400177\nINFO:root:12: Epoch 3 train loss: 1246127.0021935871\nINFO:root:8: Epoch 3 train loss: 2336139.5397114074\nINFO:root:7: Epoch 3 train loss: 19388.422916957312\nINFO:root:4: Epoch 3 train loss: 1155976.8766980853\nINFO:root:0: Epoch 3 validation loss: 910803.9568717546\nINFO:root:0: Epoch 4 train loss: 2378466.9015590125\nINFO:root:1: Epoch 4 train loss: 33303.21124267578\nINFO:root:6: Epoch 4 train loss: 1292574.4972173146\nINFO:root:14: Epoch 4 train loss: 995518.2501040867\nINFO:root:7: Epoch 4 train loss: 1643301.4808130902\nINFO:root:4: Epoch 4 train loss: 1164603.5268455895\nINFO:root:9: Epoch 4 train loss: 163685.94993373327\nINFO:root:10: Epoch 4 train loss: 1374904.3450916836\nINFO:root:11: Epoch 4 train loss: 1376973.5766339984\nINFO:root:13: Epoch 4 train loss: 1113812.2781360329\nINFO:root:3: Epoch 4 train loss: 7564.086074134068\nINFO:root:12: Epoch 4 train loss: 1261882.4305070129\nINFO:root:5: Epoch 4 train loss: 42570.608919416154\nINFO:root:8: Epoch 4 train loss: 2357567.232421875\nINFO:root:2: Epoch 4 train loss: 6410.589097942625\nINFO:root:0: Epoch 4 validation loss: 910602.1897997867\nINFO:root:0: Epoch 5 train loss: 1115038.1604799032\nINFO:root:2: Epoch 5 train loss: 25775.208332606726\nINFO:root:1: Epoch 5 train loss: 1406938.350600547\nINFO:root:3: Epoch 5 train loss: 1154321.8555494037\nINFO:root:13: Epoch 5 train loss: 951313.0410832465\nINFO:root:9: Epoch 5 train loss: 1244477.712537493\nINFO:root:7: Epoch 5 train loss: 1211959.9242392948\nINFO:root:4: Epoch 5 train loss: 29783.621317182267\nINFO:root:12: Epoch 5 train loss: 428724.75418526784\nINFO:root:6: Epoch 5 train loss: 11182.98870413644\nINFO:root:5: Epoch 5 train loss: 139770.99937602453\nINFO:root:14: Epoch 5 train loss: 1185268.1266214736\nINFO:root:10: Epoch 5 train loss: 2560154.910295759\nINFO:root:11: Epoch 5 train loss: 1187310.0906546456\nINFO:root:8: Epoch 5 train loss: 10092.346645355225\nINFO:root:0: Epoch 5 validation loss: 910339.2061891797\n", "seconds": 5.7218239307403564, "batch_size": 32, "nodes": 5, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "1 Start Epoch 0\n2 Start Epoch 0\n2: 6 batches\n1: 6 batches\n0 Start Epoch 0\n0: 6 batches\n6 Start Epoch 0\n6: 6 batches\n14 Start Epoch 0\n11 Start Epoch 0\n13 Start Epoch 0\n13: 6 batches\n14: 6 batches\n17 Start Epoch 0\n12 Start Epoch 0\n11: 6 batches\n12: 6 batches\n17: 6 batches\n9 Start Epoch 0\n10 Start Epoch 0\n9: 6 batches\n10: 6 batches\n3 Start Epoch 0\n4 Start Epoch 0\n4: 6 batches\n5 Start Epoch 0\n5: 6 batches\n3: 6 batches\n15 Start Epoch 0\n16 Start Epoch 0\n7 Start Epoch 0\n8 Start Epoch 0\n16: 6 batches\n15: 6 batches\n7: 6 batches\n8: 6 batches\n2 Start Epoch 1\n1 Start Epoch 1\n2: 6 batches\n1: 6 batches\n4 Start Epoch 1\n5 Start Epoch 1\n5: 6 batches\n9 Start Epoch 1\n4: 6 batches\n9: 6 batches\n13 Start Epoch 1\n14 Start Epoch 1\n7 Start Epoch 1\n14: 6 batches\n13: 6 batches\n8 Start Epoch 1\n17 Start Epoch 1\n8: 6 batches\n16 Start Epoch 1\n7: 6 batches\n16: 6 batches\n6 Start Epoch 1\n15 Start Epoch 1\n6: 6 batches\n17: 6 batches\n11 Start Epoch 1\n15: 6 batches\n11: 6 batches\n10 Start Epoch 1\n10: 6 batches\n3 Start Epoch 1\n3: 6 batches\n12 Start Epoch 1\n12: 6 batches\n0 Start Epoch 1\n0: 6 batches\n2 Start Epoch 2\n2: 6 batches\n14 Start Epoch 2\n1 Start Epoch 2\n14: 6 batches\n4 Start Epoch 2\n4: 6 batches\n11 Start Epoch 2\n9 Start Epoch 2\n16 Start Epoch 2\n17 Start Epoch 2\n16: 6 batches\n15 Start Epoch 2\n15: 6 batches\n12 Start Epoch 2\n17: 6 batches\n12: 6 batches\n1: 6 batches\n3 Start Epoch 2\n5 Start Epoch 2\n3: 6 batches\n7 Start Epoch 2\n5: 6 batches\n6 Start Epoch 2\n8 Start Epoch 2\n8: 6 batches\n7: 6 batches\n6: 6 batches\n10 Start Epoch 2\n10: 6 batches\n11: 6 batches\n9: 6 batches\n13 Start Epoch 2\n13: 6 batches\n0 Start Epoch 2\n0: 6 batches\n2 Start Epoch 3\n2: 6 batches\n9 Start Epoch 3\n9: 6 batches\n4 Start Epoch 3\n4: 6 batches\n5 Start Epoch 3\n12 Start Epoch 3\n17 Start Epoch 3\n5: 6 batches\n17: 6 batches\n12: 6 batches\n7 Start Epoch 3\n6 Start Epoch 3\n7: 6 batches\n8 Start Epoch 3\n8: 6 batches\n6: 6 batches\n13 Start Epoch 3\n13: 6 batches\n10 Start Epoch 3\n10: 6 batches\n16 Start Epoch 3\n16: 6 batches\n15 Start Epoch 3\n15: 6 batches\n11 Start Epoch 3\n11: 6 batches\n1 Start Epoch 3\n1: 6 batches\n14 Start Epoch 3\n14: 6 batches\n3 Start Epoch 3\n3: 6 batches\n0 Start Epoch 3\n0: 6 batches\n12 Start Epoch 4\n1 Start Epoch 4\n1: 6 batches\n12: 6 batches\n5 Start Epoch 4\n6 Start Epoch 4\n10 Start Epoch 4\n17 Start Epoch 4\n6: 6 batches\n9 Start Epoch 4\n17: 6 batches\n3 Start Epoch 4\n3: 6 batches\n5: 6 batches\n9: 6 batches\n10: 6 batches\n2 Start Epoch 4\n2: 6 batches\n16 Start Epoch 4\n7 Start Epoch 4\n16: 6 batches\n13 Start Epoch 4\n8 Start Epoch 4\n13: 6 batches\n15 Start Epoch 4\n7: 6 batches\n14 Start Epoch 4\n14: 6 batches\n15: 6 batches\n4 Start Epoch 4\n4: 6 batches\n8: 6 batches\n11 Start Epoch 4\n11: 6 batches\n0 Start Epoch 4\n0: 6 batches\n14 Start Epoch 5\n2 Start Epoch 5\n1 Start Epoch 5\n1: 6 batches\n2: 6 batches\n13 Start Epoch 5\n14: 6 batches\n8 Start Epoch 5\n13: 6 batches\n7 Start Epoch 5\n15 Start Epoch 5\n8: 6 batches\n11 Start Epoch 5\n16 Start Epoch 5\n5 Start Epoch 5\n7: 6 batches\n15: 6 batches\n4 Start Epoch 5\n4: 6 batches\n9 Start Epoch 5\n10 Start Epoch 5\n17 Start Epoch 5\n5: 6 batches\n11: 6 batches\n16: 6 batches\n3 Start Epoch 5\n3: 6 batches\n10: 6 batches\n17: 6 batches\n9: 6 batches\n12 Start Epoch 5\n12: 6 batches\n6 Start Epoch 5\n6: 6 batches\n0 Start Epoch 5\n0: 6 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:1: Epoch 0 train loss: 14496.316202799479\nINFO:root:2: Epoch 0 train loss: 25928.770493825275\nINFO:root:5: Epoch 0 train loss: 34682.72652943929\nINFO:root:4: Epoch 0 train loss: 8919.194290161133\nINFO:root:9: Epoch 0 train loss: 44258.07253011068\nINFO:root:14: Epoch 0 train loss: 1156833.268884984\nINFO:root:13: Epoch 0 train loss: 5287.297235250473\nINFO:root:8: Epoch 0 train loss: 1382555.6733194988\nINFO:root:16: Epoch 0 train loss: 8987.92635599772\nINFO:root:6: Epoch 0 train loss: 1349973.1115614881\nINFO:root:17: Epoch 0 train loss: 1328307.5205485027\nINFO:root:7: Epoch 0 train loss: 1382770.9888827007\nINFO:root:15: Epoch 0 train loss: 17238.38643391927\nINFO:root:0: Epoch 0 train loss: 14266.853210449219\nINFO:root:11: Epoch 0 train loss: 15413.561459223429\nINFO:root:10: Epoch 0 train loss: 1114813.1439030964\nINFO:root:3: Epoch 0 train loss: 5761.885921796163\nINFO:root:12: Epoch 0 train loss: 3682.929879029592\nINFO:root:0: Epoch 0 validation loss: 138291.48896696983\nINFO:root:0: Epoch 1 train loss: 173605.63343383698\nINFO:root:1: Epoch 1 train loss: 10443.266977945963\nINFO:root:2: Epoch 1 train loss: 25444.27528889974\nINFO:root:14: Epoch 1 train loss: 1355299.6098937988\nINFO:root:10: Epoch 1 train loss: 15760.820272127787\nINFO:root:11: Epoch 1 train loss: 5244.407564798991\nINFO:root:16: Epoch 1 train loss: 23825.976633707684\nINFO:root:4: Epoch 1 train loss: 18990.524869153898\nINFO:root:9: Epoch 1 train loss: 12898.885775883993\nINFO:root:17: Epoch 1 train loss: 20858.55413266023\nINFO:root:15: Epoch 1 train loss: 1157790.321706136\nINFO:root:12: Epoch 1 train loss: 1664642.5215555828\nINFO:root:5: Epoch 1 train loss: 1194589.405611674\nINFO:root:3: Epoch 1 train loss: 1100891.2987365723\nINFO:root:6: Epoch 1 train loss: 8492.097020467123\nINFO:root:8: Epoch 1 train loss: 2481.1301938196025\nINFO:root:7: Epoch 1 train loss: 1151045.391946358\nINFO:root:13: Epoch 1 train loss: 47309.19356282552\nINFO:root:0: Epoch 1 validation loss: 138268.7512536506\nINFO:root:2: Epoch 2 train loss: 1606259.0910555522\nINFO:root:9: Epoch 2 train loss: 1340514.1846110027\nINFO:root:5: Epoch 2 train loss: 166462.44006490707\nINFO:root:4: Epoch 2 train loss: 41770.405783335365\nINFO:root:17: Epoch 2 train loss: 18941.543863932293\nINFO:root:12: Epoch 2 train loss: 11527.225463867188\nINFO:root:8: Epoch 2 train loss: 4053.7645314534507\nINFO:root:6: Epoch 2 train loss: 1341812.0490805309\nINFO:root:7: Epoch 2 train loss: 5064.743540445964\nINFO:root:13: Epoch 2 train loss: 26880.957885742188\nINFO:root:16: Epoch 2 train loss: 1605005.422867775\nINFO:root:10: Epoch 2 train loss: 1204845.0174992878\nINFO:root:0: Epoch 2 train loss: 3846502.8472086587\nINFO:root:15: Epoch 2 train loss: 1340042.8465372722\nINFO:root:11: Epoch 2 train loss: 51863.96823120117\nINFO:root:1: Epoch 2 train loss: 1615563.3855183918\nINFO:root:14: Epoch 2 train loss: 1664458.0469665527\nINFO:root:3: Epoch 2 train loss: 3019461.421840032\nINFO:root:0: Epoch 2 validation loss: 138239.79864353713\nINFO:root:9: Epoch 3 train loss: 9039.130091349283\nINFO:root:12: Epoch 3 train loss: 12203.01193745931\nINFO:root:3: Epoch 3 train loss: 1302391.6594645183\nINFO:root:6: Epoch 3 train loss: 1157085.858462572\nINFO:root:10: Epoch 3 train loss: 65189.94650268555\nINFO:root:17: Epoch 3 train loss: 21951.072556157906\nINFO:root:1: Epoch 3 train loss: 2467395.652440389\nINFO:root:5: Epoch 3 train loss: 13090.12927532196\nINFO:root:2: Epoch 3 train loss: 2887.7906703948975\nINFO:root:16: Epoch 3 train loss: 27883.918097178142\nINFO:root:7: Epoch 3 train loss: 1472822.344329834\nINFO:root:0: Epoch 3 train loss: 480319.4633296281\nINFO:root:13: Epoch 3 train loss: 19844.700714111328\nINFO:root:8: Epoch 3 train loss: 1167740.2362035115\nINFO:root:14: Epoch 3 train loss: 214557.13909657797\nINFO:root:15: Epoch 3 train loss: 6385.037096659343\nINFO:root:4: Epoch 3 train loss: 56483.188385009766\nINFO:root:11: Epoch 3 train loss: 4972.934510231018\nINFO:root:0: Epoch 3 validation loss: 138203.78543832252\nINFO:root:2: Epoch 4 train loss: 1605377.7476501465\nINFO:root:14: Epoch 4 train loss: 472431.2143147786\nINFO:root:8: Epoch 4 train loss: 1446995.0636291504\nINFO:root:13: Epoch 4 train loss: 7058.869443275656\nINFO:root:7: Epoch 4 train loss: 17761.584631357964\nINFO:root:17: Epoch 4 train loss: 9788.446074167887\nINFO:root:1: Epoch 4 train loss: 1405498.0812746685\nINFO:root:3: Epoch 4 train loss: 2504849.776233276\nINFO:root:10: Epoch 4 train loss: 38089.233645121254\nINFO:root:15: Epoch 4 train loss: 1355245.0695358377\nINFO:root:5: Epoch 4 train loss: 1386892.832051595\nINFO:root:9: Epoch 4 train loss: 1607703.340315501\nINFO:root:16: Epoch 4 train loss: 1313911.9578297932\nINFO:root:4: Epoch 4 train loss: 21555.13823445638\nINFO:root:11: Epoch 4 train loss: 14712.958635965982\nINFO:root:0: Epoch 4 train loss: 1345968.74132514\nINFO:root:12: Epoch 4 train loss: 1351685.2929280598\nINFO:root:6: Epoch 4 train loss: 11114.333145141602\nINFO:root:0: Epoch 4 validation loss: 138155.89940956474\nINFO:root:1: Epoch 5 train loss: 27454.5732421875\nINFO:root:2: Epoch 5 train loss: 36042.417643229164\nINFO:root:0: Epoch 5 train loss: 18459.885579427082\nINFO:root:8: Epoch 5 train loss: 464099.57615152997\nINFO:root:11: Epoch 5 train loss: 16726.984550616395\nINFO:root:17: Epoch 5 train loss: 1388233.2141537666\nINFO:root:14: Epoch 5 train loss: 75798.34844684601\nINFO:root:5: Epoch 5 train loss: 30325.804590861004\nINFO:root:15: Epoch 5 train loss: 1284713.0561319988\nINFO:root:13: Epoch 5 train loss: 3064478.893764496\nINFO:root:4: Epoch 5 train loss: 32743.67036183675\nINFO:root:6: Epoch 5 train loss: 31698.06422551473\nINFO:root:9: Epoch 5 train loss: 12126.982340494791\nINFO:root:12: Epoch 5 train loss: 61416.549252827965\nINFO:root:7: Epoch 5 train loss: 2800939.7465820312\nINFO:root:10: Epoch 5 train loss: 19837.413041472435\nINFO:root:16: Epoch 5 train loss: 19159.963785807293\nINFO:root:3: Epoch 5 train loss: 7317.369749575853\nINFO:root:0: Epoch 5 validation loss: 138095.2395842923\n", "seconds": 5.357705116271973, "batch_size": 32, "nodes": 6, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 5 batches\n2 Start Epoch 0\n1 Start Epoch 0\n1: 5 batches\n2: 5 batches\n4 Start Epoch 0\n7 Start Epoch 0\n4: 5 batches\n3 Start Epoch 0\n8 Start Epoch 0\n3: 5 batches\n7: 5 batches\n8: 5 batches\n15 Start Epoch 0\n15: 5 batches\n16 Start Epoch 0\n16: 5 batches\n9 Start Epoch 0\n10 Start Epoch 0\n5 Start Epoch 0\n10: 5 batches\n9: 5 batches\n6 Start Epoch 0\n14 Start Epoch 0\n20 Start Epoch 0\n5: 5 batches\n13 Start Epoch 0\n18 Start Epoch 0\n13: 5 batches\n20: 5 batches\n12 Start Epoch 0\n19 Start Epoch 0\n12: 5 batches\n18: 5 batches\n19: 5 batches\n6: 5 batches\n14: 5 batches\n17 Start Epoch 0\n17: 5 batches\n11 Start Epoch 0\n11: 5 batches\n12 Start Epoch 1\n12: 5 batches\n18 Start Epoch 1\n8 Start Epoch 1\n8: 5 batches\n19 Start Epoch 1\n4 Start Epoch 1\n14 Start Epoch 1\n20 Start Epoch 1\n3 Start Epoch 1\n3: 5 batches\n19: 5 batches\n2 Start Epoch 1\n2: 5 batches\n4: 5 batches\n13 Start Epoch 1\n20: 5 batches\n6 Start Epoch 1\n6: 5 batches\n5 Start Epoch 1\n14: 5 batches\n18: 5 batches\n7 Start Epoch 1\n5: 5 batches\n13: 5 batches\n7: 5 batches\n15 Start Epoch 1\n17 Start Epoch 1\n17: 5 batches\n15: 5 batches\n16 Start Epoch 1\n16: 5 batches\n1 Start Epoch 1\n11 Start Epoch 1\n11: 5 batches\n1: 5 batches\n10 Start Epoch 1\n10: 5 batches\n9 Start Epoch 1\n9: 5 batches\n0 Start Epoch 1\n0: 5 batches\n2 Start Epoch 2\n1 Start Epoch 2\n1: 5 batches\n2: 5 batches\n3 Start Epoch 2\n3: 5 batches\n8 Start Epoch 2\n17 Start Epoch 2\n5 Start Epoch 2\n9 Start Epoch 2\n8: 5 batches\n17: 5 batches\n5: 5 batches\n9: 5 batches\n14 Start Epoch 2\n19 Start Epoch 2\n14: 5 batches\n19: 5 batches\n7 Start Epoch 2\n7: 5 batches\n4 Start Epoch 2\n10 Start Epoch 2\n4: 5 batches\n10: 5 batches\n13 Start Epoch 2\n20 Start Epoch 2\n13: 5 batches\n15 Start Epoch 2\n11 Start Epoch 2\n18 Start Epoch 2\n16 Start Epoch 2\n15: 5 batches\n11: 5 batches\n12 Start Epoch 2\n20: 5 batches\n12: 5 batches\n16: 5 batches\n18: 5 batches\n6 Start Epoch 2\n6: 5 batches\n0 Start Epoch 2\n0: 5 batches\n20 Start Epoch 3\n20: 5 batches\n17 Start Epoch 3\n11 Start Epoch 3\n13 Start Epoch 3\n17: 5 batches\n11: 5 batches\n13: 5 batches\n8 Start Epoch 3\n14 Start Epoch 3\n7 Start Epoch 3\n5 Start Epoch 3\n3 Start Epoch 3\n14: 5 batches\n8: 5 batches\n3: 5 batches\n9 Start Epoch 3\n7: 5 batches\n15 Start Epoch 3\n4 Start Epoch 3\n19 Start Epoch 3\n18 Start Epoch 3\n6 Start Epoch 3\n16 Start Epoch 3\n4: 5 batches\n18: 5 batches\n6: 5 batches\n15: 5 batches\n5: 5 batches\n19: 5 batches\n16: 5 batches\n1 Start Epoch 3\n1: 5 batches\n2 Start Epoch 3\n2: 5 batches\n10 Start Epoch 3\n10: 5 batches\n9: 5 batches\n12 Start Epoch 3\n12: 5 batches\n0 Start Epoch 3\n0: 5 batches\n14 Start Epoch 4\n14: 5 batches\n15 Start Epoch 4\n17 Start Epoch 4\n20 Start Epoch 4\n6 Start Epoch 4\n17: 5 batches\n11 Start Epoch 4\n18 Start Epoch 4\n6: 5 batches\n15: 5 batches\n5 Start Epoch 4\n10 Start Epoch 4\n19 Start Epoch 4\n5: 5 batches\n11: 5 batches\n10: 5 batches\n19: 5 batches\n20: 5 batches\n18: 5 batches\n8 Start Epoch 4\n8: 5 batches\n2 Start Epoch 4\n2: 5 batches\n1 Start Epoch 4\n1: 5 batches\n4 Start Epoch 4\n4: 5 batches\n13 Start Epoch 4\n12 Start Epoch 4\n3 Start Epoch 4\n13: 5 batches\n3: 5 batches\n12: 5 batches\n9 Start Epoch 4\n9: 5 batches\n7 Start Epoch 4\n7: 5 batches\n16 Start Epoch 4\n16: 5 batches\n0 Start Epoch 4\n0: 5 batches\n14 Start Epoch 5\n14: 5 batches\n8 Start Epoch 5\n20 Start Epoch 5\n8: 5 batches\n11 Start Epoch 5\n20: 5 batches\n11: 5 batches\n4 Start Epoch 5\n10 Start Epoch 5\n10: 5 batches\n5 Start Epoch 5\n4: 5 batches\n17 Start Epoch 5\n16 Start Epoch 5\n16: 5 batches\n5: 5 batches\n15 Start Epoch 5\n15: 5 batches\n17: 5 batches\n2 Start Epoch 5\n2: 5 batches\n3 Start Epoch 5\n9 Start Epoch 5\n12 Start Epoch 5\n19 Start Epoch 5\n7 Start Epoch 5\n3: 5 batches\n9: 5 batches\n7: 5 batches\n12: 5 batches\n18 Start Epoch 5\n13 Start Epoch 5\n13: 5 batches\n19: 5 batches\n6 Start Epoch 5\n18: 5 batches\n6: 5 batches\n1 Start Epoch 5\n1: 5 batches\n0 Start Epoch 5\n0: 5 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:12: Epoch 0 train loss: 27164.561889648438\nINFO:root:18: Epoch 0 train loss: 1369775.9427490234\nINFO:root:20: Epoch 0 train loss: 20103.7240234375\nINFO:root:3: Epoch 0 train loss: 90205.94013671875\nINFO:root:19: Epoch 0 train loss: 2082210.7449578673\nINFO:root:8: Epoch 0 train loss: 1387598.6494598389\nINFO:root:4: Epoch 0 train loss: 1400260.848046875\nINFO:root:5: Epoch 0 train loss: 1302230.7775054933\nINFO:root:14: Epoch 0 train loss: 13266.613983154297\nINFO:root:7: Epoch 0 train loss: 1565290.7708496093\nINFO:root:6: Epoch 0 train loss: 2986632.5915527344\nINFO:root:2: Epoch 0 train loss: 1307718.5150268555\nINFO:root:13: Epoch 0 train loss: 6543.910003662109\nINFO:root:15: Epoch 0 train loss: 11376.302844238282\nINFO:root:17: Epoch 0 train loss: 81795.63095703124\nINFO:root:16: Epoch 0 train loss: 53336.35218048096\nINFO:root:1: Epoch 0 train loss: 1610474.444104004\nINFO:root:11: Epoch 0 train loss: 558918.4506347657\nINFO:root:10: Epoch 0 train loss: 5867.064294433594\nINFO:root:0: Epoch 0 train loss: 23032.881134033203\nINFO:root:9: Epoch 0 train loss: 581535.1630371094\nINFO:root:0: Epoch 0 validation loss: 120684.7046831399\nINFO:root:1: Epoch 1 train loss: 159336.6920639038\nINFO:root:2: Epoch 1 train loss: 56201.55478210449\nINFO:root:3: Epoch 1 train loss: 1576438.8163024902\nINFO:root:7: Epoch 1 train loss: 4381579.021212006\nINFO:root:8: Epoch 1 train loss: 1927211.5942016602\nINFO:root:17: Epoch 1 train loss: 20426.25879659653\nINFO:root:5: Epoch 1 train loss: 34135.90061645508\nINFO:root:9: Epoch 1 train loss: 32499.150537109374\nINFO:root:14: Epoch 1 train loss: 7950.619299316406\nINFO:root:19: Epoch 1 train loss: 4202.979120635986\nINFO:root:4: Epoch 1 train loss: 30876.001025390626\nINFO:root:10: Epoch 1 train loss: 1661171.66685791\nINFO:root:0: Epoch 1 train loss: 1791011.687512207\nINFO:root:20: Epoch 1 train loss: 11513.696977233887\nINFO:root:15: Epoch 1 train loss: 186596.25675659179\nINFO:root:13: Epoch 1 train loss: 179329.51494750977\nINFO:root:16: Epoch 1 train loss: 11974.05972290039\nINFO:root:11: Epoch 1 train loss: 1412048.0027893067\nINFO:root:18: Epoch 1 train loss: 8924.451098632813\nINFO:root:12: Epoch 1 train loss: 4767221.898657227\nINFO:root:6: Epoch 1 train loss: 7967.17724609375\nINFO:root:0: Epoch 1 validation loss: 120663.2824354604\nINFO:root:20: Epoch 2 train loss: 5562.752465820313\nINFO:root:17: Epoch 2 train loss: 2155381.988671875\nINFO:root:11: Epoch 2 train loss: 14494.5619140625\nINFO:root:13: Epoch 2 train loss: 7333.623687744141\nINFO:root:8: Epoch 2 train loss: 18527.498828125\nINFO:root:3: Epoch 2 train loss: 8756.186386108398\nINFO:root:4: Epoch 2 train loss: 7000.853460693359\nINFO:root:7: Epoch 2 train loss: 3547.7457122802734\nINFO:root:5: Epoch 2 train loss: 56304.54013671875\nINFO:root:14: Epoch 2 train loss: 1675706.0271484375\nINFO:root:9: Epoch 2 train loss: 14530.426904296875\nINFO:root:18: Epoch 2 train loss: 186482.5320541382\nINFO:root:16: Epoch 2 train loss: 36821.63413085938\nINFO:root:19: Epoch 2 train loss: 2468.443716430664\nINFO:root:15: Epoch 2 train loss: 44303.0111328125\nINFO:root:6: Epoch 2 train loss: 25149.33757019043\nINFO:root:1: Epoch 2 train loss: 22768.86329345703\nINFO:root:0: Epoch 2 train loss: 13323.142358398438\nINFO:root:2: Epoch 2 train loss: 1421526.8568481444\nINFO:root:10: Epoch 2 train loss: 8699.003930664063\nINFO:root:12: Epoch 2 train loss: 2448.929818725586\nINFO:root:0: Epoch 2 validation loss: 120639.00454297481\nINFO:root:14: Epoch 3 train loss: 31297.663657569887\nINFO:root:15: Epoch 3 train loss: 2506.3595207214357\nINFO:root:17: Epoch 3 train loss: 1924489.6478027343\nINFO:root:18: Epoch 3 train loss: 4400.460314941406\nINFO:root:10: Epoch 3 train loss: 3781381.048535156\nINFO:root:20: Epoch 3 train loss: 5315.4262023925785\nINFO:root:11: Epoch 3 train loss: 40757.05757446289\nINFO:root:19: Epoch 3 train loss: 25143.58572692871\nINFO:root:6: Epoch 3 train loss: 1608990.7147216797\nINFO:root:5: Epoch 3 train loss: 29650.88162841797\nINFO:root:8: Epoch 3 train loss: 6253.463940429688\nINFO:root:1: Epoch 3 train loss: 20205.936596679687\nINFO:root:0: Epoch 3 train loss: 9562.598046875\nINFO:root:2: Epoch 3 train loss: 133927.08110351564\nINFO:root:4: Epoch 3 train loss: 33478.305853271486\nINFO:root:12: Epoch 3 train loss: 2276172.9903442385\nINFO:root:13: Epoch 3 train loss: 31793.124475097655\nINFO:root:3: Epoch 3 train loss: 4696.153080749512\nINFO:root:9: Epoch 3 train loss: 24610.14991760254\nINFO:root:7: Epoch 3 train loss: 1666730.6208824157\nINFO:root:16: Epoch 3 train loss: 17449.007446289062\nINFO:root:0: Epoch 3 validation loss: 120609.25697992484\nINFO:root:14: Epoch 4 train loss: 15053.71678314209\nINFO:root:8: Epoch 4 train loss: 7512.859799194336\nINFO:root:11: Epoch 4 train loss: 35387.61475219727\nINFO:root:10: Epoch 4 train loss: 9219.686923885345\nINFO:root:20: Epoch 4 train loss: 548410.391595459\nINFO:root:4: Epoch 4 train loss: 27403.130078125\nINFO:root:16: Epoch 4 train loss: 3591.4244750976563\nINFO:root:5: Epoch 4 train loss: 8721.726214957238\nINFO:root:17: Epoch 4 train loss: 10152.586535644532\nINFO:root:15: Epoch 4 train loss: 2957142.8584960937\nINFO:root:0: Epoch 4 train loss: 25505.873266601564\nINFO:root:3: Epoch 4 train loss: 13077.600929260254\nINFO:root:9: Epoch 4 train loss: 16164.841354370117\nINFO:root:12: Epoch 4 train loss: 11165.310919189453\nINFO:root:19: Epoch 4 train loss: 1929854.1513305665\nINFO:root:2: Epoch 4 train loss: 20095.524560546874\nINFO:root:6: Epoch 4 train loss: 1713953.7684242248\nINFO:root:7: Epoch 4 train loss: 1597861.3997039795\nINFO:root:13: Epoch 4 train loss: 13133.964379882813\nINFO:root:18: Epoch 4 train loss: 24107.401666259764\nINFO:root:1: Epoch 4 train loss: 12572.53289489746\nINFO:root:0: Epoch 4 validation loss: 120571.22070709281\nINFO:root:1: Epoch 5 train loss: 14640.800537109375\nINFO:root:2: Epoch 5 train loss: 3665582.19296875\nINFO:root:4: Epoch 5 train loss: 1622350.8241455078\nINFO:root:13: Epoch 5 train loss: 554282.3518554687\nINFO:root:14: Epoch 5 train loss: 566098.6339660644\nINFO:root:8: Epoch 5 train loss: 1548744.2165222168\nINFO:root:16: Epoch 5 train loss: 24501.632114219665\nINFO:root:18: Epoch 5 train loss: 3759558.7839508057\nINFO:root:7: Epoch 5 train loss: 552623.8151367188\nINFO:root:17: Epoch 5 train loss: 2972143.3564155577\nINFO:root:11: Epoch 5 train loss: 1392595.990234375\nINFO:root:20: Epoch 5 train loss: 36645.8726852417\nINFO:root:6: Epoch 5 train loss: 193644.794140625\nINFO:root:15: Epoch 5 train loss: 7385.184286499023\nINFO:root:10: Epoch 5 train loss: 1667584.7725830078\nINFO:root:19: Epoch 5 train loss: 1175.6069557189942\nINFO:root:9: Epoch 5 train loss: 13359.1294921875\nINFO:root:5: Epoch 5 train loss: 5124.041943359375\nINFO:root:3: Epoch 5 train loss: 1307555.3725341796\nINFO:root:0: Epoch 5 train loss: 22932.0455078125\nINFO:root:12: Epoch 5 train loss: 1560296.1986999512\nINFO:root:0: Epoch 5 validation loss: 120521.13814251857\n", "seconds": 5.923962831497192, "batch_size": 32, "nodes": 7, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 4 batches\n1 Start Epoch 0\n2 Start Epoch 0\n2: 4 batches\n1: 4 batches\n4 Start Epoch 0\n4: 4 batches\n3 Start Epoch 0\n23 Start Epoch 0\n3: 4 batches\n23: 4 batches\n15 Start Epoch 0\n7 Start Epoch 0\n11 Start Epoch 0\n16 Start Epoch 0\n8 Start Epoch 0\n8: 4 batches\n11: 4 batches\n12 Start Epoch 0\n16: 4 batches\n12: 4 batches\n15: 4 batches\n7: 4 batches\n19 Start Epoch 0\n20 Start Epoch 0\n19: 4 batches\n20: 4 batches\n5 Start Epoch 0\n5: 4 batches\n17 Start Epoch 0\n18 Start Epoch 0\n6 Start Epoch 0\n6: 4 batches\n17: 4 batches\n18: 4 batches\n10 Start Epoch 0\n10: 4 batches\n9 Start Epoch 0\n9: 4 batches\n13 Start Epoch 0\n21 Start Epoch 0\n14 Start Epoch 0\n13: 4 batches\n22 Start Epoch 0\n14: 4 batches\n22: 4 batches\n21: 4 batches\n11 Start Epoch 1\n5 Start Epoch 1\n8 Start Epoch 1\n5: 4 batches\n11: 4 batches\n23 Start Epoch 1\n8: 4 batches\n23: 4 batches\n22 Start Epoch 1\n6 Start Epoch 1\n6: 4 batches\n20 Start Epoch 1\n20: 4 batches\n1 Start Epoch 1\n1: 4 batches\n2 Start Epoch 1\n2: 4 batches\n21 Start Epoch 1\n7 Start Epoch 1\n9 Start Epoch 1\n17 Start Epoch 1\n18 Start Epoch 1\n4 Start Epoch 1\n14 Start Epoch 1\n17: 4 batches\n18: 4 batches\n21: 4 batches\n7: 4 batches\n14: 4 batches\n22: 4 batches\n3 Start Epoch 1\n9: 4 batches\n10 Start Epoch 1\n4: 4 batches\n3: 4 batches\n10: 4 batches\n12 Start Epoch 1\n15 Start Epoch 1\n12: 4 batches\n15: 4 batches\n13 Start Epoch 1\n16 Start Epoch 1\n13: 4 batches\n16: 4 batches\n19 Start Epoch 1\n19: 4 batches\n0 Start Epoch 1\n0: 4 batches\n20 Start Epoch 2\n8 Start Epoch 2\n4 Start Epoch 2\n9 Start Epoch 2\n20: 4 batches\n7 Start Epoch 2\n4: 4 batches\n9: 4 batches\n8: 4 batches\n5 Start Epoch 2\n10 Start Epoch 2\n15 Start Epoch 2\n15: 4 batches\n5: 4 batches\n10: 4 batches\n11 Start Epoch 2\n17 Start Epoch 2\n11: 4 batches\n12 Start Epoch 2\n12: 4 batches\n16 Start Epoch 2\n17: 4 batches\n16: 4 batches\n23 Start Epoch 2\n23: 4 batches\n22 Start Epoch 2\n22: 4 batches\n19 Start Epoch 2\n19: 4 batches\n21 Start Epoch 2\n21: 4 batches\n18 Start Epoch 2\n18: 4 batches\n14 Start Epoch 2\n7: 4 batches\n14: 4 batches\n13 Start Epoch 2\n6 Start Epoch 2\n6: 4 batches\n2 Start Epoch 2\n2: 4 batches\n1 Start Epoch 2\n1: 4 batches\n13: 4 batches\n3 Start Epoch 2\n3: 4 batches\n0 Start Epoch 2\n0: 4 batches\n2 Start Epoch 3\n2: 4 batches\n8 Start Epoch 3\n5 Start Epoch 3\n10 Start Epoch 3\n8: 4 batches\n5: 4 batches\n20 Start Epoch 3\n20: 4 batches\n10: 4 batches\n23 Start Epoch 3\n16 Start Epoch 3\n23: 4 batches\n16: 4 batches\n17 Start Epoch 3\n22 Start Epoch 3\n22: 4 batches\n17: 4 batches\n21 Start Epoch 3\n21: 4 batches\n11 Start Epoch 3\n11: 4 batches\n6 Start Epoch 3\n6: 4 batches\n4 Start Epoch 3\n4: 4 batches\n3 Start Epoch 3\n12 Start Epoch 3\n19 Start Epoch 3\n3: 4 batches\n12: 4 batches\n18 Start Epoch 3\n19: 4 batches\n18: 4 batches\n7 Start Epoch 3\n1 Start Epoch 3\n1: 4 batches\n15 Start Epoch 3\n15: 4 batches\n13 Start Epoch 3\n14 Start Epoch 3\n13: 4 batches\n14: 4 batches\n9 Start Epoch 3\n9: 4 batches\n7: 4 batches\n0 Start Epoch 3\n0: 4 batches\n2 Start Epoch 4\n2: 4 batches\n4 Start Epoch 4\n5 Start Epoch 4\n8 Start Epoch 4\n5: 4 batches\n20 Start Epoch 4\n8: 4 batches\n16 Start Epoch 4\n20: 4 batches\n10 Start Epoch 4\n17 Start Epoch 4\n21 Start Epoch 4\n16: 4 batches\n23 Start Epoch 4\n9 Start Epoch 4\n17: 4 batches\n23: 4 batches\n10: 4 batches\n11 Start Epoch 4\n18 Start Epoch 4\n22 Start Epoch 4\n7 Start Epoch 4\n3 Start Epoch 4\n18: 4 batches\n7: 4 batches\n3: 4 batches\n11: 4 batches\n9: 4 batches\n19 Start Epoch 4\n19: 4 batches\n12 Start Epoch 4\n14 Start Epoch 4\n14: 4 batches\n21: 4 batches\n22: 4 batches\n13 Start Epoch 4\n13: 4 batches\n12: 4 batches\n1 Start Epoch 4\n1: 4 batches\n15 Start Epoch 4\n6 Start Epoch 4\n6: 4 batches\n15: 4 batches\n4: 4 batches\n0 Start Epoch 4\n0: 4 batches\n2 Start Epoch 5\n2: 4 batches\n9 Start Epoch 5\n23 Start Epoch 5\n7 Start Epoch 5\n23: 4 batches\n8 Start Epoch 5\n4 Start Epoch 5\n9: 4 batches\n8: 4 batches\n4: 4 batches\n11 Start Epoch 5\n11: 4 batches\n3 Start Epoch 5\n3: 4 batches\n5 Start Epoch 5\n5: 4 batches\n10 Start Epoch 5\n12 Start Epoch 5\n10: 4 batches\n12: 4 batches\n21 Start Epoch 5\n21: 4 batches\n22 Start Epoch 5\n22: 4 batches\n7: 4 batches\n20 Start Epoch 5\n15 Start Epoch 5\n18 Start Epoch 5\n17 Start Epoch 5\n19 Start Epoch 5\n15: 4 batches\n20: 4 batches\n17: 4 batches\n18: 4 batches\n16 Start Epoch 5\n19: 4 batches\n16: 4 batches\n6 Start Epoch 5\n6: 4 batches\n13 Start Epoch 5\n13: 4 batches\n14 Start Epoch 5\n14: 4 batches\n1 Start Epoch 5\n1: 4 batches\n0 Start Epoch 5\n0: 4 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:5: Epoch 0 train loss: 60310.665283203125\nINFO:root:11: Epoch 0 train loss: 1150.0182943344116\nINFO:root:22: Epoch 0 train loss: 8905.943969726562\nINFO:root:8: Epoch 0 train loss: 8642.851879119873\nINFO:root:23: Epoch 0 train loss: 9546.6501121521\nINFO:root:6: Epoch 0 train loss: 1731793.2686462402\nINFO:root:20: Epoch 0 train loss: 49368.65545654297\nINFO:root:1: Epoch 0 train loss: 7776.566799163818\nINFO:root:0: Epoch 0 train loss: 27389.542999267578\nINFO:root:2: Epoch 0 train loss: 4592437.558837891\nINFO:root:7: Epoch 0 train loss: 14524.057739257812\nINFO:root:4: Epoch 0 train loss: 5917.398696899414\nINFO:root:9: Epoch 0 train loss: 2613707.0407714844\nINFO:root:14: Epoch 0 train loss: 25933.272945404053\nINFO:root:17: Epoch 0 train loss: 33503.37033081055\nINFO:root:18: Epoch 0 train loss: 3668931.899055481\nINFO:root:21: Epoch 0 train loss: 1921.7275657653809\nINFO:root:3: Epoch 0 train loss: 8434.593856811523\nINFO:root:13: Epoch 0 train loss: 5666.2305908203125\nINFO:root:10: Epoch 0 train loss: 4903.809295654297\nINFO:root:16: Epoch 0 train loss: 241676.49584960938\nINFO:root:12: Epoch 0 train loss: 18047.47544002533\nINFO:root:15: Epoch 0 train loss: 5441.808372497559\nINFO:root:19: Epoch 0 train loss: 41040.26731109619\nINFO:root:0: Epoch 0 validation loss: 66259.88494008053\nINFO:root:7: Epoch 1 train loss: 2086357.1081895828\nINFO:root:4: Epoch 1 train loss: 4589056.257324219\nINFO:root:10: Epoch 1 train loss: 683785.7565917969\nINFO:root:20: Epoch 1 train loss: 687221.6053161621\nINFO:root:8: Epoch 1 train loss: 49301.058837890625\nINFO:root:5: Epoch 1 train loss: 9191.010828971863\nINFO:root:9: Epoch 1 train loss: 1877459.3034667969\nINFO:root:15: Epoch 1 train loss: 2076539.3754577637\nINFO:root:11: Epoch 1 train loss: 2963.712127685547\nINFO:root:17: Epoch 1 train loss: 2092108.2036132812\nINFO:root:12: Epoch 1 train loss: 2003053.0952453613\nINFO:root:16: Epoch 1 train loss: 22221.172592163086\nINFO:root:23: Epoch 1 train loss: 12217.968170166016\nINFO:root:22: Epoch 1 train loss: 2045368.6425170898\nINFO:root:18: Epoch 1 train loss: 52512.99931335449\nINFO:root:19: Epoch 1 train loss: 8290.54623413086\nINFO:root:21: Epoch 1 train loss: 7902.8070068359375\nINFO:root:14: Epoch 1 train loss: 2000833.5959625244\nINFO:root:13: Epoch 1 train loss: 2812.6119747161865\nINFO:root:6: Epoch 1 train loss: 24805.975784301758\nINFO:root:0: Epoch 1 train loss: 268174.82238197327\nINFO:root:2: Epoch 1 train loss: 2404263.492553711\nINFO:root:1: Epoch 1 train loss: 1726883.4569854736\nINFO:root:3: Epoch 1 train loss: 112027.47950744629\nINFO:root:0: Epoch 1 validation loss: 66251.2735156013\nINFO:root:2: Epoch 2 train loss: 2392874.6323242188\nINFO:root:5: Epoch 2 train loss: 2220277.0575561523\nINFO:root:10: Epoch 2 train loss: 9029.996520996094\nINFO:root:8: Epoch 2 train loss: 2069326.8626327515\nINFO:root:20: Epoch 2 train loss: 8606.19217300415\nINFO:root:16: Epoch 2 train loss: 1740536.266494751\nINFO:root:23: Epoch 2 train loss: 677344.8411712646\nINFO:root:17: Epoch 2 train loss: 25976.05810546875\nINFO:root:22: Epoch 2 train loss: 20614.597900390625\nINFO:root:21: Epoch 2 train loss: 10662.308403015137\nINFO:root:11: Epoch 2 train loss: 19397.906280517578\nINFO:root:6: Epoch 2 train loss: 16276.327392578125\nINFO:root:3: Epoch 2 train loss: 1656674.5129394531\nINFO:root:12: Epoch 2 train loss: 4462946.847045898\nINFO:root:4: Epoch 2 train loss: 231077.0952758789\nINFO:root:18: Epoch 2 train loss: 9945.386947631836\nINFO:root:19: Epoch 2 train loss: 1525.1323509216309\nINFO:root:7: Epoch 2 train loss: 2772.828109741211\nINFO:root:15: Epoch 2 train loss: 34513.67198944092\nINFO:root:0: Epoch 2 train loss: 10589.053802490234\nINFO:root:1: Epoch 2 train loss: 3037729.0180358887\nINFO:root:14: Epoch 2 train loss: 8108.347503662109\nINFO:root:13: Epoch 2 train loss: 2612182.348220825\nINFO:root:9: Epoch 2 train loss: 3729210.473510742\nINFO:root:0: Epoch 2 validation loss: 66242.50759993531\nINFO:root:2: Epoch 3 train loss: 23842.247100830078\nINFO:root:5: Epoch 3 train loss: 354.4941053390503\nINFO:root:4: Epoch 3 train loss: 12158.749477386475\nINFO:root:8: Epoch 3 train loss: 13828.29135131836\nINFO:root:22: Epoch 3 train loss: 2178.971405029297\nINFO:root:9: Epoch 3 train loss: 5468.334560394287\nINFO:root:17: Epoch 3 train loss: 12678.965881347656\nINFO:root:20: Epoch 3 train loss: 34212.74379348755\nINFO:root:11: Epoch 3 train loss: 5284.930233001709\nINFO:root:16: Epoch 3 train loss: 29427.964965820312\nINFO:root:21: Epoch 3 train loss: 87129.0029296875\nINFO:root:23: Epoch 3 train loss: 89282.17370605469\nINFO:root:10: Epoch 3 train loss: 35147.502349853516\nINFO:root:18: Epoch 3 train loss: 2930.370128631592\nINFO:root:7: Epoch 3 train loss: 681838.526673317\nINFO:root:3: Epoch 3 train loss: 69022.16778564453\nINFO:root:19: Epoch 3 train loss: 36891.41540527344\nINFO:root:0: Epoch 3 train loss: 7022.041320800781\nINFO:root:12: Epoch 3 train loss: 1898.2583389282227\nINFO:root:13: Epoch 3 train loss: 4114145.645374298\nINFO:root:14: Epoch 3 train loss: 52081.96044921875\nINFO:root:1: Epoch 3 train loss: 7749.9083824157715\nINFO:root:15: Epoch 3 train loss: 10342.886169433594\nINFO:root:6: Epoch 3 train loss: 63569.0\nINFO:root:0: Epoch 3 validation loss: 66232.72103278866\nINFO:root:2: Epoch 4 train loss: 23107.9541015625\nINFO:root:8: Epoch 4 train loss: 43484.5682220459\nINFO:root:23: Epoch 4 train loss: 2181458.438446045\nINFO:root:7: Epoch 4 train loss: 11477.80647456646\nINFO:root:9: Epoch 4 train loss: 268243.01123046875\nINFO:root:4: Epoch 4 train loss: 57356.893493652344\nINFO:root:11: Epoch 4 train loss: 677517.337846756\nINFO:root:3: Epoch 4 train loss: 18579.87286376953\nINFO:root:5: Epoch 4 train loss: 6814.088417053223\nINFO:root:10: Epoch 4 train loss: 1955486.4161376953\nINFO:root:12: Epoch 4 train loss: 9007.60604095459\nINFO:root:22: Epoch 4 train loss: 31747.48126220703\nINFO:root:21: Epoch 4 train loss: 2515089.1015625\nINFO:root:18: Epoch 4 train loss: 32407.97004699707\nINFO:root:15: Epoch 4 train loss: 39879.005056381226\nINFO:root:19: Epoch 4 train loss: 24157.43243408203\nINFO:root:17: Epoch 4 train loss: 2395310.6239852905\nINFO:root:20: Epoch 4 train loss: 2758999.302886963\nINFO:root:16: Epoch 4 train loss: 2867.0127868652344\nINFO:root:13: Epoch 4 train loss: 2325648.626953125\nINFO:root:6: Epoch 4 train loss: 62854.30554199219\nINFO:root:14: Epoch 4 train loss: 15528.860379815102\nINFO:root:0: Epoch 4 train loss: 2400716.071006775\nINFO:root:1: Epoch 4 train loss: 1629661.4189510345\nINFO:root:0: Epoch 4 validation loss: 66221.3119195502\nINFO:root:8: Epoch 5 train loss: 1643204.249633789\nINFO:root:1: Epoch 5 train loss: 9839.596015930176\nINFO:root:11: Epoch 5 train loss: 19736.400982618332\nINFO:root:20: Epoch 5 train loss: 2742273.70337677\nINFO:root:22: Epoch 5 train loss: 1958162.7064819336\nINFO:root:3: Epoch 5 train loss: 1862022.2523117065\nINFO:root:9: Epoch 5 train loss: 2375958.330810547\nINFO:root:17: Epoch 5 train loss: 2230138.1283569336\nINFO:root:21: Epoch 5 train loss: 16997.425415039062\nINFO:root:4: Epoch 5 train loss: 34085.3844909668\nINFO:root:5: Epoch 5 train loss: 7210.433212280273\nINFO:root:19: Epoch 5 train loss: 12362.972961425781\nINFO:root:16: Epoch 5 train loss: 7059.497467041016\nINFO:root:13: Epoch 5 train loss: 15326.595775604248\nINFO:root:18: Epoch 5 train loss: 2072893.9181232452\nINFO:root:15: Epoch 5 train loss: 18394.555374145508\nINFO:root:12: Epoch 5 train loss: 8132.929735183716\nINFO:root:2: Epoch 5 train loss: 31541.218170166016\nINFO:root:14: Epoch 5 train loss: 13062.678741455078\nINFO:root:0: Epoch 5 train loss: 2202955.6435546875\nINFO:root:10: Epoch 5 train loss: 78237.01390838623\nINFO:root:7: Epoch 5 train loss: 28700.420028686523\nINFO:root:6: Epoch 5 train loss: 14118.413940429688\nINFO:root:23: Epoch 5 train loss: 224607.83504486084\nINFO:root:0: Epoch 5 validation loss: 66207.57188320828\n", "seconds": 6.638141870498657, "batch_size": 32, "nodes": 8, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 4 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 4 batches\n2: 4 batches\n3 Start Epoch 0\n4 Start Epoch 0\n4: 4 batches\n3: 4 batches\n23 Start Epoch 0\n23: 4 batches\n24 Start Epoch 0\n24: 4 batches\n15 Start Epoch 0\n19 Start Epoch 0\n16 Start Epoch 0\n19: 4 batches\n15: 4 batches\n20 Start Epoch 0\n20: 4 batches\n16: 4 batches\n12 Start Epoch 0\n12: 4 batches\n18 Start Epoch 0\n18: 4 batches\n5 Start Epoch 0\n5: 4 batches\n8 Start Epoch 0\n7 Start Epoch 0\n8: 4 batches\n7: 4 batches\n6 Start Epoch 0\n6: 4 batches\n17 Start Epoch 0\n25 Start Epoch 0\n26 Start Epoch 0\n17: 4 batches\n26: 4 batches\n11 Start Epoch 0\n25: 4 batches\n11: 4 batches\n9 Start Epoch 0\n10 Start Epoch 0\n10: 4 batches\n9: 4 batches\n13 Start Epoch 0\n14 Start Epoch 0\n13: 4 batches\n22 Start Epoch 0\n21 Start Epoch 0\n14: 4 batches\n22: 4 batches\n21: 4 batches\n22 Start Epoch 1\n22: 4 batches\n19 Start Epoch 1\n18 Start Epoch 1\n18: 4 batches\n20 Start Epoch 1\n20: 4 batches\n19: 4 batches\n21 Start Epoch 1\n21: 4 batches\n11 Start Epoch 1\n11: 4 batches\n1 Start Epoch 1\n14 Start Epoch 1\n3 Start Epoch 1\n15 Start Epoch 1\n13 Start Epoch 1\n14: 4 batches\n4 Start Epoch 1\n4: 4 batches\n16 Start Epoch 1\n15: 4 batches\n13: 4 batches\n3: 4 batches\n5 Start Epoch 1\n17 Start Epoch 1\n5: 4 batches\n17: 4 batches\n1: 4 batches\n16: 4 batches\n10 Start Epoch 1\n10: 4 batches\n7 Start Epoch 1\n26 Start Epoch 1\n6 Start Epoch 1\n25 Start Epoch 1\n12 Start Epoch 1\n6: 4 batches\n25: 4 batches\n9 Start Epoch 1\n9: 4 batches\n7: 4 batches\n26: 4 batches\n12: 4 batches\n24 Start Epoch 1\n24: 4 batches\n23 Start Epoch 1\n23: 4 batches\n8 Start Epoch 1\n8: 4 batches\n2 Start Epoch 1\n2: 4 batches\n0 Start Epoch 1\n0: 4 batches\n8 Start Epoch 2\n5 Start Epoch 2\n8: 4 batches\n5: 4 batches\n17 Start Epoch 2\n20 Start Epoch 2\n20: 4 batches\n21 Start Epoch 2\n17: 4 batches\n22 Start Epoch 2\n10 Start Epoch 2\n22: 4 batches\n9 Start Epoch 2\n9: 4 batches\n21: 4 batches\n11 Start Epoch 2\n11: 4 batches\n10: 4 batches\n24 Start Epoch 2\n23 Start Epoch 2\n23: 4 batches\n12 Start Epoch 2\n14 Start Epoch 2\n14: 4 batches\n12: 4 batches\n4 Start Epoch 2\n4: 4 batches\n24: 4 batches\n2 Start Epoch 2\n2: 4 batches\n3 Start Epoch 2\n3: 4 batches\n6 Start Epoch 2\n6: 4 batches\n7 Start Epoch 2\n7: 4 batches\n26 Start Epoch 2\n25 Start Epoch 2\n25: 4 batches\n26: 4 batches\n1 Start Epoch 2\n1: 4 batches\n13 Start Epoch 2\n13: 4 batches\n16 Start Epoch 2\n15 Start Epoch 2\n16: 4 batches\n19 Start Epoch 2\n15: 4 batches\n19: 4 batches\n18 Start Epoch 2\n18: 4 batches\n0 Start Epoch 2\n0: 4 batches\n11 Start Epoch 3\n11: 4 batches\n3 Start Epoch 3\n3: 4 batches\n8 Start Epoch 3\n6 Start Epoch 3\n17 Start Epoch 3\n1 Start Epoch 3\n22 Start Epoch 3\n1: 4 batches\n6: 4 batches\n17: 4 batches\n22: 4 batches\n18 Start Epoch 3\n18: 4 batches\n8: 4 batches\n21 Start Epoch 3\n21: 4 batches\n20 Start Epoch 3\n9 Start Epoch 3\n20: 4 batches\n4 Start Epoch 3\n5 Start Epoch 3\n12 Start Epoch 3\n4: 4 batches\n7 Start Epoch 3\n12: 4 batches\n5: 4 batches\n7: 4 batches\n16 Start Epoch 3\n19 Start Epoch 3\n9: 4 batches\n16: 4 batches\n19: 4 batches\n13 Start Epoch 3\n10 Start Epoch 3\n13: 4 batches\n10: 4 batches\n14 Start Epoch 3\n14: 4 batches\n15 Start Epoch 3\n15: 4 batches\n2 Start Epoch 3\n24 Start Epoch 3\n24: 4 batches\n26 Start Epoch 3\n26: 4 batches\n2: 4 batches\n25 Start Epoch 3\n25: 4 batches\n23 Start Epoch 3\n23: 4 batches\n0 Start Epoch 3\n0: 4 batches\n2 Start Epoch 4\n2: 4 batches\n9 Start Epoch 4\n11 Start Epoch 4\n5 Start Epoch 4\n8 Start Epoch 4\n4 Start Epoch 4\n6 Start Epoch 4\n21 Start Epoch 4\n20 Start Epoch 4\n8: 4 batches\n16 Start Epoch 4\n21: 4 batches\n20: 4 batches\n11: 4 batches\n5: 4 batches\n24 Start Epoch 4\n9: 4 batches\n4: 4 batches\n6: 4 batches\n17 Start Epoch 4\n17: 4 batches\n22 Start Epoch 4\n19 Start Epoch 4\n26 Start Epoch 4\n16: 4 batches\n22: 4 batches\n19: 4 batches\n24: 4 batches\n7 Start Epoch 4\n26: 4 batches\n3 Start Epoch 4\n7: 4 batches\n25 Start Epoch 4\n3: 4 batches\n15 Start Epoch 4\n25: 4 batches\n15: 4 batches\n12 Start Epoch 4\n14 Start Epoch 4\n13 Start Epoch 4\n12: 4 batches\n13: 4 batches\n14: 4 batches\n10 Start Epoch 4\n23 Start Epoch 4\n23: 4 batches\n10: 4 batches\n1 Start Epoch 4\n1: 4 batches\n18 Start Epoch 4\n18: 4 batches\n0 Start Epoch 4\n0: 4 batches\n1 Start Epoch 5\n1: 4 batches\n4 Start Epoch 5\n20 Start Epoch 5\n26 Start Epoch 5\n17 Start Epoch 5\n20: 4 batches\n26: 4 batches\n4: 4 batches\n8 Start Epoch 5\n17: 4 batches\n21 Start Epoch 5\n6 Start Epoch 5\n3 Start Epoch 5\n8: 4 batches\n23 Start Epoch 5\n23: 4 batches\n6: 4 batches\n22 Start Epoch 5\n3: 4 batches\n7 Start Epoch 5\n7: 4 batches\n21: 4 batches\n22: 4 batches\n15 Start Epoch 5\n25 Start Epoch 5\n24 Start Epoch 5\n15: 4 batches\n25: 4 batches\n14 Start Epoch 5\n24: 4 batches\n14: 4 batches\n18 Start Epoch 5\n19 Start Epoch 5\n18: 4 batches\n19: 4 batches\n12 Start Epoch 5\n12: 4 batches\n13 Start Epoch 5\n11 Start Epoch 5\n13: 4 batches\n11: 4 batches\n2 Start Epoch 5\n2: 4 batches\n5 Start Epoch 5\n5: 4 batches\n10 Start Epoch 5\n10: 4 batches\n9 Start Epoch 5\n9: 4 batches\n16 Start Epoch 5\n16: 4 batches\n0 Start Epoch 5\n0: 4 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:22: Epoch 0 train loss: 18289.3662109375\nINFO:root:20: Epoch 0 train loss: 1930221.0354458094\nINFO:root:18: Epoch 0 train loss: 2323972.6492004395\nINFO:root:19: Epoch 0 train loss: 4581986.018676758\nINFO:root:21: Epoch 0 train loss: 4673.853038787842\nINFO:root:23: Epoch 0 train loss: 231752.2305908203\nINFO:root:11: Epoch 0 train loss: 3764044.69140625\nINFO:root:1: Epoch 0 train loss: 13154.449813842773\nINFO:root:13: Epoch 0 train loss: 7282.31156539917\nINFO:root:3: Epoch 0 train loss: 26976.148197174072\nINFO:root:17: Epoch 0 train loss: 2066012.46950531\nINFO:root:4: Epoch 0 train loss: 2076296.0353851318\nINFO:root:16: Epoch 0 train loss: 1156.0674431622028\nINFO:root:14: Epoch 0 train loss: 226072.61905288696\nINFO:root:5: Epoch 0 train loss: 8337.277903944254\nINFO:root:15: Epoch 0 train loss: 95955.38037109375\nINFO:root:26: Epoch 0 train loss: 1630834.7655639648\nINFO:root:10: Epoch 0 train loss: 11006.784729003906\nINFO:root:6: Epoch 0 train loss: 10204.50774383545\nINFO:root:25: Epoch 0 train loss: 18028.992263793945\nINFO:root:7: Epoch 0 train loss: 55381.89143371582\nINFO:root:12: Epoch 0 train loss: 54130.223373413086\nINFO:root:9: Epoch 0 train loss: 23603.479515075684\nINFO:root:0: Epoch 0 train loss: 4162.780418395996\nINFO:root:24: Epoch 0 train loss: 53184.42431640625\nINFO:root:8: Epoch 0 train loss: 10288.662544250488\nINFO:root:2: Epoch 0 train loss: 266273.8271484375\nINFO:root:0: Epoch 0 validation loss: 239558.99852716905\nINFO:root:8: Epoch 1 train loss: 9023.866806030273\nINFO:root:5: Epoch 1 train loss: 824385.8671875\nINFO:root:20: Epoch 1 train loss: 30110.399291992188\nINFO:root:9: Epoch 1 train loss: 16792.786887168884\nINFO:root:17: Epoch 1 train loss: 2175621.8826446533\nINFO:root:21: Epoch 1 train loss: 1684609.4042358398\nINFO:root:10: Epoch 1 train loss: 1939659.4896240234\nINFO:root:22: Epoch 1 train loss: 5918.814242362976\nINFO:root:11: Epoch 1 train loss: 695695.6190607548\nINFO:root:24: Epoch 1 train loss: 14287.838241577148\nINFO:root:23: Epoch 1 train loss: 2169578.8278808594\nINFO:root:12: Epoch 1 train loss: 71534.77393341064\nINFO:root:14: Epoch 1 train loss: 6470.77165555954\nINFO:root:4: Epoch 1 train loss: 25707.00457763672\nINFO:root:2: Epoch 1 train loss: 30201.693237304688\nINFO:root:3: Epoch 1 train loss: 71873.37782669067\nINFO:root:6: Epoch 1 train loss: 15828.468294143677\nINFO:root:7: Epoch 1 train loss: 7418.818260192871\nINFO:root:26: Epoch 1 train loss: 11437.624771118164\nINFO:root:25: Epoch 1 train loss: 31471.108276367188\nINFO:root:1: Epoch 1 train loss: 10437.408981323242\nINFO:root:13: Epoch 1 train loss: 8896.676139354706\nINFO:root:0: Epoch 1 train loss: 530839.6369628906\nINFO:root:16: Epoch 1 train loss: 14369.482284545898\nINFO:root:15: Epoch 1 train loss: 18426.300270080566\nINFO:root:19: Epoch 1 train loss: 2443461.3962402344\nINFO:root:18: Epoch 1 train loss: 8139.781366348267\nINFO:root:0: Epoch 1 validation loss: 239531.3599762483\nINFO:root:11: Epoch 2 train loss: 2467.519287109375\nINFO:root:3: Epoch 2 train loss: 2167601.0731658936\nINFO:root:6: Epoch 2 train loss: 14034.056884765625\nINFO:root:8: Epoch 2 train loss: 35166.968505859375\nINFO:root:17: Epoch 2 train loss: 83968.9161529541\nINFO:root:22: Epoch 2 train loss: 296.0442111492157\nINFO:root:1: Epoch 2 train loss: 18109.967658996582\nINFO:root:18: Epoch 2 train loss: 30459.207321166992\nINFO:root:21: Epoch 2 train loss: 45161.74391937256\nINFO:root:9: Epoch 2 train loss: 7294.911659240723\nINFO:root:20: Epoch 2 train loss: 2044518.988067627\nINFO:root:5: Epoch 2 train loss: 2025687.8664779663\nINFO:root:4: Epoch 2 train loss: 35206.842834472656\nINFO:root:12: Epoch 2 train loss: 3832.6021090745926\nINFO:root:7: Epoch 2 train loss: 1968.8146877288818\nINFO:root:19: Epoch 2 train loss: 34253.11376953125\nINFO:root:16: Epoch 2 train loss: 1373.089247226715\nINFO:root:13: Epoch 2 train loss: 28491.122985839844\nINFO:root:10: Epoch 2 train loss: 8975.595428466797\nINFO:root:14: Epoch 2 train loss: 687443.7908325195\nINFO:root:15: Epoch 2 train loss: 2000447.540350914\nINFO:root:0: Epoch 2 train loss: 75026.3505859375\nINFO:root:2: Epoch 2 train loss: 12225.072021484375\nINFO:root:24: Epoch 2 train loss: 5652.480003356934\nINFO:root:26: Epoch 2 train loss: 44957.33525085449\nINFO:root:25: Epoch 2 train loss: 1566.9667150378227\nINFO:root:23: Epoch 2 train loss: 15359.420104980469\nINFO:root:0: Epoch 2 validation loss: 239502.16991497332\nINFO:root:2: Epoch 3 train loss: 23197.968391418457\nINFO:root:9: Epoch 3 train loss: 1925171.739643097\nINFO:root:5: Epoch 3 train loss: 14971.717346191406\nINFO:root:8: Epoch 3 train loss: 24995.767700195312\nINFO:root:6: Epoch 3 train loss: 2251138.253173828\nINFO:root:4: Epoch 3 train loss: 2185218.114777088\nINFO:root:20: Epoch 3 train loss: 7433.890686035156\nINFO:root:25: Epoch 3 train loss: 1637850.528892517\nINFO:root:17: Epoch 3 train loss: 5490.458698272705\nINFO:root:21: Epoch 3 train loss: 7480.666107177734\nINFO:root:11: Epoch 3 train loss: 44916.023986816406\nINFO:root:16: Epoch 3 train loss: 2023551.6728363037\nINFO:root:26: Epoch 3 train loss: 2405882.1041259766\nINFO:root:24: Epoch 3 train loss: 1773901.8116035461\nINFO:root:19: Epoch 3 train loss: 26302.048887252808\nINFO:root:22: Epoch 3 train loss: 3626419.16973114\nINFO:root:7: Epoch 3 train loss: 690985.4109115601\nINFO:root:3: Epoch 3 train loss: 1977167.1824035645\nINFO:root:12: Epoch 3 train loss: 79363.048828125\nINFO:root:15: Epoch 3 train loss: 2393914.0187950134\nINFO:root:13: Epoch 3 train loss: 25598.193759918213\nINFO:root:14: Epoch 3 train loss: 618.394229888916\nINFO:root:0: Epoch 3 train loss: 18667.5015335083\nINFO:root:23: Epoch 3 train loss: 47184.113189697266\nINFO:root:10: Epoch 3 train loss: 51807.00819396973\nINFO:root:1: Epoch 3 train loss: 716.1305031776428\nINFO:root:18: Epoch 3 train loss: 17228.785711288452\nINFO:root:0: Epoch 3 validation loss: 239470.12829987422\nINFO:root:1: Epoch 4 train loss: 1631.006492614746\nINFO:root:0: Epoch 4 train loss: 2067726.1144599915\nINFO:root:4: Epoch 4 train loss: 21984.92840576172\nINFO:root:6: Epoch 4 train loss: 13921.170700073242\nINFO:root:20: Epoch 4 train loss: 686093.8835754395\nINFO:root:26: Epoch 4 train loss: 56103.616331100464\nINFO:root:7: Epoch 4 train loss: 7192.208625793457\nINFO:root:17: Epoch 4 train loss: 2337.4837646484375\nINFO:root:23: Epoch 4 train loss: 29778.680419921875\nINFO:root:21: Epoch 4 train loss: 42268.74768066406\nINFO:root:8: Epoch 4 train loss: 44198.567321777344\nINFO:root:22: Epoch 4 train loss: 4963302.642089844\nINFO:root:3: Epoch 4 train loss: 2061042.2220458984\nINFO:root:25: Epoch 4 train loss: 18873.948143959045\nINFO:root:15: Epoch 4 train loss: 4408472.002761841\nINFO:root:24: Epoch 4 train loss: 8475.770538330078\nINFO:root:14: Epoch 4 train loss: 26465.701782226562\nINFO:root:18: Epoch 4 train loss: 18205.59292602539\nINFO:root:19: Epoch 4 train loss: 26810.013427734375\nINFO:root:12: Epoch 4 train loss: 5608.337875366211\nINFO:root:13: Epoch 4 train loss: 3653.6525268554688\nINFO:root:11: Epoch 4 train loss: 25272.727111816406\nINFO:root:2: Epoch 4 train loss: 46526.890884399414\nINFO:root:5: Epoch 4 train loss: 30888.155752182007\nINFO:root:9: Epoch 4 train loss: 4227699.6420555115\nINFO:root:10: Epoch 4 train loss: 3322.048370361328\nINFO:root:16: Epoch 4 train loss: 12465.630615234375\nINFO:root:0: Epoch 4 validation loss: 239435.8495949183\nINFO:root:2: Epoch 5 train loss: 21049.994689941406\nINFO:root:1: Epoch 5 train loss: 16494.10733795166\nINFO:root:0: Epoch 5 train loss: 6304.961776733398\nINFO:root:3: Epoch 5 train loss: 18156.927352905273\nINFO:root:11: Epoch 5 train loss: 7188.822174072266\nINFO:root:25: Epoch 5 train loss: 56831.5697799325\nINFO:root:9: Epoch 5 train loss: 13047.820068359375\nINFO:root:24: Epoch 5 train loss: 18015.414202690125\nINFO:root:10: Epoch 5 train loss: 2079231.3322753906\nINFO:root:26: Epoch 5 train loss: 378.54652404785156\nINFO:root:5: Epoch 5 train loss: 11805.030135631561\nINFO:root:17: Epoch 5 train loss: 23090.013568878174\nINFO:root:18: Epoch 5 train loss: 8735.240692138672\nINFO:root:15: Epoch 5 train loss: 13343.492324829102\nINFO:root:12: Epoch 5 train loss: 1736195.8015327454\nINFO:root:8: Epoch 5 train loss: 104562.94696807861\nINFO:root:19: Epoch 5 train loss: 700778.6655273438\nINFO:root:4: Epoch 5 train loss: 12210.243961811066\nINFO:root:14: Epoch 5 train loss: 9700.367023468018\nINFO:root:13: Epoch 5 train loss: 79195.90335083008\nINFO:root:23: Epoch 5 train loss: 17136.873306274414\nINFO:root:21: Epoch 5 train loss: 9174.929931640625\nINFO:root:22: Epoch 5 train loss: 19634.197326660156\nINFO:root:16: Epoch 5 train loss: 20635.811767578125\nINFO:root:20: Epoch 5 train loss: 577381.7096405029\nINFO:root:6: Epoch 5 train loss: 16749.479007720947\nINFO:root:7: Epoch 5 train loss: 18627.633544921875\nINFO:root:0: Epoch 5 validation loss: 239397.2099901366\n", "seconds": 6.597959041595459, "batch_size": 32, "nodes": 9, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 4 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 4 batches\n2: 4 batches\n4 Start Epoch 0\n3 Start Epoch 0\n3: 4 batches\n4: 4 batches\n29 Start Epoch 0\n29: 4 batches\n23 Start Epoch 0\n23: 4 batches\n18 Start Epoch 0\n16 Start Epoch 0\n24 Start Epoch 0\n5 Start Epoch 0\n15 Start Epoch 0\n5: 4 batches\n9 Start Epoch 0\n18: 4 batches\n10 Start Epoch 0\n15: 4 batches\n6 Start Epoch 0\n26 Start Epoch 0\n14 Start Epoch 0\n10: 4 batches\n16: 4 batches\n7 Start Epoch 0\n25 Start Epoch 0\n9: 4 batches\n6: 4 batches\n17 Start Epoch 0\n8 Start Epoch 0\n26: 4 batches\n25: 4 batches\n13 Start Epoch 0\n19 Start Epoch 0\n21 Start Epoch 0\n17: 4 batches\n7: 4 batches\n13: 4 batches\n11 Start Epoch 0\n19: 4 batches\n22 Start Epoch 0\n8: 4 batches\n24: 4 batches\n27 Start Epoch 0\n14: 4 batches\n11: 4 batches\n20 Start Epoch 0\n21: 4 batches\n20: 4 batches\n22: 4 batches\n28 Start Epoch 0\n27: 4 batches\n12 Start Epoch 0\n28: 4 batches\n12: 4 batches\n5 Start Epoch 1\n5: 4 batches\n29 Start Epoch 1\n20 Start Epoch 1\n21 Start Epoch 1\n29: 4 batches\n20: 4 batches\n21: 4 batches\n2 Start Epoch 1\n2: 4 batches\n22 Start Epoch 1\n28 Start Epoch 1\n1 Start Epoch 1\n1: 4 batches\n6 Start Epoch 1\n6: 4 batches\n16 Start Epoch 1\n28: 4 batches\n19 Start Epoch 1\n23 Start Epoch 1\n17 Start Epoch 1\n10 Start Epoch 1\n18 Start Epoch 1\n22: 4 batches\n26 Start Epoch 1\n27 Start Epoch 1\n25 Start Epoch 1\n4 Start Epoch 1\n11 Start Epoch 1\n19: 4 batches\n16: 4 batches\n27: 4 batches\n8 Start Epoch 1\n24 Start Epoch 1\n14 Start Epoch 1\n4: 4 batches\n11: 4 batches\n18: 4 batches\n23: 4 batches\n17: 4 batches\n7 Start Epoch 1\n26: 4 batches\n14: 4 batches\n3 Start Epoch 1\n10: 4 batches\n15 Start Epoch 1\n7: 4 batches\n25: 4 batches\n12 Start Epoch 1\n3: 4 batches\n12: 4 batches\n9 Start Epoch 1\n15: 4 batches\n8: 4 batches\n24: 4 batches\n9: 4 batches\n13 Start Epoch 1\n13: 4 batches\n0 Start Epoch 1\n0: 4 batches\n2 Start Epoch 2\n2: 4 batches\n24 Start Epoch 2\n10 Start Epoch 2\n20 Start Epoch 2\n6 Start Epoch 2\n17 Start Epoch 2\n8 Start Epoch 2\n11 Start Epoch 2\n20: 4 batches\n22 Start Epoch 2\n16 Start Epoch 2\n27 Start Epoch 2\n6: 4 batches\n25 Start Epoch 2\n25: 4 batches\n5 Start Epoch 2\n10: 4 batches\n11: 4 batches\n23 Start Epoch 2\n17: 4 batches\n29 Start Epoch 2\n8: 4 batches\n24: 4 batches\n3 Start Epoch 2\n4 Start Epoch 2\n18 Start Epoch 2\n23: 4 batches\n16: 4 batches\n29: 4 batches\n12 Start Epoch 2\n28 Start Epoch 2\n7 Start Epoch 2\n26 Start Epoch 2\n12: 4 batches\n5: 4 batches\n9 Start Epoch 2\n18: 4 batches\n22: 4 batches\n9: 4 batches\n21 Start Epoch 2\n1 Start Epoch 2\n28: 4 batches\n7: 4 batches\n1: 4 batches\n26: 4 batches\n4: 4 batches\n3: 4 batches\n19 Start Epoch 2\n21: 4 batches\n13 Start Epoch 2\n19: 4 batches\n14 Start Epoch 2\n14: 4 batches\n13: 4 batches\n15 Start Epoch 2\n15: 4 batches\n27: 4 batches\n0 Start Epoch 2\n0: 4 batches\n6 Start Epoch 3\n9 Start Epoch 3\n6: 4 batches\n1 Start Epoch 3\n2 Start Epoch 3\n2: 4 batches\n10 Start Epoch 3\n19 Start Epoch 3\n1: 4 batches\n23 Start Epoch 3\n9: 4 batches\n19: 4 batches\n23: 4 batches\n17 Start Epoch 3\n7 Start Epoch 3\n4 Start Epoch 3\n4: 4 batches\n15 Start Epoch 3\n15: 4 batches\n27 Start Epoch 3\n26 Start Epoch 3\n10: 4 batches\n28 Start Epoch 3\n8 Start Epoch 3\n25 Start Epoch 3\n5 Start Epoch 3\n5: 4 batches\n17: 4 batches\n22 Start Epoch 3\n27: 4 batches\n7: 4 batches\n24 Start Epoch 3\n12 Start Epoch 3\n11 Start Epoch 3\n18 Start Epoch 3\n11: 4 batches\n18: 4 batches\n21 Start Epoch 3\n16 Start Epoch 3\n29 Start Epoch 3\n8: 4 batches\n26: 4 batches\n14 Start Epoch 3\n13 Start Epoch 3\n3 Start Epoch 3\n3: 4 batches\n20 Start Epoch 3\n21: 4 batches\n16: 4 batches\n29: 4 batches\n25: 4 batches\n28: 4 batches\n24: 4 batches\n14: 4 batches\n20: 4 batches\n22: 4 batches\n13: 4 batches\n12: 4 batches\n0 Start Epoch 3\n0: 4 batches\n11 Start Epoch 4\n8 Start Epoch 4\n26 Start Epoch 4\n11: 4 batches\n28 Start Epoch 4\n8: 4 batches\n26: 4 batches\n28: 4 batches\n27 Start Epoch 4\n27: 4 batches\n12 Start Epoch 4\n12: 4 batches\n18 Start Epoch 4\n21 Start Epoch 4\n17 Start Epoch 4\n21: 4 batches\n17: 4 batches\n25 Start Epoch 4\n9 Start Epoch 4\n18: 4 batches\n10 Start Epoch 4\n25: 4 batches\n24 Start Epoch 4\n10: 4 batches\n20 Start Epoch 4\n22 Start Epoch 4\n24: 4 batches\n9: 4 batches\n20: 4 batches\n23 Start Epoch 4\n22: 4 batches\n13 Start Epoch 4\n19 Start Epoch 4\n29 Start Epoch 4\n14 Start Epoch 4\n19: 4 batches\n29: 4 batches\n13: 4 batches\n14: 4 batches\n23: 4 batches\n16 Start Epoch 4\n16: 4 batches\n15 Start Epoch 4\n15: 4 batches\n7 Start Epoch 4\n7: 4 batches\n5 Start Epoch 4\n6 Start Epoch 4\n5: 4 batches\n6: 4 batches\n4 Start Epoch 4\n4: 4 batches\n1 Start Epoch 4\n1: 4 batches\n3 Start Epoch 4\n3: 4 batches\n2 Start Epoch 4\n2: 4 batches\n0 Start Epoch 4\n0: 4 batches\n23 Start Epoch 5\n17 Start Epoch 5\n2 Start Epoch 5\n2: 4 batches\n24 Start Epoch 5\n5 Start Epoch 5\n11 Start Epoch 5\n23: 4 batches\n17: 4 batches\n1 Start Epoch 5\n1: 4 batches\n24: 4 batches\n5: 4 batches\n11: 4 batches\n19 Start Epoch 5\n19: 4 batches\n27 Start Epoch 5\n7 Start Epoch 5\n13 Start Epoch 5\n18 Start Epoch 5\n18: 4 batches\n21 Start Epoch 5\n28 Start Epoch 5\n7: 4 batches\n25 Start Epoch 5\n13: 4 batches\n21: 4 batches\n16 Start Epoch 5\n28: 4 batches\n8 Start Epoch 5\n25: 4 batches\n10 Start Epoch 5\n10: 4 batches\n20 Start Epoch 5\n15 Start Epoch 5\n29 Start Epoch 5\n8: 4 batches\n12 Start Epoch 5\n26 Start Epoch 5\n12: 4 batches\n20: 4 batches\n22 Start Epoch 5\n15: 4 batches\n29: 4 batches\n9 Start Epoch 5\n22: 4 batches\n16: 4 batches\n27: 4 batches\n26: 4 batches\n9: 4 batches\n3 Start Epoch 5\n3: 4 batches\n6 Start Epoch 5\n6: 4 batches\n4 Start Epoch 5\n4: 4 batches\n14 Start Epoch 5\n14: 4 batches\n0 Start Epoch 5\n0: 4 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:5: Epoch 0 train loss: 338.2148389816284\nINFO:root:29: Epoch 0 train loss: 143473.5444946289\nINFO:root:20: Epoch 0 train loss: 4270.885450601578\nINFO:root:21: Epoch 0 train loss: 1733190.0835876465\nINFO:root:6: Epoch 0 train loss: 1633596.3826012067\nINFO:root:22: Epoch 0 train loss: 23145.89218711853\nINFO:root:2: Epoch 0 train loss: 2009837.7531817853\nINFO:root:28: Epoch 0 train loss: 34506.04574170515\nINFO:root:19: Epoch 0 train loss: 2073655.3877034187\nINFO:root:0: Epoch 0 train loss: 42301.86749267578\nINFO:root:16: Epoch 0 train loss: 81060.45482635498\nINFO:root:1: Epoch 0 train loss: 3887496.062675476\nINFO:root:25: Epoch 0 train loss: 2462137.0665283203\nINFO:root:24: Epoch 0 train loss: 24322.75635123998\nINFO:root:10: Epoch 0 train loss: 3155.3093967437744\nINFO:root:18: Epoch 0 train loss: 4765.50712207146\nINFO:root:23: Epoch 0 train loss: 16948.92977142334\nINFO:root:3: Epoch 0 train loss: 47240.37404259273\nINFO:root:11: Epoch 0 train loss: 998.8748134672642\nINFO:root:26: Epoch 0 train loss: 31348.37315750122\nINFO:root:12: Epoch 0 train loss: 4744.61540222168\nINFO:root:4: Epoch 0 train loss: 65685.82001992967\nINFO:root:17: Epoch 0 train loss: 2173490.60379982\nINFO:root:27: Epoch 0 train loss: 744123.2464523315\nINFO:root:7: Epoch 0 train loss: 2068326.599723786\nINFO:root:8: Epoch 0 train loss: 4672.588580682874\nINFO:root:14: Epoch 0 train loss: 1672.1179275512695\nINFO:root:15: Epoch 0 train loss: 1697195.3730659052\nINFO:root:9: Epoch 0 train loss: 3352.8350763320923\nINFO:root:13: Epoch 0 train loss: 7312.978464186192\nINFO:root:0: Epoch 0 validation loss: 10826.361729879703\nINFO:root:0: Epoch 1 train loss: 49074.2294921875\nINFO:root:2: Epoch 1 train loss: 1929446.44510746\nINFO:root:11: Epoch 1 train loss: 8991.534889221191\nINFO:root:6: Epoch 1 train loss: 8118.619514465332\nINFO:root:16: Epoch 1 train loss: 13356.460266113281\nINFO:root:29: Epoch 1 train loss: 9628.08449198585\nINFO:root:8: Epoch 1 train loss: 2212.352516412735\nINFO:root:3: Epoch 1 train loss: 10353.24843621254\nINFO:root:10: Epoch 1 train loss: 1999150.5358428955\nINFO:root:20: Epoch 1 train loss: 1739089.5830956085\nINFO:root:21: Epoch 1 train loss: 1221.7411804199219\nINFO:root:4: Epoch 1 train loss: 48808.5703125\nINFO:root:23: Epoch 1 train loss: 15003.723840347913\nINFO:root:17: Epoch 1 train loss: 52533.71466064453\nINFO:root:27: Epoch 1 train loss: 2967.2286491394043\nINFO:root:25: Epoch 1 train loss: 1761814.8607177734\nINFO:root:22: Epoch 1 train loss: 933.7706461846828\nINFO:root:28: Epoch 1 train loss: 14539.48351597786\nINFO:root:24: Epoch 1 train loss: 18287.334213256836\nINFO:root:5: Epoch 1 train loss: 3775.8176560103893\nINFO:root:18: Epoch 1 train loss: 5278.557777432303\nINFO:root:12: Epoch 1 train loss: 6789.391082763672\nINFO:root:9: Epoch 1 train loss: 3082427.773501763\nINFO:root:7: Epoch 1 train loss: 5351.760538101196\nINFO:root:26: Epoch 1 train loss: 20534929.64666748\nINFO:root:19: Epoch 1 train loss: 22467.07131576538\nINFO:root:1: Epoch 1 train loss: 2007763.6209454536\nINFO:root:14: Epoch 1 train loss: 14831.979612708092\nINFO:root:13: Epoch 1 train loss: 237723.31837065512\nINFO:root:15: Epoch 1 train loss: 19383.89387512207\nINFO:root:0: Epoch 1 validation loss: 10819.183669158514\nINFO:root:6: Epoch 2 train loss: 1812513.1882083118\nINFO:root:9: Epoch 2 train loss: 4785.245568037033\nINFO:root:10: Epoch 2 train loss: 677393.4768447876\nINFO:root:19: Epoch 2 train loss: 18658.816703796387\nINFO:root:23: Epoch 2 train loss: 47383.34732055664\nINFO:root:15: Epoch 2 train loss: 2395379.0332012177\nINFO:root:28: Epoch 2 train loss: 28915.368267774582\nINFO:root:24: Epoch 2 train loss: 18949.254545211792\nINFO:root:2: Epoch 2 train loss: 30357.79052734375\nINFO:root:1: Epoch 2 train loss: 1638262.0030899048\nINFO:root:17: Epoch 2 train loss: 13668.880271911621\nINFO:root:29: Epoch 2 train loss: 17076.12001149822\nINFO:root:0: Epoch 2 train loss: 21027.476684570312\nINFO:root:7: Epoch 2 train loss: 84128.59088170528\nINFO:root:26: Epoch 2 train loss: 3899018.8743896484\nINFO:root:27: Epoch 2 train loss: 4678.415741086006\nINFO:root:25: Epoch 2 train loss: 2812.6456611156464\nINFO:root:13: Epoch 2 train loss: 518.1901435852051\nINFO:root:18: Epoch 2 train loss: 4971.680553496\nINFO:root:21: Epoch 2 train loss: 4230555.049501419\nINFO:root:8: Epoch 2 train loss: 15000.495395153761\nINFO:root:12: Epoch 2 train loss: 2407654.4283714294\nINFO:root:5: Epoch 2 train loss: 15420.6526149758\nINFO:root:14: Epoch 2 train loss: 1770.1388511657715\nINFO:root:11: Epoch 2 train loss: 31845.665855407715\nINFO:root:20: Epoch 2 train loss: 4704.41068276763\nINFO:root:22: Epoch 2 train loss: 25968.839754104614\nINFO:root:16: Epoch 2 train loss: 36640.79350280762\nINFO:root:3: Epoch 2 train loss: 37789.5237827301\nINFO:root:4: Epoch 2 train loss: 21813.737389087677\nINFO:root:0: Epoch 2 validation loss: 10811.352720883257\nINFO:root:11: Epoch 3 train loss: 14958.34683227539\nINFO:root:26: Epoch 3 train loss: 332308.74279785156\nINFO:root:28: Epoch 3 train loss: 355554.0091342926\nINFO:root:8: Epoch 3 train loss: 4700.001804351807\nINFO:root:27: Epoch 3 train loss: 235018.28419503756\nINFO:root:12: Epoch 3 train loss: 38447.48396587372\nINFO:root:0: Epoch 3 train loss: 3863.609706878662\nINFO:root:18: Epoch 3 train loss: 5989.303290404379\nINFO:root:21: Epoch 3 train loss: 38695.47236370266\nINFO:root:17: Epoch 3 train loss: 227720.34126663208\nINFO:root:25: Epoch 3 train loss: 2936.2723770500743\nINFO:root:9: Epoch 3 train loss: 29265.13397216797\nINFO:root:24: Epoch 3 train loss: 7532.336196184158\nINFO:root:10: Epoch 3 train loss: 690295.6469726562\nINFO:root:20: Epoch 3 train loss: 19881.05282815738\nINFO:root:22: Epoch 3 train loss: 6369.934440612793\nINFO:root:13: Epoch 3 train loss: 17625.84179982543\nINFO:root:23: Epoch 3 train loss: 8605.094831466675\nINFO:root:14: Epoch 3 train loss: 243537.2282375808\nINFO:root:19: Epoch 3 train loss: 9416.203964233398\nINFO:root:29: Epoch 3 train loss: 69193.70346069336\nINFO:root:16: Epoch 3 train loss: 13758.671907424927\nINFO:root:15: Epoch 3 train loss: 34606.238525390625\nINFO:root:7: Epoch 3 train loss: 12449.145431518555\nINFO:root:5: Epoch 3 train loss: 2404379.291518964\nINFO:root:6: Epoch 3 train loss: 1757458.5499195457\nINFO:root:4: Epoch 3 train loss: 6295.607868552208\nINFO:root:1: Epoch 3 train loss: 17050.667700709775\nINFO:root:3: Epoch 3 train loss: 35657.637798754906\nINFO:root:2: Epoch 3 train loss: 1157.2452940046787\nINFO:root:0: Epoch 3 validation loss: 10801.55021053193\nINFO:root:29: Epoch 4 train loss: 18198.205575287342\nINFO:root:24: Epoch 4 train loss: 2203788.1864860244\nINFO:root:23: Epoch 4 train loss: 5551.57776260376\nINFO:root:17: Epoch 4 train loss: 2935.1969850063324\nINFO:root:5: Epoch 4 train loss: 12918.456319212914\nINFO:root:11: Epoch 4 train loss: 2140602.768053055\nINFO:root:19: Epoch 4 train loss: 3103810.987548828\nINFO:root:28: Epoch 4 train loss: 1629973.6362560987\nINFO:root:2: Epoch 4 train loss: 35727.24593787582\nINFO:root:7: Epoch 4 train loss: 2075562.9667663574\nINFO:root:13: Epoch 4 train loss: 7324.177100658417\nINFO:root:18: Epoch 4 train loss: 4706.850303515792\nINFO:root:27: Epoch 4 train loss: 26218.398153814138\nINFO:root:1: Epoch 4 train loss: 2171.94900649786\nINFO:root:8: Epoch 4 train loss: 7449.005126953125\nINFO:root:21: Epoch 4 train loss: 36601.578857421875\nINFO:root:15: Epoch 4 train loss: 12135.190856933594\nINFO:root:25: Epoch 4 train loss: 15958.047931671143\nINFO:root:10: Epoch 4 train loss: 2395867.615966797\nINFO:root:16: Epoch 4 train loss: 71763.89273071289\nINFO:root:12: Epoch 4 train loss: 28219.0513381958\nINFO:root:20: Epoch 4 train loss: 10766.330505371094\nINFO:root:22: Epoch 4 train loss: 18374635.45843506\nINFO:root:26: Epoch 4 train loss: 13595.01590012014\nINFO:root:9: Epoch 4 train loss: 17971.454269826412\nINFO:root:3: Epoch 4 train loss: 2910.807029724121\nINFO:root:6: Epoch 4 train loss: 4889.6801681518555\nINFO:root:4: Epoch 4 train loss: 1730.1073455810547\nINFO:root:0: Epoch 4 train loss: 7701.0145263671875\nINFO:root:14: Epoch 4 train loss: 2087330.1923828125\nINFO:root:0: Epoch 4 validation loss: 10788.961127319213\nINFO:root:11: Epoch 5 train loss: 23104914.234405518\nINFO:root:6: Epoch 5 train loss: 6548.761246062815\nINFO:root:2: Epoch 5 train loss: 8254.761875468539\nINFO:root:10: Epoch 5 train loss: 4459425.148863316\nINFO:root:19: Epoch 5 train loss: 10944.36518279463\nINFO:root:22: Epoch 5 train loss: 6550.884590625763\nINFO:root:17: Epoch 5 train loss: 51284.28936767578\nINFO:root:7: Epoch 5 train loss: 21319485.912902832\nINFO:root:26: Epoch 5 train loss: 1630020.610836029\nINFO:root:20: Epoch 5 train loss: 14734.753829956055\nINFO:root:23: Epoch 5 train loss: 3114.99271774292\nINFO:root:12: Epoch 5 train loss: 5474.953717678785\nINFO:root:8: Epoch 5 train loss: 7903.344579078257\nINFO:root:24: Epoch 5 train loss: 2082495.0138788223\nINFO:root:25: Epoch 5 train loss: 244039.66258060932\nINFO:root:18: Epoch 5 train loss: 233041.77910735807\nINFO:root:1: Epoch 5 train loss: 2616784.904794078\nINFO:root:29: Epoch 5 train loss: 28012.79411315918\nINFO:root:0: Epoch 5 train loss: 2688058.1384171247\nINFO:root:15: Epoch 5 train loss: 27678.4066696167\nINFO:root:13: Epoch 5 train loss: 156.80224768817425\nINFO:root:3: Epoch 5 train loss: 1500.0902555584908\nINFO:root:14: Epoch 5 train loss: 5914.653427124023\nINFO:root:4: Epoch 5 train loss: 27916.20970493555\nINFO:root:5: Epoch 5 train loss: 687567.7608137098\nINFO:root:27: Epoch 5 train loss: 88380.97125966987\nINFO:root:28: Epoch 5 train loss: 30621.11456298828\nINFO:root:9: Epoch 5 train loss: 10395.506938677281\nINFO:root:16: Epoch 5 train loss: 4546.270807256922\nINFO:root:21: Epoch 5 train loss: 5605.218250274658\nINFO:root:0: Epoch 5 validation loss: 10773.575511309607\n", "seconds": 7.311204195022583, "batch_size": 32, "nodes": 10, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 3 batches\n1 Start Epoch 0\n1: 3 batches\n2 Start Epoch 0\n2: 3 batches\n3 Start Epoch 0\n4 Start Epoch 0\n3: 3 batches\n4: 3 batches\n5 Start Epoch 0\n5: 3 batches\n32 Start Epoch 0\n6 Start Epoch 0\n23 Start Epoch 0\n15 Start Epoch 0\n31 Start Epoch 0\n31: 3 batches\n8 Start Epoch 0\n23: 3 batches\n16 Start Epoch 0\n32: 3 batches\n15: 3 batches\n24 Start Epoch 0\n8: 3 batches\n16: 3 batches\n6: 3 batches\n7 Start Epoch 0\n7: 3 batches\n24: 3 batches\n11 Start Epoch 0\n27 Start Epoch 0\n12 Start Epoch 0\n11: 3 batches\n12: 3 batches\n28 Start Epoch 0\n28: 3 batches\n19 Start Epoch 0\n20 Start Epoch 0\n19: 3 batches\n20: 3 batches\n27: 3 batches\n17 Start Epoch 0\n18 Start Epoch 0\n10 Start Epoch 0\n9 Start Epoch 0\n17: 3 batches\n25 Start Epoch 0\n9: 3 batches\n18: 3 batches\n26 Start Epoch 0\n25: 3 batches\n26: 3 batches\n10: 3 batches\n21 Start Epoch 0\n22 Start Epoch 0\n21: 3 batches\n22: 3 batches\n30 Start Epoch 0\n13 Start Epoch 0\n14 Start Epoch 0\n14: 3 batches\n30: 3 batches\n29 Start Epoch 0\n13: 3 batches\n29: 3 batches\n5 Start Epoch 1\n28 Start Epoch 1\n28: 3 batches\n29 Start Epoch 1\n29: 3 batches\n9 Start Epoch 1\n9: 3 batches\n10 Start Epoch 1\n10: 3 batches\n5: 3 batches\n32 Start Epoch 1\n11 Start Epoch 1\n26 Start Epoch 1\n32: 3 batches\n11: 3 batches\n15 Start Epoch 1\n18 Start Epoch 1\n15: 3 batches\n1 Start Epoch 1\n2 Start Epoch 1\n22 Start Epoch 1\n18: 3 batches\n1: 3 batches\n27 Start Epoch 1\n23 Start Epoch 1\n27: 3 batches\n14 Start Epoch 1\n4 Start Epoch 1\n23: 3 batches\n7 Start Epoch 1\n3 Start Epoch 1\n22: 3 batches\n12 Start Epoch 1\n12: 3 batches\n6 Start Epoch 1\n3: 3 batches\n31 Start Epoch 1\n14: 3 batches\n8 Start Epoch 1\n4: 3 batches\n31: 3 batches\n13 Start Epoch 1\n8: 3 batches\n6: 3 batches\n13: 3 batches\n30 Start Epoch 1\n7: 3 batches\n19 Start Epoch 1\n21 Start Epoch 1\n20 Start Epoch 1\n21: 3 batches\n17 Start Epoch 1\n19: 3 batches\n16 Start Epoch 1\n20: 3 batches\n30: 3 batches\n17: 3 batches\n16: 3 batches\n2: 3 batches\n26: 3 batches\n24 Start Epoch 1\n24: 3 batches\n25 Start Epoch 1\n25: 3 batches\n0 Start Epoch 1\n0: 3 batches\n8 Start Epoch 2\n8: 3 batches\n29 Start Epoch 2\n26 Start Epoch 2\n9 Start Epoch 2\n28 Start Epoch 2\n24 Start Epoch 2\n9: 3 batches\n15 Start Epoch 2\n27 Start Epoch 2\n25 Start Epoch 2\n16 Start Epoch 2\n28: 3 batches\n26: 3 batches\n4 Start Epoch 2\n23 Start Epoch 2\n16: 3 batches\n27: 3 batches\n25: 3 batches\n3 Start Epoch 2\n15: 3 batches\n29: 3 batches\n10 Start Epoch 2\n7 Start Epoch 2\n4: 3 batches\n17 Start Epoch 2\n20 Start Epoch 2\n17: 3 batches\n18 Start Epoch 2\n12 Start Epoch 2\n10: 3 batches\n6 Start Epoch 2\n3: 3 batches\n13 Start Epoch 2\n6: 3 batches\n5 Start Epoch 2\n18: 3 batches\n7: 3 batches\n5: 3 batches\n20: 3 batches\n13: 3 batches\n12: 3 batches\n11 Start Epoch 2\n30 Start Epoch 2\n31 Start Epoch 2\n11: 3 batches\n31: 3 batches\n32 Start Epoch 2\n30: 3 batches\n32: 3 batches\n1 Start Epoch 2\n1: 3 batches\n2 Start Epoch 2\n2: 3 batches\n24: 3 batches\n21 Start Epoch 2\n22 Start Epoch 2\n23: 3 batches\n22: 3 batches\n21: 3 batches\n19 Start Epoch 2\n19: 3 batches\n14 Start Epoch 2\n14: 3 batches\n0 Start Epoch 2\n0: 3 batches\n25 Start Epoch 3\n17 Start Epoch 3\n17: 3 batches\n28 Start Epoch 3\n25: 3 batches\n9 Start Epoch 3\n23 Start Epoch 3\n27 Start Epoch 3\n9: 3 batches\n23: 3 batches\n26 Start Epoch 3\n8 Start Epoch 3\n5 Start Epoch 3\n20 Start Epoch 3\n28: 3 batches\n26: 3 batches\n15 Start Epoch 3\n20: 3 batches\n27: 3 batches\n32 Start Epoch 3\n10 Start Epoch 3\n6 Start Epoch 3\n3 Start Epoch 3\n16 Start Epoch 3\n29 Start Epoch 3\n32: 3 batches\n13 Start Epoch 3\n10: 3 batches\n8: 3 batches\n3: 3 batches\n29: 3 batches\n14 Start Epoch 3\n7 Start Epoch 3\n5: 3 batches\n16: 3 batches\n13: 3 batches\n7: 3 batches\n4 Start Epoch 3\n4: 3 batches\n15: 3 batches\n30 Start Epoch 3\n14: 3 batches\n6: 3 batches\n30: 3 batches\n18 Start Epoch 3\n18: 3 batches\n19 Start Epoch 3\n19: 3 batches\n31 Start Epoch 3\n31: 3 batches\n12 Start Epoch 3\n12: 3 batches\n24 Start Epoch 3\n24: 3 batches\n11 Start Epoch 3\n11: 3 batches\n22 Start Epoch 3\n22: 3 batches\n21 Start Epoch 3\n21: 3 batches\n1 Start Epoch 3\n2 Start Epoch 3\n2: 3 batches\n1: 3 batches\n0 Start Epoch 3\n0: 3 batches\n27 Start Epoch 4\n27: 3 batches\n26 Start Epoch 4\n26: 3 batches\n9 Start Epoch 4\n10 Start Epoch 4\n29 Start Epoch 4\n29: 3 batches\n15 Start Epoch 4\n15: 3 batches\n24 Start Epoch 4\n24: 3 batches\n25 Start Epoch 4\n25: 3 batches\n32 Start Epoch 4\n32: 3 batches\n31 Start Epoch 4\n30 Start Epoch 4\n31: 3 batches\n30: 3 batches\n10: 3 batches\n16 Start Epoch 4\n12 Start Epoch 4\n9: 3 batches\n14 Start Epoch 4\n22 Start Epoch 4\n16: 3 batches\n23 Start Epoch 4\n12: 3 batches\n14: 3 batches\n23: 3 batches\n22: 3 batches\n20 Start Epoch 4\n19 Start Epoch 4\n18 Start Epoch 4\n19: 3 batches\n20: 3 batches\n18: 3 batches\n13 Start Epoch 4\n21 Start Epoch 4\n13: 3 batches\n21: 3 batches\n7 Start Epoch 4\n5 Start Epoch 4\n8 Start Epoch 4\n5: 3 batches\n28 Start Epoch 4\n7: 3 batches\n28: 3 batches\n8: 3 batches\n11 Start Epoch 4\n11: 3 batches\n4 Start Epoch 4\n4: 3 batches\n1 Start Epoch 4\n1: 3 batches\n17 Start Epoch 4\n17: 3 batches\n6 Start Epoch 4\n3 Start Epoch 4\n6: 3 batches\n3: 3 batches\n2 Start Epoch 4\n2: 3 batches\n0 Start Epoch 4\n0: 3 batches\n10 Start Epoch 5\n8 Start Epoch 5\n17 Start Epoch 5\n26 Start Epoch 5\n17: 3 batches\n29 Start Epoch 5\n10: 3 batches\n8: 3 batches\n29: 3 batches\n26: 3 batches\n11 Start Epoch 5\n11: 3 batches\n21 Start Epoch 5\n15 Start Epoch 5\n21: 3 batches\n15: 3 batches\n16 Start Epoch 5\n28 Start Epoch 5\n16: 3 batches\n27 Start Epoch 5\n20 Start Epoch 5\n27: 3 batches\n18 Start Epoch 5\n28: 3 batches\n18: 3 batches\n12 Start Epoch 5\n20: 3 batches\n31 Start Epoch 5\n14 Start Epoch 5\n14: 3 batches\n7 Start Epoch 5\n5 Start Epoch 5\n6 Start Epoch 5\n5: 3 batches\n30 Start Epoch 5\n12: 3 batches\n30: 3 batches\n13 Start Epoch 5\n6: 3 batches\n9 Start Epoch 5\n7: 3 batches\n3 Start Epoch 5\n31: 3 batches\n13: 3 batches\n32 Start Epoch 5\n9: 3 batches\n3: 3 batches\n32: 3 batches\n4 Start Epoch 5\n4: 3 batches\n1 Start Epoch 5\n1: 3 batches\n2 Start Epoch 5\n2: 3 batches\n19 Start Epoch 5\n23 Start Epoch 5\n19: 3 batches\n25 Start Epoch 5\n24 Start Epoch 5\n22 Start Epoch 5\n23: 3 batches\n24: 3 batches\n22: 3 batches\n25: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:5: Epoch 0 train loss: 1852.3970540364583\nINFO:root:28: Epoch 0 train loss: 2957902.052408854\nINFO:root:29: Epoch 0 train loss: 927803.6220703125\nINFO:root:9: Epoch 0 train loss: 7494883.31258138\nINFO:root:10: Epoch 0 train loss: 2777002.8990071616\nINFO:root:11: Epoch 0 train loss: 2179164.957356771\nINFO:root:26: Epoch 0 train loss: 16738.823160807293\nINFO:root:32: Epoch 0 train loss: 11550.607177734375\nINFO:root:15: Epoch 0 train loss: 2310495.2116597495\nINFO:root:18: Epoch 0 train loss: 1609.0734965006511\nINFO:root:23: Epoch 0 train loss: 11810.936157226562\nINFO:root:12: Epoch 0 train loss: 367712.2301127116\nINFO:root:1: Epoch 0 train loss: 14376.252482096354\nINFO:root:0: Epoch 0 train loss: 903255.3502985636\nINFO:root:2: Epoch 0 train loss: 24680.24853515625\nINFO:root:22: Epoch 0 train loss: 42330.63212076823\nINFO:root:27: Epoch 0 train loss: 26350.996175130207\nINFO:root:14: Epoch 0 train loss: 2213728.89453125\nINFO:root:6: Epoch 0 train loss: 7287.7142333984375\nINFO:root:3: Epoch 0 train loss: 13632.249084472656\nINFO:root:13: Epoch 0 train loss: 25309.73483022054\nINFO:root:7: Epoch 0 train loss: 15120.601603190104\nINFO:root:4: Epoch 0 train loss: 24810.329915364582\nINFO:root:31: Epoch 0 train loss: 383356.5248616536\nINFO:root:8: Epoch 0 train loss: 17924.165771484375\nINFO:root:20: Epoch 0 train loss: 7889.7792561848955\nINFO:root:19: Epoch 0 train loss: 1675.313725789388\nINFO:root:30: Epoch 0 train loss: 2892861.7577311196\nINFO:root:21: Epoch 0 train loss: 8161.165547688802\nINFO:root:16: Epoch 0 train loss: 1083.3726971944172\nINFO:root:17: Epoch 0 train loss: 15410.955729166666\nINFO:root:24: Epoch 0 train loss: 33904.52734375\nINFO:root:25: Epoch 0 train loss: 160778.09765625\nINFO:root:0: Epoch 0 validation loss: 732838.9054635026\nINFO:root:28: Epoch 1 train loss: 2176398.4451090493\nINFO:root:25: Epoch 1 train loss: 8124.564000447591\nINFO:root:29: Epoch 1 train loss: 1423.1585693359375\nINFO:root:24: Epoch 1 train loss: 7976.89963277181\nINFO:root:8: Epoch 1 train loss: 13737.368496576944\nINFO:root:17: Epoch 1 train loss: 905733.2616780599\nINFO:root:27: Epoch 1 train loss: 2649.1626790364585\nINFO:root:26: Epoch 1 train loss: 135089.29069010416\nINFO:root:9: Epoch 1 train loss: 9875.994059244791\nINFO:root:15: Epoch 1 train loss: 39791.45612080892\nINFO:root:16: Epoch 1 train loss: 65189.470540364586\nINFO:root:3: Epoch 1 train loss: 16511.28173828125\nINFO:root:4: Epoch 1 train loss: 2720411.5923055015\nINFO:root:23: Epoch 1 train loss: 15129.163045247396\nINFO:root:10: Epoch 1 train loss: 28437.659118652344\nINFO:root:5: Epoch 1 train loss: 25461.86683146159\nINFO:root:7: Epoch 1 train loss: 2450.1448364257812\nINFO:root:18: Epoch 1 train loss: 4349.07958984375\nINFO:root:11: Epoch 1 train loss: 5558268.8492838545\nINFO:root:6: Epoch 1 train loss: 108145.13802083333\nINFO:root:20: Epoch 1 train loss: 16006.000569661459\nINFO:root:13: Epoch 1 train loss: 15442.603108723959\nINFO:root:12: Epoch 1 train loss: 37295.12240600586\nINFO:root:31: Epoch 1 train loss: 7319.441569010417\nINFO:root:32: Epoch 1 train loss: 2893593.891845703\nINFO:root:30: Epoch 1 train loss: 8160.071858723958\nINFO:root:0: Epoch 1 train loss: 3753.5308837890625\nINFO:root:2: Epoch 1 train loss: 10801.445917765299\nINFO:root:1: Epoch 1 train loss: 2877988.4153645835\nINFO:root:21: Epoch 1 train loss: 18304.396036783855\nINFO:root:22: Epoch 1 train loss: 26415.345703125\nINFO:root:19: Epoch 1 train loss: 7677.322977701823\nINFO:root:14: Epoch 1 train loss: 3592561.1432291665\nINFO:root:0: Epoch 1 validation loss: 732824.7081558377\nINFO:root:17: Epoch 2 train loss: 912739.0968424479\nINFO:root:29: Epoch 2 train loss: 87712.2919921875\nINFO:root:25: Epoch 2 train loss: 902316.4515991211\nINFO:root:27: Epoch 2 train loss: 33138.29458872477\nINFO:root:9: Epoch 2 train loss: 1862.541748046875\nINFO:root:6: Epoch 2 train loss: 28047.381469726562\nINFO:root:4: Epoch 2 train loss: 3377.3417358398438\nINFO:root:23: Epoch 2 train loss: 2595803.1295674643\nINFO:root:7: Epoch 2 train loss: 13795.16860961914\nINFO:root:5: Epoch 2 train loss: 2565860.6597595215\nINFO:root:26: Epoch 2 train loss: 52094.619791666664\nINFO:root:8: Epoch 2 train loss: 11812.083780924479\nINFO:root:3: Epoch 2 train loss: 7838.0619710286455\nINFO:root:16: Epoch 2 train loss: 90777.9385579427\nINFO:root:20: Epoch 2 train loss: 4771.614807128906\nINFO:root:28: Epoch 2 train loss: 2674233.7506510415\nINFO:root:32: Epoch 2 train loss: 3231094.8276774087\nINFO:root:14: Epoch 2 train loss: 60519.42529296875\nINFO:root:10: Epoch 2 train loss: 281.66175333658856\nINFO:root:15: Epoch 2 train loss: 49172.471354166664\nINFO:root:13: Epoch 2 train loss: 6430.343771298726\nINFO:root:30: Epoch 2 train loss: 932168.4423014323\nINFO:root:18: Epoch 2 train loss: 10104.99072265625\nINFO:root:19: Epoch 2 train loss: 10557.524007161459\nINFO:root:31: Epoch 2 train loss: 10907.814208984375\nINFO:root:12: Epoch 2 train loss: 2755886.3994547524\nINFO:root:24: Epoch 2 train loss: 61074.98998260498\nINFO:root:11: Epoch 2 train loss: 2570732.8009033203\nINFO:root:22: Epoch 2 train loss: 5017.610168457031\nINFO:root:21: Epoch 2 train loss: 8516.57867940267\nINFO:root:0: Epoch 2 train loss: 11619.847330729166\nINFO:root:2: Epoch 2 train loss: 3993184.01953125\nINFO:root:1: Epoch 2 train loss: 589.1993611653646\nINFO:root:0: Epoch 2 validation loss: 732810.1311902308\nINFO:root:29: Epoch 3 train loss: 7236593.072845459\nINFO:root:27: Epoch 3 train loss: 3288604.0408198037\nINFO:root:26: Epoch 3 train loss: 2560.0570278167725\nINFO:root:9: Epoch 3 train loss: 15107.903116861979\nINFO:root:10: Epoch 3 train loss: 9029.714192708334\nINFO:root:15: Epoch 3 train loss: 2915827.282910665\nINFO:root:24: Epoch 3 train loss: 1689.701416015625\nINFO:root:25: Epoch 3 train loss: 2464309.663909912\nINFO:root:16: Epoch 3 train loss: 8926.339884440104\nINFO:root:31: Epoch 3 train loss: 59017.2421468099\nINFO:root:30: Epoch 3 train loss: 2311501.3644307456\nINFO:root:32: Epoch 3 train loss: 1964.3162434895833\nINFO:root:14: Epoch 3 train loss: 42017.78125\nINFO:root:17: Epoch 3 train loss: 399.9198881785075\nINFO:root:12: Epoch 3 train loss: 21834.76611328125\nINFO:root:22: Epoch 3 train loss: 9700.43603515625\nINFO:root:23: Epoch 3 train loss: 2306788.4468078613\nINFO:root:20: Epoch 3 train loss: 2856328.8489583335\nINFO:root:19: Epoch 3 train loss: 100300.16822306316\nINFO:root:18: Epoch 3 train loss: 2193457.320638021\nINFO:root:0: Epoch 3 train loss: 1834.0739669799805\nINFO:root:21: Epoch 3 train loss: 103751.28344726562\nINFO:root:28: Epoch 3 train loss: 713.645383199056\nINFO:root:13: Epoch 3 train loss: 17749.16796875\nINFO:root:7: Epoch 3 train loss: 11924.822825113932\nINFO:root:8: Epoch 3 train loss: 2437019.0481770835\nINFO:root:5: Epoch 3 train loss: 6004.013427734375\nINFO:root:11: Epoch 3 train loss: 2614600.8133138022\nINFO:root:4: Epoch 3 train loss: 19674.08223470052\nINFO:root:1: Epoch 3 train loss: 9220.330078125\nINFO:root:6: Epoch 3 train loss: 22686.282267252605\nINFO:root:3: Epoch 3 train loss: 7570.288937886556\nINFO:root:2: Epoch 3 train loss: 15188.814412434896\nINFO:root:0: Epoch 3 validation loss: 732794.911659246\nINFO:root:10: Epoch 4 train loss: 2423.1313680013022\nINFO:root:17: Epoch 4 train loss: 6269.009623209636\nINFO:root:11: Epoch 4 train loss: 2680536.2247924805\nINFO:root:8: Epoch 4 train loss: 106583.98494466145\nINFO:root:29: Epoch 4 train loss: 8833.172281901041\nINFO:root:26: Epoch 4 train loss: 2638267.785481771\nINFO:root:16: Epoch 4 train loss: 7342.476623535156\nINFO:root:21: Epoch 4 train loss: 6782.8648681640625\nINFO:root:15: Epoch 4 train loss: 2771683.237548828\nINFO:root:28: Epoch 4 train loss: 6617669.3336588545\nINFO:root:27: Epoch 4 train loss: 2890414.2006022134\nINFO:root:18: Epoch 4 train loss: 2580332.3282877603\nINFO:root:20: Epoch 4 train loss: 8562.810546875\nINFO:root:12: Epoch 4 train loss: 13622.87520980835\nINFO:root:31: Epoch 4 train loss: 5241633.129475911\nINFO:root:14: Epoch 4 train loss: 2619.7487182617188\nINFO:root:30: Epoch 4 train loss: 911954.328125\nINFO:root:13: Epoch 4 train loss: 16362.33462524414\nINFO:root:6: Epoch 4 train loss: 2297643.6996663413\nINFO:root:32: Epoch 4 train loss: 342698.9583333333\nINFO:root:7: Epoch 4 train loss: 305057.72265625\nINFO:root:5: Epoch 4 train loss: 2693752.7568359375\nINFO:root:9: Epoch 4 train loss: 1818.956059773763\nINFO:root:3: Epoch 4 train loss: 12715.030080159506\nINFO:root:4: Epoch 4 train loss: 1824.0257568359375\nINFO:root:1: Epoch 4 train loss: 17477.601033528645\nINFO:root:2: Epoch 4 train loss: 8472.461949666342\nINFO:root:24: Epoch 4 train loss: 19055.198974609375\nINFO:root:22: Epoch 4 train loss: 22603.727864583332\nINFO:root:19: Epoch 4 train loss: 34611.525065104164\nINFO:root:25: Epoch 4 train loss: 2777233.0880940757\nINFO:root:23: Epoch 4 train loss: 3201950.7641067505\nINFO:root:0: Epoch 4 train loss: 3401601.0851745605\nINFO:root:0: Epoch 4 validation loss: 732778.534419836\nINFO:root:9: Epoch 5 train loss: 66583.38163248698\nINFO:root:10: Epoch 5 train loss: 40156.407389322914\nINFO:root:8: Epoch 5 train loss: 9300.586405436197\nINFO:root:11: Epoch 5 train loss: 372404.6881510417\nINFO:root:7: Epoch 5 train loss: 10563.131632486979\nINFO:root:29: Epoch 5 train loss: 21469.824493408203\nINFO:root:28: Epoch 5 train loss: 4639.208984375\nINFO:root:25: Epoch 5 train loss: 9390.0986328125\nINFO:root:26: Epoch 5 train loss: 93670.5859375\nINFO:root:5: Epoch 5 train loss: 2165322.2025146484\nINFO:root:14: Epoch 5 train loss: 850.5101216634115\nINFO:root:12: Epoch 5 train loss: 1927.993054707845\nINFO:root:13: Epoch 5 train loss: 2905369.6197916665\nINFO:root:16: Epoch 5 train loss: 32759.594360351562\nINFO:root:21: Epoch 5 train loss: 3057.02783203125\nINFO:root:20: Epoch 5 train loss: 8819.008036295572\nINFO:root:19: Epoch 5 train loss: 3057219.6024271646\nINFO:root:31: Epoch 5 train loss: 21432.88884480794\nINFO:root:30: Epoch 5 train loss: 53112.307291666664\nINFO:root:32: Epoch 5 train loss: 2179959.461263021\nINFO:root:15: Epoch 5 train loss: 3300140.340901693\nINFO:root:3: Epoch 5 train loss: 3576164.7041015625\nINFO:root:4: Epoch 5 train loss: 1129835.1205851238\nINFO:root:27: Epoch 5 train loss: 11543.57937113444\nINFO:root:24: Epoch 5 train loss: 2635.550089518229\nINFO:root:23: Epoch 5 train loss: 5064022.185546875\nINFO:root:22: Epoch 5 train loss: 11754.34637705485\nINFO:root:0: Epoch 5 train loss: 6622.540211995442\nINFO:root:2: Epoch 5 train loss: 18347.041015625\nINFO:root:1: Epoch 5 train loss: 15504.97787475586\nINFO:root:6: Epoch 5 train loss: 30893.645100911457\nINFO:root:18: Epoch 5 train loss: 2774799.188985189\nINFO:root:17: Epoch 5 train loss: 5957.499186197917\nINFO:root:0: Epoch 5 validation loss: 732760.9897385623\n", "seconds": 7.234546899795532, "batch_size": 32, "nodes": 11, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 3 batches\n3 Start Epoch 0\n4 Start Epoch 0\n4: 3 batches\n3: 3 batches\n35 Start Epoch 0\n35: 3 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 3 batches\n2: 3 batches\n24 Start Epoch 0\n24: 3 batches\n23 Start Epoch 0\n23: 3 batches\n7 Start Epoch 0\n8 Start Epoch 0\n7: 3 batches\n8: 3 batches\n11 Start Epoch 0\n31 Start Epoch 0\n15 Start Epoch 0\n11: 3 batches\n32 Start Epoch 0\n15: 3 batches\n32: 3 batches\n31: 3 batches\n16 Start Epoch 0\n16: 3 batches\n12 Start Epoch 0\n28 Start Epoch 0\n12: 3 batches\n20 Start Epoch 0\n27 Start Epoch 0\n19 Start Epoch 0\n27: 3 batches\n19: 3 batches\n28: 3 batches\n20: 3 batches\n6 Start Epoch 0\n5 Start Epoch 0\n5: 3 batches\n6: 3 batches\n9 Start Epoch 0\n9: 3 batches\n10 Start Epoch 0\n10: 3 batches\n18 Start Epoch 0\n25 Start Epoch 0\n18: 3 batches\n26 Start Epoch 0\n17 Start Epoch 0\n33 Start Epoch 0\n26: 3 batches\n17: 3 batches\n34 Start Epoch 0\n25: 3 batches\n34: 3 batches\n33: 3 batches\n30 Start Epoch 0\n14 Start Epoch 0\n30: 3 batches\n13 Start Epoch 0\n21 Start Epoch 0\n29 Start Epoch 0\n13: 3 batches\n29: 3 batches\n14: 3 batches\n22 Start Epoch 0\n21: 3 batches\n22: 3 batches\n27 Start Epoch 1\n28 Start Epoch 1\n28: 3 batches\n27: 3 batches\n5 Start Epoch 1\n29 Start Epoch 1\n29: 3 batches\n11 Start Epoch 1\n5: 3 batches\n10 Start Epoch 1\n10: 3 batches\n11: 3 batches\n2 Start Epoch 1\n2: 3 batches\n1 Start Epoch 1\n1: 3 batches\n30 Start Epoch 1\n14 Start Epoch 1\n17 Start Epoch 1\n9 Start Epoch 1\n21 Start Epoch 1\n21: 3 batches\n35 Start Epoch 1\n4 Start Epoch 1\n9: 3 batches\n23 Start Epoch 1\n23: 3 batches\n35: 3 batches\n4: 3 batches\n20 Start Epoch 1\n24 Start Epoch 1\n30: 3 batches\n14: 3 batches\n17: 3 batches\n6 Start Epoch 1\n19 Start Epoch 1\n26 Start Epoch 1\n22 Start Epoch 1\n22: 3 batches\n34 Start Epoch 1\n3 Start Epoch 1\n8 Start Epoch 1\n20: 3 batches\n24: 3 batches\n32 Start Epoch 1\n12 Start Epoch 1\n16 Start Epoch 1\n34: 3 batches\n3: 3 batches\n6: 3 batches\n19: 3 batches\n26: 3 batches\n32: 3 batches\n13 Start Epoch 1\n15 Start Epoch 1\n8: 3 batches\n33 Start Epoch 1\n7 Start Epoch 1\n18 Start Epoch 1\n25 Start Epoch 1\n31 Start Epoch 1\n12: 3 batches\n16: 3 batches\n25: 3 batches\n31: 3 batches\n13: 3 batches\n15: 3 batches\n33: 3 batches\n7: 3 batches\n18: 3 batches\n0 Start Epoch 1\n0: 3 batches\n9 Start Epoch 2\n9: 3 batches\n3 Start Epoch 2\n3: 3 batches\n28 Start Epoch 2\n32 Start Epoch 2\n32: 3 batches\n22 Start Epoch 2\n34 Start Epoch 2\n28: 3 batches\n23 Start Epoch 2\n35 Start Epoch 2\n11 Start Epoch 2\n35: 3 batches\n22: 3 batches\n23: 3 batches\n34: 3 batches\n2 Start Epoch 2\n2: 3 batches\n1 Start Epoch 2\n1: 3 batches\n4 Start Epoch 2\n15 Start Epoch 2\n10 Start Epoch 2\n21 Start Epoch 2\n18 Start Epoch 2\n29 Start Epoch 2\n30 Start Epoch 2\n14 Start Epoch 2\n10: 3 batches\n21: 3 batches\n5 Start Epoch 2\n29: 3 batches\n26 Start Epoch 2\n31 Start Epoch 2\n13 Start Epoch 2\n17 Start Epoch 2\n4: 3 batches\n6 Start Epoch 2\n20 Start Epoch 2\n30: 3 batches\n13: 3 batches\n15: 3 batches\n5: 3 batches\n8 Start Epoch 2\n20: 3 batches\n24 Start Epoch 2\n18: 3 batches\n26: 3 batches\n31: 3 batches\n14: 3 batches\n17: 3 batches\n8: 3 batches\n7 Start Epoch 2\n24: 3 batches\n6: 3 batches\n25 Start Epoch 2\n16 Start Epoch 2\n25: 3 batches\n16: 3 batches\n7: 3 batches\n11: 3 batches\n33 Start Epoch 2\n33: 3 batches\n27 Start Epoch 2\n12 Start Epoch 2\n19 Start Epoch 2\n27: 3 batches\n12: 3 batches\n19: 3 batches\n0 Start Epoch 2\n0: 3 batches\n11 Start Epoch 3\n11: 3 batches\n23 Start Epoch 3\n20 Start Epoch 3\n29 Start Epoch 3\n20: 3 batches\n28 Start Epoch 3\n23: 3 batches\n17 Start Epoch 3\n28: 3 batches\n16 Start Epoch 3\n22 Start Epoch 3\n16: 3 batches\n27 Start Epoch 3\n21 Start Epoch 3\n21: 3 batches\n22: 3 batches\n29: 3 batches\n30 Start Epoch 3\n27: 3 batches\n30: 3 batches\n17: 3 batches\n34 Start Epoch 3\n15 Start Epoch 3\n15: 3 batches\n34: 3 batches\n18 Start Epoch 3\n13 Start Epoch 3\n10 Start Epoch 3\n2 Start Epoch 3\n26 Start Epoch 3\n26: 3 batches\n32 Start Epoch 3\n14 Start Epoch 3\n9 Start Epoch 3\n3 Start Epoch 3\n7 Start Epoch 3\n7: 3 batches\n18: 3 batches\n19 Start Epoch 3\n25 Start Epoch 3\n25: 3 batches\n31 Start Epoch 3\n14: 3 batches\n10: 3 batches\n33 Start Epoch 3\n4 Start Epoch 3\n6 Start Epoch 3\n6: 3 batches\n33: 3 batches\n5 Start Epoch 3\n8 Start Epoch 3\n8: 3 batches\n19: 3 batches\n24 Start Epoch 3\n24: 3 batches\n31: 3 batches\n13: 3 batches\n9: 3 batches\n32: 3 batches\n3: 3 batches\n5: 3 batches\n12 Start Epoch 3\n4: 3 batches\n12: 3 batches\n1 Start Epoch 3\n1: 3 batches\n35 Start Epoch 3\n35: 3 batches\n2: 3 batches\n0 Start Epoch 3\n0: 3 batches\n10 Start Epoch 4\n10: 3 batches\n8 Start Epoch 4\n27 Start Epoch 4\n8: 3 batches\n27: 3 batches\n11 Start Epoch 4\n11: 3 batches\n4 Start Epoch 4\n34 Start Epoch 4\n3 Start Epoch 4\n6 Start Epoch 4\n29 Start Epoch 4\n23 Start Epoch 4\n34: 3 batches\n3: 3 batches\n29: 3 batches\n26 Start Epoch 4\n5 Start Epoch 4\n7 Start Epoch 4\n26: 3 batches\n12 Start Epoch 4\n9 Start Epoch 4\n23: 3 batches\n9: 3 batches\n35 Start Epoch 4\n5: 3 batches\n6: 3 batches\n19 Start Epoch 4\n28 Start Epoch 4\n31 Start Epoch 4\n12: 3 batches\n19: 3 batches\n28: 3 batches\n24 Start Epoch 4\n16 Start Epoch 4\n35: 3 batches\n7: 3 batches\n13 Start Epoch 4\n17 Start Epoch 4\n22 Start Epoch 4\n4: 3 batches\n24: 3 batches\n32 Start Epoch 4\n21 Start Epoch 4\n30 Start Epoch 4\n13: 3 batches\n17: 3 batches\n16: 3 batches\n22: 3 batches\n25 Start Epoch 4\n31: 3 batches\n25: 3 batches\n30: 3 batches\n14 Start Epoch 4\n21: 3 batches\n32: 3 batches\n14: 3 batches\n2 Start Epoch 4\n2: 3 batches\n20 Start Epoch 4\n15 Start Epoch 4\n33 Start Epoch 4\n20: 3 batches\n15: 3 batches\n33: 3 batches\n18 Start Epoch 4\n18: 3 batches\n1 Start Epoch 4\n1: 3 batches\n0 Start Epoch 4\n0: 3 batches\n27 Start Epoch 5\n27: 3 batches\n23 Start Epoch 5\n23: 3 batches\n30 Start Epoch 5\n22 Start Epoch 5\n30: 3 batches\n22: 3 batches\n20 Start Epoch 5\n29 Start Epoch 5\n29: 3 batches\n17 Start Epoch 5\n17: 3 batches\n28 Start Epoch 5\n20: 3 batches\n28: 3 batches\n16 Start Epoch 5\n21 Start Epoch 5\n35 Start Epoch 5\n8 Start Epoch 5\n16: 3 batches\n35: 3 batches\n8: 3 batches\n11 Start Epoch 5\n21: 3 batches\n9 Start Epoch 5\n26 Start Epoch 5\n11: 3 batches\n26: 3 batches\n3 Start Epoch 5\n4 Start Epoch 5\n25 Start Epoch 5\n25: 3 batches\n3: 3 batches\n5 Start Epoch 5\n5: 3 batches\n4: 3 batches\n15 Start Epoch 5\n33 Start Epoch 5\n7 Start Epoch 5\n19 Start Epoch 5\n32 Start Epoch 5\n15: 3 batches\n7: 3 batches\n19: 3 batches\n31 Start Epoch 5\n12 Start Epoch 5\n9: 3 batches\n34 Start Epoch 5\n13 Start Epoch 5\n34: 3 batches\n6 Start Epoch 5\n18 Start Epoch 5\n31: 3 batches\n33: 3 batches\n6: 3 batches\n18: 3 batches\n32: 3 batches\n12: 3 batches\n14 Start Epoch 5\n14: 3 batches\n13: 3 batches\n24 Start Epoch 5\n24: 3 batches\n10 Start Epoch 5\n10: 3 batches\n1 Start Epoch 5\n1: 3 batches\n2 Start Epoch 5\n2: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:27: Epoch 0 train loss: 36175.224278767906\nINFO:root:28: Epoch 0 train loss: 3476.549761803491\nINFO:root:29: Epoch 0 train loss: 14937.6103515625\nINFO:root:11: Epoch 0 train loss: 6193.586123148601\nINFO:root:5: Epoch 0 train loss: 18104.671264648438\nINFO:root:10: Epoch 0 train loss: 16328.396769205729\nINFO:root:1: Epoch 0 train loss: 3181.2458292643228\nINFO:root:2: Epoch 0 train loss: 3204051.895843506\nINFO:root:26: Epoch 0 train loss: 7084.401194254558\nINFO:root:30: Epoch 0 train loss: 37201.733723958336\nINFO:root:14: Epoch 0 train loss: 638.4860407511393\nINFO:root:17: Epoch 0 train loss: 39406.600911458336\nINFO:root:9: Epoch 0 train loss: 12169.814412434896\nINFO:root:21: Epoch 0 train loss: 305597.7900390625\nINFO:root:35: Epoch 0 train loss: 20889.42755126953\nINFO:root:4: Epoch 0 train loss: 2414.2680867513022\nINFO:root:6: Epoch 0 train loss: 5647431.137369792\nINFO:root:20: Epoch 0 train loss: 2166335.8005777993\nINFO:root:24: Epoch 0 train loss: 7739.99609375\nINFO:root:8: Epoch 0 train loss: 26041.111165364582\nINFO:root:19: Epoch 0 train loss: 28986.60498046875\nINFO:root:7: Epoch 0 train loss: 68145.59114114444\nINFO:root:32: Epoch 0 train loss: 777.3509318033854\nINFO:root:13: Epoch 0 train loss: 2762152.8139648438\nINFO:root:16: Epoch 0 train loss: 1929.266866048177\nINFO:root:23: Epoch 0 train loss: 2778545.400390625\nINFO:root:34: Epoch 0 train loss: 441.2525342305501\nINFO:root:3: Epoch 0 train loss: 20497.3837890625\nINFO:root:12: Epoch 0 train loss: 1522.792744954427\nINFO:root:15: Epoch 0 train loss: 10729.621012369791\nINFO:root:22: Epoch 0 train loss: 597571.4380696615\nINFO:root:25: Epoch 0 train loss: 912459.7221679688\nINFO:root:31: Epoch 0 train loss: 1723.1007080078125\nINFO:root:33: Epoch 0 train loss: 2499.9220530192056\nINFO:root:18: Epoch 0 train loss: 2918098.1497395835\nINFO:root:0: Epoch 0 train loss: 3205466.0318603516\nINFO:root:0: Epoch 0 validation loss: 553011.171915748\nINFO:root:9: Epoch 1 train loss: 221651.81803385416\nINFO:root:3: Epoch 1 train loss: 2156.382609049479\nINFO:root:28: Epoch 1 train loss: 99196.7240600586\nINFO:root:32: Epoch 1 train loss: 19159.29754638672\nINFO:root:22: Epoch 1 train loss: 2172545.234049479\nINFO:root:34: Epoch 1 train loss: 15498.944224039713\nINFO:root:23: Epoch 1 train loss: 2776590.9737955728\nINFO:root:35: Epoch 1 train loss: 35080.392903645836\nINFO:root:11: Epoch 1 train loss: 7365.3965250651045\nINFO:root:5: Epoch 1 train loss: 60226.586588541664\nINFO:root:2: Epoch 1 train loss: 1402.871732076009\nINFO:root:1: Epoch 1 train loss: 636.9795227050781\nINFO:root:0: Epoch 1 train loss: 6469.8452555338545\nINFO:root:26: Epoch 1 train loss: 2192413.830795288\nINFO:root:31: Epoch 1 train loss: 6450.650817871094\nINFO:root:13: Epoch 1 train loss: 11012.519938151041\nINFO:root:15: Epoch 1 train loss: 2620786.56101354\nINFO:root:10: Epoch 1 train loss: 4323.791768391927\nINFO:root:21: Epoch 1 train loss: 17959.815666834515\nINFO:root:4: Epoch 1 train loss: 12551.771667480469\nINFO:root:7: Epoch 1 train loss: 37347.93465169271\nINFO:root:18: Epoch 1 train loss: 31608.524007161457\nINFO:root:27: Epoch 1 train loss: 5258.857259114583\nINFO:root:6: Epoch 1 train loss: 4501544.6832682295\nINFO:root:20: Epoch 1 train loss: 23824.6318359375\nINFO:root:29: Epoch 1 train loss: 2315964.3779296875\nINFO:root:24: Epoch 1 train loss: 888.2142448425293\nINFO:root:30: Epoch 1 train loss: 61162.99560292562\nINFO:root:14: Epoch 1 train loss: 620.6181691487631\nINFO:root:25: Epoch 1 train loss: 16241.349848429361\nINFO:root:17: Epoch 1 train loss: 315216.29532877606\nINFO:root:8: Epoch 1 train loss: 1538510.3538411458\nINFO:root:16: Epoch 1 train loss: 8917.612703323364\nINFO:root:19: Epoch 1 train loss: 12061.86589304606\nINFO:root:12: Epoch 1 train loss: 20581.499674479168\nINFO:root:33: Epoch 1 train loss: 23188.184608459473\nINFO:root:0: Epoch 1 validation loss: 552989.4170489421\nINFO:root:11: Epoch 2 train loss: 2069.5387268066406\nINFO:root:16: Epoch 2 train loss: 44552.329427083336\nINFO:root:23: Epoch 2 train loss: 7476.64382425944\nINFO:root:20: Epoch 2 train loss: 12953.601725260416\nINFO:root:28: Epoch 2 train loss: 141924.203125\nINFO:root:17: Epoch 2 train loss: 59717.966796875\nINFO:root:15: Epoch 2 train loss: 3761241.3951822915\nINFO:root:29: Epoch 2 train loss: 5338.163187662761\nINFO:root:22: Epoch 2 train loss: 60816.27726618449\nINFO:root:21: Epoch 2 train loss: 1364.6932258605957\nINFO:root:27: Epoch 2 train loss: 4345172.787109375\nINFO:root:30: Epoch 2 train loss: 5341.581868489583\nINFO:root:9: Epoch 2 train loss: 20110.124669392902\nINFO:root:34: Epoch 2 train loss: 913503.2362874349\nINFO:root:4: Epoch 2 train loss: 3213053.492502848\nINFO:root:8: Epoch 2 train loss: 12655.184204101562\nINFO:root:19: Epoch 2 train loss: 2597.9356791178384\nINFO:root:26: Epoch 2 train loss: 4283.3729248046875\nINFO:root:14: Epoch 2 train loss: 16461.7387898763\nINFO:root:10: Epoch 2 train loss: 7255.508219401042\nINFO:root:5: Epoch 2 train loss: 6364.325391133626\nINFO:root:7: Epoch 2 train loss: 8556.258188883463\nINFO:root:18: Epoch 2 train loss: 151935.83420817056\nINFO:root:24: Epoch 2 train loss: 9432.300412495932\nINFO:root:31: Epoch 2 train loss: 5531.4668375651045\nINFO:root:13: Epoch 2 train loss: 8068.028645833333\nINFO:root:3: Epoch 2 train loss: 33501.0407816569\nINFO:root:6: Epoch 2 train loss: 364.6604715983073\nINFO:root:25: Epoch 2 train loss: 317839.4812113444\nINFO:root:32: Epoch 2 train loss: 2179420.038330078\nINFO:root:2: Epoch 2 train loss: 30949.912760416668\nINFO:root:33: Epoch 2 train loss: 2171615.1888427734\nINFO:root:12: Epoch 2 train loss: 14293.865707397461\nINFO:root:1: Epoch 2 train loss: 49369.062255859375\nINFO:root:35: Epoch 2 train loss: 14425.077799479166\nINFO:root:0: Epoch 2 train loss: 16903.155721028645\nINFO:root:0: Epoch 2 validation loss: 552966.6785338034\nINFO:root:3: Epoch 3 train loss: 36933.143798828125\nINFO:root:8: Epoch 3 train loss: 17736.488199869793\nINFO:root:27: Epoch 3 train loss: 2566025.9283447266\nINFO:root:11: Epoch 3 train loss: 38638.82345072428\nINFO:root:4: Epoch 3 train loss: 2175249.907674154\nINFO:root:5: Epoch 3 train loss: 1456.6258176167805\nINFO:root:10: Epoch 3 train loss: 2907980.703379313\nINFO:root:34: Epoch 3 train loss: 102019.41845703125\nINFO:root:6: Epoch 3 train loss: 3193805.0595703125\nINFO:root:29: Epoch 3 train loss: 903739.2050882975\nINFO:root:23: Epoch 3 train loss: 34829.334309895836\nINFO:root:26: Epoch 3 train loss: 49785.428283691406\nINFO:root:9: Epoch 3 train loss: 298711.09007263184\nINFO:root:7: Epoch 3 train loss: 23293.112335681915\nINFO:root:32: Epoch 3 train loss: 330560.7128092448\nINFO:root:12: Epoch 3 train loss: 10971.276355107626\nINFO:root:19: Epoch 3 train loss: 32873.3310953776\nINFO:root:28: Epoch 3 train loss: 2202168.579803467\nINFO:root:30: Epoch 3 train loss: 15984.577742258707\nINFO:root:16: Epoch 3 train loss: 7860.941752115886\nINFO:root:35: Epoch 3 train loss: 8717.946004231771\nINFO:root:21: Epoch 3 train loss: 23145.601348876953\nINFO:root:24: Epoch 3 train loss: 7697.9919840494795\nINFO:root:17: Epoch 3 train loss: 9210.505696614584\nINFO:root:31: Epoch 3 train loss: 24295.75557454427\nINFO:root:13: Epoch 3 train loss: 2906542.791346232\nINFO:root:22: Epoch 3 train loss: 25231.176106770832\nINFO:root:25: Epoch 3 train loss: 19232.28852335612\nINFO:root:14: Epoch 3 train loss: 18117.939371744793\nINFO:root:0: Epoch 3 train loss: 32719.605712890625\nINFO:root:2: Epoch 3 train loss: 17407.6884765625\nINFO:root:33: Epoch 3 train loss: 26388.316731770832\nINFO:root:20: Epoch 3 train loss: 6317.110062360764\nINFO:root:15: Epoch 3 train loss: 21643.50614420573\nINFO:root:18: Epoch 3 train loss: 3868140.8397623696\nINFO:root:1: Epoch 3 train loss: 75980.99348958333\nINFO:root:0: Epoch 3 validation loss: 552942.5999642361\nINFO:root:27: Epoch 4 train loss: 23365.235586802166\nINFO:root:23: Epoch 4 train loss: 14091.920166015625\nINFO:root:29: Epoch 4 train loss: 2566451.3307800293\nINFO:root:30: Epoch 4 train loss: 22886.783548990887\nINFO:root:22: Epoch 4 train loss: 997751.1809895834\nINFO:root:28: Epoch 4 train loss: 3208764.469156901\nINFO:root:20: Epoch 4 train loss: 9932.7912495931\nINFO:root:17: Epoch 4 train loss: 14063.404541015625\nINFO:root:16: Epoch 4 train loss: 52259.147216796875\nINFO:root:35: Epoch 4 train loss: 27210.736002604168\nINFO:root:8: Epoch 4 train loss: 1613676.2067871094\nINFO:root:11: Epoch 4 train loss: 7748.762532552083\nINFO:root:21: Epoch 4 train loss: 3423.6240437825522\nINFO:root:9: Epoch 4 train loss: 997.7532653808594\nINFO:root:5: Epoch 4 train loss: 2894782.3463541665\nINFO:root:26: Epoch 4 train loss: 43179.70860799154\nINFO:root:3: Epoch 4 train loss: 299487.2982788086\nINFO:root:4: Epoch 4 train loss: 4956.550018310547\nINFO:root:25: Epoch 4 train loss: 2457332.1204427085\nINFO:root:33: Epoch 4 train loss: 14097.834125518799\nINFO:root:6: Epoch 4 train loss: 10428.630105535189\nINFO:root:18: Epoch 4 train loss: 4475.6418050130205\nINFO:root:31: Epoch 4 train loss: 58535.2305094401\nINFO:root:14: Epoch 4 train loss: 831.5067545572916\nINFO:root:15: Epoch 4 train loss: 606.8656412760416\nINFO:root:7: Epoch 4 train loss: 2670831.743192037\nINFO:root:19: Epoch 4 train loss: 2679575.2342122397\nINFO:root:32: Epoch 4 train loss: 5661.168538411458\nINFO:root:13: Epoch 4 train loss: 2759.682383219401\nINFO:root:34: Epoch 4 train loss: 18710.3984375\nINFO:root:12: Epoch 4 train loss: 501.5443598429362\nINFO:root:24: Epoch 4 train loss: 17263.178263346355\nINFO:root:10: Epoch 4 train loss: 1643.3861897786458\nINFO:root:2: Epoch 4 train loss: 18570.98021189372\nINFO:root:1: Epoch 4 train loss: 30754.694986979168\nINFO:root:0: Epoch 4 train loss: 15335.02197265625\nINFO:root:0: Epoch 4 validation loss: 552916.1761696513\nINFO:root:29: Epoch 5 train loss: 24367.735026041668\nINFO:root:28: Epoch 5 train loss: 877.4079793294271\nINFO:root:27: Epoch 5 train loss: 2764062.047342936\nINFO:root:25: Epoch 5 train loss: 6809.443064371745\nINFO:root:24: Epoch 5 train loss: 52431.165771484375\nINFO:root:8: Epoch 5 train loss: 4559.776041666667\nINFO:root:23: Epoch 5 train loss: 300634.75263722736\nINFO:root:11: Epoch 5 train loss: 39765.03515625\nINFO:root:10: Epoch 5 train loss: 305060.6076660156\nINFO:root:30: Epoch 5 train loss: 25248.85125732422\nINFO:root:13: Epoch 5 train loss: 31026.845052083332\nINFO:root:16: Epoch 5 train loss: 23912.179036458332\nINFO:root:22: Epoch 5 train loss: 2595122.28515625\nINFO:root:19: Epoch 5 train loss: 22368.417317708332\nINFO:root:12: Epoch 5 train loss: 24407.184041341145\nINFO:root:15: Epoch 5 train loss: 73144.28059895833\nINFO:root:20: Epoch 5 train loss: 24288.210357666016\nINFO:root:34: Epoch 5 train loss: 4997.589487711589\nINFO:root:14: Epoch 5 train loss: 2322098.3155314126\nINFO:root:21: Epoch 5 train loss: 2470.1019388834634\nINFO:root:4: Epoch 5 train loss: 5659859.285832723\nINFO:root:7: Epoch 5 train loss: 2665047.3960876465\nINFO:root:5: Epoch 5 train loss: 2169588.348429362\nINFO:root:6: Epoch 5 train loss: 16968.75298055013\nINFO:root:3: Epoch 5 train loss: 3207552.7213541665\nINFO:root:2: Epoch 5 train loss: 89414.78715006511\nINFO:root:0: Epoch 5 train loss: 12879.18011188507\nINFO:root:1: Epoch 5 train loss: 18260.974578857422\nINFO:root:17: Epoch 5 train loss: 4093451.935546875\nINFO:root:9: Epoch 5 train loss: 503277.9546101888\nINFO:root:33: Epoch 5 train loss: 37924.90441894531\nINFO:root:18: Epoch 5 train loss: 67415.27545674641\nINFO:root:32: Epoch 5 train loss: 8104.470703125\nINFO:root:31: Epoch 5 train loss: 35639.355086008705\nINFO:root:35: Epoch 5 train loss: 102450.51041666667\nINFO:root:26: Epoch 5 train loss: 34510.8369140625\nINFO:root:0: Epoch 5 validation loss: 552886.3892355695\n", "seconds": 7.440433025360107, "batch_size": 32, "nodes": 12, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.15,192.168.2.15,192.168.2.15 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "1 Start Epoch 0\n2 Start Epoch 0\n0 Start Epoch 0\n1: 24 batches\n2: 24 batches\n3 Start Epoch 0\n0: 24 batches\n3: 24 batches\n2 Start Epoch 1\n2: 24 batches\n3 Start Epoch 1\n3: 24 batches\n1 Start Epoch 1\n1: 24 batches\n0 Start Epoch 1\n0: 24 batches\n2 Start Epoch 2\n1 Start Epoch 2\n1: 24 batches\n2: 24 batches\n3 Start Epoch 2\n3: 24 batches\n0 Start Epoch 2\n0: 24 batches\n2 Start Epoch 3\n2: 24 batches\n1 Start Epoch 3\n1: 24 batches\n3 Start Epoch 3\n3: 24 batches\n0 Start Epoch 3\n0: 24 batches\n3 Start Epoch 4\n3: 24 batches\n1 Start Epoch 4\n1: 24 batches\n2 Start Epoch 4\n2: 24 batches\n0 Start Epoch 4\n0: 24 batches\n2 Start Epoch 5\n1 Start Epoch 5\n3 Start Epoch 5\n1: 24 batches\n3: 24 batches\n2: 24 batches\n0 Start Epoch 5\n0: 24 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:2: Epoch 0 train loss: 723774.2688059608\nINFO:root:0: Epoch 0 train loss: 371548.50839144486\nINFO:root:3: Epoch 0 train loss: 657850.6062841266\nINFO:root:1: Epoch 0 train loss: 294567.34631649655\nINFO:root:0: Epoch 0 validation loss: 1884750.1890146532\nINFO:root:2: Epoch 1 train loss: 14848.505806387713\nINFO:root:1: Epoch 1 train loss: 292802.9557537635\nINFO:root:3: Epoch 1 train loss: 605471.0118235853\nINFO:root:0: Epoch 1 train loss: 16520.698404905077\nINFO:root:0: Epoch 1 validation loss: 1883378.027836577\nINFO:root:0: Epoch 2 train loss: 969666.0920009613\nINFO:root:2: Epoch 2 train loss: 24253.57501411438\nINFO:root:1: Epoch 2 train loss: 2696659.2266257606\nINFO:root:3: Epoch 2 train loss: 669431.0716727575\nINFO:root:0: Epoch 2 validation loss: 1881955.2149028429\nINFO:root:3: Epoch 3 train loss: 308249.8679707845\nINFO:root:0: Epoch 3 train loss: 375132.02049541473\nINFO:root:1: Epoch 3 train loss: 460671.4585370024\nINFO:root:2: Epoch 3 train loss: 307387.04522037506\nINFO:root:0: Epoch 3 validation loss: 1881112.303681686\nINFO:root:0: Epoch 4 train loss: 58928.13672478994\nINFO:root:3: Epoch 4 train loss: 808266.3811991612\nINFO:root:1: Epoch 4 train loss: 385896.2310033242\nINFO:root:2: Epoch 4 train loss: 997845.177652359\nINFO:root:0: Epoch 4 validation loss: 1880414.4515622237\nINFO:root:3: Epoch 5 train loss: 376818.4489298463\nINFO:root:2: Epoch 5 train loss: 480361.4142665863\nINFO:root:1: Epoch 5 train loss: 147085.25273535648\nINFO:root:0: Epoch 5 train loss: 793529.0482546488\nINFO:root:0: Epoch 5 validation loss: 1879678.6789081837\n", "seconds": 10.739617109298706, "batch_size": 32, "nodes": 1, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.15,192.168.2.2,192.168.2.15,192.168.2.2,192.168.2.15,192.168.2.2 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "1 Start Epoch 0\n2 Start Epoch 0\n2: 12 batches\n1: 12 batches\n5 Start Epoch 0\n6 Start Epoch 0\n6: 12 batches\n0 Start Epoch 0\n0: 12 batches\n5: 12 batches\n7 Start Epoch 0\n7: 12 batches\n3 Start Epoch 0\n3: 12 batches\n4 Start Epoch 0\n4: 12 batches\n1 Start Epoch 1\n7 Start Epoch 1\n1: 12 batches\n7: 12 batches\n4 Start Epoch 1\n4: 12 batches\n2 Start Epoch 1\n6 Start Epoch 1\n2: 12 batches\n5 Start Epoch 1\n6: 12 batches\n5: 12 batches\n3 Start Epoch 1\n3: 12 batches\n0 Start Epoch 1\n0: 12 batches\n2 Start Epoch 2\n2: 12 batches\n3 Start Epoch 2\n3: 12 batches\n5 Start Epoch 2\n1 Start Epoch 2\n1: 12 batches\n6 Start Epoch 2\n6: 12 batches\n5: 12 batches\n7 Start Epoch 2\n7: 12 batches\n4 Start Epoch 2\n4: 12 batches\n0 Start Epoch 2\n0: 12 batches\n1 Start Epoch 3\n1: 12 batches\n5 Start Epoch 3\n7 Start Epoch 3\n6 Start Epoch 3\n5: 12 batches\n6: 12 batches\n7: 12 batches\n3 Start Epoch 3\n3: 12 batches\n4 Start Epoch 3\n4: 12 batches\n2 Start Epoch 3\n2: 12 batches\n0 Start Epoch 3\n0: 12 batches\n2 Start Epoch 4\n1 Start Epoch 4\n7 Start Epoch 4\n6 Start Epoch 4\n5 Start Epoch 4\n5: 12 batches\n6: 12 batches\n2: 12 batches\n1: 12 batches\n4 Start Epoch 4\n4: 12 batches\n7: 12 batches\n3 Start Epoch 4\n3: 12 batches\n0 Start Epoch 4\n0: 12 batches\n3 Start Epoch 5\n3: 12 batches\n5 Start Epoch 5\n7 Start Epoch 5\n7: 12 batches\n6 Start Epoch 5\n6: 12 batches\n5: 12 batches\n1 Start Epoch 5\n1: 12 batches\n4 Start Epoch 5\n4: 12 batches\n2 Start Epoch 5\n2: 12 batches\n0 Start Epoch 5\n0: 12 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 14436.32210858663\nINFO:root:1: Epoch 0 train loss: 235994.27613631883\nINFO:root:7: Epoch 0 train loss: 966280.890054067\nINFO:root:4: Epoch 0 train loss: 965031.3257802328\nINFO:root:2: Epoch 0 train loss: 817450.9322509766\nINFO:root:6: Epoch 0 train loss: 86733.59201661746\nINFO:root:5: Epoch 0 train loss: 1318400.5401509602\nINFO:root:3: Epoch 0 train loss: 30572.817535877228\nINFO:root:0: Epoch 0 validation loss: 291394.82456300367\nINFO:root:3: Epoch 1 train loss: 589918.9099028906\nINFO:root:2: Epoch 1 train loss: 1478636.8934516907\nINFO:root:5: Epoch 1 train loss: 1305007.7759755452\nINFO:root:1: Epoch 1 train loss: 1193542.1432348888\nINFO:root:0: Epoch 1 train loss: 1243497.0627288818\nINFO:root:7: Epoch 1 train loss: 27843.94646199544\nINFO:root:6: Epoch 1 train loss: 37359.22476696968\nINFO:root:4: Epoch 1 train loss: 1612467.681081136\nINFO:root:0: Epoch 1 validation loss: 291286.0112067903\nINFO:root:0: Epoch 2 train loss: 601063.3813680013\nINFO:root:1: Epoch 2 train loss: 573133.0006332397\nINFO:root:6: Epoch 2 train loss: 1375122.4400177002\nINFO:root:7: Epoch 2 train loss: 10739.899744669596\nINFO:root:5: Epoch 2 train loss: 744065.1644643148\nINFO:root:3: Epoch 2 train loss: 749756.1925239563\nINFO:root:4: Epoch 2 train loss: 17651.475541591644\nINFO:root:2: Epoch 2 train loss: 18379.46934191386\nINFO:root:0: Epoch 2 validation loss: 291058.67091337877\nINFO:root:1: Epoch 3 train loss: 2303300.2646636963\nINFO:root:2: Epoch 3 train loss: 742387.4821322759\nINFO:root:6: Epoch 3 train loss: 49284.46666208903\nINFO:root:5: Epoch 3 train loss: 783105.5198764801\nINFO:root:7: Epoch 3 train loss: 588670.9090623856\nINFO:root:4: Epoch 3 train loss: 1509335.4637088776\nINFO:root:0: Epoch 3 train loss: 2182417.6896572113\nINFO:root:3: Epoch 3 train loss: 46215.522667487465\nINFO:root:0: Epoch 3 validation loss: 290728.36703009444\nINFO:root:3: Epoch 4 train loss: 1923688.1271225612\nINFO:root:5: Epoch 4 train loss: 2229506.885588646\nINFO:root:7: Epoch 4 train loss: 254719.42893473306\nINFO:root:6: Epoch 4 train loss: 1342582.9816182454\nINFO:root:1: Epoch 4 train loss: 7201.643536170323\nINFO:root:0: Epoch 4 train loss: 1606980.2913570404\nINFO:root:4: Epoch 4 train loss: 105817.74265797932\nINFO:root:2: Epoch 4 train loss: 107680.53315226237\nINFO:root:0: Epoch 4 validation loss: 290414.32965473266\nINFO:root:1: Epoch 5 train loss: 704401.5486857096\nINFO:root:0: Epoch 5 train loss: 2389717.0490519204\nINFO:root:7: Epoch 5 train loss: 656988.2409184774\nINFO:root:3: Epoch 5 train loss: 51251.9603360494\nINFO:root:4: Epoch 5 train loss: 580332.9395119349\nINFO:root:5: Epoch 5 train loss: 758343.5414687792\nINFO:root:6: Epoch 5 train loss: 19762.423678080242\nINFO:root:2: Epoch 5 train loss: 816016.7762568792\nINFO:root:0: Epoch 5 validation loss: 290152.0446399744\n", "seconds": 8.142506837844849, "batch_size": 32, "nodes": 2, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.15,192.168.2.2,192.168.2.3 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 8 batches\n1 Start Epoch 0\n2 Start Epoch 0\n3 Start Epoch 0\n2: 8 batches\n11 Start Epoch 0\n7 Start Epoch 0\n11: 8 batches\n3: 8 batches\n4 Start Epoch 0\n8 Start Epoch 0\n4: 8 batches\n8: 8 batches\n1: 8 batches\n7: 8 batches\n6 Start Epoch 0\n5 Start Epoch 0\n6: 8 batches\n10 Start Epoch 0\n5: 8 batches\n9 Start Epoch 0\n9: 8 batches\n10: 8 batches\n1 Start Epoch 1\n1: 8 batches\n6 Start Epoch 1\n6: 8 batches\n8 Start Epoch 1\n9 Start Epoch 1\n11 Start Epoch 1\n8: 8 batches\n7 Start Epoch 1\n9: 8 batches\n7: 8 batches\n10 Start Epoch 1\n10: 8 batches\n11: 8 batches\n3 Start Epoch 1\n3: 8 batches\n2 Start Epoch 1\n2: 8 batches\n5 Start Epoch 1\n5: 8 batches\n4 Start Epoch 1\n4: 8 batches\n0 Start Epoch 1\n0: 8 batches\n3 Start Epoch 2\n3: 8 batches\n11 Start Epoch 2\n4 Start Epoch 2\n11: 8 batches\n5 Start Epoch 2\n5: 8 batches\n4: 8 batches\n6 Start Epoch 2\n6: 8 batches\n7 Start Epoch 2\n7: 8 batches\n9 Start Epoch 2\n10 Start Epoch 2\n10: 8 batches\n8 Start Epoch 2\n9: 8 batches\n8: 8 batches\n2 Start Epoch 2\n2: 8 batches\n1 Start Epoch 2\n1: 8 batches\n0 Start Epoch 2\n0: 8 batches\n11 Start Epoch 3\n11: 8 batches\n1 Start Epoch 3\n1: 8 batches\n8 Start Epoch 3\n9 Start Epoch 3\n2 Start Epoch 3\n2: 8 batches\n7 Start Epoch 3\n7: 8 batches\n5 Start Epoch 3\n3 Start Epoch 3\n3: 8 batches\n10 Start Epoch 3\n10: 8 batches\n9: 8 batches\n8: 8 batches\n5: 8 batches\n4 Start Epoch 3\n6 Start Epoch 3\n4: 8 batches\n6: 8 batches\n0 Start Epoch 3\n0: 8 batches\n8 Start Epoch 4\n9 Start Epoch 4\n8: 8 batches\n9: 8 batches\n5 Start Epoch 4\n7 Start Epoch 4\n4 Start Epoch 4\n5: 8 batches\n4: 8 batches\n6 Start Epoch 4\n6: 8 batches\n7: 8 batches\n3 Start Epoch 4\n3: 8 batches\n2 Start Epoch 4\n2: 8 batches\n10 Start Epoch 4\n10: 8 batches\n1 Start Epoch 4\n1: 8 batches\n11 Start Epoch 4\n11: 8 batches\n0 Start Epoch 4\n0: 8 batches\n1 Start Epoch 5\n5 Start Epoch 5\n4 Start Epoch 5\n4: 8 batches\n3 Start Epoch 5\n11 Start Epoch 5\n11: 8 batches\n10 Start Epoch 5\n9 Start Epoch 5\n10: 8 batches\n3: 8 batches\n1: 8 batches\n9: 8 batches\n2 Start Epoch 5\n8 Start Epoch 5\n2: 8 batches\n8: 8 batches\n5: 8 batches\n7 Start Epoch 5\n7: 8 batches\n6 Start Epoch 5\n6: 8 batches\n0 Start Epoch 5\n0: 8 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 134629.24121665955\nINFO:root:1: Epoch 0 train loss: 123032.48566627502\nINFO:root:6: Epoch 0 train loss: 1853526.4299926758\nINFO:root:9: Epoch 0 train loss: 869682.9563674927\nINFO:root:10: Epoch 0 train loss: 2756319.957572937\nINFO:root:11: Epoch 0 train loss: 12110.616047382355\nINFO:root:8: Epoch 0 train loss: 971013.211974144\nINFO:root:7: Epoch 0 train loss: 48907.816833496094\nINFO:root:3: Epoch 0 train loss: 986197.2641983032\nINFO:root:5: Epoch 0 train loss: 122713.71861934662\nINFO:root:2: Epoch 0 train loss: 830135.7233638763\nINFO:root:4: Epoch 0 train loss: 2067077.973537445\nINFO:root:0: Epoch 0 validation loss: 2089.7476158094205\nINFO:root:3: Epoch 1 train loss: 1826306.4568862915\nINFO:root:4: Epoch 1 train loss: 815593.9495816231\nINFO:root:11: Epoch 1 train loss: 11349.156319618225\nINFO:root:5: Epoch 1 train loss: 120088.96413421631\nINFO:root:0: Epoch 1 train loss: 4406.346529960632\nINFO:root:2: Epoch 1 train loss: 835964.7236785889\nINFO:root:6: Epoch 1 train loss: 10657.245901107788\nINFO:root:7: Epoch 1 train loss: 35915.176973342896\nINFO:root:8: Epoch 1 train loss: 992931.5746016502\nINFO:root:9: Epoch 1 train loss: 5451.248314380646\nINFO:root:10: Epoch 1 train loss: 1841928.892074585\nINFO:root:1: Epoch 1 train loss: 9076.10200881958\nINFO:root:0: Epoch 1 validation loss: 2083.80832817544\nINFO:root:11: Epoch 2 train loss: 1850458.1504325867\nINFO:root:1: Epoch 2 train loss: 1836576.557848215\nINFO:root:0: Epoch 2 train loss: 20154.5274810791\nINFO:root:10: Epoch 2 train loss: 46263.410789489746\nINFO:root:8: Epoch 2 train loss: 38435.85425758362\nINFO:root:9: Epoch 2 train loss: 2335994.3250427246\nINFO:root:2: Epoch 2 train loss: 31895.414253234863\nINFO:root:7: Epoch 2 train loss: 34857.54864501953\nINFO:root:3: Epoch 2 train loss: 879327.9658575058\nINFO:root:5: Epoch 2 train loss: 27491.61898803711\nINFO:root:4: Epoch 2 train loss: 23219.53134918213\nINFO:root:6: Epoch 2 train loss: 42618.60830593109\nINFO:root:0: Epoch 2 validation loss: 2075.767544199745\nINFO:root:8: Epoch 3 train loss: 980311.1069623232\nINFO:root:9: Epoch 3 train loss: 1400785.496887207\nINFO:root:7: Epoch 3 train loss: 891781.2702484131\nINFO:root:5: Epoch 3 train loss: 1904074.2291679382\nINFO:root:4: Epoch 3 train loss: 977499.8042068481\nINFO:root:6: Epoch 3 train loss: 37333.59994506836\nINFO:root:3: Epoch 3 train loss: 3092042.3726489544\nINFO:root:2: Epoch 3 train loss: 1208624.820175171\nINFO:root:10: Epoch 3 train loss: 6696.900115966797\nINFO:root:0: Epoch 3 train loss: 10823.46251487732\nINFO:root:1: Epoch 3 train loss: 993709.4332466125\nINFO:root:11: Epoch 3 train loss: 900235.2346687317\nINFO:root:0: Epoch 3 validation loss: 2064.613224433928\nINFO:root:0: Epoch 4 train loss: 843241.9753761292\nINFO:root:1: Epoch 4 train loss: 26645.40421485901\nINFO:root:5: Epoch 4 train loss: 1859565.6782245636\nINFO:root:4: Epoch 4 train loss: 13080.1911611557\nINFO:root:3: Epoch 4 train loss: 14358.316944122314\nINFO:root:9: Epoch 4 train loss: 29038.373413085938\nINFO:root:11: Epoch 4 train loss: 43478.701449394226\nINFO:root:10: Epoch 4 train loss: 1129016.2901916504\nINFO:root:2: Epoch 4 train loss: 19639.73648262024\nINFO:root:8: Epoch 4 train loss: 2820920.386689186\nINFO:root:7: Epoch 4 train loss: 133361.8774857521\nINFO:root:6: Epoch 4 train loss: 25304.602734565735\nINFO:root:0: Epoch 4 validation loss: 2047.4970302407085\nINFO:root:0: Epoch 5 train loss: 873910.1361732483\nINFO:root:1: Epoch 5 train loss: 8459.416611671448\nINFO:root:7: Epoch 5 train loss: 6387.674789428711\nINFO:root:4: Epoch 5 train loss: 1096970.7338638306\nINFO:root:8: Epoch 5 train loss: 1118083.3668059409\nINFO:root:10: Epoch 5 train loss: 1211231.5985336304\nINFO:root:2: Epoch 5 train loss: 23355.406463623047\nINFO:root:3: Epoch 5 train loss: 2044180.0025689602\nINFO:root:9: Epoch 5 train loss: 30651.085292816162\nINFO:root:11: Epoch 5 train loss: 1245080.4610042572\nINFO:root:6: Epoch 5 train loss: 32778.643463134766\nINFO:root:5: Epoch 5 train loss: 1551282.76521492\nINFO:root:0: Epoch 5 validation loss: 2023.8482052293316\n", "seconds": 6.859677076339722, "batch_size": 32, "nodes": 3, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 6 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 6 batches\n2: 6 batches\n8 Start Epoch 0\n11 Start Epoch 0\n4 Start Epoch 0\n4: 6 batches\n7 Start Epoch 0\n7: 6 batches\n15 Start Epoch 0\n15: 6 batches\n12 Start Epoch 0\n12: 6 batches\n13 Start Epoch 0\n5 Start Epoch 0\n8: 6 batches\n14 Start Epoch 0\n6 Start Epoch 0\n11: 6 batches\n14: 6 batches\n6: 6 batches\n13: 6 batches\n9 Start Epoch 0\n10 Start Epoch 0\n9: 6 batches\n5: 6 batches\n10: 6 batches\n3 Start Epoch 0\n3: 6 batches\n11 Start Epoch 1\n10 Start Epoch 1\n1 Start Epoch 1\n1: 6 batches\n10: 6 batches\n11: 6 batches\n4 Start Epoch 1\n6 Start Epoch 1\n4: 6 batches\n3 Start Epoch 1\n3: 6 batches\n12 Start Epoch 1\n12: 6 batches\n13 Start Epoch 1\n13: 6 batches\n15 Start Epoch 1\n15: 6 batches\n6: 6 batches\n5 Start Epoch 1\n7 Start Epoch 1\n7: 6 batches\n5: 6 batches\n14 Start Epoch 1\n14: 6 batches\n9 Start Epoch 1\n8 Start Epoch 1\n8: 6 batches\n9: 6 batches\n2 Start Epoch 1\n2: 6 batches\n0 Start Epoch 1\n0: 6 batches\n2 Start Epoch 2\n11 Start Epoch 2\n10 Start Epoch 2\n10: 6 batches\n2: 6 batches\n3 Start Epoch 2\n3: 6 batches\n1 Start Epoch 2\n1: 6 batches\n11: 6 batches\n12 Start Epoch 2\n12: 6 batches\n13 Start Epoch 2\n13: 6 batches\n14 Start Epoch 2\n14: 6 batches\n5 Start Epoch 2\n9 Start Epoch 2\n4 Start Epoch 2\n9: 6 batches\n15 Start Epoch 2\n7 Start Epoch 2\n7: 6 batches\n8 Start Epoch 2\n15: 6 batches\n8: 6 batches\n4: 6 batches\n6 Start Epoch 2\n6: 6 batches\n5: 6 batches\n0 Start Epoch 2\n0: 6 batches\n2 Start Epoch 3\n1 Start Epoch 3\n1: 6 batches\n3 Start Epoch 3\n7 Start Epoch 3\n7: 6 batches\n3: 6 batches\n9 Start Epoch 3\n8 Start Epoch 3\n10 Start Epoch 3\n10: 6 batches\n9: 6 batches\n13 Start Epoch 3\n13: 6 batches\n8: 6 batches\n12 Start Epoch 3\n12: 6 batches\n15 Start Epoch 3\n15: 6 batches\n5 Start Epoch 3\n14 Start Epoch 3\n5: 6 batches\n2: 6 batches\n14: 6 batches\n4 Start Epoch 3\n4: 6 batches\n6 Start Epoch 3\n6: 6 batches\n11 Start Epoch 3\n11: 6 batches\n0 Start Epoch 3\n0: 6 batches\n2 Start Epoch 4\n3 Start Epoch 4\n3: 6 batches\n2: 6 batches\n11 Start Epoch 4\n15 Start Epoch 4\n7 Start Epoch 4\n15: 6 batches\n6 Start Epoch 4\n12 Start Epoch 4\n6: 6 batches\n12: 6 batches\n5 Start Epoch 4\n5: 6 batches\n7: 6 batches\n4 Start Epoch 4\n1 Start Epoch 4\n1: 6 batches\n14 Start Epoch 4\n13 Start Epoch 4\n13: 6 batches\n14: 6 batches\n9 Start Epoch 4\n9: 6 batches\n10 Start Epoch 4\n10: 6 batches\n11: 6 batches\n8 Start Epoch 4\n8: 6 batches\n4: 6 batches\n0 Start Epoch 4\n0: 6 batches\n2 Start Epoch 5\n3 Start Epoch 5\n2: 6 batches\n11 Start Epoch 5\n10 Start Epoch 5\n10: 6 batches\n3: 6 batches\n5 Start Epoch 5\n5: 6 batches\n7 Start Epoch 5\n7: 6 batches\n15 Start Epoch 5\n15: 6 batches\n13 Start Epoch 5\n13: 6 batches\n14 Start Epoch 5\n12 Start Epoch 5\n12: 6 batches\n14: 6 batches\n11: 6 batches\n1 Start Epoch 5\n1: 6 batches\n8 Start Epoch 5\n9 Start Epoch 5\n8: 6 batches\n9: 6 batches\n6 Start Epoch 5\n6: 6 batches\n4 Start Epoch 5\n4: 6 batches\n0 Start Epoch 5\n0: 6 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:10: Epoch 0 train loss: 22922.949442545574\nINFO:root:0: Epoch 0 train loss: 1172421.4686787922\nINFO:root:1: Epoch 0 train loss: 1455142.6854248047\nINFO:root:11: Epoch 0 train loss: 1191771.36064593\nINFO:root:4: Epoch 0 train loss: 9523.54758199056\nINFO:root:6: Epoch 0 train loss: 51397.1093343099\nINFO:root:3: Epoch 0 train loss: 12217.212870279947\nINFO:root:12: Epoch 0 train loss: 122225.56412760417\nINFO:root:15: Epoch 0 train loss: 5837.055859883626\nINFO:root:13: Epoch 0 train loss: 1444350.8054072063\nINFO:root:5: Epoch 0 train loss: 16901.74415588379\nINFO:root:7: Epoch 0 train loss: 12218.378438313803\nINFO:root:14: Epoch 0 train loss: 10812.05730597178\nINFO:root:9: Epoch 0 train loss: 18652.527707417805\nINFO:root:8: Epoch 0 train loss: 29343.60626220703\nINFO:root:2: Epoch 0 train loss: 2767299.455851237\nINFO:root:0: Epoch 0 validation loss: 1738.3619637541424\nINFO:root:3: Epoch 1 train loss: 3027381.5540771484\nINFO:root:2: Epoch 1 train loss: 11864.456088383993\nINFO:root:11: Epoch 1 train loss: 1303568.914642334\nINFO:root:10: Epoch 1 train loss: 1981582.9481964111\nINFO:root:1: Epoch 1 train loss: 160135.09406288466\nINFO:root:13: Epoch 1 train loss: 25096.83297030131\nINFO:root:14: Epoch 1 train loss: 2479355.353205363\nINFO:root:12: Epoch 1 train loss: 5596.639439900716\nINFO:root:6: Epoch 1 train loss: 1186023.0442708333\nINFO:root:0: Epoch 1 train loss: 8356.770384470621\nINFO:root:5: Epoch 1 train loss: 7097.438303629558\nINFO:root:8: Epoch 1 train loss: 55557.913581848145\nINFO:root:7: Epoch 1 train loss: 154346.66626993814\nINFO:root:9: Epoch 1 train loss: 1347360.273217519\nINFO:root:4: Epoch 1 train loss: 466758.3687133789\nINFO:root:15: Epoch 1 train loss: 1383763.3587900798\nINFO:root:0: Epoch 1 validation loss: 1735.3645808413817\nINFO:root:2: Epoch 2 train loss: 1794684.343037923\nINFO:root:3: Epoch 2 train loss: 1097921.0528564453\nINFO:root:1: Epoch 2 train loss: 7195.0855712890625\nINFO:root:7: Epoch 2 train loss: 1344838.420984904\nINFO:root:9: Epoch 2 train loss: 1650052.0474650066\nINFO:root:10: Epoch 2 train loss: 68396.96907552083\nINFO:root:8: Epoch 2 train loss: 28649.86962890625\nINFO:root:15: Epoch 2 train loss: 1338981.145228068\nINFO:root:13: Epoch 2 train loss: 1746617.2092313766\nINFO:root:14: Epoch 2 train loss: 35969.304707845055\nINFO:root:12: Epoch 2 train loss: 3564834.994547526\nINFO:root:5: Epoch 2 train loss: 1634737.998433431\nINFO:root:4: Epoch 2 train loss: 18155.83999633789\nINFO:root:6: Epoch 2 train loss: 1172467.2633666992\nINFO:root:0: Epoch 2 train loss: 1491787.8291015625\nINFO:root:11: Epoch 2 train loss: 8847.47720336914\nINFO:root:0: Epoch 2 validation loss: 1731.9209863435606\nINFO:root:2: Epoch 3 train loss: 2901609.3922322593\nINFO:root:3: Epoch 3 train loss: 2661569.324441274\nINFO:root:6: Epoch 3 train loss: 2815720.9774881997\nINFO:root:12: Epoch 3 train loss: 17414.664326985676\nINFO:root:15: Epoch 3 train loss: 56805.28865559896\nINFO:root:7: Epoch 3 train loss: 1301844.633623759\nINFO:root:1: Epoch 3 train loss: 1335246.0133209229\nINFO:root:5: Epoch 3 train loss: 4706.977886199951\nINFO:root:4: Epoch 3 train loss: 3082807.9257354736\nINFO:root:0: Epoch 3 train loss: 4854.514366149902\nINFO:root:13: Epoch 3 train loss: 15162.053304036459\nINFO:root:14: Epoch 3 train loss: 453218.17987060547\nINFO:root:9: Epoch 3 train loss: 28962.053184191387\nINFO:root:11: Epoch 3 train loss: 17347.32476043701\nINFO:root:10: Epoch 3 train loss: 1196362.1738942463\nINFO:root:8: Epoch 3 train loss: 14428.730194091797\nINFO:root:0: Epoch 3 validation loss: 1727.6368514242872\nINFO:root:3: Epoch 4 train loss: 1530626.0241292317\nINFO:root:2: Epoch 4 train loss: 2882983.1539408364\nINFO:root:10: Epoch 4 train loss: 1499095.159016927\nINFO:root:11: Epoch 4 train loss: 8228.393847147623\nINFO:root:15: Epoch 4 train loss: 1820639.9224039714\nINFO:root:14: Epoch 4 train loss: 55391.849589029945\nINFO:root:7: Epoch 4 train loss: 58581.7633972168\nINFO:root:5: Epoch 4 train loss: 1421036.69233195\nINFO:root:13: Epoch 4 train loss: 49524.42142740885\nINFO:root:12: Epoch 4 train loss: 53600.682525634766\nINFO:root:1: Epoch 4 train loss: 14376.074747721354\nINFO:root:0: Epoch 4 train loss: 18607.684705734253\nINFO:root:9: Epoch 4 train loss: 45739.954010009766\nINFO:root:8: Epoch 4 train loss: 1463254.6041870117\nINFO:root:6: Epoch 4 train loss: 19113.859929402668\nINFO:root:4: Epoch 4 train loss: 1191984.3833821614\nINFO:root:0: Epoch 4 validation loss: 1721.3410737771412\nINFO:root:6: Epoch 5 train loss: 31049.720494588215\nINFO:root:7: Epoch 5 train loss: 1634094.752766927\nINFO:root:5: Epoch 5 train loss: 1610152.9804458618\nINFO:root:8: Epoch 5 train loss: 9295.13298034668\nINFO:root:9: Epoch 5 train loss: 1696653.69140625\nINFO:root:2: Epoch 5 train loss: 1472388.2346394856\nINFO:root:1: Epoch 5 train loss: 1455955.4976552327\nINFO:root:3: Epoch 5 train loss: 19597.830647786457\nINFO:root:10: Epoch 5 train loss: 56662.090662638344\nINFO:root:11: Epoch 5 train loss: 1166185.9677581787\nINFO:root:12: Epoch 5 train loss: 1615269.120279948\nINFO:root:4: Epoch 5 train loss: 31389.999959309895\nINFO:root:0: Epoch 5 train loss: 58431.030293782555\nINFO:root:13: Epoch 5 train loss: 172194.24134318033\nINFO:root:14: Epoch 5 train loss: 24179.84748808543\nINFO:root:15: Epoch 5 train loss: 1871409.4759114583\nINFO:root:0: Epoch 5 validation loss: 1711.8643412516162\n", "seconds": 6.080454111099243, "batch_size": 32, "nodes": 4, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 5 batches\n2 Start Epoch 0\n2: 5 batches\n12 Start Epoch 0\n19 Start Epoch 0\n12: 5 batches\n19: 5 batches\n15 Start Epoch 0\n15: 5 batches\n1 Start Epoch 0\n8 Start Epoch 0\n8: 5 batches\n1: 5 batches\n16 Start Epoch 0\n16: 5 batches\n11 Start Epoch 0\n11: 5 batches\n7 Start Epoch 0\n7: 5 batches\n13 Start Epoch 0\n3 Start Epoch 0\n3: 5 batches\n14 Start Epoch 0\n14: 5 batches\n4 Start Epoch 0\n13: 5 batches\n4: 5 batches\n9 Start Epoch 0\n10 Start Epoch 0\n9: 5 batches\n10: 5 batches\n5 Start Epoch 0\n6 Start Epoch 0\n17 Start Epoch 0\n5: 5 batches\n18 Start Epoch 0\n6: 5 batches\n17: 5 batches\n18: 5 batches\n15 Start Epoch 1\n15: 5 batches\n6 Start Epoch 1\n6: 5 batches\n7 Start Epoch 1\n7: 5 batches\n3 Start Epoch 1\n13 Start Epoch 1\n14 Start Epoch 1\n13: 5 batches\n14: 5 batches\n1 Start Epoch 1\n12 Start Epoch 1\n4 Start Epoch 1\n12: 5 batches\n16 Start Epoch 1\n4: 5 batches\n18 Start Epoch 1\n1: 5 batches\n3: 5 batches\n18: 5 batches\n16: 5 batches\n19 Start Epoch 1\n5 Start Epoch 1\n19: 5 batches\n5: 5 batches\n2 Start Epoch 1\n2: 5 batches\n17 Start Epoch 1\n17: 5 batches\n11 Start Epoch 1\n11: 5 batches\n10 Start Epoch 1\n10: 5 batches\n8 Start Epoch 1\n9 Start Epoch 1\n8: 5 batches\n9: 5 batches\n0 Start Epoch 1\n0: 5 batches\n7 Start Epoch 2\n7: 5 batches\n14 Start Epoch 2\n15 Start Epoch 2\n14: 5 batches\n3 Start Epoch 2\n3: 5 batches\n15: 5 batches\n1 Start Epoch 2\n1: 5 batches\n4 Start Epoch 2\n18 Start Epoch 2\n16 Start Epoch 2\n6 Start Epoch 2\n6: 5 batches\n17 Start Epoch 2\n5 Start Epoch 2\n17: 5 batches\n18: 5 batches\n4: 5 batches\n5: 5 batches\n19 Start Epoch 2\n19: 5 batches\n16: 5 batches\n2 Start Epoch 2\n2: 5 batches\n12 Start Epoch 2\n12: 5 batches\n13 Start Epoch 2\n13: 5 batches\n10 Start Epoch 2\n10: 5 batches\n8 Start Epoch 2\n8: 5 batches\n11 Start Epoch 2\n11: 5 batches\n9 Start Epoch 2\n9: 5 batches\n0 Start Epoch 2\n0: 5 batches\n15 Start Epoch 3\n15: 5 batches\n13 Start Epoch 3\n14 Start Epoch 3\n14: 5 batches\n10 Start Epoch 3\n10: 5 batches\n11 Start Epoch 3\n11: 5 batches\n16 Start Epoch 3\n16: 5 batches\n9 Start Epoch 3\n9: 5 batches\n13: 5 batches\n12 Start Epoch 3\n12: 5 batches\n7 Start Epoch 3\n6 Start Epoch 3\n6: 5 batches\n7: 5 batches\n17 Start Epoch 3\n17: 5 batches\n8 Start Epoch 3\n8: 5 batches\n5 Start Epoch 3\n3 Start Epoch 3\n3: 5 batches\n1 Start Epoch 3\n1: 5 batches\n5: 5 batches\n2 Start Epoch 3\n2: 5 batches\n4 Start Epoch 3\n4: 5 batches\n19 Start Epoch 3\n18 Start Epoch 3\n19: 5 batches\n18: 5 batches\n0 Start Epoch 3\n0: 5 batches\n10 Start Epoch 4\n10: 5 batches\n11 Start Epoch 4\n11: 5 batches\n13 Start Epoch 4\n12 Start Epoch 4\n12: 5 batches\n13: 5 batches\n9 Start Epoch 4\n9: 5 batches\n1 Start Epoch 4\n1: 5 batches\n19 Start Epoch 4\n19: 5 batches\n8 Start Epoch 4\n6 Start Epoch 4\n14 Start Epoch 4\n8: 5 batches\n7 Start Epoch 4\n15 Start Epoch 4\n7: 5 batches\n14: 5 batches\n15: 5 batches\n6: 5 batches\n16 Start Epoch 4\n16: 5 batches\n18 Start Epoch 4\n18: 5 batches\n4 Start Epoch 4\n5 Start Epoch 4\n4: 5 batches\n3 Start Epoch 4\n3: 5 batches\n5: 5 batches\n17 Start Epoch 4\n17: 5 batches\n2 Start Epoch 4\n2: 5 batches\n0 Start Epoch 4\n0: 5 batches\n3 Start Epoch 5\n3: 5 batches\n1 Start Epoch 5\n1: 5 batches\n19 Start Epoch 5\n5 Start Epoch 5\n15 Start Epoch 5\n4 Start Epoch 5\n14 Start Epoch 5\n16 Start Epoch 5\n15: 5 batches\n4: 5 batches\n5: 5 batches\n14: 5 batches\n9 Start Epoch 5\n11 Start Epoch 5\n10 Start Epoch 5\n9: 5 batches\n11: 5 batches\n8 Start Epoch 5\n8: 5 batches\n10: 5 batches\n16: 5 batches\n19: 5 batches\n7 Start Epoch 5\n7: 5 batches\n17 Start Epoch 5\n6 Start Epoch 5\n18 Start Epoch 5\n6: 5 batches\n17: 5 batches\n18: 5 batches\n2 Start Epoch 5\n2: 5 batches\n12 Start Epoch 5\n13 Start Epoch 5\n12: 5 batches\n13: 5 batches\n0 Start Epoch 5\n0: 5 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:15: Epoch 0 train loss: 5743.0898712158205\nINFO:root:0: Epoch 0 train loss: 4997110.080987548\nINFO:root:6: Epoch 0 train loss: 32366.950463867186\nINFO:root:7: Epoch 0 train loss: 1765762.5832092285\nINFO:root:3: Epoch 0 train loss: 1764657.0276855468\nINFO:root:14: Epoch 0 train loss: 67031.92153320313\nINFO:root:13: Epoch 0 train loss: 30058.595419311525\nINFO:root:1: Epoch 0 train loss: 1694885.1771484376\nINFO:root:18: Epoch 0 train loss: 6716.581043243408\nINFO:root:4: Epoch 0 train loss: 548248.9422470093\nINFO:root:12: Epoch 0 train loss: 37763.92530136109\nINFO:root:16: Epoch 0 train loss: 1397006.965963745\nINFO:root:19: Epoch 0 train loss: 45513.01875\nINFO:root:5: Epoch 0 train loss: 42458.675048828125\nINFO:root:2: Epoch 0 train loss: 28229.624161052703\nINFO:root:17: Epoch 0 train loss: 66013.35435791015\nINFO:root:10: Epoch 0 train loss: 68810.24558105468\nINFO:root:11: Epoch 0 train loss: 22950.163940429688\nINFO:root:9: Epoch 0 train loss: 1419228.5958007812\nINFO:root:8: Epoch 0 train loss: 23684.223748016357\nINFO:root:0: Epoch 0 validation loss: 530028.0938599834\nINFO:root:7: Epoch 1 train loss: 1775752.3675292968\nINFO:root:14: Epoch 1 train loss: 56158.7509765625\nINFO:root:15: Epoch 1 train loss: 16413.929132080077\nINFO:root:3: Epoch 1 train loss: 27130.371801757814\nINFO:root:0: Epoch 1 train loss: 3475140.7721191407\nINFO:root:1: Epoch 1 train loss: 561409.7931060791\nINFO:root:13: Epoch 1 train loss: 1618137.5072509765\nINFO:root:18: Epoch 1 train loss: 19615.81590576172\nINFO:root:4: Epoch 1 train loss: 61707.96918945313\nINFO:root:12: Epoch 1 train loss: 14733.701403808594\nINFO:root:16: Epoch 1 train loss: 1545583.2551223754\nINFO:root:5: Epoch 1 train loss: 186411.80483398438\nINFO:root:6: Epoch 1 train loss: 48002.6385673523\nINFO:root:17: Epoch 1 train loss: 29707.27589111328\nINFO:root:19: Epoch 1 train loss: 25314.82373046875\nINFO:root:2: Epoch 1 train loss: 42361.80916748047\nINFO:root:9: Epoch 1 train loss: 19127.168785095215\nINFO:root:11: Epoch 1 train loss: 4841.736785888672\nINFO:root:8: Epoch 1 train loss: 30699.466534423827\nINFO:root:10: Epoch 1 train loss: 91143.4997314453\nINFO:root:0: Epoch 1 validation loss: 529966.0916563128\nINFO:root:15: Epoch 2 train loss: 37226.01742553711\nINFO:root:12: Epoch 2 train loss: 2460883.542982197\nINFO:root:14: Epoch 2 train loss: 3984664.66640625\nINFO:root:13: Epoch 2 train loss: 11000.503131866455\nINFO:root:10: Epoch 2 train loss: 3046.3624267578125\nINFO:root:11: Epoch 2 train loss: 26203.425732421874\nINFO:root:16: Epoch 2 train loss: 16612.45379638672\nINFO:root:9: Epoch 2 train loss: 11505.59448852539\nINFO:root:7: Epoch 2 train loss: 23501.90108642578\nINFO:root:6: Epoch 2 train loss: 9881.776611328125\nINFO:root:17: Epoch 2 train loss: 2530441.8689941405\nINFO:root:8: Epoch 2 train loss: 11272.168908691407\nINFO:root:5: Epoch 2 train loss: 5574.96630859375\nINFO:root:3: Epoch 2 train loss: 1486527.4565429688\nINFO:root:1: Epoch 2 train loss: 2549042.586328125\nINFO:root:2: Epoch 2 train loss: 18668.894091796876\nINFO:root:4: Epoch 2 train loss: 1325303.2752456665\nINFO:root:0: Epoch 2 train loss: 35584.354296875\nINFO:root:18: Epoch 2 train loss: 11433.924653625489\nINFO:root:19: Epoch 2 train loss: 8712.417559814454\nINFO:root:0: Epoch 2 validation loss: 529886.6571489213\nINFO:root:10: Epoch 3 train loss: 31193.94208984375\nINFO:root:11: Epoch 3 train loss: 16397.664306640625\nINFO:root:13: Epoch 3 train loss: 28061.181646728517\nINFO:root:12: Epoch 3 train loss: 3068616.2116210936\nINFO:root:9: Epoch 3 train loss: 10700.051515197754\nINFO:root:0: Epoch 3 train loss: 46227.89853515625\nINFO:root:1: Epoch 3 train loss: 34639.20400390625\nINFO:root:6: Epoch 3 train loss: 51187.51460571289\nINFO:root:14: Epoch 3 train loss: 50935.1775390625\nINFO:root:8: Epoch 3 train loss: 21566.428982543945\nINFO:root:15: Epoch 3 train loss: 1936092.9907674312\nINFO:root:19: Epoch 3 train loss: 3124233.5984695433\nINFO:root:7: Epoch 3 train loss: 7746.243648529053\nINFO:root:16: Epoch 3 train loss: 24225.704919433592\nINFO:root:18: Epoch 3 train loss: 1574934.5677124024\nINFO:root:5: Epoch 3 train loss: 21429.71908569336\nINFO:root:4: Epoch 3 train loss: 30006.973486328126\nINFO:root:3: Epoch 3 train loss: 23961.328076171874\nINFO:root:17: Epoch 3 train loss: 12245.094689941407\nINFO:root:2: Epoch 3 train loss: 594421.0478820801\nINFO:root:0: Epoch 3 validation loss: 529781.1931947032\nINFO:root:3: Epoch 4 train loss: 1738252.449786377\nINFO:root:0: Epoch 4 train loss: 1388506.0353530883\nINFO:root:1: Epoch 4 train loss: 834109.2367675782\nINFO:root:14: Epoch 4 train loss: 36706.38857421875\nINFO:root:19: Epoch 4 train loss: 4381.04716796875\nINFO:root:4: Epoch 4 train loss: 1742201.8075927733\nINFO:root:5: Epoch 4 train loss: 194601.23419189453\nINFO:root:15: Epoch 4 train loss: 15206.353137207032\nINFO:root:8: Epoch 4 train loss: 43794.664642333984\nINFO:root:16: Epoch 4 train loss: 3927.8852813720705\nINFO:root:10: Epoch 4 train loss: 2538074.581955147\nINFO:root:9: Epoch 4 train loss: 1669224.484133625\nINFO:root:11: Epoch 4 train loss: 1746571.5411499024\nINFO:root:7: Epoch 4 train loss: 2337.5054931640625\nINFO:root:6: Epoch 4 train loss: 1315174.2739257812\nINFO:root:17: Epoch 4 train loss: 1661738.5596679687\nINFO:root:18: Epoch 4 train loss: 1391367.7622558593\nINFO:root:2: Epoch 4 train loss: 208799.281640625\nINFO:root:13: Epoch 4 train loss: 1928136.1488830566\nINFO:root:12: Epoch 4 train loss: 18613.81845703125\nINFO:root:0: Epoch 4 validation loss: 529639.2188776865\nINFO:root:9: Epoch 5 train loss: 1930457.32013855\nINFO:root:6: Epoch 5 train loss: 11847.877374267578\nINFO:root:7: Epoch 5 train loss: 34625.38802642822\nINFO:root:15: Epoch 5 train loss: 1301827.4147399901\nINFO:root:12: Epoch 5 train loss: 11145.84912109375\nINFO:root:18: Epoch 5 train loss: 11658.256521606445\nINFO:root:19: Epoch 5 train loss: 3010.270299530029\nINFO:root:3: Epoch 5 train loss: 11827.104388427735\nINFO:root:0: Epoch 5 train loss: 6694.7590057373045\nINFO:root:11: Epoch 5 train loss: 3225286.5978515623\nINFO:root:14: Epoch 5 train loss: 825095.1460632324\nINFO:root:16: Epoch 5 train loss: 23100.541052246095\nINFO:root:17: Epoch 5 train loss: 47152.98583984375\nINFO:root:4: Epoch 5 train loss: 2380.9591133117674\nINFO:root:10: Epoch 5 train loss: 551417.9421875\nINFO:root:5: Epoch 5 train loss: 1924874.320062256\nINFO:root:1: Epoch 5 train loss: 23162.123193359374\nINFO:root:2: Epoch 5 train loss: 1916404.501159668\nINFO:root:13: Epoch 5 train loss: 11074.745666503906\nINFO:root:8: Epoch 5 train loss: 12432.57021484375\nINFO:root:0: Epoch 5 validation loss: 529462.7169244171\n", "seconds": 6.704137086868286, "batch_size": 32, "nodes": 5, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "1 Start Epoch 0\n2 Start Epoch 0\n2: 4 batches\n1: 4 batches\n0 Start Epoch 0\n0: 4 batches\n23 Start Epoch 0\n23: 4 batches\n4 Start Epoch 0\n4: 4 batches\n8 Start Epoch 0\n16 Start Epoch 0\n8: 4 batches\n16: 4 batches\n15 Start Epoch 0\n15: 4 batches\n7 Start Epoch 0\n7: 4 batches\n3 Start Epoch 0\n3: 4 batches\n5 Start Epoch 0\n6 Start Epoch 0\n6: 4 batches\n5: 4 batches\n12 Start Epoch 0\n20 Start Epoch 0\n12: 4 batches\n11 Start Epoch 0\n20: 4 batches\n11: 4 batches\n10 Start Epoch 0\n17 Start Epoch 0\n10: 4 batches\n19 Start Epoch 0\n17: 4 batches\n18 Start Epoch 0\n19: 4 batches\n9 Start Epoch 0\n18: 4 batches\n9: 4 batches\n14 Start Epoch 0\n13 Start Epoch 0\n21 Start Epoch 0\n14: 4 batches\n13: 4 batches\n22 Start Epoch 0\n21: 4 batches\n22: 4 batches\n15 Start Epoch 1\n15: 4 batches\n11 Start Epoch 1\n11: 4 batches\n12 Start Epoch 1\n12: 4 batches\n17 Start Epoch 1\n16 Start Epoch 1\n16: 4 batches\n17: 4 batches\n14 Start Epoch 1\n14: 4 batches\n3 Start Epoch 1\n1 Start Epoch 1\n10 Start Epoch 1\n22 Start Epoch 1\n9 Start Epoch 1\n9: 4 batches\n4 Start Epoch 1\n6 Start Epoch 1\n10: 4 batches\n5 Start Epoch 1\n4: 4 batches\n5: 4 batches\n7 Start Epoch 1\n7: 4 batches\n6: 4 batches\n1: 4 batches\n3: 4 batches\n2 Start Epoch 1\n23 Start Epoch 1\n23: 4 batches\n22: 4 batches\n2: 4 batches\n8 Start Epoch 1\n8: 4 batches\n19 Start Epoch 1\n19: 4 batches\n18 Start Epoch 1\n18: 4 batches\n13 Start Epoch 1\n13: 4 batches\n20 Start Epoch 1\n20: 4 batches\n21 Start Epoch 1\n21: 4 batches\n0 Start Epoch 1\n0: 4 batches\n10 Start Epoch 2\n23 Start Epoch 2\n13 Start Epoch 2\n11 Start Epoch 2\n14 Start Epoch 2\n10: 4 batches\n23: 4 batches\n14: 4 batches\n11: 4 batches\n7 Start Epoch 2\n7: 4 batches\n2 Start Epoch 2\n2: 4 batches\n1 Start Epoch 2\n1: 4 batches\n13: 4 batches\n3 Start Epoch 2\n3: 4 batches\n15 Start Epoch 2\n15: 4 batches\n8 Start Epoch 2\n16 Start Epoch 2\n12 Start Epoch 2\n12: 4 batches\n17 Start Epoch 2\n17: 4 batches\n19 Start Epoch 2\n8: 4 batches\n9 Start Epoch 2\n9: 4 batches\n16: 4 batches\n19: 4 batches\n4 Start Epoch 2\n4: 4 batches\n5 Start Epoch 2\n5: 4 batches\n6 Start Epoch 2\n6: 4 batches\n22 Start Epoch 2\n21 Start Epoch 2\n21: 4 batches\n18 Start Epoch 2\n22: 4 batches\n18: 4 batches\n20 Start Epoch 2\n20: 4 batches\n0 Start Epoch 2\n0: 4 batches\n3 Start Epoch 3\n11 Start Epoch 3\n11: 4 batches\n3: 4 batches\n15 Start Epoch 3\n14 Start Epoch 3\n7 Start Epoch 3\n13 Start Epoch 3\n6 Start Epoch 3\n6: 4 batches\n15: 4 batches\n14: 4 batches\n13: 4 batches\n7: 4 batches\n23 Start Epoch 3\n23: 4 batches\n9 Start Epoch 3\n9: 4 batches\n2 Start Epoch 3\n2: 4 batches\n1 Start Epoch 3\n1: 4 batches\n12 Start Epoch 3\n10 Start Epoch 3\n22 Start Epoch 3\n4 Start Epoch 3\n22: 4 batches\n4: 4 batches\n12: 4 batches\n10: 4 batches\n19 Start Epoch 3\n17 Start Epoch 3\n21 Start Epoch 3\n21: 4 batches\n8 Start Epoch 3\n8: 4 batches\n18 Start Epoch 3\n20 Start Epoch 3\n20: 4 batches\n17: 4 batches\n18: 4 batches\n19: 4 batches\n5 Start Epoch 3\n5: 4 batches\n16 Start Epoch 3\n16: 4 batches\n0 Start Epoch 3\n0: 4 batches\n11 Start Epoch 4\n11: 4 batches\n14 Start Epoch 4\n12 Start Epoch 4\n7 Start Epoch 4\n12: 4 batches\n14: 4 batches\n15 Start Epoch 4\n7: 4 batches\n15: 4 batches\n6 Start Epoch 4\n8 Start Epoch 4\n6: 4 batches\n8: 4 batches\n5 Start Epoch 4\n17 Start Epoch 4\n17: 4 batches\n5: 4 batches\n13 Start Epoch 4\n13: 4 batches\n9 Start Epoch 4\n16 Start Epoch 4\n9: 4 batches\n1 Start Epoch 4\n3 Start Epoch 4\n3: 4 batches\n1: 4 batches\n4 Start Epoch 4\n4: 4 batches\n19 Start Epoch 4\n19: 4 batches\n18 Start Epoch 4\n16: 4 batches\n18: 4 batches\n23 Start Epoch 4\n23: 4 batches\n10 Start Epoch 4\n10: 4 batches\n22 Start Epoch 4\n22: 4 batches\n21 Start Epoch 4\n20 Start Epoch 4\n20: 4 batches\n21: 4 batches\n2 Start Epoch 4\n2: 4 batches\n0 Start Epoch 4\n0: 4 batches\n23 Start Epoch 5\n23: 4 batches\n19 Start Epoch 5\n19: 4 batches\n18 Start Epoch 5\n20 Start Epoch 5\n22 Start Epoch 5\n21 Start Epoch 5\n22: 4 batches\n21: 4 batches\n20: 4 batches\n18: 4 batches\n1 Start Epoch 5\n1: 4 batches\n3 Start Epoch 5\n2 Start Epoch 5\n2: 4 batches\n9 Start Epoch 5\n5 Start Epoch 5\n14 Start Epoch 5\n4 Start Epoch 5\n14: 4 batches\n4: 4 batches\n15 Start Epoch 5\n5: 4 batches\n15: 4 batches\n3: 4 batches\n9: 4 batches\n7 Start Epoch 5\n7: 4 batches\n11 Start Epoch 5\n8 Start Epoch 5\n11: 4 batches\n10 Start Epoch 5\n10: 4 batches\n8: 4 batches\n17 Start Epoch 5\n16 Start Epoch 5\n16: 4 batches\n17: 4 batches\n6 Start Epoch 5\n6: 4 batches\n12 Start Epoch 5\n12: 4 batches\n13 Start Epoch 5\n13: 4 batches\n0 Start Epoch 5\n0: 4 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:15: Epoch 0 train loss: 685206.9715957642\nINFO:root:11: Epoch 0 train loss: 2074055.4543762207\nINFO:root:12: Epoch 0 train loss: 10427.661987304688\nINFO:root:16: Epoch 0 train loss: 6436.176225662231\nINFO:root:17: Epoch 0 train loss: 22102.995880126953\nINFO:root:14: Epoch 0 train loss: 967.563982963562\nINFO:root:2: Epoch 0 train loss: 73424.7373046875\nINFO:root:3: Epoch 0 train loss: 21534.338989257812\nINFO:root:1: Epoch 0 train loss: 1950865.4932861328\nINFO:root:4: Epoch 0 train loss: 2117770.9159317017\nINFO:root:9: Epoch 0 train loss: 29850.37536239624\nINFO:root:23: Epoch 0 train loss: 19215.578674316406\nINFO:root:22: Epoch 0 train loss: 22625.883758544922\nINFO:root:6: Epoch 0 train loss: 13347.337524414062\nINFO:root:10: Epoch 0 train loss: 13912.435913085938\nINFO:root:5: Epoch 0 train loss: 1964023.3308258057\nINFO:root:7: Epoch 0 train loss: 17279.256591796875\nINFO:root:0: Epoch 0 train loss: 48347.842529296875\nINFO:root:8: Epoch 0 train loss: 3931822.5747070312\nINFO:root:18: Epoch 0 train loss: 2279977.3848876953\nINFO:root:19: Epoch 0 train loss: 2997.434558868408\nINFO:root:13: Epoch 0 train loss: 30057.9619140625\nINFO:root:20: Epoch 0 train loss: 2417063.7208251953\nINFO:root:21: Epoch 0 train loss: 247095.10668945312\nINFO:root:0: Epoch 0 validation loss: 160693.1961889486\nINFO:root:10: Epoch 1 train loss: 2382797.755859375\nINFO:root:2: Epoch 1 train loss: 2749881.2573547363\nINFO:root:13: Epoch 1 train loss: 681836.4580001831\nINFO:root:11: Epoch 1 train loss: 13157.720979690552\nINFO:root:14: Epoch 1 train loss: 2165433.034561157\nINFO:root:23: Epoch 1 train loss: 24233.903076171875\nINFO:root:4: Epoch 1 train loss: 31503.393928527832\nINFO:root:7: Epoch 1 train loss: 3779.0673217773438\nINFO:root:1: Epoch 1 train loss: 9334.639503479004\nINFO:root:3: Epoch 1 train loss: 80598.537109375\nINFO:root:15: Epoch 1 train loss: 2412516.9336395264\nINFO:root:16: Epoch 1 train loss: 295016.9119873047\nINFO:root:8: Epoch 1 train loss: 1334.5612869262695\nINFO:root:12: Epoch 1 train loss: 33175.460525512695\nINFO:root:0: Epoch 1 train loss: 11288.714736938477\nINFO:root:17: Epoch 1 train loss: 2739390.040664673\nINFO:root:19: Epoch 1 train loss: 10226.28109741211\nINFO:root:9: Epoch 1 train loss: 1930170.7604370117\nINFO:root:5: Epoch 1 train loss: 245819.89232635498\nINFO:root:6: Epoch 1 train loss: 5804.371780395508\nINFO:root:22: Epoch 1 train loss: 53518.218505859375\nINFO:root:21: Epoch 1 train loss: 28690.41307067871\nINFO:root:18: Epoch 1 train loss: 50977.459129333496\nINFO:root:20: Epoch 1 train loss: 20731.254943847656\nINFO:root:0: Epoch 1 validation loss: 160671.49572025705\nINFO:root:3: Epoch 2 train loss: 3634.9255981445312\nINFO:root:11: Epoch 2 train loss: 3095.798231124878\nINFO:root:14: Epoch 2 train loss: 9166.785919189453\nINFO:root:15: Epoch 2 train loss: 10186.14714050293\nINFO:root:13: Epoch 2 train loss: 2079129.3116149902\nINFO:root:7: Epoch 2 train loss: 2284860.8671875\nINFO:root:6: Epoch 2 train loss: 1976735.1986083984\nINFO:root:23: Epoch 2 train loss: 2000472.0335578918\nINFO:root:9: Epoch 2 train loss: 16722.04473876953\nINFO:root:22: Epoch 2 train loss: 1186.1431922912598\nINFO:root:1: Epoch 2 train loss: 11091.088912963867\nINFO:root:0: Epoch 2 train loss: 24886.486778259277\nINFO:root:2: Epoch 2 train loss: 2072646.0418291092\nINFO:root:12: Epoch 2 train loss: 4537.611610412598\nINFO:root:10: Epoch 2 train loss: 4090.5152781009674\nINFO:root:18: Epoch 2 train loss: 2289641.8444519043\nINFO:root:21: Epoch 2 train loss: 11988.573753356934\nINFO:root:4: Epoch 2 train loss: 28466.337737083435\nINFO:root:17: Epoch 2 train loss: 1627538.4973134995\nINFO:root:19: Epoch 2 train loss: 37934.46365356445\nINFO:root:8: Epoch 2 train loss: 78295.94677734375\nINFO:root:20: Epoch 2 train loss: 21134.36767578125\nINFO:root:5: Epoch 2 train loss: 7462.514129638672\nINFO:root:16: Epoch 2 train loss: 270156.2099609375\nINFO:root:0: Epoch 2 validation loss: 160649.410754724\nINFO:root:11: Epoch 3 train loss: 16787.166046142578\nINFO:root:14: Epoch 3 train loss: 16871.86496734619\nINFO:root:15: Epoch 3 train loss: 87751.97555541992\nINFO:root:12: Epoch 3 train loss: 1723070.9817228913\nINFO:root:7: Epoch 3 train loss: 15131.483505249023\nINFO:root:6: Epoch 3 train loss: 11604.396369934082\nINFO:root:8: Epoch 3 train loss: 3438.0601959228516\nINFO:root:5: Epoch 3 train loss: 44750.857204437256\nINFO:root:17: Epoch 3 train loss: 2196343.702671051\nINFO:root:13: Epoch 3 train loss: 30525.165950775146\nINFO:root:16: Epoch 3 train loss: 1724976.0478839874\nINFO:root:9: Epoch 3 train loss: 24807.60858154297\nINFO:root:1: Epoch 3 train loss: 4161.4910888671875\nINFO:root:0: Epoch 3 train loss: 2041913.80859375\nINFO:root:3: Epoch 3 train loss: 2098168.076171875\nINFO:root:4: Epoch 3 train loss: 2229820.768661499\nINFO:root:18: Epoch 3 train loss: 9426.2177028656\nINFO:root:19: Epoch 3 train loss: 2401770.112121582\nINFO:root:23: Epoch 3 train loss: 6031.199073791504\nINFO:root:10: Epoch 3 train loss: 17492.021224975586\nINFO:root:22: Epoch 3 train loss: 10503.499996185303\nINFO:root:21: Epoch 3 train loss: 18547.302528381348\nINFO:root:20: Epoch 3 train loss: 17147.04071044922\nINFO:root:2: Epoch 3 train loss: 12276.004783630371\nINFO:root:0: Epoch 3 validation loss: 160625.83842126717\nINFO:root:23: Epoch 4 train loss: 225761.7299194336\nINFO:root:19: Epoch 4 train loss: 25491.66731262207\nINFO:root:18: Epoch 4 train loss: 10192.255004882812\nINFO:root:22: Epoch 4 train loss: 10540.193176269531\nINFO:root:21: Epoch 4 train loss: 62981.606689453125\nINFO:root:20: Epoch 4 train loss: 2845442.5488796234\nINFO:root:0: Epoch 4 train loss: 2073453.5131225586\nINFO:root:1: Epoch 4 train loss: 709024.7469482422\nINFO:root:3: Epoch 4 train loss: 19822.750945568085\nINFO:root:2: Epoch 4 train loss: 2231644.894130707\nINFO:root:5: Epoch 4 train loss: 2411456.8505706787\nINFO:root:14: Epoch 4 train loss: 13108.52079963684\nINFO:root:9: Epoch 4 train loss: 3928.5833129882812\nINFO:root:4: Epoch 4 train loss: 29704.8983001709\nINFO:root:15: Epoch 4 train loss: 1952907.7521705627\nINFO:root:7: Epoch 4 train loss: 4222.098693847656\nINFO:root:8: Epoch 4 train loss: 265024.5064086914\nINFO:root:10: Epoch 4 train loss: 33061.97053527832\nINFO:root:11: Epoch 4 train loss: 2091646.5961914062\nINFO:root:17: Epoch 4 train loss: 6406.412704467773\nINFO:root:16: Epoch 4 train loss: 2079920.5637664795\nINFO:root:6: Epoch 4 train loss: 14399.72769165039\nINFO:root:12: Epoch 4 train loss: 28106.353515625\nINFO:root:13: Epoch 4 train loss: 2010318.759613037\nINFO:root:0: Epoch 4 validation loss: 160598.61800607963\nINFO:root:0: Epoch 5 train loss: 235763.45510101318\nINFO:root:7: Epoch 5 train loss: 3053.874008178711\nINFO:root:15: Epoch 5 train loss: 9026.101776123047\nINFO:root:2: Epoch 5 train loss: 31066.6533203125\nINFO:root:3: Epoch 5 train loss: 7367.361892700195\nINFO:root:4: Epoch 5 train loss: 17109.28662109375\nINFO:root:16: Epoch 5 train loss: 2292168.4968566895\nINFO:root:17: Epoch 5 train loss: 24165.31640625\nINFO:root:11: Epoch 5 train loss: 25201.60108947754\nINFO:root:23: Epoch 5 train loss: 19308.688995361328\nINFO:root:6: Epoch 5 train loss: 27586.085083007812\nINFO:root:18: Epoch 5 train loss: 24475.400390625\nINFO:root:12: Epoch 5 train loss: 8736.986083984375\nINFO:root:19: Epoch 5 train loss: 273382.64587402344\nINFO:root:13: Epoch 5 train loss: 244085.58477783203\nINFO:root:14: Epoch 5 train loss: 2000806.726387024\nINFO:root:5: Epoch 5 train loss: 60260.857421875\nINFO:root:22: Epoch 5 train loss: 40252.55603027344\nINFO:root:9: Epoch 5 train loss: 3203.9115142822266\nINFO:root:21: Epoch 5 train loss: 44612.326263427734\nINFO:root:8: Epoch 5 train loss: 2078699.5858459473\nINFO:root:10: Epoch 5 train loss: 6885.554107666016\nINFO:root:20: Epoch 5 train loss: 51726.0439453125\nINFO:root:1: Epoch 5 train loss: 2251.1701831817627\nINFO:root:0: Epoch 5 validation loss: 160566.49255981296\n", "seconds": 7.600332021713257, "batch_size": 32, "nodes": 6, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 4 batches\n2 Start Epoch 0\n1 Start Epoch 0\n2: 4 batches\n1: 4 batches\n27 Start Epoch 0\n27: 4 batches\n5 Start Epoch 0\n6 Start Epoch 0\n6: 4 batches\n5: 4 batches\n3 Start Epoch 0\n3: 4 batches\n4 Start Epoch 0\n4: 4 batches\n11 Start Epoch 0\n11: 4 batches\n8 Start Epoch 0\n8: 4 batches\n7 Start Epoch 0\n24 Start Epoch 0\n16 Start Epoch 0\n24: 4 batches\n7: 4 batches\n19 Start Epoch 0\n19: 4 batches\n13 Start Epoch 0\n13: 4 batches\n16: 4 batches\n14 Start Epoch 0\n14: 4 batches\n15 Start Epoch 0\n15: 4 batches\n12 Start Epoch 0\n12: 4 batches\n20 Start Epoch 0\n20: 4 batches\n23 Start Epoch 0\n23: 4 batches\n21 Start Epoch 0\n22 Start Epoch 0\n21: 4 batches\n22: 4 batches\n9 Start Epoch 0\n10 Start Epoch 0\n10: 4 batches\n9: 4 batches\n18 Start Epoch 0\n17 Start Epoch 0\n18: 4 batches\n17: 4 batches\n25 Start Epoch 0\n26 Start Epoch 0\n26: 4 batches\n25: 4 batches\n24 Start Epoch 1\n27 Start Epoch 1\n24: 4 batches\n23 Start Epoch 1\n23: 4 batches\n11 Start Epoch 1\n11: 4 batches\n27: 4 batches\n1 Start Epoch 1\n1: 4 batches\n25 Start Epoch 1\n9 Start Epoch 1\n9: 4 batches\n7 Start Epoch 1\n7: 4 batches\n25: 4 batches\n21 Start Epoch 1\n21: 4 batches\n17 Start Epoch 1\n22 Start Epoch 1\n17: 4 batches\n16 Start Epoch 1\n22: 4 batches\n16: 4 batches\n26 Start Epoch 1\n26: 4 batches\n3 Start Epoch 1\n3: 4 batches\n15 Start Epoch 1\n14 Start Epoch 1\n5 Start Epoch 1\n5: 4 batches\n15: 4 batches\n14: 4 batches\n13 Start Epoch 1\n13: 4 batches\n6 Start Epoch 1\n6: 4 batches\n8 Start Epoch 1\n8: 4 batches\n4 Start Epoch 1\n4: 4 batches\n12 Start Epoch 1\n12: 4 batches\n20 Start Epoch 1\n20: 4 batches\n10 Start Epoch 1\n10: 4 batches\n18 Start Epoch 1\n19 Start Epoch 1\n18: 4 batches\n19: 4 batches\n2 Start Epoch 1\n2: 4 batches\n0 Start Epoch 1\n0: 4 batches\n23 Start Epoch 2\n23: 4 batches\n11 Start Epoch 2\n9 Start Epoch 2\n9: 4 batches\n7 Start Epoch 2\n11: 4 batches\n4 Start Epoch 2\n5 Start Epoch 2\n5: 4 batches\n7: 4 batches\n8 Start Epoch 2\n8: 4 batches\n16 Start Epoch 2\n17 Start Epoch 2\n16: 4 batches\n3 Start Epoch 2\n17: 4 batches\n25 Start Epoch 2\n25: 4 batches\n24 Start Epoch 2\n24: 4 batches\n4: 4 batches\n26 Start Epoch 2\n27 Start Epoch 2\n26: 4 batches\n13 Start Epoch 2\n13: 4 batches\n12 Start Epoch 2\n12: 4 batches\n14 Start Epoch 2\n14: 4 batches\n27: 4 batches\n15 Start Epoch 2\n15: 4 batches\n22 Start Epoch 2\n22: 4 batches\n6 Start Epoch 2\n6: 4 batches\n2 Start Epoch 2\n2: 4 batches\n3: 4 batches\n10 Start Epoch 2\n10: 4 batches\n1 Start Epoch 2\n1: 4 batches\n21 Start Epoch 2\n21: 4 batches\n19 Start Epoch 2\n19: 4 batches\n18 Start Epoch 2\n20 Start Epoch 2\n20: 4 batches\n18: 4 batches\n0 Start Epoch 2\n0: 4 batches\n23 Start Epoch 3\n23: 4 batches\n15 Start Epoch 3\n15: 4 batches\n22 Start Epoch 3\n21 Start Epoch 3\n22: 4 batches\n21: 4 batches\n6 Start Epoch 3\n6: 4 batches\n10 Start Epoch 3\n9 Start Epoch 3\n17 Start Epoch 3\n7 Start Epoch 3\n7: 4 batches\n12 Start Epoch 3\n12: 4 batches\n9: 4 batches\n13 Start Epoch 3\n10: 4 batches\n13: 4 batches\n8 Start Epoch 3\n8: 4 batches\n27 Start Epoch 3\n25 Start Epoch 3\n14 Start Epoch 3\n11 Start Epoch 3\n27: 4 batches\n14: 4 batches\n26 Start Epoch 3\n11: 4 batches\n26: 4 batches\n2 Start Epoch 3\n2: 4 batches\n3 Start Epoch 3\n3: 4 batches\n1 Start Epoch 3\n1: 4 batches\n5 Start Epoch 3\n5: 4 batches\n4 Start Epoch 3\n4: 4 batches\n18 Start Epoch 3\n18: 4 batches\n24 Start Epoch 3\n20 Start Epoch 3\n25: 4 batches\n20: 4 batches\n17: 4 batches\n19 Start Epoch 3\n19: 4 batches\n16 Start Epoch 3\n16: 4 batches\n24: 4 batches\n0 Start Epoch 3\n0: 4 batches\n27 Start Epoch 4\n27: 4 batches\n22 Start Epoch 4\n23 Start Epoch 4\n22: 4 batches\n23: 4 batches\n14 Start Epoch 4\n7 Start Epoch 4\n14: 4 batches\n4 Start Epoch 4\n15 Start Epoch 4\n7: 4 batches\n15: 4 batches\n12 Start Epoch 4\n12: 4 batches\n8 Start Epoch 4\n6 Start Epoch 4\n25 Start Epoch 4\n20 Start Epoch 4\n5 Start Epoch 4\n25: 4 batches\n20: 4 batches\n26 Start Epoch 4\n16 Start Epoch 4\n21 Start Epoch 4\n11 Start Epoch 4\n11: 4 batches\n6: 4 batches\n17 Start Epoch 4\n26: 4 batches\n5: 4 batches\n16: 4 batches\n21: 4 batches\n8: 4 batches\n17: 4 batches\n24 Start Epoch 4\n24: 4 batches\n19 Start Epoch 4\n19: 4 batches\n13 Start Epoch 4\n13: 4 batches\n9 Start Epoch 4\n9: 4 batches\n3 Start Epoch 4\n3: 4 batches\n1 Start Epoch 4\n1: 4 batches\n2 Start Epoch 4\n2: 4 batches\n18 Start Epoch 4\n18: 4 batches\n4: 4 batches\n10 Start Epoch 4\n10: 4 batches\n0 Start Epoch 4\n0: 4 batches\n27 Start Epoch 5\n3 Start Epoch 5\n3: 4 batches\n2 Start Epoch 5\n2: 4 batches\n5 Start Epoch 5\n27: 4 batches\n9 Start Epoch 5\n8 Start Epoch 5\n23 Start Epoch 5\n9: 4 batches\n22 Start Epoch 5\n22: 4 batches\n23: 4 batches\n7 Start Epoch 5\n8: 4 batches\n6 Start Epoch 5\n6: 4 batches\n7: 4 batches\n5: 4 batches\n19 Start Epoch 5\n19: 4 batches\n16 Start Epoch 5\n16: 4 batches\n14 Start Epoch 5\n15 Start Epoch 5\n15: 4 batches\n24 Start Epoch 5\n14: 4 batches\n10 Start Epoch 5\n12 Start Epoch 5\n20 Start Epoch 5\n10: 4 batches\n24: 4 batches\n20: 4 batches\n11 Start Epoch 5\n21 Start Epoch 5\n11: 4 batches\n12: 4 batches\n21: 4 batches\n1 Start Epoch 5\n1: 4 batches\n18 Start Epoch 5\n18: 4 batches\n13 Start Epoch 5\n13: 4 batches\n26 Start Epoch 5\n17 Start Epoch 5\n17: 4 batches\n25 Start Epoch 5\n25: 4 batches\n4 Start Epoch 5\n4: 4 batches\n26: 4 batches\n0 Start Epoch 5\n0: 4 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:27: Epoch 0 train loss: 26727.848571777344\nINFO:root:24: Epoch 0 train loss: 1739300.3934402466\nINFO:root:23: Epoch 0 train loss: 722382.9781188965\nINFO:root:11: Epoch 0 train loss: 29104.829986572266\nINFO:root:22: Epoch 0 train loss: 1353.435474395752\nINFO:root:9: Epoch 0 train loss: 17121.868408203125\nINFO:root:1: Epoch 0 train loss: 25033.884452819824\nINFO:root:25: Epoch 0 train loss: 10446.253122508526\nINFO:root:0: Epoch 0 train loss: 680311.2474460602\nINFO:root:21: Epoch 0 train loss: 60911.48263549805\nINFO:root:7: Epoch 0 train loss: 2066179.2840185165\nINFO:root:16: Epoch 0 train loss: 5533585.147949219\nINFO:root:17: Epoch 0 train loss: 26216.564910888672\nINFO:root:26: Epoch 0 train loss: 18893.146804332733\nINFO:root:3: Epoch 0 train loss: 4010.626045227051\nINFO:root:13: Epoch 0 train loss: 1735977.71875\nINFO:root:15: Epoch 0 train loss: 2909.1535148620605\nINFO:root:14: Epoch 0 train loss: 595.0538139343262\nINFO:root:4: Epoch 0 train loss: 52575.9365272522\nINFO:root:6: Epoch 0 train loss: 56510.54211425781\nINFO:root:5: Epoch 0 train loss: 47586.09226226807\nINFO:root:8: Epoch 0 train loss: 12344.01921081543\nINFO:root:12: Epoch 0 train loss: 3526.4248657226562\nINFO:root:10: Epoch 0 train loss: 1737017.3798866272\nINFO:root:20: Epoch 0 train loss: 14738.300181388855\nINFO:root:19: Epoch 0 train loss: 4332907.867858887\nINFO:root:18: Epoch 0 train loss: 3454.7420806884766\nINFO:root:2: Epoch 0 train loss: 43942.596771240234\nINFO:root:0: Epoch 0 validation loss: 1009008.9420431143\nINFO:root:23: Epoch 1 train loss: 6729.538665771484\nINFO:root:11: Epoch 1 train loss: 1738810.742477417\nINFO:root:9: Epoch 1 train loss: 5695.951416015625\nINFO:root:4: Epoch 1 train loss: 5597.584831237793\nINFO:root:5: Epoch 1 train loss: 23190.042866528034\nINFO:root:7: Epoch 1 train loss: 3451.655776977539\nINFO:root:8: Epoch 1 train loss: 2342.1982707977295\nINFO:root:16: Epoch 1 train loss: 444.7830505371094\nINFO:root:17: Epoch 1 train loss: 5546.333473801613\nINFO:root:3: Epoch 1 train loss: 36060.3077583909\nINFO:root:25: Epoch 1 train loss: 2166659.2297799885\nINFO:root:22: Epoch 1 train loss: 1935888.139099121\nINFO:root:24: Epoch 1 train loss: 3897.216339111328\nINFO:root:26: Epoch 1 train loss: 18560.675491333008\nINFO:root:27: Epoch 1 train loss: 230893.3271999359\nINFO:root:12: Epoch 1 train loss: 2082033.434020996\nINFO:root:13: Epoch 1 train loss: 2075397.2435913086\nINFO:root:14: Epoch 1 train loss: 20640.66683959961\nINFO:root:15: Epoch 1 train loss: 30023.064208984375\nINFO:root:6: Epoch 1 train loss: 150406.35961914062\nINFO:root:0: Epoch 1 train loss: 15845.398712158203\nINFO:root:2: Epoch 1 train loss: 73849.9467163086\nINFO:root:10: Epoch 1 train loss: 18172.519439697266\nINFO:root:1: Epoch 1 train loss: 1957684.9429793358\nINFO:root:21: Epoch 1 train loss: 18491.146545410156\nINFO:root:18: Epoch 1 train loss: 39630.071882247925\nINFO:root:19: Epoch 1 train loss: 93173.2836945504\nINFO:root:20: Epoch 1 train loss: 2402954.5622558594\nINFO:root:0: Epoch 1 validation loss: 1008974.5889303621\nINFO:root:23: Epoch 2 train loss: 6912.008923172951\nINFO:root:15: Epoch 2 train loss: 6598.750009536743\nINFO:root:21: Epoch 2 train loss: 2555.3303451538086\nINFO:root:22: Epoch 2 train loss: 19302.607440948486\nINFO:root:6: Epoch 2 train loss: 4725.513877868652\nINFO:root:7: Epoch 2 train loss: 221350.16258239746\nINFO:root:9: Epoch 2 train loss: 8643.345107078552\nINFO:root:10: Epoch 2 train loss: 2028480.5830078125\nINFO:root:12: Epoch 2 train loss: 29081.468710899353\nINFO:root:26: Epoch 2 train loss: 6191.904457092285\nINFO:root:13: Epoch 2 train loss: 231759.4889945984\nINFO:root:25: Epoch 2 train loss: 88684.98603343964\nINFO:root:27: Epoch 2 train loss: 8170.094146728516\nINFO:root:8: Epoch 2 train loss: 9124.04818725586\nINFO:root:14: Epoch 2 train loss: 11018.38483428955\nINFO:root:11: Epoch 2 train loss: 1953.974838256836\nINFO:root:3: Epoch 2 train loss: 5415.265898704529\nINFO:root:0: Epoch 2 train loss: 14800.948181152344\nINFO:root:2: Epoch 2 train loss: 41364.60876464844\nINFO:root:1: Epoch 2 train loss: 4218.449325799942\nINFO:root:20: Epoch 2 train loss: 12430.080713510513\nINFO:root:18: Epoch 2 train loss: 16643.170629501343\nINFO:root:24: Epoch 2 train loss: 14365.955078125\nINFO:root:4: Epoch 2 train loss: 49511.830627441406\nINFO:root:17: Epoch 2 train loss: 7643.305178642273\nINFO:root:5: Epoch 2 train loss: 8304.59652709961\nINFO:root:16: Epoch 2 train loss: 15954.929100036621\nINFO:root:19: Epoch 2 train loss: 42445.36926269531\nINFO:root:0: Epoch 2 validation loss: 1008936.0932847088\nINFO:root:27: Epoch 3 train loss: 37919.073427557945\nINFO:root:22: Epoch 3 train loss: 8795076.91286087\nINFO:root:23: Epoch 3 train loss: 20931.72487640381\nINFO:root:14: Epoch 3 train loss: 53868.92758178711\nINFO:root:15: Epoch 3 train loss: 226800.60128974915\nINFO:root:7: Epoch 3 train loss: 39350.98367357254\nINFO:root:4: Epoch 3 train loss: 17952.057331085205\nINFO:root:12: Epoch 3 train loss: 7171.883819580078\nINFO:root:8: Epoch 3 train loss: 5923.420585632324\nINFO:root:11: Epoch 3 train loss: 9797.270341873169\nINFO:root:25: Epoch 3 train loss: 29204.25497817993\nINFO:root:6: Epoch 3 train loss: 2185999.016456604\nINFO:root:26: Epoch 3 train loss: 2408584.8666992188\nINFO:root:20: Epoch 3 train loss: 31615.558990478516\nINFO:root:17: Epoch 3 train loss: 73082.54643249512\nINFO:root:16: Epoch 3 train loss: 4233.748424530029\nINFO:root:21: Epoch 3 train loss: 14326.562742710114\nINFO:root:5: Epoch 3 train loss: 3569.667971611023\nINFO:root:24: Epoch 3 train loss: 10871.562845468521\nINFO:root:13: Epoch 3 train loss: 2411809.8001098633\nINFO:root:9: Epoch 3 train loss: 14772.414825439453\nINFO:root:1: Epoch 3 train loss: 31400.98065185547\nINFO:root:0: Epoch 3 train loss: 78904.55661869049\nINFO:root:2: Epoch 3 train loss: 690.455982208252\nINFO:root:3: Epoch 3 train loss: 12371.643411636353\nINFO:root:19: Epoch 3 train loss: 17097.927520751953\nINFO:root:18: Epoch 3 train loss: 45241.01193904877\nINFO:root:10: Epoch 3 train loss: 21954.299194335938\nINFO:root:0: Epoch 3 validation loss: 1008892.5722751525\nINFO:root:27: Epoch 4 train loss: 60164.70923805237\nINFO:root:3: Epoch 4 train loss: 6519.909828186035\nINFO:root:2: Epoch 4 train loss: 263496.8723144531\nINFO:root:0: Epoch 4 train loss: 1154.3502464294434\nINFO:root:5: Epoch 4 train loss: 6089.554076194763\nINFO:root:9: Epoch 4 train loss: 12017.563415527344\nINFO:root:8: Epoch 4 train loss: 88336.4994506836\nINFO:root:23: Epoch 4 train loss: 3346875.446762085\nINFO:root:22: Epoch 4 train loss: 702796.1896362305\nINFO:root:6: Epoch 4 train loss: 13754.031162261963\nINFO:root:7: Epoch 4 train loss: 2014064.4461517334\nINFO:root:19: Epoch 4 train loss: 1631196.5260314941\nINFO:root:16: Epoch 4 train loss: 13333.131759643555\nINFO:root:15: Epoch 4 train loss: 1869.4869995117188\nINFO:root:14: Epoch 4 train loss: 181754.72680664062\nINFO:root:1: Epoch 4 train loss: 1743505.0248947144\nINFO:root:11: Epoch 4 train loss: 10887.757490158081\nINFO:root:24: Epoch 4 train loss: 4024.582290649414\nINFO:root:21: Epoch 4 train loss: 7296.678369522095\nINFO:root:10: Epoch 4 train loss: 11372.58208990097\nINFO:root:20: Epoch 4 train loss: 23740.561412334442\nINFO:root:12: Epoch 4 train loss: 19606.266830444336\nINFO:root:18: Epoch 4 train loss: 2399556.6781311035\nINFO:root:13: Epoch 4 train loss: 1877.9880676269531\nINFO:root:26: Epoch 4 train loss: 13107.18815612793\nINFO:root:17: Epoch 4 train loss: 18652.678100585938\nINFO:root:25: Epoch 4 train loss: 4782.987548828125\nINFO:root:4: Epoch 4 train loss: 8254.433799743652\nINFO:root:0: Epoch 4 validation loss: 1008841.3974110732\nINFO:root:2: Epoch 5 train loss: 10653.239776611328\nINFO:root:3: Epoch 5 train loss: 17371.15724182129\nINFO:root:23: Epoch 5 train loss: 10386.846878051758\nINFO:root:26: Epoch 5 train loss: 67505.70887374878\nINFO:root:27: Epoch 5 train loss: 6928345.8227005005\nINFO:root:7: Epoch 5 train loss: 23229.76077604294\nINFO:root:4: Epoch 5 train loss: 12736.579818725586\nINFO:root:5: Epoch 5 train loss: 71927.34862852097\nINFO:root:6: Epoch 5 train loss: 3454.97474861145\nINFO:root:25: Epoch 5 train loss: 2004889.7199249268\nINFO:root:9: Epoch 5 train loss: 2071486.4093780518\nINFO:root:8: Epoch 5 train loss: 18104.45428466797\nINFO:root:20: Epoch 5 train loss: 228646.53564453125\nINFO:root:22: Epoch 5 train loss: 3288.033443927765\nINFO:root:21: Epoch 5 train loss: 15112.74673461914\nINFO:root:24: Epoch 5 train loss: 25833.278091430664\nINFO:root:0: Epoch 5 train loss: 131927.51489257812\nINFO:root:1: Epoch 5 train loss: 1384.1683082580566\nINFO:root:14: Epoch 5 train loss: 2071252.4930758476\nINFO:root:12: Epoch 5 train loss: 1998462.3893575668\nINFO:root:17: Epoch 5 train loss: 1722555.1158246994\nINFO:root:18: Epoch 5 train loss: 26461.7431640625\nINFO:root:19: Epoch 5 train loss: 2533782.5993499756\nINFO:root:16: Epoch 5 train loss: 64141.81677246094\nINFO:root:11: Epoch 5 train loss: 4503169.020965576\nINFO:root:10: Epoch 5 train loss: 2071556.4436340332\nINFO:root:13: Epoch 5 train loss: 2097026.972222805\nINFO:root:15: Epoch 5 train loss: 3916780.653383255\nINFO:root:0: Epoch 5 validation loss: 1008776.6175804934\n", "seconds": 8.218555212020874, "batch_size": 32, "nodes": 7, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 3 batches\n2 Start Epoch 0\n2: 3 batches\n4 Start Epoch 0\n4: 3 batches\n1 Start Epoch 0\n3 Start Epoch 0\n3: 3 batches\n1: 3 batches\n31 Start Epoch 0\n31: 3 batches\n16 Start Epoch 0\n16: 3 batches\n24 Start Epoch 0\n23 Start Epoch 0\n23: 3 batches\n24: 3 batches\n15 Start Epoch 0\n8 Start Epoch 0\n15: 3 batches\n8: 3 batches\n7 Start Epoch 0\n7: 3 batches\n5 Start Epoch 0\n5: 3 batches\n28 Start Epoch 0\n28: 3 batches\n6 Start Epoch 0\n20 Start Epoch 0\n20: 3 batches\n6: 3 batches\n12 Start Epoch 0\n12: 3 batches\n27 Start Epoch 0\n10 Start Epoch 0\n9 Start Epoch 0\n9: 3 batches\n27: 3 batches\n10: 3 batches\n11 Start Epoch 0\n26 Start Epoch 0\n17 Start Epoch 0\n25 Start Epoch 0\n25: 3 batches\n18 Start Epoch 0\n11: 3 batches\n26: 3 batches\n17: 3 batches\n19 Start Epoch 0\n19: 3 batches\n21 Start Epoch 0\n29 Start Epoch 0\n22 Start Epoch 0\n30 Start Epoch 0\n22: 3 batches\n30: 3 batches\n21: 3 batches\n18: 3 batches\n29: 3 batches\n13 Start Epoch 0\n14 Start Epoch 0\n14: 3 batches\n13: 3 batches\n23 Start Epoch 1\n23: 3 batches\n2 Start Epoch 1\n11 Start Epoch 1\n4 Start Epoch 1\n22 Start Epoch 1\n22: 3 batches\n12 Start Epoch 1\n4: 3 batches\n8 Start Epoch 1\n26 Start Epoch 1\n16 Start Epoch 1\n26: 3 batches\n18 Start Epoch 1\n15 Start Epoch 1\n12: 3 batches\n7 Start Epoch 1\n11: 3 batches\n24 Start Epoch 1\n16: 3 batches\n8: 3 batches\n24: 3 batches\n18: 3 batches\n15: 3 batches\n6 Start Epoch 1\n6: 3 batches\n20 Start Epoch 1\n9 Start Epoch 1\n7: 3 batches\n20: 3 batches\n14 Start Epoch 1\n9: 3 batches\n14: 3 batches\n13 Start Epoch 1\n10 Start Epoch 1\n10: 3 batches\n13: 3 batches\n17 Start Epoch 1\n17: 3 batches\n25 Start Epoch 1\n21 Start Epoch 1\n21: 3 batches\n31 Start Epoch 1\n31: 3 batches\n28 Start Epoch 1\n28: 3 batches\n30 Start Epoch 1\n30: 3 batches\n29 Start Epoch 1\n29: 3 batches\n27 Start Epoch 1\n25: 3 batches\n27: 3 batches\n5 Start Epoch 1\n5: 3 batches\n19 Start Epoch 1\n19: 3 batches\n2: 3 batches\n3 Start Epoch 1\n3: 3 batches\n1 Start Epoch 1\n1: 3 batches\n0 Start Epoch 1\n0: 3 batches\n23 Start Epoch 2\n31 Start Epoch 2\n7 Start Epoch 2\n31: 3 batches\n11 Start Epoch 2\n7: 3 batches\n11: 3 batches\n8 Start Epoch 2\n8: 3 batches\n14 Start Epoch 2\n23: 3 batches\n13 Start Epoch 2\n12 Start Epoch 2\n12: 3 batches\n13: 3 batches\n15 Start Epoch 2\n2 Start Epoch 2\n2: 3 batches\n3 Start Epoch 2\n3: 3 batches\n1 Start Epoch 2\n1: 3 batches\n22 Start Epoch 2\n27 Start Epoch 2\n5 Start Epoch 2\n30 Start Epoch 2\n20 Start Epoch 2\n27: 3 batches\n22: 3 batches\n26 Start Epoch 2\n17 Start Epoch 2\n29 Start Epoch 2\n16 Start Epoch 2\n29: 3 batches\n20: 3 batches\n26: 3 batches\n28 Start Epoch 2\n18 Start Epoch 2\n21 Start Epoch 2\n17: 3 batches\n28: 3 batches\n16: 3 batches\n30: 3 batches\n21: 3 batches\n19 Start Epoch 2\n19: 3 batches\n18: 3 batches\n15: 3 batches\n14: 3 batches\n4 Start Epoch 2\n6 Start Epoch 2\n6: 3 batches\n5: 3 batches\n4: 3 batches\n10 Start Epoch 2\n10: 3 batches\n9 Start Epoch 2\n9: 3 batches\n24 Start Epoch 2\n25 Start Epoch 2\n25: 3 batches\n24: 3 batches\n0 Start Epoch 2\n0: 3 batches\n13 Start Epoch 3\n14 Start Epoch 3\n13: 3 batches\n14: 3 batches\n10 Start Epoch 3\n8 Start Epoch 3\n8: 3 batches\n11 Start Epoch 3\n11: 3 batches\n10: 3 batches\n9 Start Epoch 3\n9: 3 batches\n12 Start Epoch 3\n17 Start Epoch 3\n16 Start Epoch 3\n17: 3 batches\n15 Start Epoch 3\n16: 3 batches\n12: 3 batches\n7 Start Epoch 3\n7: 3 batches\n2 Start Epoch 3\n2: 3 batches\n4 Start Epoch 3\n4: 3 batches\n31 Start Epoch 3\n23 Start Epoch 3\n1 Start Epoch 3\n20 Start Epoch 3\n20: 3 batches\n1: 3 batches\n3 Start Epoch 3\n3: 3 batches\n18 Start Epoch 3\n15: 3 batches\n19 Start Epoch 3\n26 Start Epoch 3\n25 Start Epoch 3\n26: 3 batches\n19: 3 batches\n25: 3 batches\n18: 3 batches\n27 Start Epoch 3\n27: 3 batches\n24 Start Epoch 3\n24: 3 batches\n6 Start Epoch 3\n28 Start Epoch 3\n29 Start Epoch 3\n28: 3 batches\n30 Start Epoch 3\n29: 3 batches\n6: 3 batches\n30: 3 batches\n5 Start Epoch 3\n23: 3 batches\n5: 3 batches\n31: 3 batches\n22 Start Epoch 3\n21 Start Epoch 3\n22: 3 batches\n21: 3 batches\n0 Start Epoch 3\n0: 3 batches\n29 Start Epoch 4\n30 Start Epoch 4\n31 Start Epoch 4\n31: 3 batches\n30: 3 batches\n29: 3 batches\n23 Start Epoch 4\n26 Start Epoch 4\n11 Start Epoch 4\n27 Start Epoch 4\n22 Start Epoch 4\n22: 3 batches\n8 Start Epoch 4\n27: 3 batches\n23: 3 batches\n11: 3 batches\n26: 3 batches\n8: 3 batches\n7 Start Epoch 4\n21 Start Epoch 4\n17 Start Epoch 4\n21: 3 batches\n16 Start Epoch 4\n4 Start Epoch 4\n7: 3 batches\n20 Start Epoch 4\n16: 3 batches\n17: 3 batches\n4: 3 batches\n20: 3 batches\n5 Start Epoch 4\n5: 3 batches\n6 Start Epoch 4\n1 Start Epoch 4\n1: 3 batches\n3 Start Epoch 4\n3: 3 batches\n6: 3 batches\n28 Start Epoch 4\n15 Start Epoch 4\n15: 3 batches\n13 Start Epoch 4\n13: 3 batches\n28: 3 batches\n2 Start Epoch 4\n18 Start Epoch 4\n19 Start Epoch 4\n18: 3 batches\n19: 3 batches\n12 Start Epoch 4\n12: 3 batches\n2: 3 batches\n14 Start Epoch 4\n25 Start Epoch 4\n24 Start Epoch 4\n14: 3 batches\n25: 3 batches\n24: 3 batches\n9 Start Epoch 4\n9: 3 batches\n10 Start Epoch 4\n10: 3 batches\n0 Start Epoch 4\n0: 3 batches\n23 Start Epoch 5\n23: 3 batches\n15 Start Epoch 5\n15: 3 batches\n25 Start Epoch 5\n24 Start Epoch 5\n25: 3 batches\n24: 3 batches\n19 Start Epoch 5\n18 Start Epoch 5\n19: 3 batches\n18: 3 batches\n6 Start Epoch 5\n11 Start Epoch 5\n16 Start Epoch 5\n16: 3 batches\n14 Start Epoch 5\n6: 3 batches\n14: 3 batches\n13 Start Epoch 5\n7 Start Epoch 5\n31 Start Epoch 5\n11: 3 batches\n7: 3 batches\n31: 3 batches\n13: 3 batches\n9 Start Epoch 5\n9: 3 batches\n17 Start Epoch 5\n20 Start Epoch 5\n17: 3 batches\n22 Start Epoch 5\n22: 3 batches\n20: 3 batches\n21 Start Epoch 5\n8 Start Epoch 5\n21: 3 batches\n8: 3 batches\n30 Start Epoch 5\n1 Start Epoch 5\n3 Start Epoch 5\n3: 3 batches\n30: 3 batches\n12 Start Epoch 5\n28 Start Epoch 5\n27 Start Epoch 5\n12: 3 batches\n27: 3 batches\n28: 3 batches\n26 Start Epoch 5\n29 Start Epoch 5\n10 Start Epoch 5\n26: 3 batches\n10: 3 batches\n29: 3 batches\n1: 3 batches\n4 Start Epoch 5\n4: 3 batches\n5 Start Epoch 5\n5: 3 batches\n2 Start Epoch 5\n2: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:23: Epoch 0 train loss: 3374.416788736979\nINFO:root:2: Epoch 0 train loss: 5731659.5934244795\nINFO:root:26: Epoch 0 train loss: 13608.188512166342\nINFO:root:16: Epoch 0 train loss: 103509.79667154948\nINFO:root:15: Epoch 0 train loss: 3446134.7754720054\nINFO:root:4: Epoch 0 train loss: 13160.7626953125\nINFO:root:22: Epoch 0 train loss: 19809.750366210938\nINFO:root:24: Epoch 0 train loss: 3047986.033467611\nINFO:root:0: Epoch 0 train loss: 1313.975565592448\nINFO:root:18: Epoch 0 train loss: 9425.92756652832\nINFO:root:12: Epoch 0 train loss: 31012.105794270832\nINFO:root:8: Epoch 0 train loss: 44336.9794921875\nINFO:root:11: Epoch 0 train loss: 10168.525309244791\nINFO:root:7: Epoch 0 train loss: 5013.336130777995\nINFO:root:6: Epoch 0 train loss: 2175567.1778971353\nINFO:root:20: Epoch 0 train loss: 7997.437764485677\nINFO:root:14: Epoch 0 train loss: 2315759.8334960938\nINFO:root:13: Epoch 0 train loss: 48743.12345377604\nINFO:root:9: Epoch 0 train loss: 8311.872512817383\nINFO:root:10: Epoch 0 train loss: 40289.8994140625\nINFO:root:17: Epoch 0 train loss: 23283.980697631836\nINFO:root:25: Epoch 0 train loss: 2785.0475870768228\nINFO:root:21: Epoch 0 train loss: 2948417.4213867188\nINFO:root:31: Epoch 0 train loss: 2899497.0416259766\nINFO:root:30: Epoch 0 train loss: 3064897.0818684897\nINFO:root:29: Epoch 0 train loss: 24839.14345041911\nINFO:root:28: Epoch 0 train loss: 3050201.786895752\nINFO:root:27: Epoch 0 train loss: 71117.60546875\nINFO:root:5: Epoch 0 train loss: 31066.772786458332\nINFO:root:19: Epoch 0 train loss: 4852033.63671875\nINFO:root:1: Epoch 0 train loss: 38652.771484375\nINFO:root:3: Epoch 0 train loss: 1126.8582407633464\nINFO:root:0: Epoch 0 validation loss: 10125.666536639734\nINFO:root:31: Epoch 1 train loss: 60963.57936604818\nINFO:root:23: Epoch 1 train loss: 24564.49833170573\nINFO:root:11: Epoch 1 train loss: 3042419.4519856772\nINFO:root:7: Epoch 1 train loss: 386551.70686848956\nINFO:root:15: Epoch 1 train loss: 2279.642578125\nINFO:root:8: Epoch 1 train loss: 40843.542643229164\nINFO:root:14: Epoch 1 train loss: 5497010.39851888\nINFO:root:13: Epoch 1 train loss: 2573264.1330566406\nINFO:root:12: Epoch 1 train loss: 10903.362650553385\nINFO:root:0: Epoch 1 train loss: 4465.1357014973955\nINFO:root:1: Epoch 1 train loss: 38139.02587890625\nINFO:root:2: Epoch 1 train loss: 2756.0358683268228\nINFO:root:3: Epoch 1 train loss: 9160.171264648438\nINFO:root:6: Epoch 1 train loss: 11889.361063639322\nINFO:root:28: Epoch 1 train loss: 3508.294921875\nINFO:root:22: Epoch 1 train loss: 1876.2871017456055\nINFO:root:26: Epoch 1 train loss: 17699.290852864582\nINFO:root:17: Epoch 1 train loss: 3232045.9811197915\nINFO:root:5: Epoch 1 train loss: 982.7752176920573\nINFO:root:30: Epoch 1 train loss: 59672.02325439453\nINFO:root:20: Epoch 1 train loss: 2610128.2552083335\nINFO:root:27: Epoch 1 train loss: 4540.902404785156\nINFO:root:18: Epoch 1 train loss: 922349.4977213541\nINFO:root:16: Epoch 1 train loss: 8753.676472981771\nINFO:root:4: Epoch 1 train loss: 160236.68725585938\nINFO:root:29: Epoch 1 train loss: 19280.905598958332\nINFO:root:19: Epoch 1 train loss: 18062.224161783855\nINFO:root:21: Epoch 1 train loss: 9842.765502929688\nINFO:root:10: Epoch 1 train loss: 54408.70125325521\nINFO:root:9: Epoch 1 train loss: 61487.735026041664\nINFO:root:25: Epoch 1 train loss: 14775.201700846354\nINFO:root:24: Epoch 1 train loss: 26858.707682291668\nINFO:root:0: Epoch 1 validation loss: 10121.515472492652\nINFO:root:14: Epoch 2 train loss: 2330936.6705729165\nINFO:root:13: Epoch 2 train loss: 21938.517659505207\nINFO:root:8: Epoch 2 train loss: 5457.898284912109\nINFO:root:10: Epoch 2 train loss: 47246.07755533854\nINFO:root:11: Epoch 2 train loss: 22071.047200520832\nINFO:root:9: Epoch 2 train loss: 4324.2470296223955\nINFO:root:12: Epoch 2 train loss: 70072.60773722331\nINFO:root:17: Epoch 2 train loss: 6547.625874837239\nINFO:root:16: Epoch 2 train loss: 2292.9964599609375\nINFO:root:15: Epoch 2 train loss: 2401506.71875\nINFO:root:7: Epoch 2 train loss: 111685.74088541667\nINFO:root:2: Epoch 2 train loss: 3556.629389444987\nINFO:root:4: Epoch 2 train loss: 2896726.811442057\nINFO:root:0: Epoch 2 train loss: 31868.489583333332\nINFO:root:3: Epoch 2 train loss: 19242.44497680664\nINFO:root:31: Epoch 2 train loss: 26196.397298177082\nINFO:root:23: Epoch 2 train loss: 302093.03474934894\nINFO:root:1: Epoch 2 train loss: 2625.157918294271\nINFO:root:20: Epoch 2 train loss: 139292.8077392578\nINFO:root:18: Epoch 2 train loss: 2175850.328491211\nINFO:root:19: Epoch 2 train loss: 404.13669840494794\nINFO:root:25: Epoch 2 train loss: 44380.38112386068\nINFO:root:27: Epoch 2 train loss: 2768680.2467447915\nINFO:root:26: Epoch 2 train loss: 44312.35944620768\nINFO:root:24: Epoch 2 train loss: 6063.905436197917\nINFO:root:6: Epoch 2 train loss: 2550066.2179361978\nINFO:root:5: Epoch 2 train loss: 97478.75048828125\nINFO:root:30: Epoch 2 train loss: 44490.673319498695\nINFO:root:29: Epoch 2 train loss: 15505.679555257162\nINFO:root:28: Epoch 2 train loss: 16350.73089090983\nINFO:root:21: Epoch 2 train loss: 1487.68913714091\nINFO:root:22: Epoch 2 train loss: 7721.612467447917\nINFO:root:0: Epoch 2 validation loss: 10116.922426230178\nINFO:root:31: Epoch 3 train loss: 15932.392618815104\nINFO:root:29: Epoch 3 train loss: 5352546.365315755\nINFO:root:30: Epoch 3 train loss: 41787.708333333336\nINFO:root:0: Epoch 3 train loss: 5480.9833577473955\nINFO:root:23: Epoch 3 train loss: 11423.761433919271\nINFO:root:26: Epoch 3 train loss: 2899071.6373697915\nINFO:root:22: Epoch 3 train loss: 6787.417836507161\nINFO:root:11: Epoch 3 train loss: 19646.123982747395\nINFO:root:27: Epoch 3 train loss: 13610.31650797526\nINFO:root:8: Epoch 3 train loss: 2889514.1062787375\nINFO:root:1: Epoch 3 train loss: 2219765.9817708335\nINFO:root:7: Epoch 3 train loss: 3057967.5436197915\nINFO:root:20: Epoch 3 train loss: 25260.985961914062\nINFO:root:16: Epoch 3 train loss: 38135.53161621094\nINFO:root:21: Epoch 3 train loss: 7543.8181559244795\nINFO:root:17: Epoch 3 train loss: 2672850.7682291665\nINFO:root:4: Epoch 3 train loss: 3204239.1451009116\nINFO:root:5: Epoch 3 train loss: 365039.3603515625\nINFO:root:6: Epoch 3 train loss: 2583764.8318684897\nINFO:root:3: Epoch 3 train loss: 5939338.839701335\nINFO:root:2: Epoch 3 train loss: 93520.18949381511\nINFO:root:15: Epoch 3 train loss: 13954.802670796713\nINFO:root:28: Epoch 3 train loss: 5255.180928548177\nINFO:root:13: Epoch 3 train loss: 2782.4458618164062\nINFO:root:19: Epoch 3 train loss: 37843.563151041664\nINFO:root:18: Epoch 3 train loss: 58632.64530436198\nINFO:root:12: Epoch 3 train loss: 3208025.4486490884\nINFO:root:14: Epoch 3 train loss: 3030404.2610677085\nINFO:root:25: Epoch 3 train loss: 3201503.9165039062\nINFO:root:24: Epoch 3 train loss: 304597.35139973956\nINFO:root:9: Epoch 3 train loss: 928.4798806508383\nINFO:root:10: Epoch 3 train loss: 21939.93084716797\nINFO:root:0: Epoch 3 validation loss: 10112.07451668099\nINFO:root:23: Epoch 4 train loss: 21014.192057291668\nINFO:root:15: Epoch 4 train loss: 21482.616048177082\nINFO:root:25: Epoch 4 train loss: 16727.996643066406\nINFO:root:24: Epoch 4 train loss: 4296.871907552083\nINFO:root:18: Epoch 4 train loss: 108.65233723322551\nINFO:root:19: Epoch 4 train loss: 25771.741861979168\nINFO:root:11: Epoch 4 train loss: 17834.036702473957\nINFO:root:16: Epoch 4 train loss: 529.0470581054688\nINFO:root:13: Epoch 4 train loss: 2769733.2372436523\nINFO:root:6: Epoch 4 train loss: 66249.11460367839\nINFO:root:14: Epoch 4 train loss: 3087670.2194010415\nINFO:root:7: Epoch 4 train loss: 10103.492838541666\nINFO:root:31: Epoch 4 train loss: 22936.0517578125\nINFO:root:22: Epoch 4 train loss: 1807.4906412760417\nINFO:root:9: Epoch 4 train loss: 6780.1915283203125\nINFO:root:21: Epoch 4 train loss: 26485.614095052082\nINFO:root:17: Epoch 4 train loss: 12685.937316894531\nINFO:root:20: Epoch 4 train loss: 14244.992940266928\nINFO:root:8: Epoch 4 train loss: 2684042.8161977134\nINFO:root:30: Epoch 4 train loss: 5372170.690653483\nINFO:root:0: Epoch 4 train loss: 69388.2529296875\nINFO:root:1: Epoch 4 train loss: 12263.073811848959\nINFO:root:3: Epoch 4 train loss: 54709.830729166664\nINFO:root:26: Epoch 4 train loss: 8628.796875\nINFO:root:12: Epoch 4 train loss: 29924.918863932293\nINFO:root:28: Epoch 4 train loss: 2818.8470865885415\nINFO:root:27: Epoch 4 train loss: 11584.002360026041\nINFO:root:10: Epoch 4 train loss: 20180.952962239582\nINFO:root:29: Epoch 4 train loss: 350464.7789713542\nINFO:root:4: Epoch 4 train loss: 11624.287231445312\nINFO:root:5: Epoch 4 train loss: 917005.0201822916\nINFO:root:2: Epoch 4 train loss: 5635.303080240886\nINFO:root:0: Epoch 4 validation loss: 10106.67321220811\nINFO:root:15: Epoch 5 train loss: 11902.331868489584\nINFO:root:22: Epoch 5 train loss: 2673111.4713541665\nINFO:root:11: Epoch 5 train loss: 2900144.0705159507\nINFO:root:23: Epoch 5 train loss: 10801.333201090494\nINFO:root:24: Epoch 5 train loss: 365093.21269226074\nINFO:root:25: Epoch 5 train loss: 307319.051554362\nINFO:root:13: Epoch 5 train loss: 4155.1039632161455\nINFO:root:18: Epoch 5 train loss: 2673327.4988606772\nINFO:root:19: Epoch 5 train loss: 41553.512044270836\nINFO:root:14: Epoch 5 train loss: 3219888.8489990234\nINFO:root:21: Epoch 5 train loss: 6248.4927978515625\nINFO:root:10: Epoch 5 train loss: 15671.374710083008\nINFO:root:17: Epoch 5 train loss: 58305.063454945885\nINFO:root:16: Epoch 5 train loss: 969213.0475285848\nINFO:root:20: Epoch 5 train loss: 19483.968180338543\nINFO:root:12: Epoch 5 train loss: 5455454.39674886\nINFO:root:31: Epoch 5 train loss: 1486.2029418945312\nINFO:root:7: Epoch 5 train loss: 2304746.2563476562\nINFO:root:6: Epoch 5 train loss: 9670.946847279867\nINFO:root:5: Epoch 5 train loss: 13647.761205037436\nINFO:root:3: Epoch 5 train loss: 36469.19685872396\nINFO:root:2: Epoch 5 train loss: 19608.311116536457\nINFO:root:1: Epoch 5 train loss: 5456109.2734375\nINFO:root:8: Epoch 5 train loss: 1831.4829203287761\nINFO:root:9: Epoch 5 train loss: 15755.411137898764\nINFO:root:4: Epoch 5 train loss: 70311.91048177083\nINFO:root:27: Epoch 5 train loss: 6730.377166748047\nINFO:root:30: Epoch 5 train loss: 11423.509887695312\nINFO:root:29: Epoch 5 train loss: 2832935.1340789795\nINFO:root:0: Epoch 5 train loss: 29503.2739054362\nINFO:root:28: Epoch 5 train loss: 30653.146901448566\nINFO:root:26: Epoch 5 train loss: 4699.164652506511\nINFO:root:0: Epoch 5 validation loss: 10100.593489976278\n", "seconds": 8.372565031051636, "batch_size": 32, "nodes": 8, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 3 batches\n2 Start Epoch 0\n2: 3 batches\n1 Start Epoch 0\n1: 3 batches\n3 Start Epoch 0\n4 Start Epoch 0\n4: 3 batches\n3: 3 batches\n23 Start Epoch 0\n8 Start Epoch 0\n23: 3 batches\n24 Start Epoch 0\n7 Start Epoch 0\n35 Start Epoch 0\n15 Start Epoch 0\n24: 3 batches\n7: 3 batches\n8: 3 batches\n16 Start Epoch 0\n31 Start Epoch 0\n32 Start Epoch 0\n16: 3 batches\n31: 3 batches\n32: 3 batches\n11 Start Epoch 0\n20 Start Epoch 0\n15: 3 batches\n27 Start Epoch 0\n28 Start Epoch 0\n12 Start Epoch 0\n27: 3 batches\n5 Start Epoch 0\n35: 3 batches\n11: 3 batches\n19 Start Epoch 0\n20: 3 batches\n28: 3 batches\n12: 3 batches\n5: 3 batches\n19: 3 batches\n6 Start Epoch 0\n6: 3 batches\n14 Start Epoch 0\n13 Start Epoch 0\n13: 3 batches\n14: 3 batches\n26 Start Epoch 0\n33 Start Epoch 0\n9 Start Epoch 0\n18 Start Epoch 0\n29 Start Epoch 0\n25 Start Epoch 0\n33: 3 batches\n10 Start Epoch 0\n17 Start Epoch 0\n21 Start Epoch 0\n10: 3 batches\n18: 3 batches\n22 Start Epoch 0\n30 Start Epoch 0\n25: 3 batches\n34 Start Epoch 0\n17: 3 batches\n22: 3 batches\n30: 3 batches\n26: 3 batches\n34: 3 batches\n9: 3 batches\n21: 3 batches\n29: 3 batches\n7 Start Epoch 1\n7: 3 batches\n31 Start Epoch 1\n31: 3 batches\n9 Start Epoch 1\n1 Start Epoch 1\n4 Start Epoch 1\n9: 3 batches\n4: 3 batches\n1: 3 batches\n32 Start Epoch 1\n8 Start Epoch 1\n23 Start Epoch 1\n28 Start Epoch 1\n5 Start Epoch 1\n23: 3 batches\n30 Start Epoch 1\n5: 3 batches\n32: 3 batches\n8: 3 batches\n35 Start Epoch 1\n28: 3 batches\n30: 3 batches\n35: 3 batches\n25 Start Epoch 1\n24 Start Epoch 1\n26 Start Epoch 1\n25: 3 batches\n24: 3 batches\n27 Start Epoch 1\n27: 3 batches\n26: 3 batches\n16 Start Epoch 1\n29 Start Epoch 1\n15 Start Epoch 1\n6 Start Epoch 1\n15: 3 batches\n6: 3 batches\n33 Start Epoch 1\n16: 3 batches\n29: 3 batches\n33: 3 batches\n11 Start Epoch 1\n20 Start Epoch 1\n34 Start Epoch 1\n10 Start Epoch 1\n18 Start Epoch 1\n21 Start Epoch 1\n11: 3 batches\n18: 3 batches\n21: 3 batches\n34: 3 batches\n10: 3 batches\n22 Start Epoch 1\n22: 3 batches\n20: 3 batches\n3 Start Epoch 1\n3: 3 batches\n2 Start Epoch 1\n2: 3 batches\n17 Start Epoch 1\n19 Start Epoch 1\n19: 3 batches\n17: 3 batches\n12 Start Epoch 1\n12: 3 batches\n13 Start Epoch 1\n14 Start Epoch 1\n13: 3 batches\n14: 3 batches\n0 Start Epoch 1\n0: 3 batches\n7 Start Epoch 2\n15 Start Epoch 2\n15: 3 batches\n7: 3 batches\n31 Start Epoch 2\n31: 3 batches\n3 Start Epoch 2\n3: 3 batches\n16 Start Epoch 2\n24 Start Epoch 2\n6 Start Epoch 2\n34 Start Epoch 2\n16: 3 batches\n1 Start Epoch 2\n1: 3 batches\n13 Start Epoch 2\n24: 3 batches\n6: 3 batches\n30 Start Epoch 2\n14 Start Epoch 2\n34: 3 batches\n10 Start Epoch 2\n23 Start Epoch 2\n28 Start Epoch 2\n14: 3 batches\n27 Start Epoch 2\n4 Start Epoch 2\n33 Start Epoch 2\n11 Start Epoch 2\n17 Start Epoch 2\n9 Start Epoch 2\n17: 3 batches\n22 Start Epoch 2\n30: 3 batches\n13: 3 batches\n27: 3 batches\n33: 3 batches\n22: 3 batches\n28: 3 batches\n5 Start Epoch 2\n9: 3 batches\n12 Start Epoch 2\n26 Start Epoch 2\n5: 3 batches\n35 Start Epoch 2\n10: 3 batches\n19 Start Epoch 2\n23: 3 batches\n29 Start Epoch 2\n12: 3 batches\n4: 3 batches\n35: 3 batches\n11: 3 batches\n21 Start Epoch 2\n29: 3 batches\n25 Start Epoch 2\n18 Start Epoch 2\n21: 3 batches\n8 Start Epoch 2\n18: 3 batches\n25: 3 batches\n32 Start Epoch 2\n8: 3 batches\n19: 3 batches\n20 Start Epoch 2\n26: 3 batches\n32: 3 batches\n20: 3 batches\n2 Start Epoch 2\n2: 3 batches\n0 Start Epoch 2\n0: 3 batches\n1 Start Epoch 3\n1: 3 batches\n31 Start Epoch 3\n31: 3 batches\n35 Start Epoch 3\n11 Start Epoch 3\n17 Start Epoch 3\n33 Start Epoch 3\n9 Start Epoch 3\n17: 3 batches\n35: 3 batches\n9: 3 batches\n16 Start Epoch 3\n14 Start Epoch 3\n33: 3 batches\n16: 3 batches\n15 Start Epoch 3\n13 Start Epoch 3\n10 Start Epoch 3\n13: 3 batches\n34 Start Epoch 3\n11: 3 batches\n15: 3 batches\n27 Start Epoch 3\n12 Start Epoch 3\n32 Start Epoch 3\n8 Start Epoch 3\n32: 3 batches\n10: 3 batches\n29 Start Epoch 3\n12: 3 batches\n27: 3 batches\n30 Start Epoch 3\n14: 3 batches\n34: 3 batches\n8: 3 batches\n18 Start Epoch 3\n28 Start Epoch 3\n23 Start Epoch 3\n29: 3 batches\n23: 3 batches\n30: 3 batches\n7 Start Epoch 3\n18: 3 batches\n21 Start Epoch 3\n7: 3 batches\n21: 3 batches\n5 Start Epoch 3\n5: 3 batches\n6 Start Epoch 3\n6: 3 batches\n4 Start Epoch 3\n4: 3 batches\n20 Start Epoch 3\n20: 3 batches\n3 Start Epoch 3\n22 Start Epoch 3\n22: 3 batches\n3: 3 batches\n25 Start Epoch 3\n26 Start Epoch 3\n24 Start Epoch 3\n24: 3 batches\n25: 3 batches\n2 Start Epoch 3\n26: 3 batches\n28: 3 batches\n2: 3 batches\n19 Start Epoch 3\n19: 3 batches\n0 Start Epoch 3\n0: 3 batches\n17 Start Epoch 4\n16 Start Epoch 4\n17: 3 batches\n11 Start Epoch 4\n8 Start Epoch 4\n16: 3 batches\n8: 3 batches\n11: 3 batches\n7 Start Epoch 4\n7: 3 batches\n15 Start Epoch 4\n15: 3 batches\n31 Start Epoch 4\n10 Start Epoch 4\n28 Start Epoch 4\n31: 3 batches\n10: 3 batches\n35 Start Epoch 4\n18 Start Epoch 4\n9 Start Epoch 4\n18: 3 batches\n9: 3 batches\n19 Start Epoch 4\n2 Start Epoch 4\n2: 3 batches\n19: 3 batches\n21 Start Epoch 4\n30 Start Epoch 4\n12 Start Epoch 4\n12: 3 batches\n20 Start Epoch 4\n29 Start Epoch 4\n13 Start Epoch 4\n13: 3 batches\n25 Start Epoch 4\n20: 3 batches\n29: 3 batches\n14 Start Epoch 4\n14: 3 batches\n28: 3 batches\n24 Start Epoch 4\n21: 3 batches\n25: 3 batches\n1 Start Epoch 4\n1: 3 batches\n24: 3 batches\n27 Start Epoch 4\n26 Start Epoch 4\n27: 3 batches\n26: 3 batches\n4 Start Epoch 4\n6 Start Epoch 4\n6: 3 batches\n4: 3 batches\n5 Start Epoch 4\n5: 3 batches\n23 Start Epoch 4\n22 Start Epoch 4\n22: 3 batches\n23: 3 batches\n3 Start Epoch 4\n30: 3 batches\n3: 3 batches\n33 Start Epoch 4\n33: 3 batches\n34 Start Epoch 4\n34: 3 batches\n32 Start Epoch 4\n35: 3 batches\n32: 3 batches\n0 Start Epoch 4\n0: 3 batches\n31 Start Epoch 5\n31: 3 batches\n7 Start Epoch 5\n7: 3 batches\n4 Start Epoch 5\n6 Start Epoch 5\n5 Start Epoch 5\n5: 3 batches\n4: 3 batches\n6: 3 batches\n23 Start Epoch 5\n25 Start Epoch 5\n35 Start Epoch 5\n24 Start Epoch 5\n35: 3 batches\n17 Start Epoch 5\n25: 3 batches\n34 Start Epoch 5\n19 Start Epoch 5\n34: 3 batches\n17: 3 batches\n19: 3 batches\n26 Start Epoch 5\n16 Start Epoch 5\n26: 3 batches\n16: 3 batches\n27 Start Epoch 5\n27: 3 batches\n24: 3 batches\n1 Start Epoch 5\n15 Start Epoch 5\n15: 3 batches\n29 Start Epoch 5\n29: 3 batches\n12 Start Epoch 5\n12: 3 batches\n13 Start Epoch 5\n13: 3 batches\n28 Start Epoch 5\n28: 3 batches\n14 Start Epoch 5\n14: 3 batches\n1: 3 batches\n9 Start Epoch 5\n23: 3 batches\n8 Start Epoch 5\n8: 3 batches\n21 Start Epoch 5\n11 Start Epoch 5\n11: 3 batches\n21: 3 batches\n10 Start Epoch 5\n10: 3 batches\n20 Start Epoch 5\n20: 3 batches\n9: 3 batches\n30 Start Epoch 5\n30: 3 batches\n18 Start Epoch 5\n2 Start Epoch 5\n2: 3 batches\n18: 3 batches\n22 Start Epoch 5\n22: 3 batches\n3 Start Epoch 5\n3: 3 batches\n32 Start Epoch 5\n32: 3 batches\n33 Start Epoch 5\n33: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:7: Epoch 0 train loss: 503650.7912597656\nINFO:root:31: Epoch 0 train loss: 20389.03623453776\nINFO:root:4: Epoch 0 train loss: 2624172.715423584\nINFO:root:9: Epoch 0 train loss: 13881.821248372396\nINFO:root:8: Epoch 0 train loss: 3517.5642878214517\nINFO:root:5: Epoch 0 train loss: 30082.279947916668\nINFO:root:1: Epoch 0 train loss: 29459.772867838543\nINFO:root:30: Epoch 0 train loss: 37353.8039855957\nINFO:root:35: Epoch 0 train loss: 4133.125345865886\nINFO:root:23: Epoch 0 train loss: 2673206.833129883\nINFO:root:28: Epoch 0 train loss: 33512.79825846354\nINFO:root:32: Epoch 0 train loss: 13583.141105016073\nINFO:root:24: Epoch 0 train loss: 2888988.79494222\nINFO:root:25: Epoch 0 train loss: 18202.036397298176\nINFO:root:26: Epoch 0 train loss: 148366.5397644043\nINFO:root:27: Epoch 0 train loss: 651.3200149536133\nINFO:root:16: Epoch 0 train loss: 2166326.887451172\nINFO:root:21: Epoch 0 train loss: 1223.1924743652344\nINFO:root:29: Epoch 0 train loss: 19747.788920084637\nINFO:root:15: Epoch 0 train loss: 88939.80981445312\nINFO:root:6: Epoch 0 train loss: 17151.71044921875\nINFO:root:33: Epoch 0 train loss: 104548.93821207683\nINFO:root:10: Epoch 0 train loss: 4142.8633219401045\nINFO:root:20: Epoch 0 train loss: 2246.2767333984375\nINFO:root:34: Epoch 0 train loss: 13472.08512878418\nINFO:root:11: Epoch 0 train loss: 46713.44181315104\nINFO:root:22: Epoch 0 train loss: 2354257.1912434897\nINFO:root:18: Epoch 0 train loss: 14538.383544921875\nINFO:root:2: Epoch 0 train loss: 17080.557657877605\nINFO:root:3: Epoch 0 train loss: 11155.014002482096\nINFO:root:0: Epoch 0 train loss: 18889.756041208904\nINFO:root:17: Epoch 0 train loss: 2567461.299580892\nINFO:root:19: Epoch 0 train loss: 4495487.44510905\nINFO:root:12: Epoch 0 train loss: 14037.607218424479\nINFO:root:14: Epoch 0 train loss: 22370.449788411457\nINFO:root:13: Epoch 0 train loss: 311504.85432942706\nINFO:root:0: Epoch 0 validation loss: 1611298.0237255637\nINFO:root:15: Epoch 1 train loss: 50702.643229166664\nINFO:root:7: Epoch 1 train loss: 1904.1649576822917\nINFO:root:31: Epoch 1 train loss: 31177.007731119793\nINFO:root:3: Epoch 1 train loss: 302146.07242838544\nINFO:root:9: Epoch 1 train loss: 34281.470703125\nINFO:root:16: Epoch 1 train loss: 2602422.138671875\nINFO:root:28: Epoch 1 train loss: 5447.044250488281\nINFO:root:14: Epoch 1 train loss: 5960.844156901042\nINFO:root:24: Epoch 1 train loss: 2777541.74794515\nINFO:root:6: Epoch 1 train loss: 2242363.9505208335\nINFO:root:33: Epoch 1 train loss: 31188.755900065105\nINFO:root:11: Epoch 1 train loss: 11936.223266601562\nINFO:root:22: Epoch 1 train loss: 17778.101888020832\nINFO:root:29: Epoch 1 train loss: 2460.9249979654946\nINFO:root:13: Epoch 1 train loss: 12018.197026570639\nINFO:root:34: Epoch 1 train loss: 3256454.2298583984\nINFO:root:10: Epoch 1 train loss: 8468.009450276693\nINFO:root:1: Epoch 1 train loss: 5070669.307128906\nINFO:root:2: Epoch 1 train loss: 2688717.6865641274\nINFO:root:23: Epoch 1 train loss: 2763519.299519857\nINFO:root:30: Epoch 1 train loss: 6181.3320719401045\nINFO:root:17: Epoch 1 train loss: 3797.9484049479165\nINFO:root:21: Epoch 1 train loss: 2790995.0035603843\nINFO:root:27: Epoch 1 train loss: 13051.42588297526\nINFO:root:4: Epoch 1 train loss: 18233.29847208659\nINFO:root:5: Epoch 1 train loss: 23603.16412226359\nINFO:root:12: Epoch 1 train loss: 21040.799235026043\nINFO:root:26: Epoch 1 train loss: 2305452.1803385415\nINFO:root:35: Epoch 1 train loss: 368283.15901692706\nINFO:root:19: Epoch 1 train loss: 9914.546020507812\nINFO:root:25: Epoch 1 train loss: 7371.821044921875\nINFO:root:18: Epoch 1 train loss: 2583473.8248697915\nINFO:root:32: Epoch 1 train loss: 2717765.2745768228\nINFO:root:8: Epoch 1 train loss: 10773.267740885416\nINFO:root:20: Epoch 1 train loss: 2609781.9697062173\nINFO:root:0: Epoch 1 train loss: 37455.61789957682\nINFO:root:0: Epoch 1 validation loss: 1611255.9268639518\nINFO:root:1: Epoch 2 train loss: 21016.763346354168\nINFO:root:35: Epoch 2 train loss: 3232485.2880859375\nINFO:root:9: Epoch 2 train loss: 8833.064493815104\nINFO:root:16: Epoch 2 train loss: 163207.03125\nINFO:root:31: Epoch 2 train loss: 60889.202962239586\nINFO:root:14: Epoch 2 train loss: 29899.324300130207\nINFO:root:33: Epoch 2 train loss: 3763.2823791503906\nINFO:root:11: Epoch 2 train loss: 10348.395365397135\nINFO:root:17: Epoch 2 train loss: 2580065.3158365884\nINFO:root:13: Epoch 2 train loss: 741.0950876871744\nINFO:root:15: Epoch 2 train loss: 307952.5325686137\nINFO:root:12: Epoch 2 train loss: 24956.909586588543\nINFO:root:10: Epoch 2 train loss: 2696314.9322916665\nINFO:root:34: Epoch 2 train loss: 3674696.775065104\nINFO:root:28: Epoch 2 train loss: 48585.082845052086\nINFO:root:27: Epoch 2 train loss: 11612.819480895996\nINFO:root:8: Epoch 2 train loss: 22886.940673828125\nINFO:root:29: Epoch 2 train loss: 3386.6546223958335\nINFO:root:32: Epoch 2 train loss: 639.3797486623129\nINFO:root:30: Epoch 2 train loss: 36098.460286458336\nINFO:root:18: Epoch 2 train loss: 3667625.03519694\nINFO:root:23: Epoch 2 train loss: 5549.478515625\nINFO:root:21: Epoch 2 train loss: 6495.519694010417\nINFO:root:5: Epoch 2 train loss: 30825.12212117513\nINFO:root:7: Epoch 2 train loss: 26224.514729817707\nINFO:root:6: Epoch 2 train loss: 1507.8005981445312\nINFO:root:4: Epoch 2 train loss: 4662.905680338542\nINFO:root:20: Epoch 2 train loss: 28354.744791666668\nINFO:root:3: Epoch 2 train loss: 11992.250651041666\nINFO:root:22: Epoch 2 train loss: 158211.73497517905\nINFO:root:2: Epoch 2 train loss: 9983.95123799642\nINFO:root:24: Epoch 2 train loss: 23651.341196695965\nINFO:root:26: Epoch 2 train loss: 898.9915008544922\nINFO:root:25: Epoch 2 train loss: 20626.49169921875\nINFO:root:0: Epoch 2 train loss: 28995.085367838543\nINFO:root:19: Epoch 2 train loss: 59513.96083068848\nINFO:root:0: Epoch 2 validation loss: 1611211.188797396\nINFO:root:16: Epoch 3 train loss: 5981.0543212890625\nINFO:root:17: Epoch 3 train loss: 3337.5868530273438\nINFO:root:11: Epoch 3 train loss: 18611.178385416668\nINFO:root:8: Epoch 3 train loss: 14601.073404947916\nINFO:root:7: Epoch 3 train loss: 5862.914479573567\nINFO:root:10: Epoch 3 train loss: 65948.12482480209\nINFO:root:15: Epoch 3 train loss: 45539.28670247396\nINFO:root:28: Epoch 3 train loss: 999.2939154307047\nINFO:root:31: Epoch 3 train loss: 38719.30758666992\nINFO:root:18: Epoch 3 train loss: 2666017.347640991\nINFO:root:19: Epoch 3 train loss: 27158.929239908855\nINFO:root:12: Epoch 3 train loss: 3194547.638786316\nINFO:root:35: Epoch 3 train loss: 63708.470052083336\nINFO:root:9: Epoch 3 train loss: 13431.775187174479\nINFO:root:13: Epoch 3 train loss: 10441.744384765625\nINFO:root:21: Epoch 3 train loss: 4683.135828653972\nINFO:root:30: Epoch 3 train loss: 26889.701578776043\nINFO:root:2: Epoch 3 train loss: 24242.423568725586\nINFO:root:20: Epoch 3 train loss: 25856.333821614582\nINFO:root:29: Epoch 3 train loss: 129601.48177083333\nINFO:root:25: Epoch 3 train loss: 3215239.333984375\nINFO:root:24: Epoch 3 train loss: 2769219.5927327476\nINFO:root:14: Epoch 3 train loss: 6341.7255859375\nINFO:root:1: Epoch 3 train loss: 520248.87841796875\nINFO:root:27: Epoch 3 train loss: 6230.49169921875\nINFO:root:26: Epoch 3 train loss: 24505.697336832684\nINFO:root:5: Epoch 3 train loss: 43553.37052408854\nINFO:root:6: Epoch 3 train loss: 4875501.905710856\nINFO:root:4: Epoch 3 train loss: 2315832.7774251304\nINFO:root:33: Epoch 3 train loss: 3812029.3046875\nINFO:root:23: Epoch 3 train loss: 1356.1388346354167\nINFO:root:22: Epoch 3 train loss: 52297.02591959635\nINFO:root:0: Epoch 3 train loss: 3709.963285446167\nINFO:root:3: Epoch 3 train loss: 50659.275390625\nINFO:root:34: Epoch 3 train loss: 2137.991902669271\nINFO:root:32: Epoch 3 train loss: 5380563.852213542\nINFO:root:0: Epoch 3 validation loss: 1611161.5683710738\nINFO:root:31: Epoch 4 train loss: 3951020.6901041665\nINFO:root:5: Epoch 4 train loss: 4492464.329157512\nINFO:root:6: Epoch 4 train loss: 28707.32915242513\nINFO:root:7: Epoch 4 train loss: 7346.523793538411\nINFO:root:4: Epoch 4 train loss: 27472.329323450725\nINFO:root:25: Epoch 4 train loss: 2692143.0340169272\nINFO:root:35: Epoch 4 train loss: 4878.424723307292\nINFO:root:19: Epoch 4 train loss: 14895.249369303385\nINFO:root:23: Epoch 4 train loss: 12659.389231363932\nINFO:root:24: Epoch 4 train loss: 17625.740529378254\nINFO:root:34: Epoch 4 train loss: 917422.344950358\nINFO:root:17: Epoch 4 train loss: 7575.6606038411455\nINFO:root:16: Epoch 4 train loss: 14831.883829752604\nINFO:root:26: Epoch 4 train loss: 2672254.469807943\nINFO:root:27: Epoch 4 train loss: 2896.0484212239585\nINFO:root:0: Epoch 4 train loss: 3624.0709635416665\nINFO:root:15: Epoch 4 train loss: 143886.32877604166\nINFO:root:12: Epoch 4 train loss: 63110.495447794594\nINFO:root:1: Epoch 4 train loss: 12379.200744628906\nINFO:root:13: Epoch 4 train loss: 5318.2657470703125\nINFO:root:28: Epoch 4 train loss: 6992.234709421794\nINFO:root:29: Epoch 4 train loss: 2853.9616343180337\nINFO:root:14: Epoch 4 train loss: 13215.413607279459\nINFO:root:9: Epoch 4 train loss: 92860.40938313802\nINFO:root:21: Epoch 4 train loss: 41769.1357421875\nINFO:root:10: Epoch 4 train loss: 57065.298177083336\nINFO:root:11: Epoch 4 train loss: 923622.2919921875\nINFO:root:20: Epoch 4 train loss: 2757043.7232055664\nINFO:root:30: Epoch 4 train loss: 4880470.41377465\nINFO:root:8: Epoch 4 train loss: 10449.553629557291\nINFO:root:18: Epoch 4 train loss: 2572736.998006185\nINFO:root:2: Epoch 4 train loss: 1316.70458984375\nINFO:root:22: Epoch 4 train loss: 2571434.0528615317\nINFO:root:3: Epoch 4 train loss: 15632.828776041666\nINFO:root:32: Epoch 4 train loss: 40214.238118489586\nINFO:root:33: Epoch 4 train loss: 9206.740966796875\nINFO:root:0: Epoch 4 validation loss: 1611105.0325994415\nINFO:root:18: Epoch 5 train loss: 56048.98604329427\nINFO:root:19: Epoch 5 train loss: 979.0774345397949\nINFO:root:22: Epoch 5 train loss: 4098.43073908488\nINFO:root:23: Epoch 5 train loss: 13435.092061360678\nINFO:root:9: Epoch 5 train loss: 26223.077827453613\nINFO:root:13: Epoch 5 train loss: 120678.91739908855\nINFO:root:32: Epoch 5 train loss: 1205.822582244873\nINFO:root:14: Epoch 5 train loss: 2603.3944091796875\nINFO:root:5: Epoch 5 train loss: 21109.659749348957\nINFO:root:35: Epoch 5 train loss: 38908.501332600914\nINFO:root:10: Epoch 5 train loss: 24760.859130859375\nINFO:root:11: Epoch 5 train loss: 7166.4534912109375\nINFO:root:28: Epoch 5 train loss: 27815.97612508138\nINFO:root:15: Epoch 5 train loss: 7023.150258382161\nINFO:root:31: Epoch 5 train loss: 2765951.0130208335\nINFO:root:12: Epoch 5 train loss: 2764222.3246358237\nINFO:root:4: Epoch 5 train loss: 18604.345336914062\nINFO:root:6: Epoch 5 train loss: 2818999.0579427085\nINFO:root:20: Epoch 5 train loss: 3195141.594970703\nINFO:root:3: Epoch 5 train loss: 1342.0022048950195\nINFO:root:2: Epoch 5 train loss: 12186.38432184855\nINFO:root:17: Epoch 5 train loss: 10179.960947672525\nINFO:root:29: Epoch 5 train loss: 8802.038106282553\nINFO:root:25: Epoch 5 train loss: 15087.028025309244\nINFO:root:16: Epoch 5 train loss: 9281.331960042318\nINFO:root:27: Epoch 5 train loss: 502652.5407765706\nINFO:root:26: Epoch 5 train loss: 2573588.7195638022\nINFO:root:24: Epoch 5 train loss: 39018.092346191406\nINFO:root:8: Epoch 5 train loss: 36110.3203125\nINFO:root:33: Epoch 5 train loss: 7522.177719116211\nINFO:root:34: Epoch 5 train loss: 65962.75551859538\nINFO:root:30: Epoch 5 train loss: 5710.837504069011\nINFO:root:21: Epoch 5 train loss: 38777.41464996338\nINFO:root:7: Epoch 5 train loss: 59718.298502604164\nINFO:root:1: Epoch 5 train loss: 42412.1123046875\nINFO:root:0: Epoch 5 train loss: 70517.09423828125\nINFO:root:0: Epoch 5 validation loss: 1611040.5620248364\n", "seconds": 8.67895221710205, "batch_size": 32, "nodes": 9, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 3 batches\n1 Start Epoch 0\n2 Start Epoch 0\n2: 3 batches\n1: 3 batches\n4 Start Epoch 0\n4: 3 batches\n39 Start Epoch 0\n39: 3 batches\n5 Start Epoch 0\n6 Start Epoch 0\n5: 3 batches\n3 Start Epoch 0\n3: 3 batches\n26 Start Epoch 0\n10 Start Epoch 0\n26: 3 batches\n10: 3 batches\n25 Start Epoch 0\n6: 3 batches\n23 Start Epoch 0\n8 Start Epoch 0\n7 Start Epoch 0\n7: 3 batches\n9 Start Epoch 0\n23: 3 batches\n25: 3 batches\n17 Start Epoch 0\n8: 3 batches\n33 Start Epoch 0\n9: 3 batches\n34 Start Epoch 0\n18 Start Epoch 0\n33: 3 batches\n18: 3 batches\n15 Start Epoch 0\n31 Start Epoch 0\n31: 3 batches\n34: 3 batches\n17: 3 batches\n24 Start Epoch 0\n15: 3 batches\n24: 3 batches\n16 Start Epoch 0\n16: 3 batches\n36 Start Epoch 0\n36: 3 batches\n29 Start Epoch 0\n30 Start Epoch 0\n28 Start Epoch 0\n30: 3 batches\n29: 3 batches\n28: 3 batches\n37 Start Epoch 0\n38 Start Epoch 0\n37: 3 batches\n38: 3 batches\n12 Start Epoch 0\n20 Start Epoch 0\n14 Start Epoch 0\n12: 3 batches\n32 Start Epoch 0\n14: 3 batches\n32: 3 batches\n19 Start Epoch 0\n35 Start Epoch 0\n19: 3 batches\n27 Start Epoch 0\n11 Start Epoch 0\n20: 3 batches\n13 Start Epoch 0\n11: 3 batches\n35: 3 batches\n27: 3 batches\n13: 3 batches\n21 Start Epoch 0\n21: 3 batches\n22 Start Epoch 0\n22: 3 batches\n15 Start Epoch 1\n15: 3 batches\n5 Start Epoch 1\n6 Start Epoch 1\n4 Start Epoch 1\n4: 3 batches\n5: 3 batches\n7 Start Epoch 1\n7: 3 batches\n6: 3 batches\n31 Start Epoch 1\n31: 3 batches\n39 Start Epoch 1\n36 Start Epoch 1\n36: 3 batches\n8 Start Epoch 1\n8: 3 batches\n39: 3 batches\n16 Start Epoch 1\n18 Start Epoch 1\n17 Start Epoch 1\n17: 3 batches\n16: 3 batches\n28 Start Epoch 1\n19 Start Epoch 1\n28: 3 batches\n9 Start Epoch 1\n19: 3 batches\n9: 3 batches\n33 Start Epoch 1\n18: 3 batches\n24 Start Epoch 1\n30 Start Epoch 1\n10 Start Epoch 1\n34 Start Epoch 1\n27 Start Epoch 1\n14 Start Epoch 1\n30: 3 batches\n10: 3 batches\n33: 3 batches\n24: 3 batches\n37 Start Epoch 1\n1 Start Epoch 1\n1: 3 batches\n3 Start Epoch 1\n3: 3 batches\n13 Start Epoch 1\n34: 3 batches\n27: 3 batches\n14: 3 batches\n12 Start Epoch 1\n32 Start Epoch 1\n25 Start Epoch 1\n37: 3 batches\n25: 3 batches\n38 Start Epoch 1\n12: 3 batches\n29 Start Epoch 1\n32: 3 batches\n38: 3 batches\n13: 3 batches\n29: 3 batches\n22 Start Epoch 1\n22: 3 batches\n35 Start Epoch 1\n23 Start Epoch 1\n23: 3 batches\n26 Start Epoch 1\n35: 3 batches\n26: 3 batches\n20 Start Epoch 1\n20: 3 batches\n21 Start Epoch 1\n21: 3 batches\n2 Start Epoch 1\n2: 3 batches\n11 Start Epoch 1\n11: 3 batches\n0 Start Epoch 1\n0: 3 batches\n39 Start Epoch 2\n39: 3 batches\n28 Start Epoch 2\n28: 3 batches\n30 Start Epoch 2\n18 Start Epoch 2\n19 Start Epoch 2\n19: 3 batches\n1 Start Epoch 2\n1: 3 batches\n23 Start Epoch 2\n17 Start Epoch 2\n35 Start Epoch 2\n35: 3 batches\n23: 3 batches\n18: 3 batches\n26 Start Epoch 2\n7 Start Epoch 2\n7: 3 batches\n34 Start Epoch 2\n17: 3 batches\n26: 3 batches\n34: 3 batches\n20 Start Epoch 2\n27 Start Epoch 2\n38 Start Epoch 2\n20: 3 batches\n27: 3 batches\n36 Start Epoch 2\n14 Start Epoch 2\n15 Start Epoch 2\n33 Start Epoch 2\n38: 3 batches\n13 Start Epoch 2\n33: 3 batches\n22 Start Epoch 2\n25 Start Epoch 2\n36: 3 batches\n22: 3 batches\n25: 3 batches\n37 Start Epoch 2\n14: 3 batches\n37: 3 batches\n13: 3 batches\n24 Start Epoch 2\n12 Start Epoch 2\n12: 3 batches\n24: 3 batches\n15: 3 batches\n11 Start Epoch 2\n30: 3 batches\n11: 3 batches\n16 Start Epoch 2\n32 Start Epoch 2\n31 Start Epoch 2\n16: 3 batches\n31: 3 batches\n29 Start Epoch 2\n29: 3 batches\n3 Start Epoch 2\n3: 3 batches\n32: 3 batches\n21 Start Epoch 2\n21: 3 batches\n5 Start Epoch 2\n6 Start Epoch 2\n2 Start Epoch 2\n2: 3 batches\n4 Start Epoch 2\n4: 3 batches\n6: 3 batches\n5: 3 batches\n9 Start Epoch 2\n9: 3 batches\n10 Start Epoch 2\n10: 3 batches\n8 Start Epoch 2\n8: 3 batches\n0 Start Epoch 2\n0: 3 batches\n39 Start Epoch 3\n39: 3 batches\n15 Start Epoch 3\n12 Start Epoch 3\n12: 3 batches\n15: 3 batches\n7 Start Epoch 3\n35 Start Epoch 3\n38 Start Epoch 3\n10 Start Epoch 3\n35: 3 batches\n17 Start Epoch 3\n38: 3 batches\n13 Start Epoch 3\n7: 3 batches\n14 Start Epoch 3\n10: 3 batches\n17: 3 batches\n36 Start Epoch 3\n14: 3 batches\n6 Start Epoch 3\n31 Start Epoch 3\n11 Start Epoch 3\n16 Start Epoch 3\n36: 3 batches\n13: 3 batches\n16: 3 batches\n29 Start Epoch 3\n30 Start Epoch 3\n30: 3 batches\n29: 3 batches\n31: 3 batches\n2 Start Epoch 3\n1 Start Epoch 3\n1: 3 batches\n2: 3 batches\n11: 3 batches\n26 Start Epoch 3\n37 Start Epoch 3\n4 Start Epoch 3\n4: 3 batches\n28 Start Epoch 3\n28: 3 batches\n8 Start Epoch 3\n22 Start Epoch 3\n18 Start Epoch 3\n37: 3 batches\n32 Start Epoch 3\n23 Start Epoch 3\n18: 3 batches\n25 Start Epoch 3\n25: 3 batches\n6: 3 batches\n8: 3 batches\n5 Start Epoch 3\n5: 3 batches\n33 Start Epoch 3\n19 Start Epoch 3\n26: 3 batches\n32: 3 batches\n20 Start Epoch 3\n19: 3 batches\n27 Start Epoch 3\n27: 3 batches\n9 Start Epoch 3\n23: 3 batches\n9: 3 batches\n34 Start Epoch 3\n33: 3 batches\n20: 3 batches\n34: 3 batches\n22: 3 batches\n24 Start Epoch 3\n24: 3 batches\n21 Start Epoch 3\n21: 3 batches\n3 Start Epoch 3\n3: 3 batches\n0 Start Epoch 3\n0: 3 batches\n15 Start Epoch 4\n14 Start Epoch 4\n15: 3 batches\n14: 3 batches\n7 Start Epoch 4\n4 Start Epoch 4\n5 Start Epoch 4\n7: 3 batches\n5: 3 batches\n6 Start Epoch 4\n6: 3 batches\n4: 3 batches\n12 Start Epoch 4\n11 Start Epoch 4\n11: 3 batches\n12: 3 batches\n34 Start Epoch 4\n35 Start Epoch 4\n20 Start Epoch 4\n34: 3 batches\n35: 3 batches\n21 Start Epoch 4\n21: 3 batches\n20: 3 batches\n13 Start Epoch 4\n13: 3 batches\n3 Start Epoch 4\n39 Start Epoch 4\n39: 3 batches\n19 Start Epoch 4\n1 Start Epoch 4\n3: 3 batches\n17 Start Epoch 4\n19: 3 batches\n36 Start Epoch 4\n18 Start Epoch 4\n36: 3 batches\n38 Start Epoch 4\n18: 3 batches\n17: 3 batches\n37 Start Epoch 4\n1: 3 batches\n2 Start Epoch 4\n2: 3 batches\n38: 3 batches\n16 Start Epoch 4\n37: 3 batches\n9 Start Epoch 4\n16: 3 batches\n8 Start Epoch 4\n9: 3 batches\n8: 3 batches\n10 Start Epoch 4\n10: 3 batches\n25 Start Epoch 4\n25: 3 batches\n32 Start Epoch 4\n33 Start Epoch 4\n23 Start Epoch 4\n31 Start Epoch 4\n31: 3 batches\n33: 3 batches\n23: 3 batches\n32: 3 batches\n30 Start Epoch 4\n24 Start Epoch 4\n30: 3 batches\n24: 3 batches\n26 Start Epoch 4\n28 Start Epoch 4\n26: 3 batches\n29 Start Epoch 4\n28: 3 batches\n29: 3 batches\n22 Start Epoch 4\n22: 3 batches\n27 Start Epoch 4\n27: 3 batches\n0 Start Epoch 4\n0: 3 batches\n15 Start Epoch 5\n15: 3 batches\n19 Start Epoch 5\n19: 3 batches\n20 Start Epoch 5\n20: 3 batches\n8 Start Epoch 5\n21 Start Epoch 5\n11 Start Epoch 5\n8: 3 batches\n11: 3 batches\n35 Start Epoch 5\n21: 3 batches\n35: 3 batches\n22 Start Epoch 5\n27 Start Epoch 5\n29 Start Epoch 5\n31 Start Epoch 5\n22: 3 batches\n24 Start Epoch 5\n29: 3 batches\n31: 3 batches\n10 Start Epoch 5\n23 Start Epoch 5\n26 Start Epoch 5\n10: 3 batches\n26: 3 batches\n27: 3 batches\n7 Start Epoch 5\n7: 3 batches\n24: 3 batches\n23: 3 batches\n6 Start Epoch 5\n6: 3 batches\n30 Start Epoch 5\n5 Start Epoch 5\n5: 3 batches\n1 Start Epoch 5\n1: 3 batches\n3 Start Epoch 5\n3: 3 batches\n30: 3 batches\n9 Start Epoch 5\n33 Start Epoch 5\n16 Start Epoch 5\n25 Start Epoch 5\n39 Start Epoch 5\n39: 3 batches\n13 Start Epoch 5\n4 Start Epoch 5\n16: 3 batches\n25: 3 batches\n13: 3 batches\n4: 3 batches\n28 Start Epoch 5\n9: 3 batches\n33: 3 batches\n28: 3 batches\n37 Start Epoch 5\n37: 3 batches\n32 Start Epoch 5\n18 Start Epoch 5\n14 Start Epoch 5\n14: 3 batches\n32: 3 batches\n18: 3 batches\n12 Start Epoch 5\n17 Start Epoch 5\n34 Start Epoch 5\n34: 3 batches\n17: 3 batches\n12: 3 batches\n2 Start Epoch 5\n2: 3 batches\n36 Start Epoch 5\n36: 3 batches\n38 Start Epoch 5\n38: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:15: Epoch 0 train loss: 2769454.6914876304\nINFO:root:7: Epoch 0 train loss: 3388.201700846354\nINFO:root:4: Epoch 0 train loss: 2653592.6834309897\nINFO:root:6: Epoch 0 train loss: 3706.4275919596353\nINFO:root:5: Epoch 0 train loss: 3107.6709270477295\nINFO:root:36: Epoch 0 train loss: 2574252.751546224\nINFO:root:31: Epoch 0 train loss: 5782.034098307292\nINFO:root:19: Epoch 0 train loss: 16246.276285807291\nINFO:root:16: Epoch 0 train loss: 95832.82554626465\nINFO:root:39: Epoch 0 train loss: 299379.5156059265\nINFO:root:8: Epoch 0 train loss: 15580.127400716146\nINFO:root:18: Epoch 0 train loss: 38833.73771158854\nINFO:root:21: Epoch 0 train loss: 4123.604278564453\nINFO:root:17: Epoch 0 train loss: 2766460.7300079665\nINFO:root:28: Epoch 0 train loss: 327.86956787109375\nINFO:root:9: Epoch 0 train loss: 3192611.632904291\nINFO:root:27: Epoch 0 train loss: 71482.7315266927\nINFO:root:34: Epoch 0 train loss: 309464.3721923828\nINFO:root:33: Epoch 0 train loss: 13658.725423177084\nINFO:root:24: Epoch 0 train loss: 13419.365407307943\nINFO:root:14: Epoch 0 train loss: 31216.548400878906\nINFO:root:12: Epoch 0 train loss: 930.933650970459\nINFO:root:30: Epoch 0 train loss: 1629.4415232340496\nINFO:root:10: Epoch 0 train loss: 8223.306465148926\nINFO:root:13: Epoch 0 train loss: 670.9685567220052\nINFO:root:37: Epoch 0 train loss: 3522.231877644857\nINFO:root:3: Epoch 0 train loss: 2824.4624837239585\nINFO:root:0: Epoch 0 train loss: 2687887.285888672\nINFO:root:1: Epoch 0 train loss: 8039.178895950317\nINFO:root:32: Epoch 0 train loss: 4965304.020380656\nINFO:root:25: Epoch 0 train loss: 74217.42724609375\nINFO:root:38: Epoch 0 train loss: 1640.215797106425\nINFO:root:29: Epoch 0 train loss: 11066.672083377838\nINFO:root:20: Epoch 0 train loss: 12930.763743082682\nINFO:root:26: Epoch 0 train loss: 2939158.24609375\nINFO:root:35: Epoch 0 train loss: 2566976.941602429\nINFO:root:22: Epoch 0 train loss: 11223.098063151041\nINFO:root:23: Epoch 0 train loss: 2872.668416341146\nINFO:root:2: Epoch 0 train loss: 17546.136271158855\nINFO:root:11: Epoch 0 train loss: 2565858.333719889\nINFO:root:0: Epoch 0 validation loss: 604624.450104127\nINFO:root:39: Epoch 1 train loss: 2686192.236541748\nINFO:root:28: Epoch 1 train loss: 2298629.302543958\nINFO:root:30: Epoch 1 train loss: 2637079.5143229165\nINFO:root:19: Epoch 1 train loss: 4120.137044270833\nINFO:root:18: Epoch 1 train loss: 1935.6581420898438\nINFO:root:0: Epoch 1 train loss: 20060.31591796875\nINFO:root:1: Epoch 1 train loss: 25073.760208129883\nINFO:root:35: Epoch 1 train loss: 902274.733955721\nINFO:root:23: Epoch 1 train loss: 2547.4957275390625\nINFO:root:17: Epoch 1 train loss: 8170.623534520467\nINFO:root:27: Epoch 1 train loss: 2167448.074371338\nINFO:root:13: Epoch 1 train loss: 23758.045572916668\nINFO:root:7: Epoch 1 train loss: 33161.63296508789\nINFO:root:34: Epoch 1 train loss: 12100.448750813803\nINFO:root:26: Epoch 1 train loss: 23075.773396809895\nINFO:root:38: Epoch 1 train loss: 2167934.974609375\nINFO:root:37: Epoch 1 train loss: 3017.5445149739585\nINFO:root:14: Epoch 1 train loss: 645.8070576985677\nINFO:root:20: Epoch 1 train loss: 32391.466300964355\nINFO:root:36: Epoch 1 train loss: 198.55791219075522\nINFO:root:12: Epoch 1 train loss: 2304911.214515368\nINFO:root:15: Epoch 1 train loss: 147844.6873372396\nINFO:root:33: Epoch 1 train loss: 7466380.908162435\nINFO:root:22: Epoch 1 train loss: 12791.41268157959\nINFO:root:25: Epoch 1 train loss: 258533.7596435547\nINFO:root:24: Epoch 1 train loss: 658.8142293294271\nINFO:root:11: Epoch 1 train loss: 89563.35481770833\nINFO:root:32: Epoch 1 train loss: 95667.02258300781\nINFO:root:16: Epoch 1 train loss: 6315373.991574605\nINFO:root:31: Epoch 1 train loss: 13545.43021774292\nINFO:root:29: Epoch 1 train loss: 142.78748067220053\nINFO:root:3: Epoch 1 train loss: 9412.576090494791\nINFO:root:21: Epoch 1 train loss: 2773156.6963144937\nINFO:root:4: Epoch 1 train loss: 548.1289456685384\nINFO:root:6: Epoch 1 train loss: 2178121.6015930176\nINFO:root:5: Epoch 1 train loss: 24693.342122395832\nINFO:root:2: Epoch 1 train loss: 6729.1434237162275\nINFO:root:9: Epoch 1 train loss: 8443.215309143066\nINFO:root:10: Epoch 1 train loss: 22763.231363932293\nINFO:root:8: Epoch 1 train loss: 4372.280436197917\nINFO:root:0: Epoch 1 validation loss: 604597.2605727006\nINFO:root:39: Epoch 2 train loss: 6098.654467900594\nINFO:root:12: Epoch 2 train loss: 8822.14306640625\nINFO:root:15: Epoch 2 train loss: 13482.348429361979\nINFO:root:7: Epoch 2 train loss: 7211.109514872233\nINFO:root:11: Epoch 2 train loss: 11728.217484792074\nINFO:root:35: Epoch 2 train loss: 11566.20352681478\nINFO:root:16: Epoch 2 train loss: 2302523.0808156333\nINFO:root:38: Epoch 2 train loss: 12623.482971191406\nINFO:root:13: Epoch 2 train loss: 9389.356791178385\nINFO:root:14: Epoch 2 train loss: 22531.494883219402\nINFO:root:10: Epoch 2 train loss: 2170717.6162516274\nINFO:root:17: Epoch 2 train loss: 1211.0696754455566\nINFO:root:30: Epoch 2 train loss: 15860.981953938803\nINFO:root:6: Epoch 2 train loss: 904582.7956136068\nINFO:root:31: Epoch 2 train loss: 1829.1580505371094\nINFO:root:36: Epoch 2 train loss: 90911.25130208333\nINFO:root:29: Epoch 2 train loss: 3235241.2356770835\nINFO:root:0: Epoch 2 train loss: 6917.2854587038355\nINFO:root:2: Epoch 2 train loss: 19456.910071142018\nINFO:root:1: Epoch 2 train loss: 5366.163772583008\nINFO:root:3: Epoch 2 train loss: 27636.633875528973\nINFO:root:26: Epoch 2 train loss: 9915.145582040152\nINFO:root:37: Epoch 2 train loss: 21085.898619333904\nINFO:root:4: Epoch 2 train loss: 24660.332451502483\nINFO:root:28: Epoch 2 train loss: 2299966.7846679688\nINFO:root:32: Epoch 2 train loss: 4750.968566894531\nINFO:root:23: Epoch 2 train loss: 9470.932577768961\nINFO:root:18: Epoch 2 train loss: 44103.36999511719\nINFO:root:34: Epoch 2 train loss: 13862.199055989584\nINFO:root:20: Epoch 2 train loss: 2067.2984415690103\nINFO:root:19: Epoch 2 train loss: 51563.911376953125\nINFO:root:8: Epoch 2 train loss: 4025.0928522745767\nINFO:root:5: Epoch 2 train loss: 166967.06477864584\nINFO:root:33: Epoch 2 train loss: 475.9561290740967\nINFO:root:25: Epoch 2 train loss: 21557.33307647705\nINFO:root:9: Epoch 2 train loss: 29319.129465738934\nINFO:root:22: Epoch 2 train loss: 7474317.6956380205\nINFO:root:27: Epoch 2 train loss: 19273.395095825195\nINFO:root:24: Epoch 2 train loss: 34678.32350667318\nINFO:root:21: Epoch 2 train loss: 2575661.357079824\nINFO:root:0: Epoch 2 validation loss: 604568.6793558645\nINFO:root:15: Epoch 3 train loss: 9509.320539156595\nINFO:root:14: Epoch 3 train loss: 34658.17826334635\nINFO:root:6: Epoch 3 train loss: 2904.4100748697915\nINFO:root:7: Epoch 3 train loss: 27783.165349324543\nINFO:root:5: Epoch 3 train loss: 94024.73727162679\nINFO:root:4: Epoch 3 train loss: 2585030.842692057\nINFO:root:12: Epoch 3 train loss: 1160.824917793274\nINFO:root:11: Epoch 3 train loss: 7576.066825866699\nINFO:root:35: Epoch 3 train loss: 11925.640228271484\nINFO:root:34: Epoch 3 train loss: 10660372.805338541\nINFO:root:21: Epoch 3 train loss: 15719.081359863281\nINFO:root:20: Epoch 3 train loss: 3395.8609059651694\nINFO:root:19: Epoch 3 train loss: 299700.72386487323\nINFO:root:0: Epoch 3 train loss: 3910.4427693684897\nINFO:root:13: Epoch 3 train loss: 1869.8257344563801\nINFO:root:3: Epoch 3 train loss: 35813.836588541664\nINFO:root:17: Epoch 3 train loss: 5829.751434326172\nINFO:root:1: Epoch 3 train loss: 2754250.069915136\nINFO:root:39: Epoch 3 train loss: 16962.344482421875\nINFO:root:36: Epoch 3 train loss: 10434.76782989502\nINFO:root:18: Epoch 3 train loss: 45466.98186238607\nINFO:root:38: Epoch 3 train loss: 7597.351504007976\nINFO:root:37: Epoch 3 train loss: 10398.447682698568\nINFO:root:10: Epoch 3 train loss: 2680113.662763357\nINFO:root:2: Epoch 3 train loss: 13930.385720570883\nINFO:root:9: Epoch 3 train loss: 37297.38671875\nINFO:root:16: Epoch 3 train loss: 878362.8870442709\nINFO:root:8: Epoch 3 train loss: 17047.83350054423\nINFO:root:25: Epoch 3 train loss: 3069368.980794271\nINFO:root:32: Epoch 3 train loss: 2898290.0073242188\nINFO:root:31: Epoch 3 train loss: 2573197.9555664062\nINFO:root:33: Epoch 3 train loss: 14263.754887898764\nINFO:root:30: Epoch 3 train loss: 6494.241574764252\nINFO:root:23: Epoch 3 train loss: 3737.526092529297\nINFO:root:24: Epoch 3 train loss: 3210601.277741114\nINFO:root:29: Epoch 3 train loss: 9821.800004323324\nINFO:root:26: Epoch 3 train loss: 44856.78149292866\nINFO:root:28: Epoch 3 train loss: 58410.524739583336\nINFO:root:22: Epoch 3 train loss: 13438.677974303564\nINFO:root:27: Epoch 3 train loss: 35584.84378051758\nINFO:root:0: Epoch 3 validation loss: 604536.3616229879\nINFO:root:15: Epoch 4 train loss: 12517.147644042969\nINFO:root:19: Epoch 4 train loss: 1267.6270573933919\nINFO:root:21: Epoch 4 train loss: 150316.3243815104\nINFO:root:20: Epoch 4 train loss: 26697.952962239582\nINFO:root:11: Epoch 4 train loss: 11606.385435581207\nINFO:root:8: Epoch 4 train loss: 15079.512379964193\nINFO:root:31: Epoch 4 train loss: 8858.517496744791\nINFO:root:26: Epoch 4 train loss: 1255.7652384440105\nINFO:root:35: Epoch 4 train loss: 3195746.058125814\nINFO:root:22: Epoch 4 train loss: 8918.763044436773\nINFO:root:27: Epoch 4 train loss: 6796.597188313802\nINFO:root:29: Epoch 4 train loss: 61048.58932495117\nINFO:root:10: Epoch 4 train loss: 9117.297241210938\nINFO:root:23: Epoch 4 train loss: 34689.67150878906\nINFO:root:24: Epoch 4 train loss: 9507.206128438314\nINFO:root:7: Epoch 4 train loss: 5228.3386637369795\nINFO:root:30: Epoch 4 train loss: 24165.132161458332\nINFO:root:6: Epoch 4 train loss: 2331122.676106771\nINFO:root:5: Epoch 4 train loss: 2122.640380859375\nINFO:root:1: Epoch 4 train loss: 19601.969797770184\nINFO:root:3: Epoch 4 train loss: 6677.834615071614\nINFO:root:16: Epoch 4 train loss: 3755741.2475585938\nINFO:root:25: Epoch 4 train loss: 47500.331380208336\nINFO:root:39: Epoch 4 train loss: 5085.486634572347\nINFO:root:13: Epoch 4 train loss: 901905.1863263448\nINFO:root:4: Epoch 4 train loss: 11330.510306561986\nINFO:root:9: Epoch 4 train loss: 2773261.8939208984\nINFO:root:33: Epoch 4 train loss: 1000.0584840774536\nINFO:root:28: Epoch 4 train loss: 2169.0953165690103\nINFO:root:37: Epoch 4 train loss: 322.80430857340497\nINFO:root:32: Epoch 4 train loss: 16150.079994837442\nINFO:root:18: Epoch 4 train loss: 3858.7322438557944\nINFO:root:14: Epoch 4 train loss: 24464.175699869793\nINFO:root:36: Epoch 4 train loss: 33044.196005503334\nINFO:root:34: Epoch 4 train loss: 1324.3525085449219\nINFO:root:17: Epoch 4 train loss: 12943.288655598959\nINFO:root:12: Epoch 4 train loss: 30293.44551595052\nINFO:root:2: Epoch 4 train loss: 17445.186848958332\nINFO:root:38: Epoch 4 train loss: 70909.21809895833\nINFO:root:0: Epoch 4 train loss: 946107.0735677084\nINFO:root:0: Epoch 4 validation loss: 604500.2999245024\nINFO:root:7: Epoch 5 train loss: 403.40598551432294\nINFO:root:39: Epoch 5 train loss: 220.93724060058594\nINFO:root:8: Epoch 5 train loss: 69429.19189453125\nINFO:root:9: Epoch 5 train loss: 4209.809743245442\nINFO:root:19: Epoch 5 train loss: 2665054.0978800454\nINFO:root:38: Epoch 5 train loss: 3204166.051109314\nINFO:root:36: Epoch 5 train loss: 80077.2366027832\nINFO:root:37: Epoch 5 train loss: 14764.240224202475\nINFO:root:21: Epoch 5 train loss: 24741.690287272137\nINFO:root:20: Epoch 5 train loss: 21677.562337239582\nINFO:root:14: Epoch 5 train loss: 12024.786549886068\nINFO:root:15: Epoch 5 train loss: 2709.0711099505424\nINFO:root:13: Epoch 5 train loss: 18563.335441589355\nINFO:root:12: Epoch 5 train loss: 22348.441813151043\nINFO:root:0: Epoch 5 train loss: 21610.907104492188\nINFO:root:2: Epoch 5 train loss: 29405.779042561848\nINFO:root:6: Epoch 5 train loss: 2176785.9886746407\nINFO:root:4: Epoch 5 train loss: 6302.238475600879\nINFO:root:3: Epoch 5 train loss: 2772161.950439453\nINFO:root:1: Epoch 5 train loss: 26129.6259765625\nINFO:root:23: Epoch 5 train loss: 2668344.183268229\nINFO:root:17: Epoch 5 train loss: 49724.69140625\nINFO:root:24: Epoch 5 train loss: 20445.700340270996\nINFO:root:5: Epoch 5 train loss: 61216.671549479164\nINFO:root:28: Epoch 5 train loss: 217097.87044270834\nINFO:root:10: Epoch 5 train loss: 902732.3928019205\nINFO:root:35: Epoch 5 train loss: 52698.911458333336\nINFO:root:29: Epoch 5 train loss: 2755730.344645182\nINFO:root:11: Epoch 5 train loss: 2687.3041076660156\nINFO:root:34: Epoch 5 train loss: 2719.4144694010415\nINFO:root:22: Epoch 5 train loss: 13045.757804870605\nINFO:root:18: Epoch 5 train loss: 19811.32048543294\nINFO:root:25: Epoch 5 train loss: 1002.6220906575521\nINFO:root:27: Epoch 5 train loss: 2757633.6130371094\nINFO:root:31: Epoch 5 train loss: 17903.008934020996\nINFO:root:16: Epoch 5 train loss: 13063.557454427084\nINFO:root:30: Epoch 5 train loss: 9285821.596506754\nINFO:root:26: Epoch 5 train loss: 30636.621948242188\nINFO:root:33: Epoch 5 train loss: 6681373.695053101\nINFO:root:32: Epoch 5 train loss: 22428.358828226726\nINFO:root:0: Epoch 5 validation loss: 604458.4112410625\n", "seconds": 8.823235988616943, "batch_size": 32, "nodes": 10, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 3 batches\n1 Start Epoch 0\n2 Start Epoch 0\n2: 3 batches\n1: 3 batches\n4 Start Epoch 0\n4: 3 batches\n3 Start Epoch 0\n3: 3 batches\n7 Start Epoch 0\n7: 3 batches\n8 Start Epoch 0\n8: 3 batches\n39 Start Epoch 0\n39: 3 batches\n43 Start Epoch 0\n43: 3 batches\n32 Start Epoch 0\n31 Start Epoch 0\n23 Start Epoch 0\n24 Start Epoch 0\n16 Start Epoch 0\n24: 3 batches\n16: 3 batches\n32: 3 batches\n5 Start Epoch 0\n31: 3 batches\n15 Start Epoch 0\n23: 3 batches\n40 Start Epoch 0\n6 Start Epoch 0\n15: 3 batches\n40: 3 batches\n5: 3 batches\n6: 3 batches\n36 Start Epoch 0\n36: 3 batches\n12 Start Epoch 0\n12: 3 batches\n20 Start Epoch 0\n28 Start Epoch 0\n19 Start Epoch 0\n28: 3 batches\n20: 3 batches\n27 Start Epoch 0\n11 Start Epoch 0\n27: 3 batches\n19: 3 batches\n35 Start Epoch 0\n35: 3 batches\n10 Start Epoch 0\n9 Start Epoch 0\n9: 3 batches\n10: 3 batches\n11: 3 batches\n17 Start Epoch 0\n18 Start Epoch 0\n33 Start Epoch 0\n34 Start Epoch 0\n17: 3 batches\n18: 3 batches\n34: 3 batches\n33: 3 batches\n37 Start Epoch 0\n38 Start Epoch 0\n37: 3 batches\n38: 3 batches\n41 Start Epoch 0\n25 Start Epoch 0\n42 Start Epoch 0\n26 Start Epoch 0\n29 Start Epoch 0\n14 Start Epoch 0\n21 Start Epoch 0\n41: 3 batches\n22 Start Epoch 0\n42: 3 batches\n26: 3 batches\n30 Start Epoch 0\n13 Start Epoch 0\n14: 3 batches\n21: 3 batches\n25: 3 batches\n29: 3 batches\n30: 3 batches\n13: 3 batches\n22: 3 batches\n7 Start Epoch 1\n15 Start Epoch 1\n6 Start Epoch 1\n15: 3 batches\n6: 3 batches\n7: 3 batches\n5 Start Epoch 1\n8 Start Epoch 1\n26 Start Epoch 1\n14 Start Epoch 1\n23 Start Epoch 1\n14: 3 batches\n23: 3 batches\n8: 3 batches\n26: 3 batches\n4 Start Epoch 1\n4: 3 batches\n5: 3 batches\n29 Start Epoch 1\n28 Start Epoch 1\n17 Start Epoch 1\n29: 3 batches\n17: 3 batches\n28: 3 batches\n3 Start Epoch 1\n3: 3 batches\n25 Start Epoch 1\n25: 3 batches\n13 Start Epoch 1\n13: 3 batches\n24 Start Epoch 1\n24: 3 batches\n16 Start Epoch 1\n27 Start Epoch 1\n27: 3 batches\n18 Start Epoch 1\n10 Start Epoch 1\n18: 3 batches\n10: 3 batches\n16: 3 batches\n20 Start Epoch 1\n22 Start Epoch 1\n19 Start Epoch 1\n21 Start Epoch 1\n22: 3 batches\n21: 3 batches\n20: 3 batches\n12 Start Epoch 1\n11 Start Epoch 1\n11: 3 batches\n12: 3 batches\n9 Start Epoch 1\n9: 3 batches\n35 Start Epoch 1\n35: 3 batches\n34 Start Epoch 1\n34: 3 batches\n2 Start Epoch 1\n2: 3 batches\n1 Start Epoch 1\n1: 3 batches\n19: 3 batches\n33 Start Epoch 1\n36 Start Epoch 1\n30 Start Epoch 1\n41 Start Epoch 1\n33: 3 batches\n31 Start Epoch 1\n36: 3 batches\n43 Start Epoch 1\n32 Start Epoch 1\n31: 3 batches\n41: 3 batches\n43: 3 batches\n32: 3 batches\n30: 3 batches\n39 Start Epoch 1\n39: 3 batches\n40 Start Epoch 1\n37 Start Epoch 1\n37: 3 batches\n40: 3 batches\n38 Start Epoch 1\n42 Start Epoch 1\n38: 3 batches\n42: 3 batches\n0 Start Epoch 1\n0: 3 batches\n15 Start Epoch 2\n15: 3 batches\n23 Start Epoch 2\n4 Start Epoch 2\n12 Start Epoch 2\n23: 3 batches\n7 Start Epoch 2\n14 Start Epoch 2\n4: 3 batches\n12: 3 batches\n7: 3 batches\n35 Start Epoch 2\n35: 3 batches\n5 Start Epoch 2\n5: 3 batches\n1 Start Epoch 2\n1: 3 batches\n3 Start Epoch 2\n3: 3 batches\n14: 3 batches\n43 Start Epoch 2\n18 Start Epoch 2\n6 Start Epoch 2\n6: 3 batches\n37 Start Epoch 2\n43: 3 batches\n11 Start Epoch 2\n17 Start Epoch 2\n10 Start Epoch 2\n26 Start Epoch 2\n19 Start Epoch 2\n32 Start Epoch 2\n30 Start Epoch 2\n36 Start Epoch 2\n13 Start Epoch 2\n20 Start Epoch 2\n8 Start Epoch 2\n26: 3 batches\n19: 3 batches\n32: 3 batches\n31 Start Epoch 2\n37: 3 batches\n13: 3 batches\n22 Start Epoch 2\n41 Start Epoch 2\n10: 3 batches\n18: 3 batches\n34 Start Epoch 2\n31: 3 batches\n36: 3 batches\n16 Start Epoch 2\n34: 3 batches\n39 Start Epoch 2\n20: 3 batches\n41: 3 batches\n8: 3 batches\n27 Start Epoch 2\n16: 3 batches\n29 Start Epoch 2\n21 Start Epoch 2\n11: 3 batches\n27: 3 batches\n21: 3 batches\n17: 3 batches\n33 Start Epoch 2\n29: 3 batches\n39: 3 batches\n22: 3 batches\n9 Start Epoch 2\n9: 3 batches\n25 Start Epoch 2\n33: 3 batches\n24 Start Epoch 2\n38 Start Epoch 2\n38: 3 batches\n42 Start Epoch 2\n24: 3 batches\n25: 3 batches\n2 Start Epoch 2\n2: 3 batches\n40 Start Epoch 2\n28 Start Epoch 2\n28: 3 batches\n42: 3 batches\n40: 3 batches\n30: 3 batches\n0 Start Epoch 2\n0: 3 batches\n2 Start Epoch 3\n3 Start Epoch 3\n3: 3 batches\n2: 3 batches\n7 Start Epoch 3\n15 Start Epoch 3\n9 Start Epoch 3\n26 Start Epoch 3\n35 Start Epoch 3\n23 Start Epoch 3\n42 Start Epoch 3\n17 Start Epoch 3\n35: 3 batches\n7: 3 batches\n38 Start Epoch 3\n15: 3 batches\n16 Start Epoch 3\n16: 3 batches\n29 Start Epoch 3\n39 Start Epoch 3\n31 Start Epoch 3\n39: 3 batches\n17: 3 batches\n30 Start Epoch 3\n38: 3 batches\n5 Start Epoch 3\n31: 3 batches\n12 Start Epoch 3\n6 Start Epoch 3\n30: 3 batches\n13 Start Epoch 3\n13: 3 batches\n29: 3 batches\n12: 3 batches\n4 Start Epoch 3\n5: 3 batches\n14 Start Epoch 3\n28 Start Epoch 3\n4: 3 batches\n28: 3 batches\n6: 3 batches\n37 Start Epoch 3\n36 Start Epoch 3\n36: 3 batches\n37: 3 batches\n22 Start Epoch 3\n21 Start Epoch 3\n21: 3 batches\n20 Start Epoch 3\n20: 3 batches\n33 Start Epoch 3\n23: 3 batches\n19 Start Epoch 3\n33: 3 batches\n34 Start Epoch 3\n34: 3 batches\n18 Start Epoch 3\n32 Start Epoch 3\n32: 3 batches\n19: 3 batches\n18: 3 batches\n22: 3 batches\n8 Start Epoch 3\n8: 3 batches\n10 Start Epoch 3\n10: 3 batches\n9: 3 batches\n11 Start Epoch 3\n1 Start Epoch 3\n11: 3 batches\n14: 3 batches\n1: 3 batches\n40 Start Epoch 3\n40: 3 batches\n43 Start Epoch 3\n43: 3 batches\n41 Start Epoch 3\n41: 3 batches\n42: 3 batches\n26: 3 batches\n27 Start Epoch 3\n27: 3 batches\n24 Start Epoch 3\n24: 3 batches\n25 Start Epoch 3\n25: 3 batches\n0 Start Epoch 3\n0: 3 batches\n7 Start Epoch 4\n7: 3 batches\n3 Start Epoch 4\n2 Start Epoch 4\n3: 3 batches\n2: 3 batches\n43 Start Epoch 4\n38 Start Epoch 4\n35 Start Epoch 4\n36 Start Epoch 4\n15 Start Epoch 4\n20 Start Epoch 4\n34 Start Epoch 4\n5 Start Epoch 4\n13 Start Epoch 4\n20: 3 batches\n40 Start Epoch 4\n40: 3 batches\n9 Start Epoch 4\n18 Start Epoch 4\n34: 3 batches\n6 Start Epoch 4\n36: 3 batches\n15: 3 batches\n21 Start Epoch 4\n38: 3 batches\n13: 3 batches\n21: 3 batches\n11 Start Epoch 4\n19 Start Epoch 4\n19: 3 batches\n35: 3 batches\n5: 3 batches\n8 Start Epoch 4\n17 Start Epoch 4\n4 Start Epoch 4\n14 Start Epoch 4\n42 Start Epoch 4\n39 Start Epoch 4\n42: 3 batches\n9: 3 batches\n18: 3 batches\n16 Start Epoch 4\n32 Start Epoch 4\n39: 3 batches\n14: 3 batches\n8: 3 batches\n10 Start Epoch 4\n16: 3 batches\n33 Start Epoch 4\n6: 3 batches\n37 Start Epoch 4\n12 Start Epoch 4\n41 Start Epoch 4\n10: 3 batches\n17: 3 batches\n32: 3 batches\n4: 3 batches\n33: 3 batches\n37: 3 batches\n12: 3 batches\n43: 3 batches\n11: 3 batches\n30 Start Epoch 4\n30: 3 batches\n31 Start Epoch 4\n31: 3 batches\n22 Start Epoch 4\n23 Start Epoch 4\n22: 3 batches\n27 Start Epoch 4\n27: 3 batches\n25 Start Epoch 4\n25: 3 batches\n23: 3 batches\n26 Start Epoch 4\n26: 3 batches\n41: 3 batches\n28 Start Epoch 4\n24 Start Epoch 4\n29 Start Epoch 4\n28: 3 batches\n29: 3 batches\n24: 3 batches\n1 Start Epoch 4\n1: 3 batches\n0 Start Epoch 4\n0: 3 batches\n15 Start Epoch 5\n15: 3 batches\n7 Start Epoch 5\n7: 3 batches\n35 Start Epoch 5\n35: 3 batches\n23 Start Epoch 5\n11 Start Epoch 5\n11: 3 batches\n19 Start Epoch 5\n16 Start Epoch 5\n3 Start Epoch 5\n3: 3 batches\n19: 3 batches\n16: 3 batches\n5 Start Epoch 5\n38 Start Epoch 5\n38: 3 batches\n13 Start Epoch 5\n43 Start Epoch 5\n32 Start Epoch 5\n6 Start Epoch 5\n28 Start Epoch 5\n14 Start Epoch 5\n42 Start Epoch 5\n17 Start Epoch 5\n34 Start Epoch 5\n5: 3 batches\n14: 3 batches\n42: 3 batches\n24 Start Epoch 5\n34: 3 batches\n4 Start Epoch 5\n31 Start Epoch 5\n43: 3 batches\n25 Start Epoch 5\n18 Start Epoch 5\n33 Start Epoch 5\n4: 3 batches\n31: 3 batches\n13: 3 batches\n18: 3 batches\n32: 3 batches\n6: 3 batches\n28: 3 batches\n12 Start Epoch 5\n36 Start Epoch 5\n12: 3 batches\n20 Start Epoch 5\n27 Start Epoch 5\n17: 3 batches\n33: 3 batches\n30 Start Epoch 5\n30: 3 batches\n36: 3 batches\n21 Start Epoch 5\n25: 3 batches\n20: 3 batches\n26 Start Epoch 5\n22 Start Epoch 5\n9 Start Epoch 5\n24: 3 batches\n22: 3 batches\n39 Start Epoch 5\n23: 3 batches\n8 Start Epoch 5\n27: 3 batches\n37 Start Epoch 5\n21: 3 batches\n40 Start Epoch 5\n9: 3 batches\n26: 3 batches\n41 Start Epoch 5\n8: 3 batches\n39: 3 batches\n10 Start Epoch 5\n10: 3 batches\n2 Start Epoch 5\n2: 3 batches\n40: 3 batches\n37: 3 batches\n41: 3 batches\n29 Start Epoch 5\n29: 3 batches\n1 Start Epoch 5\n1: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:6: Epoch 0 train loss: 3738.7534624735513\nINFO:root:7: Epoch 0 train loss: 1823.7510986328125\nINFO:root:15: Epoch 0 train loss: 23536.713034265744\nINFO:root:14: Epoch 0 train loss: 1581.0623012909007\nINFO:root:23: Epoch 0 train loss: 9060.330668632252\nINFO:root:8: Epoch 0 train loss: 23554.094014485676\nINFO:root:26: Epoch 0 train loss: 96083.91796875\nINFO:root:4: Epoch 0 train loss: 3933.026123046875\nINFO:root:5: Epoch 0 train loss: 2312557.6912924447\nINFO:root:28: Epoch 0 train loss: 2632405.690265558\nINFO:root:29: Epoch 0 train loss: 4086.9437154134116\nINFO:root:17: Epoch 0 train loss: 26128.584879557293\nINFO:root:3: Epoch 0 train loss: 2755591.2094756695\nINFO:root:25: Epoch 0 train loss: 657.2432559331259\nINFO:root:13: Epoch 0 train loss: 10379.868825276693\nINFO:root:24: Epoch 0 train loss: 43805.34200378747\nINFO:root:16: Epoch 0 train loss: 20345.14250322183\nINFO:root:27: Epoch 0 train loss: 41719.794386198126\nINFO:root:18: Epoch 0 train loss: 4990.244486490886\nINFO:root:10: Epoch 0 train loss: 5881.71875\nINFO:root:11: Epoch 0 train loss: 64241.162109375\nINFO:root:20: Epoch 0 train loss: 3436.4070638020835\nINFO:root:22: Epoch 0 train loss: 5309.160970052083\nINFO:root:21: Epoch 0 train loss: 1361.6210919221242\nINFO:root:19: Epoch 0 train loss: 2771143.344807943\nINFO:root:12: Epoch 0 train loss: 2957.495485941569\nINFO:root:9: Epoch 0 train loss: 2144.2162321681776\nINFO:root:34: Epoch 0 train loss: 2916.747802734375\nINFO:root:35: Epoch 0 train loss: 24468.943738937378\nINFO:root:0: Epoch 0 train loss: 3202502.4207104817\nINFO:root:1: Epoch 0 train loss: 1400.2264811197917\nINFO:root:2: Epoch 0 train loss: 21663.238569895428\nINFO:root:33: Epoch 0 train loss: 27342.328014890354\nINFO:root:30: Epoch 0 train loss: 2298218.263048013\nINFO:root:36: Epoch 0 train loss: 509.01463381449383\nINFO:root:43: Epoch 0 train loss: 4410.119213740031\nINFO:root:41: Epoch 0 train loss: 2061.910568942452\nINFO:root:31: Epoch 0 train loss: 57893.164713541664\nINFO:root:37: Epoch 0 train loss: 8669.975072224936\nINFO:root:32: Epoch 0 train loss: 29242.93091392517\nINFO:root:39: Epoch 0 train loss: 2206.0644137064614\nINFO:root:40: Epoch 0 train loss: 486.35996500651044\nINFO:root:38: Epoch 0 train loss: 2357172.7626425424\nINFO:root:42: Epoch 0 train loss: 4084.9871213038764\nINFO:root:0: Epoch 0 validation loss: 210375.67289465055\nINFO:root:15: Epoch 1 train loss: 2168060.8087361655\nINFO:root:23: Epoch 1 train loss: 43441.59627278646\nINFO:root:12: Epoch 1 train loss: 7234.818372196362\nINFO:root:7: Epoch 1 train loss: 4082.736675262451\nINFO:root:4: Epoch 1 train loss: 6917.627848307292\nINFO:root:14: Epoch 1 train loss: 2411.568038131188\nINFO:root:35: Epoch 1 train loss: 96.63773212818585\nINFO:root:5: Epoch 1 train loss: 7737.363762040933\nINFO:root:19: Epoch 1 train loss: 5836.787898589547\nINFO:root:18: Epoch 1 train loss: 56433.979095458984\nINFO:root:11: Epoch 1 train loss: 8995.160359700521\nINFO:root:16: Epoch 1 train loss: 11076.995466868082\nINFO:root:1: Epoch 1 train loss: 20002.1318359375\nINFO:root:0: Epoch 1 train loss: 184071.31290690103\nINFO:root:3: Epoch 1 train loss: 3388.2188133232607\nINFO:root:10: Epoch 1 train loss: 14336.916225969791\nINFO:root:17: Epoch 1 train loss: 130914.08740234375\nINFO:root:6: Epoch 1 train loss: 3331591.8098958335\nINFO:root:37: Epoch 1 train loss: 35545.278916041054\nINFO:root:43: Epoch 1 train loss: 2586834.3172637424\nINFO:root:36: Epoch 1 train loss: 122062.65690104167\nINFO:root:20: Epoch 1 train loss: 2308987.402149836\nINFO:root:8: Epoch 1 train loss: 1325.450360139211\nINFO:root:27: Epoch 1 train loss: 74016.61927069926\nINFO:root:32: Epoch 1 train loss: 19399.299353466213\nINFO:root:30: Epoch 1 train loss: 2681069.609685967\nINFO:root:34: Epoch 1 train loss: 6506.3835042317705\nINFO:root:31: Epoch 1 train loss: 58715.20153045654\nINFO:root:13: Epoch 1 train loss: 5241.917422294617\nINFO:root:22: Epoch 1 train loss: 880.6295827229818\nINFO:root:26: Epoch 1 train loss: 10238.709762573242\nINFO:root:21: Epoch 1 train loss: 2070.498494466146\nINFO:root:41: Epoch 1 train loss: 9122.56068030993\nINFO:root:25: Epoch 1 train loss: 22163.902994791668\nINFO:root:29: Epoch 1 train loss: 7598.390745282173\nINFO:root:33: Epoch 1 train loss: 8472.910591125488\nINFO:root:39: Epoch 1 train loss: 6506.713317871094\nINFO:root:9: Epoch 1 train loss: 62520.55078125\nINFO:root:24: Epoch 1 train loss: 14549.660888671875\nINFO:root:38: Epoch 1 train loss: 70114.49641927083\nINFO:root:42: Epoch 1 train loss: 9471.333969116211\nINFO:root:2: Epoch 1 train loss: 6880.838134765625\nINFO:root:40: Epoch 1 train loss: 11827.789827982584\nINFO:root:28: Epoch 1 train loss: 3544.0460001627603\nINFO:root:0: Epoch 1 validation loss: 210356.9581532026\nINFO:root:3: Epoch 2 train loss: 1155.9172814687092\nINFO:root:2: Epoch 2 train loss: 53810.0390625\nINFO:root:42: Epoch 2 train loss: 3262569.4836527505\nINFO:root:9: Epoch 2 train loss: 62312.2234108448\nINFO:root:26: Epoch 2 train loss: 14917.301432291666\nINFO:root:16: Epoch 2 train loss: 22740.8826953513\nINFO:root:35: Epoch 2 train loss: 33038.69864908854\nINFO:root:30: Epoch 2 train loss: 4713.05322265625\nINFO:root:39: Epoch 2 train loss: 2055.3450311024985\nINFO:root:23: Epoch 2 train loss: 10223.042622884115\nINFO:root:17: Epoch 2 train loss: 15161.30022396644\nINFO:root:7: Epoch 2 train loss: 2905817.9733581543\nINFO:root:29: Epoch 2 train loss: 1778.0323645273845\nINFO:root:38: Epoch 2 train loss: 68762.25834401448\nINFO:root:15: Epoch 2 train loss: 5360305.927179882\nINFO:root:31: Epoch 2 train loss: 3211924.36138916\nINFO:root:5: Epoch 2 train loss: 3056.7476552327475\nINFO:root:13: Epoch 2 train loss: 8572.241127371788\nINFO:root:4: Epoch 2 train loss: 70764.29496892293\nINFO:root:12: Epoch 2 train loss: 29940.27247700095\nINFO:root:6: Epoch 2 train loss: 120993.70707194011\nINFO:root:14: Epoch 2 train loss: 312453.2847197627\nINFO:root:28: Epoch 2 train loss: 22687220.703999836\nINFO:root:37: Epoch 2 train loss: 13202.024963378906\nINFO:root:36: Epoch 2 train loss: 15738.62142944336\nINFO:root:20: Epoch 2 train loss: 329415.9945297241\nINFO:root:21: Epoch 2 train loss: 2283.4138387044272\nINFO:root:22: Epoch 2 train loss: 5481.345464547475\nINFO:root:33: Epoch 2 train loss: 4112.25830078125\nINFO:root:19: Epoch 2 train loss: 14922.547909186533\nINFO:root:32: Epoch 2 train loss: 11281.9677734375\nINFO:root:18: Epoch 2 train loss: 6043.32077439626\nINFO:root:34: Epoch 2 train loss: 72775.04610188802\nINFO:root:8: Epoch 2 train loss: 1989.5452938079834\nINFO:root:10: Epoch 2 train loss: 8992.718466758728\nINFO:root:11: Epoch 2 train loss: 1495.3222096761067\nINFO:root:1: Epoch 2 train loss: 377.7315568129222\nINFO:root:0: Epoch 2 train loss: 1886.339145630598\nINFO:root:43: Epoch 2 train loss: 18563.29975382487\nINFO:root:40: Epoch 2 train loss: 881.4491380055746\nINFO:root:41: Epoch 2 train loss: 903338.9860026041\nINFO:root:27: Epoch 2 train loss: 322990.44083658856\nINFO:root:24: Epoch 2 train loss: 3192932.7087605796\nINFO:root:25: Epoch 2 train loss: 60442.85103352865\nINFO:root:0: Epoch 2 validation loss: 210336.7200550546\nINFO:root:7: Epoch 3 train loss: 17396.844571431477\nINFO:root:3: Epoch 3 train loss: 1060.7632446289062\nINFO:root:2: Epoch 3 train loss: 2635706.85546875\nINFO:root:34: Epoch 3 train loss: 3631.1832682291665\nINFO:root:5: Epoch 3 train loss: 8124.947650273641\nINFO:root:36: Epoch 3 train loss: 3366166.0240885415\nINFO:root:13: Epoch 3 train loss: 2680935.9456691095\nINFO:root:20: Epoch 3 train loss: 303722.5650138855\nINFO:root:43: Epoch 3 train loss: 995.1368408203125\nINFO:root:8: Epoch 3 train loss: 18232.870869954426\nINFO:root:19: Epoch 3 train loss: 59166.55456542969\nINFO:root:11: Epoch 3 train loss: 2887119.66112264\nINFO:root:17: Epoch 3 train loss: 2578800.526865641\nINFO:root:35: Epoch 3 train loss: 22461.0029296875\nINFO:root:4: Epoch 3 train loss: 112618.47973632812\nINFO:root:15: Epoch 3 train loss: 9862.485880533854\nINFO:root:21: Epoch 3 train loss: 19861.754954020184\nINFO:root:16: Epoch 3 train loss: 2297644.6065111957\nINFO:root:6: Epoch 3 train loss: 3781.636464436849\nINFO:root:40: Epoch 3 train loss: 2297330.006225586\nINFO:root:9: Epoch 3 train loss: 5101.336181640625\nINFO:root:10: Epoch 3 train loss: 18771.816731770832\nINFO:root:18: Epoch 3 train loss: 36391.35685221354\nINFO:root:38: Epoch 3 train loss: 4284.434398651123\nINFO:root:42: Epoch 3 train loss: 3195050.815321525\nINFO:root:32: Epoch 3 train loss: 9666.767991383871\nINFO:root:39: Epoch 3 train loss: 14498.680765982406\nINFO:root:14: Epoch 3 train loss: 36501.0810546875\nINFO:root:33: Epoch 3 train loss: 2292.160032673894\nINFO:root:37: Epoch 3 train loss: 1291.4821268717449\nINFO:root:12: Epoch 3 train loss: 13990.6088902466\nINFO:root:41: Epoch 3 train loss: 2762861.1756998696\nINFO:root:30: Epoch 3 train loss: 29289.43256632487\nINFO:root:31: Epoch 3 train loss: 6975.119059244792\nINFO:root:22: Epoch 3 train loss: 39753.64306640625\nINFO:root:23: Epoch 3 train loss: 2587993.23035874\nINFO:root:25: Epoch 3 train loss: 24167.34324812338\nINFO:root:27: Epoch 3 train loss: 46082.15667215983\nINFO:root:26: Epoch 3 train loss: 2182830.7575174966\nINFO:root:28: Epoch 3 train loss: 14140.55079905192\nINFO:root:24: Epoch 3 train loss: 19399.02877998352\nINFO:root:29: Epoch 3 train loss: 2177678.150033474\nINFO:root:1: Epoch 3 train loss: 7660.477216834202\nINFO:root:0: Epoch 3 train loss: 4930.9295654296875\nINFO:root:0: Epoch 3 validation loss: 210315.29376380428\nINFO:root:15: Epoch 4 train loss: 6853.567470948522\nINFO:root:7: Epoch 4 train loss: 12534.605021158854\nINFO:root:35: Epoch 4 train loss: 32744.092807769775\nINFO:root:23: Epoch 4 train loss: 56197.230631510414\nINFO:root:11: Epoch 4 train loss: 298.7798258463542\nINFO:root:16: Epoch 4 train loss: 95218.65542602539\nINFO:root:19: Epoch 4 train loss: 7028.5268961588545\nINFO:root:5: Epoch 4 train loss: 2666320.453521093\nINFO:root:13: Epoch 4 train loss: 2574289.4474283853\nINFO:root:34: Epoch 4 train loss: 3711.2819455464683\nINFO:root:4: Epoch 4 train loss: 8127.813820670049\nINFO:root:30: Epoch 4 train loss: 162575.05917127928\nINFO:root:12: Epoch 4 train loss: 24524.819665383937\nINFO:root:3: Epoch 4 train loss: 902745.6176749816\nINFO:root:43: Epoch 4 train loss: 44935.611419677734\nINFO:root:33: Epoch 4 train loss: 3935.060399038717\nINFO:root:6: Epoch 4 train loss: 40532.72901916504\nINFO:root:32: Epoch 4 train loss: 2705821.215284591\nINFO:root:31: Epoch 4 train loss: 144389.15112304688\nINFO:root:38: Epoch 4 train loss: 901691.3423892657\nINFO:root:14: Epoch 4 train loss: 2566063.2846221924\nINFO:root:42: Epoch 4 train loss: 998204.0858001709\nINFO:root:28: Epoch 4 train loss: 33379.25702943032\nINFO:root:24: Epoch 4 train loss: 13176.131254329035\nINFO:root:17: Epoch 4 train loss: 1045.7301063537598\nINFO:root:25: Epoch 4 train loss: 18710.64687093099\nINFO:root:21: Epoch 4 train loss: 35945.689127604164\nINFO:root:18: Epoch 4 train loss: 2290.8334757486978\nINFO:root:20: Epoch 4 train loss: 2052.3338499069214\nINFO:root:27: Epoch 4 train loss: 49904.077713012695\nINFO:root:36: Epoch 4 train loss: 2889944.273491059\nINFO:root:22: Epoch 4 train loss: 41772.00586954752\nINFO:root:41: Epoch 4 train loss: 5993.651468664408\nINFO:root:8: Epoch 4 train loss: 10329.186587810516\nINFO:root:26: Epoch 4 train loss: 8427.600072224936\nINFO:root:9: Epoch 4 train loss: 7306.548278808594\nINFO:root:39: Epoch 4 train loss: 20564.816975911457\nINFO:root:37: Epoch 4 train loss: 27810.397196451824\nINFO:root:10: Epoch 4 train loss: 5456.0802001953125\nINFO:root:40: Epoch 4 train loss: 2502.1800537109375\nINFO:root:2: Epoch 4 train loss: 30636.948649088543\nINFO:root:29: Epoch 4 train loss: 27174.35597229004\nINFO:root:1: Epoch 4 train loss: 2050.711140950521\nINFO:root:0: Epoch 4 train loss: 38686.337338765465\nINFO:root:0: Epoch 4 validation loss: 210290.75314484973\nINFO:root:43: Epoch 5 train loss: 84028.42317708333\nINFO:root:1: Epoch 5 train loss: 14917.69384765625\nINFO:root:3: Epoch 5 train loss: 10806.57408396403\nINFO:root:0: Epoch 5 train loss: 14404.971896807352\nINFO:root:2: Epoch 5 train loss: 4096.109619140625\nINFO:root:13: Epoch 5 train loss: 1674.7701013361414\nINFO:root:42: Epoch 5 train loss: 14074.426778157553\nINFO:root:10: Epoch 5 train loss: 413267.7337239583\nINFO:root:16: Epoch 5 train loss: 42017.716735839844\nINFO:root:35: Epoch 5 train loss: 669.0799268086752\nINFO:root:7: Epoch 5 train loss: 9004.872361501059\nINFO:root:39: Epoch 5 train loss: 11320.965128580729\nINFO:root:8: Epoch 5 train loss: 3053333.3807779946\nINFO:root:17: Epoch 5 train loss: 25768.628987630207\nINFO:root:29: Epoch 5 train loss: 1083.1301663716633\nINFO:root:14: Epoch 5 train loss: 6943.248873384204\nINFO:root:12: Epoch 5 train loss: 15308.736368815104\nINFO:root:9: Epoch 5 train loss: 2901157.3816731772\nINFO:root:27: Epoch 5 train loss: 5864141.717366536\nINFO:root:30: Epoch 5 train loss: 5494.881861368815\nINFO:root:31: Epoch 5 train loss: 2254.360419511795\nINFO:root:15: Epoch 5 train loss: 5240.265218098958\nINFO:root:11: Epoch 5 train loss: 5671.302235921224\nINFO:root:26: Epoch 5 train loss: 729.4788871208826\nINFO:root:25: Epoch 5 train loss: 15443.309753259024\nINFO:root:20: Epoch 5 train loss: 57492.80302937826\nINFO:root:23: Epoch 5 train loss: 23691.337239583332\nINFO:root:38: Epoch 5 train loss: 14756.295862833658\nINFO:root:18: Epoch 5 train loss: 2236.696818033854\nINFO:root:19: Epoch 5 train loss: 605.8003158569336\nINFO:root:5: Epoch 5 train loss: 8465.50633880496\nINFO:root:6: Epoch 5 train loss: 21522.430141634308\nINFO:root:24: Epoch 5 train loss: 4708.134602864583\nINFO:root:32: Epoch 5 train loss: 2686439.9112955728\nINFO:root:34: Epoch 5 train loss: 439543.3359375\nINFO:root:33: Epoch 5 train loss: 2873.399027029673\nINFO:root:40: Epoch 5 train loss: 2676913.6291910806\nINFO:root:41: Epoch 5 train loss: 1263.9477947923976\nINFO:root:36: Epoch 5 train loss: 2765443.675198237\nINFO:root:37: Epoch 5 train loss: 9751.256947835287\nINFO:root:21: Epoch 5 train loss: 61603.8350016276\nINFO:root:4: Epoch 5 train loss: 24576.26708984375\nINFO:root:22: Epoch 5 train loss: 5556.324281056722\nINFO:root:28: Epoch 5 train loss: 24510.3051399036\nINFO:root:0: Epoch 5 validation loss: 210261.8218752115\n", "seconds": 8.176083087921143, "batch_size": 32, "nodes": 11, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 32 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n2 Start Epoch 0\n2: 2 batches\n1 Start Epoch 0\n1: 2 batches\n4 Start Epoch 0\n4: 2 batches\n47 Start Epoch 0\n47: 2 batches\n3 Start Epoch 0\n3: 2 batches\n5 Start Epoch 0\n6 Start Epoch 0\n5: 2 batches\n6: 2 batches\n33 Start Epoch 0\n34 Start Epoch 0\n33: 2 batches\n34: 2 batches\n37 Start Epoch 0\n38 Start Epoch 0\n38: 2 batches\n37: 2 batches\n17 Start Epoch 0\n9 Start Epoch 0\n18 Start Epoch 0\n10 Start Epoch 0\n18: 2 batches\n17: 2 batches\n9: 2 batches\n10: 2 batches\n14 Start Epoch 0\n21 Start Epoch 0\n12 Start Epoch 0\n21: 2 batches\n11 Start Epoch 0\n36 Start Epoch 0\n14: 2 batches\n22 Start Epoch 0\n11: 2 batches\n36: 2 batches\n13 Start Epoch 0\n13: 2 batches\n22: 2 batches\n12: 2 batches\n29 Start Epoch 0\n30 Start Epoch 0\n31 Start Epoch 0\n31: 2 batches\n30: 2 batches\n29: 2 batches\n39 Start Epoch 0\n8 Start Epoch 0\n40 Start Epoch 0\n39: 2 batches\n20 Start Epoch 0\n8: 2 batches\n40: 2 batches\n24 Start Epoch 0\n24: 2 batches\n15 Start Epoch 0\n20: 2 batches\n16 Start Epoch 0\n45 Start Epoch 0\n19 Start Epoch 0\n15: 2 batches\n7 Start Epoch 0\n23 Start Epoch 0\n19: 2 batches\n35 Start Epoch 0\n7: 2 batches\n23: 2 batches\n16: 2 batches\n35: 2 batches\n28 Start Epoch 0\n28: 2 batches\n32 Start Epoch 0\n32: 2 batches\n45: 2 batches\n26 Start Epoch 0\n44 Start Epoch 0\n44: 2 batches\n42 Start Epoch 0\n46 Start Epoch 0\n46: 2 batches\n41 Start Epoch 0\n26: 2 batches\n27 Start Epoch 0\n41: 2 batches\n27: 2 batches\n42: 2 batches\n25 Start Epoch 0\n43 Start Epoch 0\n25: 2 batches\n43: 2 batches\n4 Start Epoch 1\n4: 2 batches\n3 Start Epoch 1\n7 Start Epoch 1\n6 Start Epoch 1\n6: 2 batches\n15 Start Epoch 1\n9 Start Epoch 1\n17 Start Epoch 1\n15: 2 batches\n44 Start Epoch 1\n8 Start Epoch 1\n17: 2 batches\n31 Start Epoch 1\n7: 2 batches\n8: 2 batches\n27 Start Epoch 1\n14 Start Epoch 1\n9: 2 batches\n16 Start Epoch 1\n31: 2 batches\n34 Start Epoch 1\n27: 2 batches\n37 Start Epoch 1\n16: 2 batches\n34: 2 batches\n36 Start Epoch 1\n21 Start Epoch 1\n37: 2 batches\n21: 2 batches\n10 Start Epoch 1\n1 Start Epoch 1\n36: 2 batches\n3: 2 batches\n1: 2 batches\n41 Start Epoch 1\n33 Start Epoch 1\n42 Start Epoch 1\n19 Start Epoch 1\n35 Start Epoch 1\n5 Start Epoch 1\n20 Start Epoch 1\n11 Start Epoch 1\n18 Start Epoch 1\n33: 2 batches\n39 Start Epoch 1\n5: 2 batches\n13 Start Epoch 1\n13: 2 batches\n20: 2 batches\n11: 2 batches\n40 Start Epoch 1\n30 Start Epoch 1\n35: 2 batches\n39: 2 batches\n10: 2 batches\n41: 2 batches\n19: 2 batches\n40: 2 batches\n18: 2 batches\n29 Start Epoch 1\n12 Start Epoch 1\n12: 2 batches\n30: 2 batches\n32 Start Epoch 1\n32: 2 batches\n14: 2 batches\n43 Start Epoch 1\n29: 2 batches\n43: 2 batches\n42: 2 batches\n28 Start Epoch 1\n28: 2 batches\n2 Start Epoch 1\n2: 2 batches\n44: 2 batches\n45 Start Epoch 1\n45: 2 batches\n47 Start Epoch 1\n47: 2 batches\n38 Start Epoch 1\n38: 2 batches\n46 Start Epoch 1\n22 Start Epoch 1\n46: 2 batches\n22: 2 batches\n23 Start Epoch 1\n25 Start Epoch 1\n26 Start Epoch 1\n23: 2 batches\n24 Start Epoch 1\n24: 2 batches\n26: 2 batches\n25: 2 batches\n0 Start Epoch 1\n0: 2 batches\n43 Start Epoch 2\n43: 2 batches\n44 Start Epoch 2\n4 Start Epoch 2\n7 Start Epoch 2\n4: 2 batches\n15 Start Epoch 2\n15: 2 batches\n46 Start Epoch 2\n38 Start Epoch 2\n2 Start Epoch 2\n2: 2 batches\n6 Start Epoch 2\n46: 2 batches\n6: 2 batches\n47 Start Epoch 2\n44: 2 batches\n30 Start Epoch 2\n35 Start Epoch 2\n35: 2 batches\n39 Start Epoch 2\n47: 2 batches\n8 Start Epoch 2\n30: 2 batches\n31 Start Epoch 2\n10 Start Epoch 2\n40 Start Epoch 2\n10: 2 batches\n42 Start Epoch 2\n31: 2 batches\n34 Start Epoch 2\n8: 2 batches\n40: 2 batches\n34: 2 batches\n41 Start Epoch 2\n11 Start Epoch 2\n41: 2 batches\n11: 2 batches\n42: 2 batches\n3 Start Epoch 2\n3: 2 batches\n7: 2 batches\n13 Start Epoch 2\n13: 2 batches\n9 Start Epoch 2\n9: 2 batches\n33 Start Epoch 2\n38: 2 batches\n17 Start Epoch 2\n33: 2 batches\n5 Start Epoch 2\n5: 2 batches\n17: 2 batches\n37 Start Epoch 2\n37: 2 batches\n32 Start Epoch 2\n23 Start Epoch 2\n32: 2 batches\n39: 2 batches\n1 Start Epoch 2\n1: 2 batches\n23: 2 batches\n16 Start Epoch 2\n16: 2 batches\n26 Start Epoch 2\n36 Start Epoch 2\n12 Start Epoch 2\n12: 2 batches\n22 Start Epoch 2\n28 Start Epoch 2\n26: 2 batches\n36: 2 batches\n14 Start Epoch 2\n14: 2 batches\n22: 2 batches\n28: 2 batches\n18 Start Epoch 2\n29 Start Epoch 2\n24 Start Epoch 2\n20 Start Epoch 2\n24: 2 batches\n45 Start Epoch 2\n20: 2 batches\n19 Start Epoch 2\n29: 2 batches\n19: 2 batches\n18: 2 batches\n45: 2 batches\n21 Start Epoch 2\n21: 2 batches\n25 Start Epoch 2\n25: 2 batches\n27 Start Epoch 2\n27: 2 batches\n0 Start Epoch 2\n0: 2 batches\n41 Start Epoch 3\n41: 2 batches\n45 Start Epoch 3\n45: 2 batches\n7 Start Epoch 3\n7: 2 batches\n15 Start Epoch 3\n15: 2 batches\n42 Start Epoch 3\n44 Start Epoch 3\n44: 2 batches\n31 Start Epoch 3\n31: 2 batches\n35 Start Epoch 3\n35: 2 batches\n37 Start Epoch 3\n12 Start Epoch 3\n22 Start Epoch 3\n22: 2 batches\n37: 2 batches\n12: 2 batches\n47 Start Epoch 3\n38 Start Epoch 3\n14 Start Epoch 3\n20 Start Epoch 3\n17 Start Epoch 3\n33 Start Epoch 3\n2 Start Epoch 3\n2: 2 batches\n25 Start Epoch 3\n38: 2 batches\n14: 2 batches\n46 Start Epoch 3\n20: 2 batches\n1 Start Epoch 3\n1: 2 batches\n17: 2 batches\n33: 2 batches\n26 Start Epoch 3\n47: 2 batches\n42: 2 batches\n19 Start Epoch 3\n27 Start Epoch 3\n39 Start Epoch 3\n5 Start Epoch 3\n46: 2 batches\n23 Start Epoch 3\n34 Start Epoch 3\n25: 2 batches\n6 Start Epoch 3\n13 Start Epoch 3\n23: 2 batches\n43 Start Epoch 3\n43: 2 batches\n16 Start Epoch 3\n30 Start Epoch 3\n34: 2 batches\n27: 2 batches\n36 Start Epoch 3\n4 Start Epoch 3\n13: 2 batches\n10 Start Epoch 3\n10: 2 batches\n24 Start Epoch 3\n36: 2 batches\n6: 2 batches\n19: 2 batches\n29 Start Epoch 3\n29: 2 batches\n4: 2 batches\n11 Start Epoch 3\n11: 2 batches\n40 Start Epoch 3\n18 Start Epoch 3\n28 Start Epoch 3\n24: 2 batches\n5: 2 batches\n8 Start Epoch 3\n8: 2 batches\n40: 2 batches\n30: 2 batches\n26: 2 batches\n18: 2 batches\n28: 2 batches\n9 Start Epoch 3\n9: 2 batches\n16: 2 batches\n3 Start Epoch 3\n3: 2 batches\n21 Start Epoch 3\n21: 2 batches\n32 Start Epoch 3\n32: 2 batches\n39: 2 batches\n0 Start Epoch 3\n0: 2 batches\n15 Start Epoch 4\n15: 2 batches\n5 Start Epoch 4\n6 Start Epoch 4\n7 Start Epoch 4\n7: 2 batches\n5: 2 batches\n6: 2 batches\n1 Start Epoch 4\n1: 2 batches\n34 Start Epoch 4\n34: 2 batches\n43 Start Epoch 4\n31 Start Epoch 4\n26 Start Epoch 4\n38 Start Epoch 4\n41 Start Epoch 4\n30 Start Epoch 4\n27 Start Epoch 4\n39 Start Epoch 4\n40 Start Epoch 4\n40: 2 batches\n31: 2 batches\n39: 2 batches\n43: 2 batches\n37 Start Epoch 4\n44 Start Epoch 4\n29 Start Epoch 4\n37: 2 batches\n44: 2 batches\n8 Start Epoch 4\n38: 2 batches\n8: 2 batches\n30: 2 batches\n4 Start Epoch 4\n41: 2 batches\n29: 2 batches\n33 Start Epoch 4\n4: 2 batches\n33: 2 batches\n36 Start Epoch 4\n20 Start Epoch 4\n28 Start Epoch 4\n36: 2 batches\n28: 2 batches\n3 Start Epoch 4\n3: 2 batches\n2 Start Epoch 4\n2: 2 batches\n25 Start Epoch 4\n25: 2 batches\n20: 2 batches\n26: 2 batches\n46 Start Epoch 4\n10 Start Epoch 4\n42 Start Epoch 4\n10: 2 batches\n42: 2 batches\n32 Start Epoch 4\n27: 2 batches\n12 Start Epoch 4\n45 Start Epoch 4\n22 Start Epoch 4\n18 Start Epoch 4\n32: 2 batches\n13 Start Epoch 4\n45: 2 batches\n22: 2 batches\n11 Start Epoch 4\n17 Start Epoch 4\n35 Start Epoch 4\n24 Start Epoch 4\n24: 2 batches\n12: 2 batches\n21 Start Epoch 4\n18: 2 batches\n35: 2 batches\n14 Start Epoch 4\n47 Start Epoch 4\n9 Start Epoch 4\n16 Start Epoch 4\n14: 2 batches\n46: 2 batches\n23 Start Epoch 4\n11: 2 batches\n16: 2 batches\n13: 2 batches\n47: 2 batches\n23: 2 batches\n17: 2 batches\n21: 2 batches\n19 Start Epoch 4\n19: 2 batches\n9: 2 batches\n0 Start Epoch 4\n0: 2 batches\n39 Start Epoch 5\n27 Start Epoch 5\n27: 2 batches\n40 Start Epoch 5\n40: 2 batches\n34 Start Epoch 5\n34: 2 batches\n33 Start Epoch 5\n26 Start Epoch 5\n25 Start Epoch 5\n26: 2 batches\n25: 2 batches\n33: 2 batches\n15 Start Epoch 5\n31 Start Epoch 5\n31: 2 batches\n32 Start Epoch 5\n32: 2 batches\n7 Start Epoch 5\n4 Start Epoch 5\n4: 2 batches\n7: 2 batches\n19 Start Epoch 5\n43 Start Epoch 5\n42 Start Epoch 5\n24 Start Epoch 5\n45 Start Epoch 5\n21 Start Epoch 5\n42: 2 batches\n24: 2 batches\n45: 2 batches\n43: 2 batches\n21: 2 batches\n37 Start Epoch 5\n29 Start Epoch 5\n36 Start Epoch 5\n11 Start Epoch 5\n29: 2 batches\n37: 2 batches\n12 Start Epoch 5\n10 Start Epoch 5\n39: 2 batches\n38 Start Epoch 5\n15: 2 batches\n11: 2 batches\n12: 2 batches\n46 Start Epoch 5\n36: 2 batches\n10: 2 batches\n16 Start Epoch 5\n30 Start Epoch 5\n38: 2 batches\n47 Start Epoch 5\n23 Start Epoch 5\n19: 2 batches\n28 Start Epoch 5\n47: 2 batches\n22 Start Epoch 5\n8 Start Epoch 5\n46: 2 batches\n22: 2 batches\n8: 2 batches\n28: 2 batches\n6 Start Epoch 5\n44 Start Epoch 5\n30: 2 batches\n44: 2 batches\n5 Start Epoch 5\n5: 2 batches\n9 Start Epoch 5\n14 Start Epoch 5\n13 Start Epoch 5\n14: 2 batches\n13: 2 batches\n9: 2 batches\n20 Start Epoch 5\n17 Start Epoch 5\n17: 2 batches\n23: 2 batches\n18 Start Epoch 5\n18: 2 batches\n35 Start Epoch 5\n35: 2 batches\n6: 2 batches\n41 Start Epoch 5\n41: 2 batches\n16: 2 batches\n1 Start Epoch 5\n1: 2 batches\n2 Start Epoch 5\n2: 2 batches\n3 Start Epoch 5\n3: 2 batches\n20: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:4: Epoch 0 train loss: 43372.515625\nINFO:root:3: Epoch 0 train loss: 977.9387168884277\nINFO:root:6: Epoch 0 train loss: 3444657.0490942\nINFO:root:15: Epoch 0 train loss: 82977.05798339844\nINFO:root:9: Epoch 0 train loss: 24444.6171875\nINFO:root:44: Epoch 0 train loss: 28914.310943603516\nINFO:root:17: Epoch 0 train loss: 11662.138549804688\nINFO:root:7: Epoch 0 train loss: 21112.0043258667\nINFO:root:8: Epoch 0 train loss: 6220.8194580078125\nINFO:root:34: Epoch 0 train loss: 16740.779571533203\nINFO:root:27: Epoch 0 train loss: 44948.31066894531\nINFO:root:36: Epoch 0 train loss: 4890.737548828125\nINFO:root:16: Epoch 0 train loss: 17769.517333984375\nINFO:root:31: Epoch 0 train loss: 1442594.3898925781\nINFO:root:35: Epoch 0 train loss: 399.1524658203125\nINFO:root:37: Epoch 0 train loss: 1756.6119384765625\nINFO:root:14: Epoch 0 train loss: 6398.598159790039\nINFO:root:21: Epoch 0 train loss: 2943.5504608154297\nINFO:root:41: Epoch 0 train loss: 9085.939849853516\nINFO:root:42: Epoch 0 train loss: 3848736.8892822266\nINFO:root:0: Epoch 0 train loss: 48972.6044921875\nINFO:root:10: Epoch 0 train loss: 4726.29248046875\nINFO:root:40: Epoch 0 train loss: 141023.56796264648\nINFO:root:19: Epoch 0 train loss: 1664.6319274902344\nINFO:root:33: Epoch 0 train loss: 5124832.6015625\nINFO:root:1: Epoch 0 train loss: 1013.5765380859375\nINFO:root:5: Epoch 0 train loss: 27746.267333984375\nINFO:root:20: Epoch 0 train loss: 4796780.626953125\nINFO:root:11: Epoch 0 train loss: 5165195.1416015625\nINFO:root:18: Epoch 0 train loss: 5311.700241088867\nINFO:root:29: Epoch 0 train loss: 1697.6734924316406\nINFO:root:39: Epoch 0 train loss: 8099592.802734375\nINFO:root:30: Epoch 0 train loss: 2459.9720458984375\nINFO:root:13: Epoch 0 train loss: 13492.636932373047\nINFO:root:32: Epoch 0 train loss: 3984.0219116210938\nINFO:root:12: Epoch 0 train loss: 8797.09284210205\nINFO:root:43: Epoch 0 train loss: 44691.849609375\nINFO:root:28: Epoch 0 train loss: 675.4425144195557\nINFO:root:2: Epoch 0 train loss: 28423.5546875\nINFO:root:45: Epoch 0 train loss: 19708.73486328125\nINFO:root:47: Epoch 0 train loss: 50520.337890625\nINFO:root:38: Epoch 0 train loss: 11951.98486328125\nINFO:root:46: Epoch 0 train loss: 22649.933715820312\nINFO:root:23: Epoch 0 train loss: 10981.891614198685\nINFO:root:24: Epoch 0 train loss: 3463649.3850631714\nINFO:root:22: Epoch 0 train loss: 90602.04895019531\nINFO:root:25: Epoch 0 train loss: 2825.423141479492\nINFO:root:26: Epoch 0 train loss: 4797253.1103515625\nINFO:root:0: Epoch 0 validation loss: 4978.234232159925\nINFO:root:43: Epoch 1 train loss: 4478.599182128906\nINFO:root:44: Epoch 1 train loss: 66404.748046875\nINFO:root:45: Epoch 1 train loss: 50809.98828125\nINFO:root:7: Epoch 1 train loss: 32401.18310546875\nINFO:root:4: Epoch 1 train loss: 51687.07441711426\nINFO:root:15: Epoch 1 train loss: 10529.939239501953\nINFO:root:47: Epoch 1 train loss: 72297.73388671875\nINFO:root:46: Epoch 1 train loss: 16982.996673583984\nINFO:root:38: Epoch 1 train loss: 18470.98876953125\nINFO:root:6: Epoch 1 train loss: 6924587.5\nINFO:root:0: Epoch 1 train loss: 121848.859375\nINFO:root:2: Epoch 1 train loss: 31781.723754882812\nINFO:root:30: Epoch 1 train loss: 64491.515625\nINFO:root:31: Epoch 1 train loss: 1853.4073028564453\nINFO:root:35: Epoch 1 train loss: 2973.63671875\nINFO:root:10: Epoch 1 train loss: 2450.769775390625\nINFO:root:40: Epoch 1 train loss: 11459.05581665039\nINFO:root:8: Epoch 1 train loss: 47287.251708984375\nINFO:root:41: Epoch 1 train loss: 22329.1044921875\nINFO:root:42: Epoch 1 train loss: 336.71561431884766\nINFO:root:34: Epoch 1 train loss: 38327.35266113281\nINFO:root:11: Epoch 1 train loss: 129.59295654296875\nINFO:root:9: Epoch 1 train loss: 4769.58251953125\nINFO:root:3: Epoch 1 train loss: 516.4229469299316\nINFO:root:33: Epoch 1 train loss: 241.53892517089844\nINFO:root:17: Epoch 1 train loss: 3999109.619140625\nINFO:root:5: Epoch 1 train loss: 29916.801231384277\nINFO:root:39: Epoch 1 train loss: 34124.6884765625\nINFO:root:23: Epoch 1 train loss: 42153.597412109375\nINFO:root:32: Epoch 1 train loss: 34291.296630859375\nINFO:root:22: Epoch 1 train loss: 1674.9496307373047\nINFO:root:37: Epoch 1 train loss: 20849.291564941406\nINFO:root:16: Epoch 1 train loss: 12655.798706054688\nINFO:root:13: Epoch 1 train loss: 11386.146118164062\nINFO:root:36: Epoch 1 train loss: 4998.56424331665\nINFO:root:1: Epoch 1 train loss: 2184.2734375\nINFO:root:12: Epoch 1 train loss: 35097.879583358765\nINFO:root:28: Epoch 1 train loss: 30380.715087890625\nINFO:root:26: Epoch 1 train loss: 15002.867095947266\nINFO:root:29: Epoch 1 train loss: 739.5084838867188\nINFO:root:18: Epoch 1 train loss: 4637.957336425781\nINFO:root:24: Epoch 1 train loss: 20458.703125\nINFO:root:14: Epoch 1 train loss: 1569.8595581054688\nINFO:root:20: Epoch 1 train loss: 10317.1640625\nINFO:root:19: Epoch 1 train loss: 34867.44094848633\nINFO:root:21: Epoch 1 train loss: 591.2870826721191\nINFO:root:25: Epoch 1 train loss: 7046.522308349609\nINFO:root:27: Epoch 1 train loss: 37752.756103515625\nINFO:root:0: Epoch 1 validation loss: 4976.280112885935\nINFO:root:41: Epoch 2 train loss: 6769.9276123046875\nINFO:root:45: Epoch 2 train loss: 3675947.3567123413\nINFO:root:7: Epoch 2 train loss: 3272255.4739723206\nINFO:root:15: Epoch 2 train loss: 40569.53125\nINFO:root:42: Epoch 2 train loss: 132283.1234741211\nINFO:root:44: Epoch 2 train loss: 30266.41796875\nINFO:root:31: Epoch 2 train loss: 15000.626708984375\nINFO:root:35: Epoch 2 train loss: 3445620.3864746094\nINFO:root:37: Epoch 2 train loss: 20082.5341796875\nINFO:root:12: Epoch 2 train loss: 8286.573272705078\nINFO:root:22: Epoch 2 train loss: 30568.309204101562\nINFO:root:8: Epoch 2 train loss: 115344.734375\nINFO:root:25: Epoch 2 train loss: 32977.734375\nINFO:root:47: Epoch 2 train loss: 4114896.4470825195\nINFO:root:26: Epoch 2 train loss: 79428.24145507812\nINFO:root:14: Epoch 2 train loss: 62451.9296875\nINFO:root:20: Epoch 2 train loss: 10347.33676147461\nINFO:root:17: Epoch 2 train loss: 36491.80987548828\nINFO:root:27: Epoch 2 train loss: 3457094.1154785156\nINFO:root:38: Epoch 2 train loss: 11243.426696777344\nINFO:root:6: Epoch 2 train loss: 47147.33420944214\nINFO:root:46: Epoch 2 train loss: 4615.0714111328125\nINFO:root:33: Epoch 2 train loss: 4132310.493774414\nINFO:root:24: Epoch 2 train loss: 26683.33740234375\nINFO:root:2: Epoch 2 train loss: 57983.8876953125\nINFO:root:5: Epoch 2 train loss: 4313.2711181640625\nINFO:root:1: Epoch 2 train loss: 143870.6162109375\nINFO:root:39: Epoch 2 train loss: 11093.092956542969\nINFO:root:4: Epoch 2 train loss: 8994.64404296875\nINFO:root:23: Epoch 2 train loss: 7421.33642578125\nINFO:root:19: Epoch 2 train loss: 147968.53833007812\nINFO:root:0: Epoch 2 train loss: 101373.2705078125\nINFO:root:29: Epoch 2 train loss: 1442335.741897583\nINFO:root:43: Epoch 2 train loss: 14339.40087890625\nINFO:root:28: Epoch 2 train loss: 3269878.98828125\nINFO:root:34: Epoch 2 train loss: 99787.716796875\nINFO:root:13: Epoch 2 train loss: 1653.0963745117188\nINFO:root:30: Epoch 2 train loss: 24895.7144241333\nINFO:root:36: Epoch 2 train loss: 3857778.6669921875\nINFO:root:9: Epoch 2 train loss: 1664.6388244628906\nINFO:root:16: Epoch 2 train loss: 82724.20288467407\nINFO:root:10: Epoch 2 train loss: 96894.23828125\nINFO:root:40: Epoch 2 train loss: 25964.966430664062\nINFO:root:18: Epoch 2 train loss: 23984.837127685547\nINFO:root:11: Epoch 2 train loss: 20403.336791992188\nINFO:root:3: Epoch 2 train loss: 10304302.32421875\nINFO:root:21: Epoch 2 train loss: 8183300.991516113\nINFO:root:32: Epoch 2 train loss: 161818.421875\nINFO:root:0: Epoch 2 validation loss: 4974.377307294643\nINFO:root:15: Epoch 3 train loss: 556803.458984375\nINFO:root:5: Epoch 3 train loss: 15368.607421875\nINFO:root:7: Epoch 3 train loss: 3216.9698486328125\nINFO:root:6: Epoch 3 train loss: 17838.574127197266\nINFO:root:1: Epoch 3 train loss: 4619556.657043457\nINFO:root:41: Epoch 3 train loss: 15946.247100830078\nINFO:root:34: Epoch 3 train loss: 20414.6376953125\nINFO:root:43: Epoch 3 train loss: 33726.37634277344\nINFO:root:27: Epoch 3 train loss: 4621705.021972656\nINFO:root:39: Epoch 3 train loss: 1691.3504028320312\nINFO:root:37: Epoch 3 train loss: 24755.52960205078\nINFO:root:40: Epoch 3 train loss: 10262.24893951416\nINFO:root:31: Epoch 3 train loss: 1452.8516693115234\nINFO:root:26: Epoch 3 train loss: 11873.594345092773\nINFO:root:24: Epoch 3 train loss: 17314.688903808594\nINFO:root:38: Epoch 3 train loss: 9386.3508644104\nINFO:root:30: Epoch 3 train loss: 1727.103271484375\nINFO:root:44: Epoch 3 train loss: 146164.88647460938\nINFO:root:8: Epoch 3 train loss: 94979.75390625\nINFO:root:29: Epoch 3 train loss: 1255.8499450683594\nINFO:root:4: Epoch 3 train loss: 2919.0281982421875\nINFO:root:33: Epoch 3 train loss: 1361056.994140625\nINFO:root:36: Epoch 3 train loss: 3799.272491455078\nINFO:root:20: Epoch 3 train loss: 4334689.729370117\nINFO:root:28: Epoch 3 train loss: 9007.027282714844\nINFO:root:0: Epoch 3 train loss: 3679520.0959472656\nINFO:root:3: Epoch 3 train loss: 12931.326171875\nINFO:root:2: Epoch 3 train loss: 66270.095703125\nINFO:root:10: Epoch 3 train loss: 3251796.85546875\nINFO:root:42: Epoch 3 train loss: 1639.5907897949219\nINFO:root:17: Epoch 3 train loss: 33455.310546875\nINFO:root:32: Epoch 3 train loss: 8651.2431640625\nINFO:root:14: Epoch 3 train loss: 854.8658428192139\nINFO:root:46: Epoch 3 train loss: 25898.080139160156\nINFO:root:18: Epoch 3 train loss: 4408352.894775391\nINFO:root:35: Epoch 3 train loss: 4906.8194580078125\nINFO:root:13: Epoch 3 train loss: 119105.29296875\nINFO:root:21: Epoch 3 train loss: 4240214.53125\nINFO:root:12: Epoch 3 train loss: 1464.4690475463867\nINFO:root:45: Epoch 3 train loss: 6250.6915283203125\nINFO:root:22: Epoch 3 train loss: 5181.5845947265625\nINFO:root:16: Epoch 3 train loss: 658.7871246337891\nINFO:root:25: Epoch 3 train loss: 10943.74169921875\nINFO:root:11: Epoch 3 train loss: 2548.534942626953\nINFO:root:47: Epoch 3 train loss: 10128.546997070312\nINFO:root:9: Epoch 3 train loss: 1215.9218139648438\nINFO:root:23: Epoch 3 train loss: 11464.037353515625\nINFO:root:19: Epoch 3 train loss: 19155.55484008789\nINFO:root:0: Epoch 3 validation loss: 4972.38101807089\nINFO:root:39: Epoch 4 train loss: 854.2223205566406\nINFO:root:27: Epoch 4 train loss: 3161.1441650390625\nINFO:root:40: Epoch 4 train loss: 430.5540466308594\nINFO:root:34: Epoch 4 train loss: 5829.861328125\nINFO:root:33: Epoch 4 train loss: 14153.402160644531\nINFO:root:26: Epoch 4 train loss: 197290.3671875\nINFO:root:25: Epoch 4 train loss: 34099.072265625\nINFO:root:15: Epoch 4 train loss: 3253.5400390625\nINFO:root:31: Epoch 4 train loss: 649.7280426025391\nINFO:root:12: Epoch 4 train loss: 7177.208396911621\nINFO:root:32: Epoch 4 train loss: 25393.6943359375\nINFO:root:7: Epoch 4 train loss: 4373.576467514038\nINFO:root:4: Epoch 4 train loss: 4408602.845458984\nINFO:root:19: Epoch 4 train loss: 4157809.84375\nINFO:root:42: Epoch 4 train loss: 22284.2333984375\nINFO:root:43: Epoch 4 train loss: 6804.58154296875\nINFO:root:16: Epoch 4 train loss: 1493.2558403015137\nINFO:root:24: Epoch 4 train loss: 25057.462890625\nINFO:root:45: Epoch 4 train loss: 9525.409912109375\nINFO:root:21: Epoch 4 train loss: 79321.642578125\nINFO:root:36: Epoch 4 train loss: 6204.275817871094\nINFO:root:29: Epoch 4 train loss: 2854.6022338867188\nINFO:root:37: Epoch 4 train loss: 613386.734375\nINFO:root:28: Epoch 4 train loss: 4381.2742919921875\nINFO:root:38: Epoch 4 train loss: 6907.065994262695\nINFO:root:10: Epoch 4 train loss: 478151.76654052734\nINFO:root:11: Epoch 4 train loss: 478005.8507080078\nINFO:root:46: Epoch 4 train loss: 564.6307983398438\nINFO:root:23: Epoch 4 train loss: 7095.233947753906\nINFO:root:30: Epoch 4 train loss: 36251.162109375\nINFO:root:47: Epoch 4 train loss: 1543.8436889648438\nINFO:root:22: Epoch 4 train loss: 3834.3421630859375\nINFO:root:8: Epoch 4 train loss: 276.0032157897949\nINFO:root:44: Epoch 4 train loss: 4263740.357543945\nINFO:root:6: Epoch 4 train loss: 10590.82861328125\nINFO:root:5: Epoch 4 train loss: 21875.06884765625\nINFO:root:9: Epoch 4 train loss: 199.67127990722656\nINFO:root:14: Epoch 4 train loss: 16147.924194335938\nINFO:root:13: Epoch 4 train loss: 499845.4597167969\nINFO:root:20: Epoch 4 train loss: 4342199.172546387\nINFO:root:17: Epoch 4 train loss: 2007.417724609375\nINFO:root:18: Epoch 4 train loss: 6765.92822265625\nINFO:root:35: Epoch 4 train loss: 1472223.27734375\nINFO:root:41: Epoch 4 train loss: 9123.10464477539\nINFO:root:2: Epoch 4 train loss: 3474.7262268066406\nINFO:root:0: Epoch 4 train loss: 3257870.9931640625\nINFO:root:1: Epoch 4 train loss: 359.8171691894531\nINFO:root:3: Epoch 4 train loss: 20099.965576171875\nINFO:root:0: Epoch 4 validation loss: 4970.284374411379\nINFO:root:11: Epoch 5 train loss: 551.6892471313477\nINFO:root:7: Epoch 5 train loss: 49481.54328918457\nINFO:root:2: Epoch 5 train loss: 4621302.736328125\nINFO:root:3: Epoch 5 train loss: 5573.4456787109375\nINFO:root:12: Epoch 5 train loss: 1459975.0439910889\nINFO:root:19: Epoch 5 train loss: 1395.3182373046875\nINFO:root:4: Epoch 5 train loss: 266.3609962463379\nINFO:root:15: Epoch 5 train loss: 1595.6260070800781\nINFO:root:18: Epoch 5 train loss: 78808.953125\nINFO:root:47: Epoch 5 train loss: 83.40181159973145\nINFO:root:6: Epoch 5 train loss: 20964.8671875\nINFO:root:17: Epoch 5 train loss: 3345.853759765625\nINFO:root:5: Epoch 5 train loss: 59517.662109375\nINFO:root:21: Epoch 5 train loss: 32758.2724609375\nINFO:root:20: Epoch 5 train loss: 23099.966217041016\nINFO:root:35: Epoch 5 train loss: 4145384.578125\nINFO:root:27: Epoch 5 train loss: 36491.501892089844\nINFO:root:1: Epoch 5 train loss: 1369124.7622070312\nINFO:root:0: Epoch 5 train loss: 16327.516845703125\nINFO:root:38: Epoch 5 train loss: 4412454.291671753\nINFO:root:14: Epoch 5 train loss: 76765.8667755127\nINFO:root:44: Epoch 5 train loss: 53725.8583984375\nINFO:root:43: Epoch 5 train loss: 26477.13330078125\nINFO:root:16: Epoch 5 train loss: 4627281.4541015625\nINFO:root:28: Epoch 5 train loss: 35510.2822265625\nINFO:root:13: Epoch 5 train loss: 20358.6494140625\nINFO:root:46: Epoch 5 train loss: 5634.3212890625\nINFO:root:22: Epoch 5 train loss: 9694.588623046875\nINFO:root:8: Epoch 5 train loss: 49889.25720214844\nINFO:root:42: Epoch 5 train loss: 2071.508819580078\nINFO:root:29: Epoch 5 train loss: 3841.148223876953\nINFO:root:34: Epoch 5 train loss: 29597.5458984375\nINFO:root:26: Epoch 5 train loss: 1118.5872802734375\nINFO:root:36: Epoch 5 train loss: 26154.6298828125\nINFO:root:41: Epoch 5 train loss: 3684125.431640625\nINFO:root:30: Epoch 5 train loss: 4482919.1328125\nINFO:root:32: Epoch 5 train loss: 4788461.57699585\nINFO:root:24: Epoch 5 train loss: 5936.385925292969\nINFO:root:39: Epoch 5 train loss: 1835.5457153320312\nINFO:root:45: Epoch 5 train loss: 43521.119140625\nINFO:root:23: Epoch 5 train loss: 9639.909606933594\nINFO:root:10: Epoch 5 train loss: 27401.339111328125\nINFO:root:33: Epoch 5 train loss: 1693.1865844726562\nINFO:root:25: Epoch 5 train loss: 10447.43115234375\nINFO:root:37: Epoch 5 train loss: 48220.43518066406\nINFO:root:9: Epoch 5 train loss: 8734.6298828125\nINFO:root:40: Epoch 5 train loss: 10446.007080078125\nINFO:root:31: Epoch 5 train loss: 2818.1149291992188\nINFO:root:0: Epoch 5 validation loss: 4967.9779064709255\n", "seconds": 7.82119607925415, "batch_size": 32, "nodes": 12, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 47 batches\n0 Start Epoch 1\n0: 47 batches\n0 Start Epoch 2\n0: 47 batches\n0 Start Epoch 3\n0: 47 batches\n0 Start Epoch 4\n0: 47 batches\n0 Start Epoch 5\n0: 47 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 326455.1420817274\nINFO:root:0: Epoch 0 validation loss: 2482632.405275275\nINFO:root:0: Epoch 1 train loss: 326015.70880310587\nINFO:root:0: Epoch 1 validation loss: 2479978.318229297\nINFO:root:0: Epoch 2 train loss: 325995.248973116\nINFO:root:0: Epoch 2 validation loss: 2478206.95383187\nINFO:root:0: Epoch 3 train loss: 325980.2213849007\nINFO:root:0: Epoch 3 validation loss: 2476784.367245049\nINFO:root:0: Epoch 4 train loss: 494796.2977606591\nINFO:root:0: Epoch 4 validation loss: 2475621.4787506894\nINFO:root:0: Epoch 5 train loss: 325933.06331423495\nINFO:root:0: Epoch 5 validation loss: 2474449.664520395\n", "seconds": 10.943087100982666, "batch_size": 64, "nodes": 1, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 24 batches\n1 Start Epoch 0\n1: 24 batches\n1 Start Epoch 1\n1: 24 batches\n0 Start Epoch 1\n0: 24 batches\n1 Start Epoch 2\n1: 24 batches\n0 Start Epoch 2\n0: 24 batches\n1 Start Epoch 3\n1: 24 batches\n0 Start Epoch 3\n0: 24 batches\n1 Start Epoch 4\n1: 24 batches\n0 Start Epoch 4\n0: 24 batches\n1 Start Epoch 5\n1: 24 batches\n0 Start Epoch 5\n0: 24 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 370247.2921074231\nINFO:root:1: Epoch 0 train loss: 264330.79673957825\nINFO:root:0: Epoch 0 validation loss: 1687328.787292627\nINFO:root:0: Epoch 1 train loss: 423237.3930721283\nINFO:root:1: Epoch 1 train loss: 368474.429931283\nINFO:root:0: Epoch 1 validation loss: 1686818.6737986926\nINFO:root:0: Epoch 2 train loss: 300014.3436733882\nINFO:root:1: Epoch 2 train loss: 307383.361279885\nINFO:root:0: Epoch 2 validation loss: 1685657.734460058\nINFO:root:0: Epoch 3 train loss: 456446.68940575916\nINFO:root:1: Epoch 3 train loss: 377564.1596508026\nINFO:root:0: Epoch 3 validation loss: 1684716.2088994076\nINFO:root:0: Epoch 4 train loss: 397462.4048789342\nINFO:root:1: Epoch 4 train loss: 214680.05786561966\nINFO:root:0: Epoch 4 validation loss: 1684080.6984085708\nINFO:root:0: Epoch 5 train loss: 361673.2130038738\nINFO:root:1: Epoch 5 train loss: 213478.28668276468\nINFO:root:0: Epoch 5 validation loss: 1683652.2577442958\n", "seconds": 6.5169267654418945, "batch_size": 64, "nodes": 2, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 16 batches\n2 Start Epoch 0\n2: 16 batches\n1 Start Epoch 0\n1: 16 batches\n1 Start Epoch 1\n2 Start Epoch 1\n2: 16 batches\n1: 16 batches\n0 Start Epoch 1\n0: 16 batches\n1 Start Epoch 2\n2 Start Epoch 2\n2: 16 batches\n1: 16 batches\n0 Start Epoch 2\n0: 16 batches\n2 Start Epoch 3\n2: 16 batches\n1 Start Epoch 3\n1: 16 batches\n0 Start Epoch 3\n0: 16 batches\n2 Start Epoch 4\n2: 16 batches\n1 Start Epoch 4\n1: 16 batches\n0 Start Epoch 4\n0: 16 batches\n1 Start Epoch 5\n2 Start Epoch 5\n2: 16 batches\n1: 16 batches\n0 Start Epoch 5\n0: 16 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 156193.87523460388\nINFO:root:1: Epoch 0 train loss: 396527.063079834\nINFO:root:2: Epoch 0 train loss: 435127.19349479675\nINFO:root:0: Epoch 0 validation loss: 781085.3147606113\nINFO:root:0: Epoch 1 train loss: 559343.2309074402\nINFO:root:1: Epoch 1 train loss: 200506.25994491577\nINFO:root:2: Epoch 1 train loss: 407060.0921897888\nINFO:root:0: Epoch 1 validation loss: 780851.4743282661\nINFO:root:0: Epoch 2 train loss: 399381.13423633575\nINFO:root:2: Epoch 2 train loss: 511266.04919815063\nINFO:root:1: Epoch 2 train loss: 251486.5585231781\nINFO:root:0: Epoch 2 validation loss: 780372.5927047151\nINFO:root:0: Epoch 3 train loss: 580419.3738412857\nINFO:root:2: Epoch 3 train loss: 486715.51930236816\nINFO:root:1: Epoch 3 train loss: 503746.9505748749\nINFO:root:0: Epoch 3 validation loss: 779785.327430848\nINFO:root:0: Epoch 4 train loss: 466921.00538253784\nINFO:root:2: Epoch 4 train loss: 126510.83522796631\nINFO:root:1: Epoch 4 train loss: 378010.33875632286\nINFO:root:0: Epoch 4 validation loss: 779304.9820802088\nINFO:root:0: Epoch 5 train loss: 282964.199590683\nINFO:root:2: Epoch 5 train loss: 263692.4239616394\nINFO:root:1: Epoch 5 train loss: 174908.64583206177\nINFO:root:0: Epoch 5 validation loss: 778927.6973955056\n", "seconds": 5.60503888130188, "batch_size": 64, "nodes": 3, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 12 batches\n1 Start Epoch 0\n3 Start Epoch 0\n2 Start Epoch 0\n2: 12 batches\n1: 12 batches\n3: 12 batches\n3 Start Epoch 1\n2 Start Epoch 1\n2: 12 batches\n3: 12 batches\n1 Start Epoch 1\n1: 12 batches\n0 Start Epoch 1\n0: 12 batches\n2 Start Epoch 2\n3 Start Epoch 2\n3: 12 batches\n2: 12 batches\n1 Start Epoch 2\n1: 12 batches\n0 Start Epoch 2\n0: 12 batches\n3 Start Epoch 3\n2 Start Epoch 3\n3: 12 batches\n2: 12 batches\n1 Start Epoch 3\n1: 12 batches\n0 Start Epoch 3\n0: 12 batches\n2 Start Epoch 4\n2: 12 batches\n3 Start Epoch 4\n3: 12 batches\n1 Start Epoch 4\n1: 12 batches\n0 Start Epoch 4\n0: 12 batches\n2 Start Epoch 5\n3 Start Epoch 5\n3: 12 batches\n2: 12 batches\n1 Start Epoch 5\n1: 12 batches\n0 Start Epoch 5\n0: 12 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 358108.39193725586\nINFO:root:3: Epoch 0 train loss: 524734.860903422\nINFO:root:2: Epoch 0 train loss: 208891.98702494302\nINFO:root:1: Epoch 0 train loss: 190598.91999880472\nINFO:root:0: Epoch 0 validation loss: 301269.19801664853\nINFO:root:0: Epoch 1 train loss: 366985.1547393799\nINFO:root:2: Epoch 1 train loss: 182031.34298451743\nINFO:root:3: Epoch 1 train loss: 148494.6650543213\nINFO:root:1: Epoch 1 train loss: 719588.5367126465\nINFO:root:0: Epoch 1 validation loss: 301205.7796647433\nINFO:root:0: Epoch 2 train loss: 429964.42064030963\nINFO:root:3: Epoch 2 train loss: 69986.72528076172\nINFO:root:2: Epoch 2 train loss: 206587.5142774582\nINFO:root:1: Epoch 2 train loss: 414142.2102203369\nINFO:root:0: Epoch 2 validation loss: 301072.6719072091\nINFO:root:0: Epoch 3 train loss: 342942.40595499676\nINFO:root:2: Epoch 3 train loss: 170464.74532063803\nINFO:root:3: Epoch 3 train loss: 12846.645080566406\nINFO:root:1: Epoch 3 train loss: 318366.94631449383\nINFO:root:0: Epoch 3 validation loss: 300805.81530501926\nINFO:root:0: Epoch 4 train loss: 527818.4310963949\nINFO:root:2: Epoch 4 train loss: 564024.7932434082\nINFO:root:1: Epoch 4 train loss: 477742.8775583903\nINFO:root:3: Epoch 4 train loss: 383044.6560745239\nINFO:root:0: Epoch 4 validation loss: 300524.10174131393\nINFO:root:0: Epoch 5 train loss: 180066.9171180725\nINFO:root:2: Epoch 5 train loss: 604986.9873275757\nINFO:root:3: Epoch 5 train loss: 288261.6473757426\nINFO:root:1: Epoch 5 train loss: 291369.16497802734\nINFO:root:0: Epoch 5 validation loss: 300290.7351629652\n", "seconds": 5.7605140209198, "batch_size": 64, "nodes": 4, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 10 batches\n2 Start Epoch 0\n2: 10 batches\n1 Start Epoch 0\n1: 10 batches\n4 Start Epoch 0\n4: 10 batches\n3 Start Epoch 0\n3: 10 batches\n2 Start Epoch 1\n3 Start Epoch 1\n1 Start Epoch 1\n2: 10 batches\n3: 10 batches\n1: 10 batches\n4 Start Epoch 1\n4: 10 batches\n0 Start Epoch 1\n0: 10 batches\n1 Start Epoch 2\n2 Start Epoch 2\n1: 10 batches\n2: 10 batches\n4 Start Epoch 2\n4: 10 batches\n3 Start Epoch 2\n3: 10 batches\n0 Start Epoch 2\n0: 10 batches\n1 Start Epoch 3\n2 Start Epoch 3\n3 Start Epoch 3\n1: 10 batches\n2: 10 batches\n3: 10 batches\n4 Start Epoch 3\n4: 10 batches\n0 Start Epoch 3\n0: 10 batches\n2 Start Epoch 4\n3 Start Epoch 4\n1 Start Epoch 4\n2: 10 batches\n3: 10 batches\n1: 10 batches\n4 Start Epoch 4\n4: 10 batches\n0 Start Epoch 4\n0: 10 batches\n2 Start Epoch 5\n3 Start Epoch 5\n2: 10 batches\n3: 10 batches\n4 Start Epoch 5\n4: 10 batches\n1 Start Epoch 5\n1: 10 batches\n0 Start Epoch 5\n0: 10 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:2: Epoch 0 train loss: 77525.02095031738\nINFO:root:3: Epoch 0 train loss: 388274.8512573242\nINFO:root:1: Epoch 0 train loss: 245945.4724609375\nINFO:root:0: Epoch 0 train loss: 199337.27318725587\nINFO:root:4: Epoch 0 train loss: 254562.9660003662\nINFO:root:0: Epoch 0 validation loss: 962370.7677819283\nINFO:root:1: Epoch 1 train loss: 250485.9338745117\nINFO:root:2: Epoch 1 train loss: 15541.527192687989\nINFO:root:0: Epoch 1 train loss: 383146.94219970703\nINFO:root:4: Epoch 1 train loss: 249278.37890472412\nINFO:root:3: Epoch 1 train loss: 6997.164172363281\nINFO:root:0: Epoch 1 validation loss: 962197.3276819129\nINFO:root:0: Epoch 2 train loss: 8441.215618896484\nINFO:root:1: Epoch 2 train loss: 276545.72959747317\nINFO:root:2: Epoch 2 train loss: 415745.5635269165\nINFO:root:3: Epoch 2 train loss: 247202.26957092286\nINFO:root:4: Epoch 2 train loss: 402745.3851501465\nINFO:root:0: Epoch 2 validation loss: 961952.8897573984\nINFO:root:0: Epoch 3 train loss: 994824.0305419922\nINFO:root:2: Epoch 3 train loss: 416090.4207183838\nINFO:root:3: Epoch 3 train loss: 1070419.4349914552\nINFO:root:1: Epoch 3 train loss: 400459.7524719238\nINFO:root:4: Epoch 3 train loss: 31013.290518188478\nINFO:root:0: Epoch 3 validation loss: 961619.3857085746\nINFO:root:0: Epoch 4 train loss: 169653.5972448349\nINFO:root:3: Epoch 4 train loss: 8714.662672424316\nINFO:root:2: Epoch 4 train loss: 849833.358770752\nINFO:root:4: Epoch 4 train loss: 30537.200253295898\nINFO:root:1: Epoch 4 train loss: 277573.0326416016\nINFO:root:0: Epoch 4 validation loss: 961220.1945753344\nINFO:root:3: Epoch 5 train loss: 412026.4876022339\nINFO:root:2: Epoch 5 train loss: 749661.8181823731\nINFO:root:0: Epoch 5 train loss: 175245.28968048096\nINFO:root:4: Epoch 5 train loss: 202741.00057373047\nINFO:root:1: Epoch 5 train loss: 962506.4706604003\nINFO:root:0: Epoch 5 validation loss: 960753.0963325336\n", "seconds": 6.7129809856414795, "batch_size": 64, "nodes": 5, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 8 batches\n5 Start Epoch 0\n5: 8 batches\n3 Start Epoch 0\n3: 8 batches\n4 Start Epoch 0\n4: 8 batches\n2 Start Epoch 0\n2: 8 batches\n1 Start Epoch 0\n1: 8 batches\n1 Start Epoch 1\n2 Start Epoch 1\n3 Start Epoch 1\n1: 8 batches\n2: 8 batches\n5 Start Epoch 1\n3: 8 batches\n5: 8 batches\n4 Start Epoch 1\n4: 8 batches\n0 Start Epoch 1\n0: 8 batches\n1 Start Epoch 2\n2 Start Epoch 2\n3 Start Epoch 2\n2: 8 batches\n3: 8 batches\n1: 8 batches\n4 Start Epoch 2\n5 Start Epoch 2\n5: 8 batches\n4: 8 batches\n0 Start Epoch 2\n0: 8 batches\n1 Start Epoch 3\n2 Start Epoch 3\n3 Start Epoch 3\n1: 8 batches\n2: 8 batches\n5 Start Epoch 3\n3: 8 batches\n5: 8 batches\n4 Start Epoch 3\n4: 8 batches\n0 Start Epoch 3\n0: 8 batches\n1 Start Epoch 4\n2 Start Epoch 4\n1: 8 batches\n2: 8 batches\n3 Start Epoch 4\n3: 8 batches\n4 Start Epoch 4\n5 Start Epoch 4\n5: 8 batches\n4: 8 batches\n0 Start Epoch 4\n0: 8 batches\n1 Start Epoch 5\n1: 8 batches\n2 Start Epoch 5\n2: 8 batches\n3 Start Epoch 5\n3: 8 batches\n4 Start Epoch 5\n5 Start Epoch 5\n5: 8 batches\n4: 8 batches\n0 Start Epoch 5\n0: 8 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 295446.3400039673\nINFO:root:3: Epoch 0 train loss: 659061.6868743896\nINFO:root:1: Epoch 0 train loss: 253689.23497390747\nINFO:root:2: Epoch 0 train loss: 386923.5712890625\nINFO:root:5: Epoch 0 train loss: 828023.397277832\nINFO:root:4: Epoch 0 train loss: 739147.6621398926\nINFO:root:0: Epoch 0 validation loss: 15186.594846590036\nINFO:root:0: Epoch 1 train loss: 304379.28816223145\nINFO:root:1: Epoch 1 train loss: 609722.3530387878\nINFO:root:2: Epoch 1 train loss: 12981.505735397339\nINFO:root:3: Epoch 1 train loss: 547163.1358642578\nINFO:root:4: Epoch 1 train loss: 20303.687393188477\nINFO:root:5: Epoch 1 train loss: 36875.351749420166\nINFO:root:0: Epoch 1 validation loss: 15168.46599711375\nINFO:root:1: Epoch 2 train loss: 571305.0834732056\nINFO:root:2: Epoch 2 train loss: 121737.90782928467\nINFO:root:3: Epoch 2 train loss: 1144927.052520752\nINFO:root:5: Epoch 2 train loss: 353630.068069458\nINFO:root:4: Epoch 2 train loss: 491406.20862960815\nINFO:root:0: Epoch 2 train loss: 247010.80628585815\nINFO:root:0: Epoch 2 validation loss: 15143.686633339474\nINFO:root:1: Epoch 3 train loss: 287706.3527698517\nINFO:root:2: Epoch 3 train loss: 10817.584117889404\nINFO:root:3: Epoch 3 train loss: 481478.46281433105\nINFO:root:4: Epoch 3 train loss: 120814.73127746582\nINFO:root:5: Epoch 3 train loss: 584654.5766601562\nINFO:root:0: Epoch 3 train loss: 811164.4505157471\nINFO:root:0: Epoch 3 validation loss: 15104.372336946428\nINFO:root:1: Epoch 4 train loss: 398380.1469116211\nINFO:root:2: Epoch 4 train loss: 42033.27181625366\nINFO:root:3: Epoch 4 train loss: 913549.011680603\nINFO:root:4: Epoch 4 train loss: 525293.1891708374\nINFO:root:5: Epoch 4 train loss: 231134.64539718628\nINFO:root:0: Epoch 4 train loss: 845391.1859970093\nINFO:root:0: Epoch 4 validation loss: 15046.725158092147\nINFO:root:5: Epoch 5 train loss: 230842.85161209106\nINFO:root:1: Epoch 5 train loss: 470724.60330200195\nINFO:root:2: Epoch 5 train loss: 719318.6149902344\nINFO:root:4: Epoch 5 train loss: 101323.68811416626\nINFO:root:0: Epoch 5 train loss: 730648.0802726746\nINFO:root:3: Epoch 5 train loss: 90484.07930755615\nINFO:root:0: Epoch 5 validation loss: 14982.676826061874\n", "seconds": 7.724648952484131, "batch_size": 64, "nodes": 6, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 7 batches\n2 Start Epoch 0\n2: 7 batches\n1 Start Epoch 0\n4 Start Epoch 0\n5 Start Epoch 0\n1: 7 batches\n6 Start Epoch 0\n4: 7 batches\n3 Start Epoch 0\n3: 7 batches\n5: 7 batches\n6: 7 batches\n5 Start Epoch 1\n5: 7 batches\n3 Start Epoch 1\n2 Start Epoch 1\n3: 7 batches\n2: 7 batches\n4 Start Epoch 1\n4: 7 batches\n1 Start Epoch 1\n1: 7 batches\n6 Start Epoch 1\n6: 7 batches\n0 Start Epoch 1\n0: 7 batches\n5 Start Epoch 2\n3 Start Epoch 2\n3: 7 batches\n2 Start Epoch 2\n5: 7 batches\n2: 7 batches\n6 Start Epoch 2\n6: 7 batches\n4 Start Epoch 2\n4: 7 batches\n1 Start Epoch 2\n1: 7 batches\n0 Start Epoch 2\n0: 7 batches\n5 Start Epoch 3\n3 Start Epoch 3\n3: 7 batches\n5: 7 batches\n2 Start Epoch 3\n2: 7 batches\n6 Start Epoch 3\n6: 7 batches\n4 Start Epoch 3\n4: 7 batches\n1 Start Epoch 3\n1: 7 batches\n0 Start Epoch 3\n0: 7 batches\n3 Start Epoch 4\n2 Start Epoch 4\n3: 7 batches\n2: 7 batches\n5 Start Epoch 4\n5: 7 batches\n6 Start Epoch 4\n4 Start Epoch 4\n6: 7 batches\n4: 7 batches\n1 Start Epoch 4\n1: 7 batches\n0 Start Epoch 4\n0: 7 batches\n3 Start Epoch 5\n3: 7 batches\n5 Start Epoch 5\n5: 7 batches\n2 Start Epoch 5\n2: 7 batches\n6 Start Epoch 5\n4 Start Epoch 5\n4: 7 batches\n6: 7 batches\n1 Start Epoch 5\n1: 7 batches\n0 Start Epoch 5\n0: 7 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:5: Epoch 0 train loss: 160913.9388558524\nINFO:root:3: Epoch 0 train loss: 385073.6942225865\nINFO:root:2: Epoch 0 train loss: 17729.13010951451\nINFO:root:4: Epoch 0 train loss: 255101.22145298548\nINFO:root:1: Epoch 0 train loss: 8863.539576939174\nINFO:root:0: Epoch 0 train loss: 365933.77388327464\nINFO:root:6: Epoch 0 train loss: 331283.22106933594\nINFO:root:0: Epoch 0 validation loss: 95471134.72404957\nINFO:root:5: Epoch 1 train loss: 561692.880972726\nINFO:root:3: Epoch 1 train loss: 280327.92790876114\nINFO:root:2: Epoch 1 train loss: 257279.45964050293\nINFO:root:6: Epoch 1 train loss: 794311.3301348005\nINFO:root:4: Epoch 1 train loss: 5313.600555419922\nINFO:root:1: Epoch 1 train loss: 635985.1594063895\nINFO:root:0: Epoch 1 train loss: 278820.40819440567\nINFO:root:0: Epoch 1 validation loss: 95470672.36707412\nINFO:root:3: Epoch 2 train loss: 265270.37585231237\nINFO:root:5: Epoch 2 train loss: 308715.3651297433\nINFO:root:2: Epoch 2 train loss: 446369.3542480469\nINFO:root:6: Epoch 2 train loss: 280806.0589076451\nINFO:root:4: Epoch 2 train loss: 284751.4710279192\nINFO:root:0: Epoch 2 train loss: 347109.0813860212\nINFO:root:1: Epoch 2 train loss: 458563.01004900254\nINFO:root:0: Epoch 2 validation loss: 95470147.6047769\nINFO:root:3: Epoch 3 train loss: 10322.636003766742\nINFO:root:2: Epoch 3 train loss: 323396.8533979143\nINFO:root:5: Epoch 3 train loss: 283217.65096609935\nINFO:root:0: Epoch 3 train loss: 313593.80969892227\nINFO:root:6: Epoch 3 train loss: 235175.56227220807\nINFO:root:4: Epoch 3 train loss: 624916.0078473772\nINFO:root:1: Epoch 3 train loss: 16128.255684988839\nINFO:root:0: Epoch 3 validation loss: 95469400.70270066\nINFO:root:3: Epoch 4 train loss: 891909.0486711775\nINFO:root:5: Epoch 4 train loss: 5696.636771065848\nINFO:root:2: Epoch 4 train loss: 602913.6674434117\nINFO:root:6: Epoch 4 train loss: 9723.677943638393\nINFO:root:4: Epoch 4 train loss: 325393.79316493444\nINFO:root:0: Epoch 4 train loss: 361431.78248814173\nINFO:root:1: Epoch 4 train loss: 583643.1118512835\nINFO:root:0: Epoch 4 validation loss: 95468271.90933675\nINFO:root:5: Epoch 5 train loss: 304170.9866333008\nINFO:root:2: Epoch 5 train loss: 22264.04451424735\nINFO:root:3: Epoch 5 train loss: 657628.3579665592\nINFO:root:6: Epoch 5 train loss: 674901.6038643973\nINFO:root:0: Epoch 5 train loss: 466877.4248788016\nINFO:root:4: Epoch 5 train loss: 11714.539934430804\nINFO:root:1: Epoch 5 train loss: 286568.5946393694\nINFO:root:0: Epoch 5 validation loss: 95466637.3725972\n", "seconds": 7.193881988525391, "batch_size": 64, "nodes": 7, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 6 batches\n7 Start Epoch 0\n7: 6 batches\n2 Start Epoch 0\n2: 6 batches\n4 Start Epoch 0\n3 Start Epoch 0\n1 Start Epoch 0\n3: 6 batches\n5 Start Epoch 0\n1: 6 batches\n6 Start Epoch 0\n4: 6 batches\n5: 6 batches\n6: 6 batches\n5 Start Epoch 1\n2 Start Epoch 1\n5: 6 batches\n7 Start Epoch 1\n1 Start Epoch 1\n2: 6 batches\n7: 6 batches\n1: 6 batches\n6 Start Epoch 1\n4 Start Epoch 1\n6: 6 batches\n4: 6 batches\n3 Start Epoch 1\n3: 6 batches\n0 Start Epoch 1\n0: 6 batches\n2 Start Epoch 2\n1 Start Epoch 2\n2: 6 batches\n1: 6 batches\n6 Start Epoch 2\n6: 6 batches\n4 Start Epoch 2\n3 Start Epoch 2\n4: 6 batches\n3: 6 batches\n5 Start Epoch 2\n5: 6 batches\n7 Start Epoch 2\n7: 6 batches\n0 Start Epoch 2\n0: 6 batches\n7 Start Epoch 3\n2 Start Epoch 3\n7: 6 batches\n1 Start Epoch 3\n1: 6 batches\n2: 6 batches\n6 Start Epoch 3\n6: 6 batches\n4 Start Epoch 3\n4: 6 batches\n3 Start Epoch 3\n5 Start Epoch 3\n3: 6 batches\n5: 6 batches\n0 Start Epoch 3\n0: 6 batches\n7 Start Epoch 4\n1 Start Epoch 4\n2 Start Epoch 4\n7: 6 batches\n1: 6 batches\n2: 6 batches\n6 Start Epoch 4\n4 Start Epoch 4\n4: 6 batches\n6: 6 batches\n3 Start Epoch 4\n5 Start Epoch 4\n3: 6 batches\n5: 6 batches\n0 Start Epoch 4\n0: 6 batches\n2 Start Epoch 5\n1 Start Epoch 5\n1: 6 batches\n2: 6 batches\n7 Start Epoch 5\n5 Start Epoch 5\n5: 6 batches\n7: 6 batches\n4 Start Epoch 5\n3 Start Epoch 5\n6 Start Epoch 5\n4: 6 batches\n3: 6 batches\n6: 6 batches\n0 Start Epoch 5\n0: 6 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:5: Epoch 0 train loss: 660500.1640268961\nINFO:root:7: Epoch 0 train loss: 8806.447408040365\nINFO:root:1: Epoch 0 train loss: 300589.98030598956\nINFO:root:2: Epoch 0 train loss: 10647.414154052734\nINFO:root:6: Epoch 0 train loss: 432533.4356282552\nINFO:root:4: Epoch 0 train loss: 1112596.078244527\nINFO:root:3: Epoch 0 train loss: 122253.21158854167\nINFO:root:0: Epoch 0 train loss: 653656.1720377604\nINFO:root:0: Epoch 0 validation loss: 3014.967327232353\nINFO:root:1: Epoch 1 train loss: 18194.739115397137\nINFO:root:2: Epoch 1 train loss: 294642.74450683594\nINFO:root:6: Epoch 1 train loss: 13891.893127441406\nINFO:root:4: Epoch 1 train loss: 418412.9977213542\nINFO:root:3: Epoch 1 train loss: 5270.654429117839\nINFO:root:0: Epoch 1 train loss: 7966.680450439453\nINFO:root:5: Epoch 1 train loss: 449927.60440063477\nINFO:root:7: Epoch 1 train loss: 21268.469980875652\nINFO:root:0: Epoch 1 validation loss: 3011.1596372133395\nINFO:root:7: Epoch 2 train loss: 353645.6367492676\nINFO:root:1: Epoch 2 train loss: 396419.1600036621\nINFO:root:2: Epoch 2 train loss: 639456.5354919434\nINFO:root:6: Epoch 2 train loss: 797042.609568278\nINFO:root:4: Epoch 2 train loss: 627322.5893147787\nINFO:root:3: Epoch 2 train loss: 738047.3669560751\nINFO:root:0: Epoch 2 train loss: 350430.8342285156\nINFO:root:5: Epoch 2 train loss: 11036.648122151693\nINFO:root:0: Epoch 2 validation loss: 3006.6190190904226\nINFO:root:7: Epoch 3 train loss: 745503.7532552084\nINFO:root:2: Epoch 3 train loss: 279082.86454264325\nINFO:root:1: Epoch 3 train loss: 825048.5943501791\nINFO:root:6: Epoch 3 train loss: 325966.5035603841\nINFO:root:4: Epoch 3 train loss: 418445.5757751465\nINFO:root:3: Epoch 3 train loss: 3971.1856079101562\nINFO:root:5: Epoch 3 train loss: 45302.71096801758\nINFO:root:0: Epoch 3 train loss: 15680.776163736979\nINFO:root:0: Epoch 3 validation loss: 3000.922054024349\nINFO:root:2: Epoch 4 train loss: 555753.6379089355\nINFO:root:1: Epoch 4 train loss: 615560.8199462891\nINFO:root:5: Epoch 4 train loss: 335192.74588012695\nINFO:root:7: Epoch 4 train loss: 120112.44197591145\nINFO:root:3: Epoch 4 train loss: 925747.611328125\nINFO:root:4: Epoch 4 train loss: 130350.4051920573\nINFO:root:6: Epoch 4 train loss: 17111.34829711914\nINFO:root:0: Epoch 4 train loss: 41800.39049657186\nINFO:root:0: Epoch 4 validation loss: 2992.908284193483\nINFO:root:2: Epoch 5 train loss: 404010.2168782552\nINFO:root:3: Epoch 5 train loss: 6641.0159912109375\nINFO:root:7: Epoch 5 train loss: 386206.5703938802\nINFO:root:5: Epoch 5 train loss: 331599.79345703125\nINFO:root:6: Epoch 5 train loss: 735777.2391967773\nINFO:root:4: Epoch 5 train loss: 1214749.931508382\nINFO:root:0: Epoch 5 train loss: 378643.63317871094\nINFO:root:1: Epoch 5 train loss: 17284.409301757812\nINFO:root:0: Epoch 5 validation loss: 2981.559179448105\n", "seconds": 8.025966882705688, "batch_size": 64, "nodes": 8, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 6 batches\n6 Start Epoch 0\n1 Start Epoch 0\n2 Start Epoch 0\n6: 6 batches\n1: 6 batches\n2: 6 batches\n5 Start Epoch 0\n3 Start Epoch 0\n8 Start Epoch 0\n4 Start Epoch 0\n3: 6 batches\n8: 6 batches\n4: 6 batches\n7 Start Epoch 0\n5: 6 batches\n7: 6 batches\n3 Start Epoch 1\n3: 6 batches\n1 Start Epoch 1\n7 Start Epoch 1\n1: 6 batches\n7: 6 batches\n4 Start Epoch 1\n4: 6 batches\n5 Start Epoch 1\n5: 6 batches\n6 Start Epoch 1\n6: 6 batches\n2 Start Epoch 1\n8 Start Epoch 1\n2: 6 batches\n8: 6 batches\n0 Start Epoch 1\n0: 6 batches\n7 Start Epoch 2\n1 Start Epoch 2\n7: 6 batches\n1: 6 batches\n3 Start Epoch 2\n3: 6 batches\n4 Start Epoch 2\n5 Start Epoch 2\n4: 6 batches\n6 Start Epoch 2\n2 Start Epoch 2\n5: 6 batches\n8 Start Epoch 2\n6: 6 batches\n2: 6 batches\n8: 6 batches\n0 Start Epoch 2\n0: 6 batches\n3 Start Epoch 3\n1 Start Epoch 3\n7 Start Epoch 3\n3: 6 batches\n1: 6 batches\n7: 6 batches\n5 Start Epoch 3\n4 Start Epoch 3\n8 Start Epoch 3\n4: 6 batches\n6 Start Epoch 3\n2 Start Epoch 3\n5: 6 batches\n8: 6 batches\n6: 6 batches\n2: 6 batches\n0 Start Epoch 3\n0: 6 batches\n3 Start Epoch 4\n1 Start Epoch 4\n7 Start Epoch 4\n3: 6 batches\n1: 6 batches\n7: 6 batches\n8 Start Epoch 4\n8: 6 batches\n4 Start Epoch 4\n4: 6 batches\n2 Start Epoch 4\n2: 6 batches\n5 Start Epoch 4\n6 Start Epoch 4\n5: 6 batches\n6: 6 batches\n0 Start Epoch 4\n0: 6 batches\n7 Start Epoch 5\n7: 6 batches\n1 Start Epoch 5\n1: 6 batches\n2 Start Epoch 5\n2: 6 batches\n4 Start Epoch 5\n5 Start Epoch 5\n4: 6 batches\n6 Start Epoch 5\n5: 6 batches\n6: 6 batches\n3 Start Epoch 5\n3: 6 batches\n8 Start Epoch 5\n8: 6 batches\n0 Start Epoch 5\n0: 6 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:3: Epoch 0 train loss: 26502.973795572918\nINFO:root:1: Epoch 0 train loss: 360668.0634358724\nINFO:root:7: Epoch 0 train loss: 399398.0994867335\nINFO:root:4: Epoch 0 train loss: 18227.006267547607\nINFO:root:5: Epoch 0 train loss: 624921.1201664606\nINFO:root:6: Epoch 0 train loss: 764563.4630977312\nINFO:root:2: Epoch 0 train loss: 11692.8676071167\nINFO:root:8: Epoch 0 train loss: 409571.84494018555\nINFO:root:0: Epoch 0 train loss: 7547.209640741348\nINFO:root:0: Epoch 0 validation loss: 244257392.3727137\nINFO:root:7: Epoch 1 train loss: 4831.497172037761\nINFO:root:1: Epoch 1 train loss: 13820.572092692057\nINFO:root:3: Epoch 1 train loss: 1641125.6674346924\nINFO:root:4: Epoch 1 train loss: 55161.18454694748\nINFO:root:5: Epoch 1 train loss: 1024588.6161295573\nINFO:root:6: Epoch 1 train loss: 717641.686920166\nINFO:root:2: Epoch 1 train loss: 303434.5031636556\nINFO:root:0: Epoch 1 train loss: 9524.806637426218\nINFO:root:8: Epoch 1 train loss: 302095.4695224762\nINFO:root:0: Epoch 1 validation loss: 244257022.35110977\nINFO:root:1: Epoch 2 train loss: 710263.3019205729\nINFO:root:7: Epoch 2 train loss: 449795.44571940106\nINFO:root:3: Epoch 2 train loss: 1433155.4737548828\nINFO:root:4: Epoch 2 train loss: 378454.75619506836\nINFO:root:5: Epoch 2 train loss: 8967.879053751627\nINFO:root:8: Epoch 2 train loss: 26574.584218343098\nINFO:root:6: Epoch 2 train loss: 686112.8911946615\nINFO:root:2: Epoch 2 train loss: 501765.4837239583\nINFO:root:0: Epoch 2 train loss: 6554.453934987386\nINFO:root:0: Epoch 2 validation loss: 244256533.9978709\nINFO:root:1: Epoch 3 train loss: 409285.78847249347\nINFO:root:7: Epoch 3 train loss: 50453.102030436195\nINFO:root:3: Epoch 3 train loss: 1011190.320532163\nINFO:root:8: Epoch 3 train loss: 5906.149116516113\nINFO:root:4: Epoch 3 train loss: 360777.94873046875\nINFO:root:2: Epoch 3 train loss: 660362.5797234377\nINFO:root:0: Epoch 3 train loss: 10256.721537371477\nINFO:root:5: Epoch 3 train loss: 488246.74399312335\nINFO:root:6: Epoch 3 train loss: 19915.609944661457\nINFO:root:0: Epoch 3 validation loss: 244255845.38003528\nINFO:root:7: Epoch 4 train loss: 8758.439481099447\nINFO:root:1: Epoch 4 train loss: 378215.1482014656\nINFO:root:2: Epoch 4 train loss: 9662.385494232178\nINFO:root:4: Epoch 4 train loss: 11416.621587117514\nINFO:root:6: Epoch 4 train loss: 282752.6267801921\nINFO:root:5: Epoch 4 train loss: 4721.107070922852\nINFO:root:3: Epoch 4 train loss: 367043.7279205322\nINFO:root:8: Epoch 4 train loss: 3626.2577616373696\nINFO:root:0: Epoch 4 train loss: 4864.091487248738\nINFO:root:0: Epoch 4 validation loss: 244255014.74568623\nINFO:root:2: Epoch 5 train loss: 168972.65600585938\nINFO:root:7: Epoch 5 train loss: 14483.035018920898\nINFO:root:3: Epoch 5 train loss: 325907.6598307292\nINFO:root:0: Epoch 5 train loss: 9910.454450170198\nINFO:root:4: Epoch 5 train loss: 385020.31583531696\nINFO:root:5: Epoch 5 train loss: 129023.77293078105\nINFO:root:6: Epoch 5 train loss: 293350.8996744156\nINFO:root:8: Epoch 5 train loss: 364246.6256154378\nINFO:root:1: Epoch 5 train loss: 1352.6454060872395\nINFO:root:0: Epoch 5 validation loss: 244253806.6775159\n", "seconds": 7.178376913070679, "batch_size": 64, "nodes": 9, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 5 batches\n6 Start Epoch 0\n8 Start Epoch 0\n6: 5 batches\n8: 5 batches\n9 Start Epoch 0\n9: 5 batches\n2 Start Epoch 0\n2: 5 batches\n1 Start Epoch 0\n7 Start Epoch 0\n3 Start Epoch 0\n4 Start Epoch 0\n4: 5 batches\n1: 5 batches\n5 Start Epoch 0\n7: 5 batches\n3: 5 batches\n5: 5 batches\n3 Start Epoch 1\n1 Start Epoch 1\n3: 5 batches\n1: 5 batches\n7 Start Epoch 1\n8 Start Epoch 1\n7: 5 batches\n8: 5 batches\n5 Start Epoch 1\n4 Start Epoch 1\n6 Start Epoch 1\n2 Start Epoch 1\n9 Start Epoch 1\n6: 5 batches\n2: 5 batches\n9: 5 batches\n5: 5 batches\n4: 5 batches\n0 Start Epoch 1\n0: 5 batches\n7 Start Epoch 2\n9 Start Epoch 2\n1 Start Epoch 2\n7: 5 batches\n3 Start Epoch 2\n9: 5 batches\n1: 5 batches\n3: 5 batches\n4 Start Epoch 2\n4: 5 batches\n8 Start Epoch 2\n6 Start Epoch 2\n5 Start Epoch 2\n6: 5 batches\n2 Start Epoch 2\n5: 5 batches\n8: 5 batches\n2: 5 batches\n0 Start Epoch 2\n0: 5 batches\n3 Start Epoch 3\n3: 5 batches\n9 Start Epoch 3\n1 Start Epoch 3\n9: 5 batches\n1: 5 batches\n2 Start Epoch 3\n4 Start Epoch 3\n4: 5 batches\n5 Start Epoch 3\n6 Start Epoch 3\n2: 5 batches\n8 Start Epoch 3\n6: 5 batches\n5: 5 batches\n8: 5 batches\n7 Start Epoch 3\n7: 5 batches\n0 Start Epoch 3\n0: 5 batches\n3 Start Epoch 4\n9 Start Epoch 4\n1 Start Epoch 4\n9: 5 batches\n1: 5 batches\n3: 5 batches\n2 Start Epoch 4\n4 Start Epoch 4\n2: 5 batches\n5 Start Epoch 4\n4: 5 batches\n6 Start Epoch 4\n7 Start Epoch 4\n8 Start Epoch 4\n6: 5 batches\n5: 5 batches\n7: 5 batches\n8: 5 batches\n0 Start Epoch 4\n0: 5 batches\n8 Start Epoch 5\n9 Start Epoch 5\n1 Start Epoch 5\n3 Start Epoch 5\n8: 5 batches\n9: 5 batches\n1: 5 batches\n3: 5 batches\n6 Start Epoch 5\n6: 5 batches\n2 Start Epoch 5\n5 Start Epoch 5\n7 Start Epoch 5\n4 Start Epoch 5\n4: 5 batches\n2: 5 batches\n5: 5 batches\n7: 5 batches\n0 Start Epoch 5\n0: 5 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 412626.58671875\nINFO:root:3: Epoch 0 train loss: 329836.269140625\nINFO:root:1: Epoch 0 train loss: 327974.44016113284\nINFO:root:8: Epoch 0 train loss: 12915.159057617188\nINFO:root:7: Epoch 0 train loss: 7291.928466796875\nINFO:root:2: Epoch 0 train loss: 439306.90695800784\nINFO:root:9: Epoch 0 train loss: 4833.123919677734\nINFO:root:5: Epoch 0 train loss: 149888.1586303711\nINFO:root:4: Epoch 0 train loss: 1152149.9056640626\nINFO:root:6: Epoch 0 train loss: 689072.6372375488\nINFO:root:0: Epoch 0 validation loss: 135586.48633750321\nINFO:root:0: Epoch 1 train loss: 81983.5754638672\nINFO:root:7: Epoch 1 train loss: 14004.774340820313\nINFO:root:9: Epoch 1 train loss: 155484.58142700195\nINFO:root:1: Epoch 1 train loss: 486998.10931396484\nINFO:root:3: Epoch 1 train loss: 5898.066766357422\nINFO:root:4: Epoch 1 train loss: 405826.9006103516\nINFO:root:5: Epoch 1 train loss: 443667.32556152344\nINFO:root:8: Epoch 1 train loss: 11777.663232421875\nINFO:root:6: Epoch 1 train loss: 658074.6508544922\nINFO:root:2: Epoch 1 train loss: 360469.7640625\nINFO:root:0: Epoch 1 validation loss: 135570.9307397026\nINFO:root:3: Epoch 2 train loss: 619678.4654785156\nINFO:root:0: Epoch 2 train loss: 6647.337860107422\nINFO:root:9: Epoch 2 train loss: 614962.641796875\nINFO:root:1: Epoch 2 train loss: 8572.042935180663\nINFO:root:2: Epoch 2 train loss: 21116.7638671875\nINFO:root:4: Epoch 2 train loss: 8879.935705566406\nINFO:root:6: Epoch 2 train loss: 481478.5645980835\nINFO:root:5: Epoch 2 train loss: 7650.733969116211\nINFO:root:8: Epoch 2 train loss: 20601.876574707032\nINFO:root:7: Epoch 2 train loss: 437619.8150390625\nINFO:root:0: Epoch 2 validation loss: 135555.5747865441\nINFO:root:0: Epoch 3 train loss: 8597.415307617188\nINFO:root:9: Epoch 3 train loss: 405295.69783630373\nINFO:root:1: Epoch 3 train loss: 685255.764074707\nINFO:root:3: Epoch 3 train loss: 431046.3134536743\nINFO:root:4: Epoch 3 train loss: 8376.773944091798\nINFO:root:2: Epoch 3 train loss: 1144606.6296386719\nINFO:root:6: Epoch 3 train loss: 142749.27254638672\nINFO:root:5: Epoch 3 train loss: 2991.383381652832\nINFO:root:7: Epoch 3 train loss: 6773.326904296875\nINFO:root:8: Epoch 3 train loss: 342639.638684082\nINFO:root:0: Epoch 3 validation loss: 135538.90196039452\nINFO:root:9: Epoch 4 train loss: 1573349.3684692383\nINFO:root:1: Epoch 4 train loss: 387656.4042602539\nINFO:root:3: Epoch 4 train loss: 1159531.3680664063\nINFO:root:8: Epoch 4 train loss: 434658.72885551455\nINFO:root:0: Epoch 4 train loss: 10071.45322265625\nINFO:root:6: Epoch 4 train loss: 14441.634381103515\nINFO:root:7: Epoch 4 train loss: 1027304.3027832031\nINFO:root:4: Epoch 4 train loss: 5708.800512695312\nINFO:root:2: Epoch 4 train loss: 332681.3219238281\nINFO:root:5: Epoch 4 train loss: 16690.905847167967\nINFO:root:0: Epoch 4 validation loss: 135519.01699897184\nINFO:root:3: Epoch 5 train loss: 790671.0394897461\nINFO:root:8: Epoch 5 train loss: 7989.3182373046875\nINFO:root:1: Epoch 5 train loss: 779074.104296875\nINFO:root:0: Epoch 5 train loss: 394815.09765625\nINFO:root:5: Epoch 5 train loss: 9613.848095703124\nINFO:root:6: Epoch 5 train loss: 552901.1288574219\nINFO:root:4: Epoch 5 train loss: 659926.4304443359\nINFO:root:2: Epoch 5 train loss: 22354.10673828125\nINFO:root:7: Epoch 5 train loss: 351375.9231491089\nINFO:root:9: Epoch 5 train loss: 902629.8361175538\nINFO:root:0: Epoch 5 validation loss: 135493.65043823048\n", "seconds": 7.982365131378174, "batch_size": 64, "nodes": 10, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 5 batches\n4 Start Epoch 0\n4: 5 batches\n7 Start Epoch 0\n7: 5 batches\n2 Start Epoch 0\n2: 5 batches\n3 Start Epoch 0\n1 Start Epoch 0\n8 Start Epoch 0\n3: 5 batches\n1: 5 batches\n8: 5 batches\n6 Start Epoch 0\n5 Start Epoch 0\n6: 5 batches\n5: 5 batches\n9 Start Epoch 0\n10 Start Epoch 0\n9: 5 batches\n10: 5 batches\n3 Start Epoch 1\n9 Start Epoch 1\n3: 5 batches\n1 Start Epoch 1\n9: 5 batches\n1: 5 batches\n2 Start Epoch 1\n4 Start Epoch 1\n6 Start Epoch 1\n7 Start Epoch 1\n5 Start Epoch 1\n10 Start Epoch 1\n10: 5 batches\n8 Start Epoch 1\n2: 5 batches\n4: 5 batches\n6: 5 batches\n7: 5 batches\n5: 5 batches\n8: 5 batches\n0 Start Epoch 1\n0: 5 batches\n3 Start Epoch 2\n9 Start Epoch 2\n3: 5 batches\n1 Start Epoch 2\n9: 5 batches\n1: 5 batches\n5 Start Epoch 2\n5: 5 batches\n10 Start Epoch 2\n8 Start Epoch 2\n2 Start Epoch 2\n4 Start Epoch 2\n6 Start Epoch 2\n7 Start Epoch 2\n10: 5 batches\n8: 5 batches\n2: 5 batches\n4: 5 batches\n6: 5 batches\n7: 5 batches\n0 Start Epoch 2\n0: 5 batches\n3 Start Epoch 3\n1 Start Epoch 3\n3: 5 batches\n1: 5 batches\n9 Start Epoch 3\n9: 5 batches\n5 Start Epoch 3\n5: 5 batches\n2 Start Epoch 3\n4 Start Epoch 3\n6 Start Epoch 3\n7 Start Epoch 3\n7: 5 batches\n10 Start Epoch 3\n8 Start Epoch 3\n2: 5 batches\n4: 5 batches\n6: 5 batches\n10: 5 batches\n8: 5 batches\n0 Start Epoch 3\n0: 5 batches\n3 Start Epoch 4\n1 Start Epoch 4\n3: 5 batches\n1: 5 batches\n9 Start Epoch 4\n9: 5 batches\n5 Start Epoch 4\n4 Start Epoch 4\n5: 5 batches\n4: 5 batches\n6 Start Epoch 4\n7 Start Epoch 4\n10 Start Epoch 4\n8 Start Epoch 4\n2 Start Epoch 4\n10: 5 batches\n8: 5 batches\n2: 5 batches\n6: 5 batches\n7: 5 batches\n0 Start Epoch 4\n0: 5 batches\n1 Start Epoch 5\n9 Start Epoch 5\n1: 5 batches\n9: 5 batches\n3 Start Epoch 5\n5 Start Epoch 5\n5: 5 batches\n8 Start Epoch 5\n3: 5 batches\n8: 5 batches\n10 Start Epoch 5\n4 Start Epoch 5\n6 Start Epoch 5\n7 Start Epoch 5\n10: 5 batches\n2 Start Epoch 5\n7: 5 batches\n2: 5 batches\n4: 5 batches\n6: 5 batches\n0 Start Epoch 5\n0: 5 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:9: Epoch 0 train loss: 487830.0403289795\nINFO:root:3: Epoch 0 train loss: 18418.97691040039\nINFO:root:1: Epoch 0 train loss: 5616.378838551044\nINFO:root:0: Epoch 0 train loss: 48449.71566162109\nINFO:root:5: Epoch 0 train loss: 4253.1049858093265\nINFO:root:10: Epoch 0 train loss: 388731.14147338865\nINFO:root:2: Epoch 0 train loss: 456933.94002685545\nINFO:root:4: Epoch 0 train loss: 22760.786218261717\nINFO:root:6: Epoch 0 train loss: 22078.12061767578\nINFO:root:7: Epoch 0 train loss: 418332.2334350586\nINFO:root:8: Epoch 0 train loss: 23572.391571044922\nINFO:root:0: Epoch 0 validation loss: 376670.77373316174\nINFO:root:3: Epoch 1 train loss: 13005.710748291016\nINFO:root:9: Epoch 1 train loss: 5082.764693450928\nINFO:root:1: Epoch 1 train loss: 16228.711077523232\nINFO:root:5: Epoch 1 train loss: 14892.267138671876\nINFO:root:0: Epoch 1 train loss: 11490.153750956059\nINFO:root:10: Epoch 1 train loss: 810404.3532000541\nINFO:root:8: Epoch 1 train loss: 391966.9634277344\nINFO:root:2: Epoch 1 train loss: 668492.9682739258\nINFO:root:4: Epoch 1 train loss: 16802.337622070314\nINFO:root:6: Epoch 1 train loss: 742607.0719352722\nINFO:root:7: Epoch 1 train loss: 443958.2675048828\nINFO:root:0: Epoch 1 validation loss: 376632.5041415587\nINFO:root:3: Epoch 2 train loss: 391191.0361061096\nINFO:root:1: Epoch 2 train loss: 193815.92208862305\nINFO:root:9: Epoch 2 train loss: 6137.179315853119\nINFO:root:5: Epoch 2 train loss: 13418.176983642577\nINFO:root:0: Epoch 2 train loss: 360913.3949279785\nINFO:root:2: Epoch 2 train loss: 7672.135144042969\nINFO:root:4: Epoch 2 train loss: 899388.4099542617\nINFO:root:6: Epoch 2 train loss: 9148.96654624939\nINFO:root:7: Epoch 2 train loss: 893730.5184503555\nINFO:root:8: Epoch 2 train loss: 431369.71511230466\nINFO:root:10: Epoch 2 train loss: 333473.8603881836\nINFO:root:0: Epoch 2 validation loss: 376588.92687987385\nINFO:root:1: Epoch 3 train loss: 5116.832962036133\nINFO:root:3: Epoch 3 train loss: 2920.4605926513673\nINFO:root:9: Epoch 3 train loss: 2886.4976318359377\nINFO:root:5: Epoch 3 train loss: 4642.778112792968\nINFO:root:0: Epoch 3 train loss: 5570.684605407715\nINFO:root:4: Epoch 3 train loss: 421468.54601478577\nINFO:root:2: Epoch 3 train loss: 418959.01647464035\nINFO:root:6: Epoch 3 train loss: 486731.39685058594\nINFO:root:7: Epoch 3 train loss: 11942.009497070312\nINFO:root:10: Epoch 3 train loss: 806566.7250976562\nINFO:root:8: Epoch 3 train loss: 7104.716586303711\nINFO:root:0: Epoch 3 validation loss: 376540.1593630715\nINFO:root:1: Epoch 4 train loss: 757813.1489746093\nINFO:root:9: Epoch 4 train loss: 1492328.983251953\nINFO:root:3: Epoch 4 train loss: 439773.66678295133\nINFO:root:5: Epoch 4 train loss: 434256.8015380859\nINFO:root:8: Epoch 4 train loss: 11916.641857910156\nINFO:root:0: Epoch 4 train loss: 429732.0148925781\nINFO:root:10: Epoch 4 train loss: 7309.470518493652\nINFO:root:2: Epoch 4 train loss: 407212.02357177733\nINFO:root:4: Epoch 4 train loss: 437380.6221485138\nINFO:root:6: Epoch 4 train loss: 406297.2448974609\nINFO:root:7: Epoch 4 train loss: 403948.78589749336\nINFO:root:0: Epoch 4 validation loss: 376477.162192617\nINFO:root:9: Epoch 5 train loss: 8958.292211914062\nINFO:root:0: Epoch 5 train loss: 486417.0287841797\nINFO:root:5: Epoch 5 train loss: 792578.3380432129\nINFO:root:10: Epoch 5 train loss: 9898.418899536133\nINFO:root:2: Epoch 5 train loss: 873366.9125976562\nINFO:root:4: Epoch 5 train loss: 1105.7876708984375\nINFO:root:6: Epoch 5 train loss: 412375.9382446289\nINFO:root:8: Epoch 5 train loss: 830314.8323242187\nINFO:root:3: Epoch 5 train loss: 7536.823532104492\nINFO:root:1: Epoch 5 train loss: 5018.172143554688\nINFO:root:7: Epoch 5 train loss: 59786.26785888672\nINFO:root:0: Epoch 5 validation loss: 376395.5599360877\n", "seconds": 7.719934940338135, "batch_size": 64, "nodes": 11, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 4 batches\n2 Start Epoch 0\n2: 4 batches\n8 Start Epoch 0\n8: 4 batches\n1 Start Epoch 0\n1: 4 batches\n5 Start Epoch 0\n6 Start Epoch 0\n5: 4 batches\n6: 4 batches\n3 Start Epoch 0\n11 Start Epoch 0\n3: 4 batches\n11: 4 batches\n4 Start Epoch 0\n7 Start Epoch 0\n4: 4 batches\n7: 4 batches\n9 Start Epoch 0\n10 Start Epoch 0\n9: 4 batches\n10: 4 batches\n3 Start Epoch 1\n9 Start Epoch 1\n3: 4 batches\n9: 4 batches\n8 Start Epoch 1\n8: 4 batches\n10 Start Epoch 1\n10: 4 batches\n11 Start Epoch 1\n2 Start Epoch 1\n11: 4 batches\n2: 4 batches\n4 Start Epoch 1\n5 Start Epoch 1\n6 Start Epoch 1\n1 Start Epoch 1\n1: 4 batches\n4: 4 batches\n7 Start Epoch 1\n5: 4 batches\n6: 4 batches\n7: 4 batches\n0 Start Epoch 1\n0: 4 batches\n8 Start Epoch 2\n3 Start Epoch 2\n8: 4 batches\n3: 4 batches\n5 Start Epoch 2\n5: 4 batches\n6 Start Epoch 2\n10 Start Epoch 2\n11 Start Epoch 2\n4 Start Epoch 2\n7 Start Epoch 2\n6: 4 batches\n10: 4 batches\n1 Start Epoch 2\n9 Start Epoch 2\n11: 4 batches\n2 Start Epoch 2\n4: 4 batches\n7: 4 batches\n1: 4 batches\n9: 4 batches\n2: 4 batches\n0 Start Epoch 2\n0: 4 batches\n8 Start Epoch 3\n8: 4 batches\n3 Start Epoch 3\n3: 4 batches\n10 Start Epoch 3\n4 Start Epoch 3\n5 Start Epoch 3\n6 Start Epoch 3\n10: 4 batches\n1 Start Epoch 3\n9 Start Epoch 3\n11 Start Epoch 3\n2 Start Epoch 3\n4: 4 batches\n7 Start Epoch 3\n5: 4 batches\n6: 4 batches\n7: 4 batches\n1: 4 batches\n9: 4 batches\n11: 4 batches\n2: 4 batches\n0 Start Epoch 3\n0: 4 batches\n3 Start Epoch 4\n3: 4 batches\n8 Start Epoch 4\n8: 4 batches\n4 Start Epoch 4\n5 Start Epoch 4\n6 Start Epoch 4\n5: 4 batches\n6: 4 batches\n10 Start Epoch 4\n11 Start Epoch 4\n2 Start Epoch 4\n4: 4 batches\n7 Start Epoch 4\n10: 4 batches\n1 Start Epoch 4\n9 Start Epoch 4\n11: 4 batches\n2: 4 batches\n7: 4 batches\n9: 4 batches\n1: 4 batches\n0 Start Epoch 4\n0: 4 batches\n3 Start Epoch 5\n8 Start Epoch 5\n3: 4 batches\n8: 4 batches\n1 Start Epoch 5\n1: 4 batches\n2 Start Epoch 5\n5 Start Epoch 5\n11 Start Epoch 5\n2: 4 batches\n4 Start Epoch 5\n7 Start Epoch 5\n5: 4 batches\n6 Start Epoch 5\n10 Start Epoch 5\n10: 4 batches\n9 Start Epoch 5\n11: 4 batches\n4: 4 batches\n7: 4 batches\n6: 4 batches\n9: 4 batches\n0 Start Epoch 5\n0: 4 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:9: Epoch 0 train loss: 640601.9821777344\nINFO:root:3: Epoch 0 train loss: 15823.504760742188\nINFO:root:8: Epoch 0 train loss: 485222.6354675293\nINFO:root:10: Epoch 0 train loss: 566364.7000579834\nINFO:root:11: Epoch 0 train loss: 518441.9041748047\nINFO:root:2: Epoch 0 train loss: 22425.095947265625\nINFO:root:4: Epoch 0 train loss: 201251.71054077148\nINFO:root:5: Epoch 0 train loss: 8609.002319335938\nINFO:root:6: Epoch 0 train loss: 1181949.2589111328\nINFO:root:1: Epoch 0 train loss: 5339.249893188477\nINFO:root:7: Epoch 0 train loss: 544250.5224609375\nINFO:root:0: Epoch 0 train loss: 412660.92346191406\nINFO:root:0: Epoch 0 validation loss: 582906.6310702075\nINFO:root:8: Epoch 1 train loss: 12340.192626953125\nINFO:root:3: Epoch 1 train loss: 487995.7271575928\nINFO:root:5: Epoch 1 train loss: 178534.60876464844\nINFO:root:6: Epoch 1 train loss: 523680.46321105957\nINFO:root:10: Epoch 1 train loss: 27620.67576599121\nINFO:root:11: Epoch 1 train loss: 894785.3764648438\nINFO:root:4: Epoch 1 train loss: 588384.9792785645\nINFO:root:0: Epoch 1 train loss: 1218519.2266845703\nINFO:root:7: Epoch 1 train loss: 2392.6053009033203\nINFO:root:1: Epoch 1 train loss: 212909.30462646484\nINFO:root:9: Epoch 1 train loss: 178674.13845062256\nINFO:root:2: Epoch 1 train loss: 68892.15728759766\nINFO:root:0: Epoch 1 validation loss: 582891.7635034411\nINFO:root:8: Epoch 2 train loss: 1010838.2954101562\nINFO:root:3: Epoch 2 train loss: 7795.155570983887\nINFO:root:0: Epoch 2 train loss: 67618.75903320312\nINFO:root:5: Epoch 2 train loss: 528738.3761100769\nINFO:root:6: Epoch 2 train loss: 545176.3735961914\nINFO:root:10: Epoch 2 train loss: 4396.8297119140625\nINFO:root:4: Epoch 2 train loss: 11245.387420654297\nINFO:root:1: Epoch 2 train loss: 417810.16508865356\nINFO:root:9: Epoch 2 train loss: 612255.0725097656\nINFO:root:11: Epoch 2 train loss: 6818.460098266602\nINFO:root:2: Epoch 2 train loss: 2972.8266220092773\nINFO:root:7: Epoch 2 train loss: 547806.3978271484\nINFO:root:0: Epoch 2 validation loss: 582876.6545041044\nINFO:root:3: Epoch 3 train loss: 6966.655364990234\nINFO:root:8: Epoch 3 train loss: 410513.1788330078\nINFO:root:4: Epoch 3 train loss: 426385.5935974121\nINFO:root:5: Epoch 3 train loss: 432232.4550933838\nINFO:root:6: Epoch 3 train loss: 5546.535003662109\nINFO:root:11: Epoch 3 train loss: 16401.35041809082\nINFO:root:2: Epoch 3 train loss: 29960.77423095703\nINFO:root:7: Epoch 3 train loss: 1005393.8585205078\nINFO:root:10: Epoch 3 train loss: 604972.1859130859\nINFO:root:0: Epoch 3 train loss: 6340.574388504028\nINFO:root:1: Epoch 3 train loss: 4060.220230102539\nINFO:root:9: Epoch 3 train loss: 8036.939208984375\nINFO:root:0: Epoch 3 validation loss: 582860.5639261876\nINFO:root:3: Epoch 4 train loss: 1145246.600402832\nINFO:root:8: Epoch 4 train loss: 485480.12771606445\nINFO:root:1: Epoch 4 train loss: 6270.443786621094\nINFO:root:5: Epoch 4 train loss: 11548.685485839844\nINFO:root:2: Epoch 4 train loss: 16335.350357055664\nINFO:root:11: Epoch 4 train loss: 554436.8934326172\nINFO:root:4: Epoch 4 train loss: 520754.5695953369\nINFO:root:7: Epoch 4 train loss: 936290.6221923828\nINFO:root:6: Epoch 4 train loss: 8044.296795845032\nINFO:root:10: Epoch 4 train loss: 4803.652618408203\nINFO:root:0: Epoch 4 train loss: 15456.31869506836\nINFO:root:9: Epoch 4 train loss: 669800.82421875\nINFO:root:0: Epoch 4 validation loss: 582842.2607023017\nINFO:root:0: Epoch 5 train loss: 715071.1341781616\nINFO:root:4: Epoch 5 train loss: 509678.927734375\nINFO:root:5: Epoch 5 train loss: 407514.19246673584\nINFO:root:6: Epoch 5 train loss: 794353.8266601562\nINFO:root:7: Epoch 5 train loss: 4267.685358047485\nINFO:root:9: Epoch 5 train loss: 8670.920665740967\nINFO:root:8: Epoch 5 train loss: 14092.19287109375\nINFO:root:10: Epoch 5 train loss: 510174.85290527344\nINFO:root:11: Epoch 5 train loss: 8506.7431640625\nINFO:root:1: Epoch 5 train loss: 484353.45738220215\nINFO:root:3: Epoch 5 train loss: 705880.9422302246\nINFO:root:2: Epoch 5 train loss: 1203984.1214904785\nINFO:root:0: Epoch 5 validation loss: 582819.3152551153\n", "seconds": 7.5766448974609375, "batch_size": 64, "nodes": 12, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.15 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n1 Start Epoch 0\n0: 24 batches\n1: 24 batches\n1 Start Epoch 1\n1: 24 batches\n0 Start Epoch 1\n0: 24 batches\n1 Start Epoch 2\n1: 24 batches\n0 Start Epoch 2\n0: 24 batches\n1 Start Epoch 3\n1: 24 batches\n0 Start Epoch 3\n0: 24 batches\n1 Start Epoch 4\n1: 24 batches\n0 Start Epoch 4\n0: 24 batches\n1 Start Epoch 5\n1: 24 batches\n0 Start Epoch 5\n0: 24 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 284316.2917515437\nINFO:root:1: Epoch 0 train loss: 451810.1349919637\nINFO:root:0: Epoch 0 validation loss: 1994883.7466980733\nINFO:root:0: Epoch 1 train loss: 250239.28153900304\nINFO:root:1: Epoch 1 train loss: 176974.03924942017\nINFO:root:0: Epoch 1 validation loss: 1994220.6572257322\nINFO:root:1: Epoch 2 train loss: 339577.9930534363\nINFO:root:0: Epoch 2 train loss: 296767.38522275287\nINFO:root:0: Epoch 2 validation loss: 1993048.404333049\nINFO:root:1: Epoch 3 train loss: 713798.708577474\nINFO:root:0: Epoch 3 train loss: 541560.4580841064\nINFO:root:0: Epoch 3 validation loss: 1991725.5968098475\nINFO:root:0: Epoch 4 train loss: 342297.6298691432\nINFO:root:1: Epoch 4 train loss: 225583.63556671143\nINFO:root:0: Epoch 4 validation loss: 1991001.342205508\nINFO:root:1: Epoch 5 train loss: 196898.87824821472\nINFO:root:0: Epoch 5 train loss: 249685.63753509521\nINFO:root:0: Epoch 5 validation loss: 1990516.5970337472\n", "seconds": 7.902389049530029, "batch_size": 64, "nodes": 1, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.15,192.168.2.2 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "1 Start Epoch 0\n0 Start Epoch 0\n1: 12 batches\n0: 12 batches\n2 Start Epoch 0\n3 Start Epoch 0\n2: 12 batches\n3: 12 batches\n3 Start Epoch 1\n3: 12 batches\n1 Start Epoch 1\n1: 12 batches\n2 Start Epoch 1\n2: 12 batches\n0 Start Epoch 1\n0: 12 batches\n2 Start Epoch 2\n3 Start Epoch 2\n3: 12 batches\n2: 12 batches\n1 Start Epoch 2\n1: 12 batches\n0 Start Epoch 2\n0: 12 batches\n3 Start Epoch 3\n2 Start Epoch 3\n3: 12 batches\n2: 12 batches\n1 Start Epoch 3\n1: 12 batches\n0 Start Epoch 3\n0: 12 batches\n2 Start Epoch 4\n2: 12 batches\n1 Start Epoch 4\n1: 12 batches\n3 Start Epoch 4\n3: 12 batches\n0 Start Epoch 4\n0: 12 batches\n1 Start Epoch 5\n1: 12 batches\n3 Start Epoch 5\n3: 12 batches\n2 Start Epoch 5\n2: 12 batches\n0 Start Epoch 5\n0: 12 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:3: Epoch 0 train loss: 13696.593360265097\nINFO:root:1: Epoch 0 train loss: 470257.1878051758\nINFO:root:0: Epoch 0 train loss: 235422.80783780417\nINFO:root:2: Epoch 0 train loss: 10751.504333496094\nINFO:root:0: Epoch 0 validation loss: 89335.42224911138\nINFO:root:3: Epoch 1 train loss: 189564.31713867188\nINFO:root:2: Epoch 1 train loss: 336206.47490437824\nINFO:root:1: Epoch 1 train loss: 412929.59331003827\nINFO:root:0: Epoch 1 train loss: 28803.16981124878\nINFO:root:0: Epoch 1 validation loss: 89260.02997347507\nINFO:root:3: Epoch 2 train loss: 398652.30285135907\nINFO:root:2: Epoch 2 train loss: 313493.7402604421\nINFO:root:0: Epoch 2 train loss: 649701.9764607748\nINFO:root:1: Epoch 2 train loss: 208115.52156829834\nINFO:root:0: Epoch 2 validation loss: 89124.99110401087\nINFO:root:2: Epoch 3 train loss: 152949.86753336588\nINFO:root:1: Epoch 3 train loss: 668129.4435647329\nINFO:root:0: Epoch 3 train loss: 403471.3877067566\nINFO:root:3: Epoch 3 train loss: 519618.8202873866\nINFO:root:0: Epoch 3 validation loss: 88930.79961764195\nINFO:root:0: Epoch 4 train loss: 582529.2139027914\nINFO:root:1: Epoch 4 train loss: 200898.36217753091\nINFO:root:3: Epoch 4 train loss: 208503.2874094645\nINFO:root:2: Epoch 4 train loss: 665591.5783081055\nINFO:root:0: Epoch 4 validation loss: 88717.61028886409\nINFO:root:3: Epoch 5 train loss: 251699.62563832602\nINFO:root:2: Epoch 5 train loss: 9560.844757080078\nINFO:root:1: Epoch 5 train loss: 9954.472748438517\nINFO:root:0: Epoch 5 train loss: 535221.4232813517\nINFO:root:0: Epoch 5 validation loss: 88544.32709046685\n", "seconds": 30.25419330596924, "batch_size": 64, "nodes": 2, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.15,192.168.2.2,192.168.2.3 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 8 batches\n5 Start Epoch 0\n5: 8 batches\n2 Start Epoch 0\n2: 8 batches\n4 Start Epoch 0\n4: 8 batches\n1 Start Epoch 0\n1: 8 batches\n3 Start Epoch 0\n3: 8 batches\n3 Start Epoch 1\n3: 8 batches\n1 Start Epoch 1\n1: 8 batches\n4 Start Epoch 1\n5 Start Epoch 1\n5: 8 batches\n4: 8 batches\n2 Start Epoch 1\n2: 8 batches\n0 Start Epoch 1\n0: 8 batches\n1 Start Epoch 2\n1: 8 batches\n3 Start Epoch 2\n2 Start Epoch 2\n2: 8 batches\n3: 8 batches\n4 Start Epoch 2\n4: 8 batches\n5 Start Epoch 2\n5: 8 batches\n0 Start Epoch 2\n0: 8 batches\n3 Start Epoch 3\n3: 8 batches\n2 Start Epoch 3\n2: 8 batches\n1 Start Epoch 3\n1: 8 batches\n4 Start Epoch 3\n5 Start Epoch 3\n4: 8 batches\n5: 8 batches\n0 Start Epoch 3\n0: 8 batches\n1 Start Epoch 4\n1: 8 batches\n5 Start Epoch 4\n5: 8 batches\n3 Start Epoch 4\n3: 8 batches\n4 Start Epoch 4\n4: 8 batches\n2 Start Epoch 4\n2: 8 batches\n0 Start Epoch 4\n0: 8 batches\n5 Start Epoch 5\n4 Start Epoch 5\n5: 8 batches\n4: 8 batches\n1 Start Epoch 5\n1: 8 batches\n3 Start Epoch 5\n3: 8 batches\n2 Start Epoch 5\n2: 8 batches\n0 Start Epoch 5\n0: 8 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:3: Epoch 0 train loss: 158780.05091381073\nINFO:root:0: Epoch 0 train loss: 495627.4537677765\nINFO:root:1: Epoch 0 train loss: 269380.2583389282\nINFO:root:5: Epoch 0 train loss: 37680.942502975464\nINFO:root:4: Epoch 0 train loss: 12843.016620635986\nINFO:root:2: Epoch 0 train loss: 312499.1683731079\nINFO:root:0: Epoch 0 validation loss: 4099229.8894445905\nINFO:root:1: Epoch 1 train loss: 561658.7380981445\nINFO:root:2: Epoch 1 train loss: 558904.9555053711\nINFO:root:3: Epoch 1 train loss: 594117.6770935059\nINFO:root:0: Epoch 1 train loss: 967500.6460876465\nINFO:root:4: Epoch 1 train loss: 6687.075498580933\nINFO:root:5: Epoch 1 train loss: 1069034.3041152954\nINFO:root:0: Epoch 1 validation loss: 4098983.596024874\nINFO:root:3: Epoch 2 train loss: 1056468.721672058\nINFO:root:2: Epoch 2 train loss: 15853.788784980774\nINFO:root:1: Epoch 2 train loss: 32584.929321289062\nINFO:root:0: Epoch 2 train loss: 458641.9879369736\nINFO:root:5: Epoch 2 train loss: 101653.6494140625\nINFO:root:4: Epoch 2 train loss: 828324.7898254395\nINFO:root:0: Epoch 2 validation loss: 4098677.164109294\nINFO:root:0: Epoch 3 train loss: 9486.1068649292\nINFO:root:1: Epoch 3 train loss: 523876.16439819336\nINFO:root:5: Epoch 3 train loss: 132670.5620994568\nINFO:root:3: Epoch 3 train loss: 826781.9184684753\nINFO:root:4: Epoch 3 train loss: 126499.32047271729\nINFO:root:2: Epoch 3 train loss: 98890.26522827148\nINFO:root:0: Epoch 3 validation loss: 4098240.9692527507\nINFO:root:4: Epoch 4 train loss: 45032.32771682739\nINFO:root:5: Epoch 4 train loss: 293395.9495239258\nINFO:root:1: Epoch 4 train loss: 592946.247970581\nINFO:root:0: Epoch 4 train loss: 14002.760391235352\nINFO:root:3: Epoch 4 train loss: 208861.74695587158\nINFO:root:2: Epoch 4 train loss: 257548.0682144165\nINFO:root:0: Epoch 4 validation loss: 4097643.5487408987\nINFO:root:1: Epoch 5 train loss: 41897.455627441406\nINFO:root:5: Epoch 5 train loss: 304818.6434173584\nINFO:root:4: Epoch 5 train loss: 498931.6072692871\nINFO:root:0: Epoch 5 train loss: 10412.605285644531\nINFO:root:3: Epoch 5 train loss: 520311.5468568802\nINFO:root:2: Epoch 5 train loss: 8512.969299316406\nINFO:root:0: Epoch 5 validation loss: 4096965.0073164785\n", "seconds": 21.730340003967285, "batch_size": 64, "nodes": 3, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 6 batches\n7 Start Epoch 0\n7: 6 batches\n1 Start Epoch 0\n1: 6 batches\n2 Start Epoch 0\n2: 6 batches\n6 Start Epoch 0\n4 Start Epoch 0\n6: 6 batches\n5 Start Epoch 0\n3 Start Epoch 0\n3: 6 batches\n5: 6 batches\n4: 6 batches\n3 Start Epoch 1\n3: 6 batches\n5 Start Epoch 1\n5: 6 batches\n4 Start Epoch 1\n4: 6 batches\n6 Start Epoch 1\n6: 6 batches\n2 Start Epoch 1\n2: 6 batches\n7 Start Epoch 1\n7: 6 batches\n1 Start Epoch 1\n1: 6 batches\n0 Start Epoch 1\n0: 6 batches\n5 Start Epoch 2\n5: 6 batches\n4 Start Epoch 2\n4: 6 batches\n6 Start Epoch 2\n2 Start Epoch 2\n2: 6 batches\n1 Start Epoch 2\n1: 6 batches\n3 Start Epoch 2\n3: 6 batches\n7 Start Epoch 2\n7: 6 batches\n6: 6 batches\n0 Start Epoch 2\n0: 6 batches\n2 Start Epoch 3\n3 Start Epoch 3\n2: 6 batches\n3: 6 batches\n1 Start Epoch 3\n1: 6 batches\n5 Start Epoch 3\n5: 6 batches\n4 Start Epoch 3\n4: 6 batches\n7 Start Epoch 3\n6 Start Epoch 3\n7: 6 batches\n6: 6 batches\n0 Start Epoch 3\n0: 6 batches\n2 Start Epoch 4\n3 Start Epoch 4\n2: 6 batches\n3: 6 batches\n1 Start Epoch 4\n1: 6 batches\n5 Start Epoch 4\n5: 6 batches\n6 Start Epoch 4\n6: 6 batches\n7 Start Epoch 4\n7: 6 batches\n4 Start Epoch 4\n4: 6 batches\n0 Start Epoch 4\n0: 6 batches\n1 Start Epoch 5\n1: 6 batches\n6 Start Epoch 5\n6: 6 batches\n4 Start Epoch 5\n5 Start Epoch 5\n4: 6 batches\n5: 6 batches\n7 Start Epoch 5\n7: 6 batches\n2 Start Epoch 5\n3 Start Epoch 5\n2: 6 batches\n3: 6 batches\n0 Start Epoch 5\n0: 6 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:3: Epoch 0 train loss: 623333.7589925131\nINFO:root:5: Epoch 0 train loss: 366172.5671386719\nINFO:root:4: Epoch 0 train loss: 785022.464050293\nINFO:root:6: Epoch 0 train loss: 122286.40710449219\nINFO:root:2: Epoch 0 train loss: 405447.8564783732\nINFO:root:7: Epoch 0 train loss: 120137.42049153645\nINFO:root:0: Epoch 0 train loss: 674191.0824584961\nINFO:root:1: Epoch 0 train loss: 878355.6705220541\nINFO:root:0: Epoch 0 validation loss: 29443.873632786166\nINFO:root:5: Epoch 1 train loss: 311908.5150400798\nINFO:root:4: Epoch 1 train loss: 344454.007619222\nINFO:root:6: Epoch 1 train loss: 14242.609385172525\nINFO:root:2: Epoch 1 train loss: 479669.0884958903\nINFO:root:0: Epoch 1 train loss: 54857.88256327311\nINFO:root:1: Epoch 1 train loss: 9473.53549448649\nINFO:root:3: Epoch 1 train loss: 5950.969512939453\nINFO:root:7: Epoch 1 train loss: 298261.6770833333\nINFO:root:0: Epoch 1 validation loss: 29431.782074665232\nINFO:root:3: Epoch 2 train loss: 9951.946917215982\nINFO:root:2: Epoch 2 train loss: 752456.8661702474\nINFO:root:1: Epoch 2 train loss: 861400.0883051554\nINFO:root:5: Epoch 2 train loss: 506148.25627644855\nINFO:root:4: Epoch 2 train loss: 327653.72888183594\nINFO:root:6: Epoch 2 train loss: 363368.42517089844\nINFO:root:7: Epoch 2 train loss: 488393.3563741048\nINFO:root:0: Epoch 2 train loss: 353276.52587890625\nINFO:root:0: Epoch 2 validation loss: 29416.140862557393\nINFO:root:3: Epoch 3 train loss: 357421.08414713544\nINFO:root:2: Epoch 3 train loss: 333051.5038045247\nINFO:root:1: Epoch 3 train loss: 745461.93359375\nINFO:root:0: Epoch 3 train loss: 22584.572840372723\nINFO:root:5: Epoch 3 train loss: 15269.962646484375\nINFO:root:6: Epoch 3 train loss: 677987.956120809\nINFO:root:7: Epoch 3 train loss: 1390243.0076904297\nINFO:root:4: Epoch 3 train loss: 2820.384953816732\nINFO:root:0: Epoch 3 validation loss: 29395.83516253608\nINFO:root:0: Epoch 4 train loss: 17846.18328857422\nINFO:root:1: Epoch 4 train loss: 372410.0019836426\nINFO:root:6: Epoch 4 train loss: 328704.37694295245\nINFO:root:5: Epoch 4 train loss: 836589.9699045817\nINFO:root:4: Epoch 4 train loss: 19198.038004557293\nINFO:root:7: Epoch 4 train loss: 132034.56103515625\nINFO:root:2: Epoch 4 train loss: 328593.5558369954\nINFO:root:3: Epoch 4 train loss: 547102.9843343099\nINFO:root:0: Epoch 4 validation loss: 29368.715138775522\nINFO:root:1: Epoch 5 train loss: 287561.28670247394\nINFO:root:0: Epoch 5 train loss: 5812.033192952474\nINFO:root:7: Epoch 5 train loss: 8186.822420756022\nINFO:root:6: Epoch 5 train loss: 519698.54630533856\nINFO:root:5: Epoch 5 train loss: 6614.083964029948\nINFO:root:4: Epoch 5 train loss: 294931.45176188153\nINFO:root:2: Epoch 5 train loss: 17632.55744425456\nINFO:root:3: Epoch 5 train loss: 449971.8323567708\nINFO:root:0: Epoch 5 validation loss: 29334.93408247726\n", "seconds": 18.768746852874756, "batch_size": 64, "nodes": 4, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 5 batches\n9 Start Epoch 0\n9: 5 batches\n2 Start Epoch 0\n6 Start Epoch 0\n6: 5 batches\n3 Start Epoch 0\n3: 5 batches\n4 Start Epoch 0\n5 Start Epoch 0\n2: 5 batches\n4: 5 batches\n5: 5 batches\n1 Start Epoch 0\n1: 5 batches\n8 Start Epoch 0\n8: 5 batches\n7 Start Epoch 0\n7: 5 batches\n3 Start Epoch 1\n3: 5 batches\n2 Start Epoch 1\n2: 5 batches\n1 Start Epoch 1\n5 Start Epoch 1\n7 Start Epoch 1\n6 Start Epoch 1\n6: 5 batches\n1: 5 batches\n4 Start Epoch 1\n4: 5 batches\n7: 5 batches\n5: 5 batches\n8 Start Epoch 1\n8: 5 batches\n9 Start Epoch 1\n9: 5 batches\n0 Start Epoch 1\n0: 5 batches\n9 Start Epoch 2\n9: 5 batches\n1 Start Epoch 2\n1: 5 batches\n2 Start Epoch 2\n3 Start Epoch 2\n3: 5 batches\n2: 5 batches\n8 Start Epoch 2\n8: 5 batches\n5 Start Epoch 2\n7 Start Epoch 2\n4 Start Epoch 2\n4: 5 batches\n6 Start Epoch 2\n7: 5 batches\n6: 5 batches\n5: 5 batches\n0 Start Epoch 2\n0: 5 batches\n3 Start Epoch 3\n3: 5 batches\n2 Start Epoch 3\n2: 5 batches\n1 Start Epoch 3\n1: 5 batches\n9 Start Epoch 3\n9: 5 batches\n7 Start Epoch 3\n5 Start Epoch 3\n6 Start Epoch 3\n4 Start Epoch 3\n7: 5 batches\n4: 5 batches\n6: 5 batches\n5: 5 batches\n8 Start Epoch 3\n8: 5 batches\n0 Start Epoch 3\n0: 5 batches\n5 Start Epoch 4\n5: 5 batches\n1 Start Epoch 4\n1: 5 batches\n4 Start Epoch 4\n8 Start Epoch 4\n7 Start Epoch 4\n6 Start Epoch 4\n4: 5 batches\n9 Start Epoch 4\n2 Start Epoch 4\n9: 5 batches\n3 Start Epoch 4\n6: 5 batches\n8: 5 batches\n2: 5 batches\n7: 5 batches\n3: 5 batches\n0 Start Epoch 4\n0: 5 batches\n3 Start Epoch 5\n3: 5 batches\n2 Start Epoch 5\n2: 5 batches\n1 Start Epoch 5\n1: 5 batches\n9 Start Epoch 5\n9: 5 batches\n8 Start Epoch 5\n8: 5 batches\n5 Start Epoch 5\n4 Start Epoch 5\n7 Start Epoch 5\n5: 5 batches\n4: 5 batches\n7: 5 batches\n6 Start Epoch 5\n6: 5 batches\n0 Start Epoch 5\n0: 5 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:3: Epoch 0 train loss: 484786.34453125\nINFO:root:2: Epoch 0 train loss: 1107971.6385742188\nINFO:root:0: Epoch 0 train loss: 397095.76043395995\nINFO:root:1: Epoch 0 train loss: 216674.5581665039\nINFO:root:6: Epoch 0 train loss: 6530.034838867187\nINFO:root:4: Epoch 0 train loss: 9154.303857421875\nINFO:root:5: Epoch 0 train loss: 349912.11689453124\nINFO:root:7: Epoch 0 train loss: 7576.24462890625\nINFO:root:8: Epoch 0 train loss: 9923.271801757812\nINFO:root:9: Epoch 0 train loss: 16451.49479980469\nINFO:root:0: Epoch 0 validation loss: 3965983.9571205457\nINFO:root:9: Epoch 1 train loss: 489062.8372436523\nINFO:root:1: Epoch 1 train loss: 1743.3874816894531\nINFO:root:0: Epoch 1 train loss: 170319.5154296875\nINFO:root:2: Epoch 1 train loss: 1146405.1767578125\nINFO:root:3: Epoch 1 train loss: 12256.003515625\nINFO:root:8: Epoch 1 train loss: 393822.59924316406\nINFO:root:4: Epoch 1 train loss: 14104.900750732422\nINFO:root:6: Epoch 1 train loss: 7901.726654052734\nINFO:root:5: Epoch 1 train loss: 366693.8220703125\nINFO:root:7: Epoch 1 train loss: 518255.1875\nINFO:root:0: Epoch 1 validation loss: 3965796.4083466725\nINFO:root:3: Epoch 2 train loss: 148000.76220703125\nINFO:root:2: Epoch 2 train loss: 50069.281518554686\nINFO:root:1: Epoch 2 train loss: 749425.9303657531\nINFO:root:0: Epoch 2 train loss: 4484.988330078125\nINFO:root:9: Epoch 2 train loss: 4426.738269042969\nINFO:root:5: Epoch 2 train loss: 863508.6877197266\nINFO:root:7: Epoch 2 train loss: 19785.39357910156\nINFO:root:6: Epoch 2 train loss: 1204956.4038574218\nINFO:root:4: Epoch 2 train loss: 609306.4936035157\nINFO:root:8: Epoch 2 train loss: 412138.6515625\nINFO:root:0: Epoch 2 validation loss: 3965583.3928455496\nINFO:root:5: Epoch 3 train loss: 327219.1836669922\nINFO:root:0: Epoch 3 train loss: 871282.4121948242\nINFO:root:1: Epoch 3 train loss: 23234.498913574218\nINFO:root:7: Epoch 3 train loss: 1095350.7149902345\nINFO:root:9: Epoch 3 train loss: 395509.95859375\nINFO:root:3: Epoch 3 train loss: 72159.85451660157\nINFO:root:6: Epoch 3 train loss: 574980.5010742188\nINFO:root:4: Epoch 3 train loss: 680821.978742981\nINFO:root:8: Epoch 3 train loss: 754432.2763916015\nINFO:root:2: Epoch 3 train loss: 20961.48519897461\nINFO:root:0: Epoch 3 validation loss: 3965321.261847679\nINFO:root:3: Epoch 4 train loss: 495407.57594604493\nINFO:root:2: Epoch 4 train loss: 471628.487109375\nINFO:root:1: Epoch 4 train loss: 436158.7925048828\nINFO:root:0: Epoch 4 train loss: 1566463.7253784179\nINFO:root:9: Epoch 4 train loss: 19484.437158203124\nINFO:root:8: Epoch 4 train loss: 449140.5706665039\nINFO:root:5: Epoch 4 train loss: 444067.9687927246\nINFO:root:7: Epoch 4 train loss: 836493.2748046875\nINFO:root:4: Epoch 4 train loss: 407445.75947265624\nINFO:root:6: Epoch 4 train loss: 434484.4218017578\nINFO:root:0: Epoch 4 validation loss: 3964962.8753284677\nINFO:root:4: Epoch 5 train loss: 1518.799005126953\nINFO:root:5: Epoch 5 train loss: 873186.6548709869\nINFO:root:3: Epoch 5 train loss: 9908.683667945861\nINFO:root:2: Epoch 5 train loss: 4359.448046875\nINFO:root:9: Epoch 5 train loss: 16070.181420898438\nINFO:root:8: Epoch 5 train loss: 55842.22930908203\nINFO:root:0: Epoch 5 train loss: 656551.2837402343\nINFO:root:1: Epoch 5 train loss: 14712.821240234374\nINFO:root:6: Epoch 5 train loss: 14803.78935546875\nINFO:root:7: Epoch 5 train loss: 1033727.3576171875\nINFO:root:0: Epoch 5 validation loss: 3964483.940008236\n", "seconds": 16.801831007003784, "batch_size": 64, "nodes": 5, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 4 batches\n11 Start Epoch 0\n11: 4 batches\n4 Start Epoch 0\n8 Start Epoch 0\n2 Start Epoch 0\n7 Start Epoch 0\n4: 4 batches\n8: 4 batches\n3 Start Epoch 0\n7: 4 batches\n2: 4 batches\n3: 4 batches\n1 Start Epoch 0\n1: 4 batches\n6 Start Epoch 0\n6: 4 batches\n5 Start Epoch 0\n5: 4 batches\n9 Start Epoch 0\n9: 4 batches\n10 Start Epoch 0\n10: 4 batches\n8 Start Epoch 1\n8: 4 batches\n9 Start Epoch 1\n9: 4 batches\n1 Start Epoch 1\n1: 4 batches\n11 Start Epoch 1\n11: 4 batches\n2 Start Epoch 1\n2: 4 batches\n3 Start Epoch 1\n3: 4 batches\n4 Start Epoch 1\n4: 4 batches\n7 Start Epoch 1\n7: 4 batches\n5 Start Epoch 1\n5: 4 batches\n6 Start Epoch 1\n6: 4 batches\n10 Start Epoch 1\n10: 4 batches\n0 Start Epoch 1\n0: 4 batches\n1 Start Epoch 2\n1: 4 batches\n11 Start Epoch 2\n11: 4 batches\n7 Start Epoch 2\n7: 4 batches\n5 Start Epoch 2\n4 Start Epoch 2\n5: 4 batches\n4: 4 batches\n6 Start Epoch 2\n6: 4 batches\n9 Start Epoch 2\n9: 4 batches\n3 Start Epoch 2\n3: 4 batches\n2 Start Epoch 2\n2: 4 batches\n10 Start Epoch 2\n10: 4 batches\n8 Start Epoch 2\n8: 4 batches\n0 Start Epoch 2\n0: 4 batches\n1 Start Epoch 3\n1: 4 batches\n5 Start Epoch 3\n4 Start Epoch 3\n5: 4 batches\n4: 4 batches\n7 Start Epoch 3\n7: 4 batches\n6 Start Epoch 3\n6: 4 batches\n2 Start Epoch 3\n3 Start Epoch 3\n3: 4 batches\n2: 4 batches\n9 Start Epoch 3\n9: 4 batches\n8 Start Epoch 3\n8: 4 batches\n11 Start Epoch 3\n11: 4 batches\n10 Start Epoch 3\n10: 4 batches\n0 Start Epoch 3\n0: 4 batches\n11 Start Epoch 4\n11: 4 batches\n1 Start Epoch 4\n1: 4 batches\n3 Start Epoch 4\n2 Start Epoch 4\n2: 4 batches\n3: 4 batches\n4 Start Epoch 4\n5 Start Epoch 4\n5: 4 batches\n4: 4 batches\n6 Start Epoch 4\n7 Start Epoch 4\n7: 4 batches\n6: 4 batches\n10 Start Epoch 4\n10: 4 batches\n8 Start Epoch 4\n8: 4 batches\n9 Start Epoch 4\n9: 4 batches\n0 Start Epoch 4\n0: 4 batches\n11 Start Epoch 5\n11: 4 batches\n10 Start Epoch 5\n10: 4 batches\n7 Start Epoch 5\n7: 4 batches\n9 Start Epoch 5\n9: 4 batches\n8 Start Epoch 5\n8: 4 batches\n4 Start Epoch 5\n6 Start Epoch 5\n5 Start Epoch 5\n5: 4 batches\n3 Start Epoch 5\n2 Start Epoch 5\n3: 4 batches\n4: 4 batches\n2: 4 batches\n1 Start Epoch 5\n1: 4 batches\n6: 4 batches\n0 Start Epoch 5\n0: 4 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:8: Epoch 0 train loss: 1028078.6733398438\nINFO:root:9: Epoch 0 train loss: 24905.44744873047\nINFO:root:1: Epoch 0 train loss: 17903.696014404297\nINFO:root:0: Epoch 0 train loss: 6494.461013793945\nINFO:root:11: Epoch 0 train loss: 10186.862525939941\nINFO:root:3: Epoch 0 train loss: 468772.05236816406\nINFO:root:2: Epoch 0 train loss: 5100.742492675781\nINFO:root:4: Epoch 0 train loss: 680737.7008590698\nINFO:root:7: Epoch 0 train loss: 5681.853088378906\nINFO:root:5: Epoch 0 train loss: 3749.0061683654785\nINFO:root:6: Epoch 0 train loss: 507204.59159851074\nINFO:root:10: Epoch 0 train loss: 434833.36029052734\nINFO:root:0: Epoch 0 validation loss: 985836.2126237461\nINFO:root:0: Epoch 1 train loss: 1537006.8862304688\nINFO:root:1: Epoch 1 train loss: 8927.126663208008\nINFO:root:11: Epoch 1 train loss: 599750.728515625\nINFO:root:7: Epoch 1 train loss: 431997.9777870178\nINFO:root:5: Epoch 1 train loss: 21735.52434206009\nINFO:root:4: Epoch 1 train loss: 603654.3165283203\nINFO:root:6: Epoch 1 train loss: 12203.591186523438\nINFO:root:9: Epoch 1 train loss: 511896.3581542969\nINFO:root:3: Epoch 1 train loss: 214932.80541992188\nINFO:root:2: Epoch 1 train loss: 1529745.98828125\nINFO:root:10: Epoch 1 train loss: 504141.4389190674\nINFO:root:8: Epoch 1 train loss: 1439077.5185546875\nINFO:root:0: Epoch 1 validation loss: 985802.8273614479\nINFO:root:1: Epoch 2 train loss: 14842.744674682617\nINFO:root:4: Epoch 2 train loss: 630362.5076293945\nINFO:root:5: Epoch 2 train loss: 10400.573913574219\nINFO:root:0: Epoch 2 train loss: 521999.1997375488\nINFO:root:7: Epoch 2 train loss: 5449.937232971191\nINFO:root:6: Epoch 2 train loss: 587666.4850006104\nINFO:root:9: Epoch 2 train loss: 3574.778289794922\nINFO:root:3: Epoch 2 train loss: 7900.505081176758\nINFO:root:2: Epoch 2 train loss: 521605.9869995117\nINFO:root:8: Epoch 2 train loss: 15149.973495483398\nINFO:root:11: Epoch 2 train loss: 506955.4045715332\nINFO:root:10: Epoch 2 train loss: 25857.55126953125\nINFO:root:0: Epoch 2 validation loss: 985769.0840886845\nINFO:root:11: Epoch 3 train loss: 508475.04873657227\nINFO:root:1: Epoch 3 train loss: 414918.87255859375\nINFO:root:0: Epoch 3 train loss: 4770.8863525390625\nINFO:root:2: Epoch 3 train loss: 610082.486038208\nINFO:root:3: Epoch 3 train loss: 14040.118041992188\nINFO:root:5: Epoch 3 train loss: 511897.7190551758\nINFO:root:4: Epoch 3 train loss: 16471.60272216797\nINFO:root:6: Epoch 3 train loss: 30229.82078552246\nINFO:root:7: Epoch 3 train loss: 505928.518951416\nINFO:root:10: Epoch 3 train loss: 64945.926513671875\nINFO:root:8: Epoch 3 train loss: 553129.3276672363\nINFO:root:9: Epoch 3 train loss: 8328.95458984375\nINFO:root:0: Epoch 3 validation loss: 985730.8620757968\nINFO:root:10: Epoch 4 train loss: 7208.089525222778\nINFO:root:11: Epoch 4 train loss: 4587.0640869140625\nINFO:root:8: Epoch 4 train loss: 436698.49670410156\nINFO:root:7: Epoch 4 train loss: 3428.8584270477295\nINFO:root:9: Epoch 4 train loss: 3554.78377532959\nINFO:root:2: Epoch 4 train loss: 7647.082130432129\nINFO:root:6: Epoch 4 train loss: 936113.9106445312\nINFO:root:5: Epoch 4 train loss: 4613.035568237305\nINFO:root:3: Epoch 4 train loss: 28358.21710205078\nINFO:root:4: Epoch 4 train loss: 600707.1456298828\nINFO:root:1: Epoch 4 train loss: 3712.2577209472656\nINFO:root:0: Epoch 4 train loss: 558664.40234375\nINFO:root:0: Epoch 4 validation loss: 985687.1703825316\nINFO:root:11: Epoch 5 train loss: 450393.141204834\nINFO:root:9: Epoch 5 train loss: 17195.380853176117\nINFO:root:10: Epoch 5 train loss: 1215400.3149414062\nINFO:root:8: Epoch 5 train loss: 5905.652542114258\nINFO:root:0: Epoch 5 train loss: 177665.7342529297\nINFO:root:1: Epoch 5 train loss: 441965.9426269531\nINFO:root:4: Epoch 5 train loss: 6292.315673828125\nINFO:root:5: Epoch 5 train loss: 583862.5400848389\nINFO:root:6: Epoch 5 train loss: 611628.3059082031\nINFO:root:7: Epoch 5 train loss: 63861.49822998047\nINFO:root:2: Epoch 5 train loss: 485365.2229156494\nINFO:root:3: Epoch 5 train loss: 18677.046997070312\nINFO:root:0: Epoch 5 validation loss: 985633.5520067322\n", "seconds": 15.325603723526001, "batch_size": 64, "nodes": 6, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 4 batches\n1 Start Epoch 0\n2 Start Epoch 0\n2: 4 batches\n1: 4 batches\n6 Start Epoch 0\n5 Start Epoch 0\n9 Start Epoch 0\n6: 4 batches\n10 Start Epoch 0\n12 Start Epoch 0\n13 Start Epoch 0\n12: 4 batches\n9: 4 batches\n5: 4 batches\n10: 4 batches\n11 Start Epoch 0\n13: 4 batches\n11: 4 batches\n3 Start Epoch 0\n7 Start Epoch 0\n8 Start Epoch 0\n4 Start Epoch 0\n7: 4 batches\n4: 4 batches\n3: 4 batches\n8: 4 batches\n8 Start Epoch 1\n6 Start Epoch 1\n13 Start Epoch 1\n8: 4 batches\n11 Start Epoch 1\n10 Start Epoch 1\n2 Start Epoch 1\n7 Start Epoch 1\n9 Start Epoch 1\n5 Start Epoch 1\n9: 4 batches\n4 Start Epoch 1\n10: 4 batches\n3 Start Epoch 1\n6: 4 batches\n5: 4 batches\n11: 4 batches\n2: 4 batches\n7: 4 batches\n12 Start Epoch 1\n12: 4 batches\n13: 4 batches\n4: 4 batches\n3: 4 batches\n1 Start Epoch 1\n1: 4 batches\n0 Start Epoch 1\n0: 4 batches\n13 Start Epoch 2\n5 Start Epoch 2\n5: 4 batches\n11 Start Epoch 2\n6 Start Epoch 2\n13: 4 batches\n12 Start Epoch 2\n10 Start Epoch 2\n6: 4 batches\n2 Start Epoch 2\n7 Start Epoch 2\n12: 4 batches\n10: 4 batches\n11: 4 batches\n3 Start Epoch 2\n7: 4 batches\n2: 4 batches\n3: 4 batches\n4 Start Epoch 2\n4: 4 batches\n9 Start Epoch 2\n8 Start Epoch 2\n8: 4 batches\n9: 4 batches\n1 Start Epoch 2\n1: 4 batches\n0 Start Epoch 2\n0: 4 batches\n5 Start Epoch 3\n4 Start Epoch 3\n11 Start Epoch 3\n2 Start Epoch 3\n6 Start Epoch 3\n11: 4 batches\n3 Start Epoch 3\n7 Start Epoch 3\n3: 4 batches\n6: 4 batches\n5: 4 batches\n10 Start Epoch 3\n2: 4 batches\n7: 4 batches\n4: 4 batches\n10: 4 batches\n13 Start Epoch 3\n13: 4 batches\n8 Start Epoch 3\n9 Start Epoch 3\n12 Start Epoch 3\n8: 4 batches\n12: 4 batches\n9: 4 batches\n1 Start Epoch 3\n1: 4 batches\n0 Start Epoch 3\n0: 4 batches\n5 Start Epoch 4\n6 Start Epoch 4\n9 Start Epoch 4\n5: 4 batches\n11 Start Epoch 4\n7 Start Epoch 4\n8 Start Epoch 4\n11: 4 batches\n7: 4 batches\n8: 4 batches\n4 Start Epoch 4\n10 Start Epoch 4\n6: 4 batches\n9: 4 batches\n4: 4 batches\n10: 4 batches\n2 Start Epoch 4\n2: 4 batches\n13 Start Epoch 4\n3 Start Epoch 4\n3: 4 batches\n12 Start Epoch 4\n13: 4 batches\n12: 4 batches\n1 Start Epoch 4\n1: 4 batches\n0 Start Epoch 4\n0: 4 batches\n11 Start Epoch 5\n11: 4 batches\n10 Start Epoch 5\n10: 4 batches\n7 Start Epoch 5\n5 Start Epoch 5\n7: 4 batches\n4 Start Epoch 5\n3 Start Epoch 5\n6 Start Epoch 5\n5: 4 batches\n2 Start Epoch 5\n6: 4 batches\n3: 4 batches\n4: 4 batches\n2: 4 batches\n12 Start Epoch 5\n8 Start Epoch 5\n9 Start Epoch 5\n13 Start Epoch 5\n9: 4 batches\n12: 4 batches\n8: 4 batches\n13: 4 batches\n1 Start Epoch 5\n1: 4 batches\n0 Start Epoch 5\n0: 4 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:8: Epoch 0 train loss: 525683.6011962891\nINFO:root:10: Epoch 0 train loss: 13346.707824707031\nINFO:root:6: Epoch 0 train loss: 11393.584219932556\nINFO:root:9: Epoch 0 train loss: 9390.311584472656\nINFO:root:4: Epoch 0 train loss: 64131.885650634766\nINFO:root:11: Epoch 0 train loss: 11993.738952636719\nINFO:root:2: Epoch 0 train loss: 670787.4650878906\nINFO:root:7: Epoch 0 train loss: 8865.801666259766\nINFO:root:3: Epoch 0 train loss: 13652.154856681824\nINFO:root:5: Epoch 0 train loss: 17381.250244140625\nINFO:root:12: Epoch 0 train loss: 9923.648063659668\nINFO:root:13: Epoch 0 train loss: 8477.266571044922\nINFO:root:0: Epoch 0 train loss: 926417.8606719971\nINFO:root:1: Epoch 0 train loss: 1069346.9839782715\nINFO:root:0: Epoch 0 validation loss: 31704610.20065185\nINFO:root:12: Epoch 1 train loss: 13934.997848510742\nINFO:root:11: Epoch 1 train loss: 184218.62307739258\nINFO:root:7: Epoch 1 train loss: 605400.7993774414\nINFO:root:13: Epoch 1 train loss: 9270.317481994629\nINFO:root:5: Epoch 1 train loss: 2745.092819213867\nINFO:root:10: Epoch 1 train loss: 5101.066345214844\nINFO:root:6: Epoch 1 train loss: 16609.912658691406\nINFO:root:3: Epoch 1 train loss: 6485.999267578125\nINFO:root:2: Epoch 1 train loss: 4610.378761291504\nINFO:root:4: Epoch 1 train loss: 27588.329635620117\nINFO:root:9: Epoch 1 train loss: 488918.5738258362\nINFO:root:8: Epoch 1 train loss: 9302.319253444672\nINFO:root:0: Epoch 1 train loss: 9518.416995048523\nINFO:root:1: Epoch 1 train loss: 525433.7651977539\nINFO:root:0: Epoch 1 validation loss: 31704477.161387928\nINFO:root:2: Epoch 2 train loss: 29528.786376953125\nINFO:root:6: Epoch 2 train loss: 10859.800003051758\nINFO:root:10: Epoch 2 train loss: 547760.0162792206\nINFO:root:11: Epoch 2 train loss: 203447.61548995972\nINFO:root:3: Epoch 2 train loss: 493003.33182811737\nINFO:root:7: Epoch 2 train loss: 549401.4243164062\nINFO:root:5: Epoch 2 train loss: 14444.90463256836\nINFO:root:4: Epoch 2 train loss: 33724.283279418945\nINFO:root:13: Epoch 2 train loss: 1385202.997390747\nINFO:root:9: Epoch 2 train loss: 3299.070098876953\nINFO:root:8: Epoch 2 train loss: 8353.32557964325\nINFO:root:0: Epoch 2 train loss: 582935.0710754395\nINFO:root:12: Epoch 2 train loss: 2236827.6755371094\nINFO:root:1: Epoch 2 train loss: 412041.14783859253\nINFO:root:0: Epoch 2 validation loss: 31704331.680042215\nINFO:root:7: Epoch 3 train loss: 1740846.1328430176\nINFO:root:9: Epoch 3 train loss: 605228.6963295937\nINFO:root:5: Epoch 3 train loss: 3462.844512939453\nINFO:root:10: Epoch 3 train loss: 1309022.648864746\nINFO:root:8: Epoch 3 train loss: 985828.2629928589\nINFO:root:11: Epoch 3 train loss: 545362.8722934723\nINFO:root:6: Epoch 3 train loss: 7175.642547607422\nINFO:root:4: Epoch 3 train loss: 14774.426239013672\nINFO:root:2: Epoch 3 train loss: 1048045.4425430298\nINFO:root:13: Epoch 3 train loss: 12882.760696411133\nINFO:root:3: Epoch 3 train loss: 488476.99805259705\nINFO:root:12: Epoch 3 train loss: 3618.3853788375854\nINFO:root:1: Epoch 3 train loss: 60150.074279785156\nINFO:root:0: Epoch 3 train loss: 175597.93222767115\nINFO:root:0: Epoch 3 validation loss: 31704186.97644114\nINFO:root:10: Epoch 4 train loss: 7358.483917236328\nINFO:root:11: Epoch 4 train loss: 435709.77167129517\nINFO:root:7: Epoch 4 train loss: 19863.836669921875\nINFO:root:6: Epoch 4 train loss: 178212.20428466797\nINFO:root:5: Epoch 4 train loss: 450.6815357208252\nINFO:root:4: Epoch 4 train loss: 2072141.759765625\nINFO:root:2: Epoch 4 train loss: 22125.654418945312\nINFO:root:3: Epoch 4 train loss: 61471.03366088867\nINFO:root:12: Epoch 4 train loss: 2616.516815185547\nINFO:root:8: Epoch 4 train loss: 20217.832801818848\nINFO:root:13: Epoch 4 train loss: 18994.87953186035\nINFO:root:9: Epoch 4 train loss: 16671.976600646973\nINFO:root:0: Epoch 4 train loss: 521635.8343887329\nINFO:root:1: Epoch 4 train loss: 35141.76013183594\nINFO:root:0: Epoch 4 validation loss: 31704032.46866519\nINFO:root:2: Epoch 5 train loss: 190378.64274573326\nINFO:root:5: Epoch 5 train loss: 30187.531616210938\nINFO:root:10: Epoch 5 train loss: 11218.583740234375\nINFO:root:11: Epoch 5 train loss: 1035053.4798278809\nINFO:root:3: Epoch 5 train loss: 24512.64013671875\nINFO:root:4: Epoch 5 train loss: 11893.168365478516\nINFO:root:13: Epoch 5 train loss: 4096.455371856689\nINFO:root:8: Epoch 5 train loss: 605922.1726493835\nINFO:root:12: Epoch 5 train loss: 515760.8028564453\nINFO:root:9: Epoch 5 train loss: 7779.457244873047\nINFO:root:0: Epoch 5 train loss: 413145.4159812927\nINFO:root:1: Epoch 5 train loss: 97930.94995117188\nINFO:root:7: Epoch 5 train loss: 6993.601661682129\nINFO:root:6: Epoch 5 train loss: 5993.166078865528\nINFO:root:0: Epoch 5 validation loss: 31703853.473409392\n", "seconds": 12.75929880142212, "batch_size": 64, "nodes": 7, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 3 batches\n15 Start Epoch 0\n15: 3 batches\n1 Start Epoch 0\n1: 3 batches\n2 Start Epoch 0\n2: 3 batches\n8 Start Epoch 0\n4 Start Epoch 0\n8: 3 batches\n12 Start Epoch 0\n11 Start Epoch 0\n7 Start Epoch 0\n4: 3 batches\n12: 3 batches\n3 Start Epoch 0\n7: 3 batches\n11: 3 batches\n3: 3 batches\n14 Start Epoch 0\n9 Start Epoch 0\n10 Start Epoch 0\n6 Start Epoch 0\n5 Start Epoch 0\n13 Start Epoch 0\n14: 3 batches\n9: 3 batches\n10: 3 batches\n6: 3 batches\n5: 3 batches\n13: 3 batches\n8 Start Epoch 1\n8: 3 batches\n9 Start Epoch 1\n9: 3 batches\n12 Start Epoch 1\n13 Start Epoch 1\n13: 3 batches\n12: 3 batches\n15 Start Epoch 1\n15: 3 batches\n14 Start Epoch 1\n14: 3 batches\n11 Start Epoch 1\n10 Start Epoch 1\n10: 3 batches\n11: 3 batches\n7 Start Epoch 1\n7: 3 batches\n1 Start Epoch 1\n6 Start Epoch 1\n1: 3 batches\n6: 3 batches\n2 Start Epoch 1\n3 Start Epoch 1\n3: 3 batches\n2: 3 batches\n4 Start Epoch 1\n4: 3 batches\n5 Start Epoch 1\n5: 3 batches\n0 Start Epoch 1\n0: 3 batches\n5 Start Epoch 2\n7 Start Epoch 2\n5: 3 batches\n6 Start Epoch 2\n6: 3 batches\n13 Start Epoch 2\n10 Start Epoch 2\n13: 3 batches\n14 Start Epoch 2\n3 Start Epoch 2\n15 Start Epoch 2\n2 Start Epoch 2\n11 Start Epoch 2\n2: 3 batches\n10: 3 batches\n15: 3 batches\n14: 3 batches\n3: 3 batches\n11: 3 batches\n1 Start Epoch 2\n1: 3 batches\n4 Start Epoch 2\n4: 3 batches\n12 Start Epoch 2\n12: 3 batches\n9 Start Epoch 2\n8 Start Epoch 2\n8: 3 batches\n9: 3 batches\n7: 3 batches\n0 Start Epoch 2\n0: 3 batches\n3 Start Epoch 3\n3: 3 batches\n4 Start Epoch 3\n4: 3 batches\n7 Start Epoch 3\n7: 3 batches\n5 Start Epoch 3\n5: 3 batches\n6 Start Epoch 3\n6: 3 batches\n9 Start Epoch 3\n8 Start Epoch 3\n9: 3 batches\n8: 3 batches\n2 Start Epoch 3\n2: 3 batches\n1 Start Epoch 3\n13 Start Epoch 3\n13: 3 batches\n11 Start Epoch 3\n1: 3 batches\n12 Start Epoch 3\n12: 3 batches\n10 Start Epoch 3\n11: 3 batches\n10: 3 batches\n15 Start Epoch 3\n14 Start Epoch 3\n15: 3 batches\n14: 3 batches\n0 Start Epoch 3\n0: 3 batches\n15 Start Epoch 4\n2 Start Epoch 4\n11 Start Epoch 4\n6 Start Epoch 4\n4 Start Epoch 4\n12 Start Epoch 4\n15: 3 batches\n2: 3 batches\n4: 3 batches\n13 Start Epoch 4\n10 Start Epoch 4\n6: 3 batches\n3 Start Epoch 4\n11: 3 batches\n7 Start Epoch 4\n5 Start Epoch 4\n13: 3 batches\n3: 3 batches\n10: 3 batches\n7: 3 batches\n5: 3 batches\n12: 3 batches\n1 Start Epoch 4\n1: 3 batches\n14 Start Epoch 4\n14: 3 batches\n8 Start Epoch 4\n9 Start Epoch 4\n8: 3 batches\n9: 3 batches\n0 Start Epoch 4\n0: 3 batches\n14 Start Epoch 5\n2 Start Epoch 5\n13 Start Epoch 5\n13: 3 batches\n6 Start Epoch 5\n7 Start Epoch 5\n12 Start Epoch 5\n12: 3 batches\n15 Start Epoch 5\n15: 3 batches\n3 Start Epoch 5\n3: 3 batches\n6: 3 batches\n14: 3 batches\n2: 3 batches\n7: 3 batches\n11 Start Epoch 5\n11: 3 batches\n9 Start Epoch 5\n10 Start Epoch 5\n10: 3 batches\n9: 3 batches\n1 Start Epoch 5\n1: 3 batches\n5 Start Epoch 5\n5: 3 batches\n4 Start Epoch 5\n4: 3 batches\n8 Start Epoch 5\n8: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:9: Epoch 0 train loss: 697284.3186848959\nINFO:root:8: Epoch 0 train loss: 97778.75667317708\nINFO:root:12: Epoch 0 train loss: 2944.907470703125\nINFO:root:13: Epoch 0 train loss: 20759.1494140625\nINFO:root:14: Epoch 0 train loss: 600859.4268391927\nINFO:root:15: Epoch 0 train loss: 7260.794921875\nINFO:root:10: Epoch 0 train loss: 232360.02473958334\nINFO:root:11: Epoch 0 train loss: 13335.089518229166\nINFO:root:7: Epoch 0 train loss: 886935.0212198893\nINFO:root:1: Epoch 0 train loss: 576802.947265625\nINFO:root:6: Epoch 0 train loss: 31753.925944010418\nINFO:root:3: Epoch 0 train loss: 891792.2059733073\nINFO:root:0: Epoch 0 train loss: 574988.2323404948\nINFO:root:2: Epoch 0 train loss: 3176.422566731771\nINFO:root:4: Epoch 0 train loss: 13288.884236653646\nINFO:root:5: Epoch 0 train loss: 962554.8525797526\nINFO:root:0: Epoch 0 validation loss: 27912.11042244892\nINFO:root:7: Epoch 1 train loss: 692510.8135375977\nINFO:root:5: Epoch 1 train loss: 808323.967203776\nINFO:root:6: Epoch 1 train loss: 611915.7942708334\nINFO:root:13: Epoch 1 train loss: 4345.287455240886\nINFO:root:14: Epoch 1 train loss: 26018.647888183594\nINFO:root:3: Epoch 1 train loss: 26952.760416666668\nINFO:root:11: Epoch 1 train loss: 650098.4195963541\nINFO:root:15: Epoch 1 train loss: 644035.417582194\nINFO:root:2: Epoch 1 train loss: 239088.5599975586\nINFO:root:10: Epoch 1 train loss: 3851.333740234375\nINFO:root:1: Epoch 1 train loss: 29065.398854573566\nINFO:root:9: Epoch 1 train loss: 687386.7640380859\nINFO:root:12: Epoch 1 train loss: 725998.2084147135\nINFO:root:8: Epoch 1 train loss: 803973.3064778646\nINFO:root:4: Epoch 1 train loss: 1789423.5920766194\nINFO:root:0: Epoch 1 train loss: 705230.5404866537\nINFO:root:0: Epoch 1 validation loss: 27905.75126356694\nINFO:root:3: Epoch 2 train loss: 1714.5933939615886\nINFO:root:7: Epoch 2 train loss: 1028865.2024739584\nINFO:root:5: Epoch 2 train loss: 18261.9887898763\nINFO:root:4: Epoch 2 train loss: 9887.436442057291\nINFO:root:6: Epoch 2 train loss: 4329.3312581380205\nINFO:root:8: Epoch 2 train loss: 16643.155924479168\nINFO:root:9: Epoch 2 train loss: 885837.1944986979\nINFO:root:2: Epoch 2 train loss: 13923.322184244791\nINFO:root:12: Epoch 2 train loss: 12854.376953125\nINFO:root:10: Epoch 2 train loss: 884183.9374186198\nINFO:root:1: Epoch 2 train loss: 10484.034830729166\nINFO:root:11: Epoch 2 train loss: 6845.1174723307295\nINFO:root:13: Epoch 2 train loss: 11309.479136149088\nINFO:root:15: Epoch 2 train loss: 4412.0524495442705\nINFO:root:14: Epoch 2 train loss: 642993.9410807291\nINFO:root:0: Epoch 2 train loss: 10195.1875\nINFO:root:0: Epoch 2 validation loss: 27899.328940409807\nINFO:root:2: Epoch 3 train loss: 8552.86474609375\nINFO:root:11: Epoch 3 train loss: 4277.817209879558\nINFO:root:6: Epoch 3 train loss: 826270.215637207\nINFO:root:5: Epoch 3 train loss: 678021.0810546875\nINFO:root:13: Epoch 3 train loss: 27397.287434895832\nINFO:root:15: Epoch 3 train loss: 23248.971028645832\nINFO:root:7: Epoch 3 train loss: 2615.9117431640625\nINFO:root:4: Epoch 3 train loss: 84424.20448811848\nINFO:root:12: Epoch 3 train loss: 2993.725301106771\nINFO:root:10: Epoch 3 train loss: 1179047.2936197917\nINFO:root:3: Epoch 3 train loss: 1245663.9635009766\nINFO:root:0: Epoch 3 train loss: 3803.4733683268228\nINFO:root:1: Epoch 3 train loss: 8618.6005859375\nINFO:root:14: Epoch 3 train loss: 26722.816528320312\nINFO:root:9: Epoch 3 train loss: 16994.342814127605\nINFO:root:8: Epoch 3 train loss: 278721.6477864583\nINFO:root:0: Epoch 3 validation loss: 27892.468864637347\nINFO:root:7: Epoch 4 train loss: 89150.6552734375\nINFO:root:12: Epoch 4 train loss: 9911.1140238444\nINFO:root:2: Epoch 4 train loss: 5037.681070963542\nINFO:root:14: Epoch 4 train loss: 5834.305013020833\nINFO:root:6: Epoch 4 train loss: 6618.762858072917\nINFO:root:13: Epoch 4 train loss: 1552357.4508463542\nINFO:root:15: Epoch 4 train loss: 325561.35099283856\nINFO:root:3: Epoch 4 train loss: 675419.8538411459\nINFO:root:11: Epoch 4 train loss: 575525.6904296875\nINFO:root:9: Epoch 4 train loss: 6436.32958984375\nINFO:root:10: Epoch 4 train loss: 11238.366048177084\nINFO:root:1: Epoch 4 train loss: 8293.026682535807\nINFO:root:0: Epoch 4 train loss: 4744.436930338542\nINFO:root:5: Epoch 4 train loss: 578793.4793294271\nINFO:root:4: Epoch 4 train loss: 835132.7779134115\nINFO:root:8: Epoch 4 train loss: 6198.645202636719\nINFO:root:0: Epoch 4 validation loss: 27884.94947573729\nINFO:root:14: Epoch 5 train loss: 644405.509765625\nINFO:root:15: Epoch 5 train loss: 260201.76139322916\nINFO:root:3: Epoch 5 train loss: 232217.34219360352\nINFO:root:5: Epoch 5 train loss: 811136.9111328125\nINFO:root:7: Epoch 5 train loss: 13429.173014322916\nINFO:root:4: Epoch 5 train loss: 762643.3749593099\nINFO:root:6: Epoch 5 train loss: 810.0084025065104\nINFO:root:12: Epoch 5 train loss: 5666.9463297526045\nINFO:root:13: Epoch 5 train loss: 803243.2588907877\nINFO:root:2: Epoch 5 train loss: 708871.4190266927\nINFO:root:9: Epoch 5 train loss: 16060.1572265625\nINFO:root:8: Epoch 5 train loss: 1120218.9777832031\nINFO:root:0: Epoch 5 train loss: 1241.4951680501301\nINFO:root:1: Epoch 5 train loss: 675743.5575459799\nINFO:root:11: Epoch 5 train loss: 15213.51708984375\nINFO:root:10: Epoch 5 train loss: 886.7007039388021\nINFO:root:0: Epoch 5 validation loss: 27876.40884787525\n", "seconds": 13.651809930801392, "batch_size": 64, "nodes": 8, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 3 batches\n2 Start Epoch 0\n1 Start Epoch 0\n2: 3 batches\n1: 3 batches\n4 Start Epoch 0\n4: 3 batches\n12 Start Epoch 0\n16 Start Epoch 0\n8 Start Epoch 0\n12: 3 batches\n15 Start Epoch 0\n11 Start Epoch 0\n7 Start Epoch 0\n15: 3 batches\n11: 3 batches\n7: 3 batches\n3 Start Epoch 0\n16: 3 batches\n8: 3 batches\n3: 3 batches\n17 Start Epoch 0\n17: 3 batches\n14 Start Epoch 0\n6 Start Epoch 0\n10 Start Epoch 0\n6: 3 batches\n5 Start Epoch 0\n9 Start Epoch 0\n13 Start Epoch 0\n14: 3 batches\n10: 3 batches\n5: 3 batches\n9: 3 batches\n13: 3 batches\n16 Start Epoch 1\n17 Start Epoch 1\n14 Start Epoch 1\n15 Start Epoch 1\n6 Start Epoch 1\n3 Start Epoch 1\n5 Start Epoch 1\n12 Start Epoch 1\n15: 3 batches\n7 Start Epoch 1\n2 Start Epoch 1\n14: 3 batches\n1 Start Epoch 1\n6: 3 batches\n3: 3 batches\n1: 3 batches\n4 Start Epoch 1\n13 Start Epoch 1\n7: 3 batches\n2: 3 batches\n5: 3 batches\n17: 3 batches\n11 Start Epoch 1\n11: 3 batches\n4: 3 batches\n16: 3 batches\n8 Start Epoch 1\n12: 3 batches\n9 Start Epoch 1\n13: 3 batches\n8: 3 batches\n10 Start Epoch 1\n10: 3 batches\n9: 3 batches\n0 Start Epoch 1\n0: 3 batches\n7 Start Epoch 2\n6 Start Epoch 2\n12 Start Epoch 2\n7: 3 batches\n13 Start Epoch 2\n11 Start Epoch 2\n11: 3 batches\n6: 3 batches\n13: 3 batches\n10 Start Epoch 2\n10: 3 batches\n3 Start Epoch 2\n5 Start Epoch 2\n2 Start Epoch 2\n4 Start Epoch 2\n9 Start Epoch 2\n12: 3 batches\n3: 3 batches\n4: 3 batches\n2: 3 batches\n5: 3 batches\n8 Start Epoch 2\n9: 3 batches\n8: 3 batches\n15 Start Epoch 2\n14 Start Epoch 2\n16 Start Epoch 2\n15: 3 batches\n17 Start Epoch 2\n14: 3 batches\n16: 3 batches\n1 Start Epoch 2\n17: 3 batches\n1: 3 batches\n0 Start Epoch 2\n0: 3 batches\n3 Start Epoch 3\n2 Start Epoch 3\n3: 3 batches\n2: 3 batches\n1 Start Epoch 3\n1: 3 batches\n17 Start Epoch 3\n17: 3 batches\n16 Start Epoch 3\n16: 3 batches\n6 Start Epoch 3\n7 Start Epoch 3\n6: 3 batches\n15 Start Epoch 3\n14 Start Epoch 3\n15: 3 batches\n14: 3 batches\n8 Start Epoch 3\n12 Start Epoch 3\n13 Start Epoch 3\n12: 3 batches\n8: 3 batches\n10 Start Epoch 3\n10: 3 batches\n13: 3 batches\n11 Start Epoch 3\n11: 3 batches\n7: 3 batches\n5 Start Epoch 3\n9 Start Epoch 3\n9: 3 batches\n4 Start Epoch 3\n5: 3 batches\n4: 3 batches\n0 Start Epoch 3\n0: 3 batches\n17 Start Epoch 4\n7 Start Epoch 4\n17: 3 batches\n6 Start Epoch 4\n3 Start Epoch 4\n7: 3 batches\n2 Start Epoch 4\n6: 3 batches\n3: 3 batches\n2: 3 batches\n1 Start Epoch 4\n1: 3 batches\n5 Start Epoch 4\n5: 3 batches\n4 Start Epoch 4\n4: 3 batches\n16 Start Epoch 4\n15 Start Epoch 4\n14 Start Epoch 4\n15: 3 batches\n14: 3 batches\n8 Start Epoch 4\n9 Start Epoch 4\n11 Start Epoch 4\n8: 3 batches\n11: 3 batches\n10 Start Epoch 4\n9: 3 batches\n16: 3 batches\n10: 3 batches\n13 Start Epoch 4\n12 Start Epoch 4\n13: 3 batches\n12: 3 batches\n0 Start Epoch 4\n0: 3 batches\n15 Start Epoch 5\n6 Start Epoch 5\n7 Start Epoch 5\n2 Start Epoch 5\n16 Start Epoch 5\n17 Start Epoch 5\n14 Start Epoch 5\n14: 3 batches\n17: 3 batches\n15: 3 batches\n7: 3 batches\n16: 3 batches\n6: 3 batches\n1 Start Epoch 5\n1: 3 batches\n2: 3 batches\n3 Start Epoch 5\n3: 3 batches\n4 Start Epoch 5\n5 Start Epoch 5\n9 Start Epoch 5\n12 Start Epoch 5\n10 Start Epoch 5\n13 Start Epoch 5\n10: 3 batches\n4: 3 batches\n8 Start Epoch 5\n8: 3 batches\n12: 3 batches\n11 Start Epoch 5\n5: 3 batches\n9: 3 batches\n13: 3 batches\n11: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:16: Epoch 0 train loss: 6412.324401855469\nINFO:root:14: Epoch 0 train loss: 14539.832682291666\nINFO:root:15: Epoch 0 train loss: 11051.52328491211\nINFO:root:6: Epoch 0 train loss: 11110.16884358724\nINFO:root:2: Epoch 0 train loss: 6652.672119140625\nINFO:root:17: Epoch 0 train loss: 1864.1344909667969\nINFO:root:7: Epoch 0 train loss: 960976.9453125\nINFO:root:3: Epoch 0 train loss: 12276.660807291666\nINFO:root:5: Epoch 0 train loss: 27786.737630208332\nINFO:root:13: Epoch 0 train loss: 590029.1226806641\nINFO:root:4: Epoch 0 train loss: 43623.511586507164\nINFO:root:1: Epoch 0 train loss: 1898567.4692382812\nINFO:root:9: Epoch 0 train loss: 706247.3176167806\nINFO:root:12: Epoch 0 train loss: 45811.818359375\nINFO:root:10: Epoch 0 train loss: 7018.523763020833\nINFO:root:8: Epoch 0 train loss: 154477.4028930664\nINFO:root:11: Epoch 0 train loss: 1158646.6510213215\nINFO:root:0: Epoch 0 train loss: 587625.0136515299\nINFO:root:0: Epoch 0 validation loss: 351507.1721177563\nINFO:root:7: Epoch 1 train loss: 10023.900960286459\nINFO:root:6: Epoch 1 train loss: 803484.7542317709\nINFO:root:13: Epoch 1 train loss: 724334.9212239584\nINFO:root:12: Epoch 1 train loss: 10284.561604817709\nINFO:root:11: Epoch 1 train loss: 46834.180391947426\nINFO:root:10: Epoch 1 train loss: 5847.927388509114\nINFO:root:2: Epoch 1 train loss: 8206.94482421875\nINFO:root:4: Epoch 1 train loss: 870144.204457601\nINFO:root:3: Epoch 1 train loss: 805409.7221679688\nINFO:root:5: Epoch 1 train loss: 1184.2023518880208\nINFO:root:8: Epoch 1 train loss: 13465.734700520834\nINFO:root:0: Epoch 1 train loss: 583192.8282165527\nINFO:root:9: Epoch 1 train loss: 23433.4833984375\nINFO:root:15: Epoch 1 train loss: 770760.35546875\nINFO:root:14: Epoch 1 train loss: 742048.4792480469\nINFO:root:17: Epoch 1 train loss: 765397.4271240234\nINFO:root:16: Epoch 1 train loss: 594.4828236897787\nINFO:root:1: Epoch 1 train loss: 13581.67431640625\nINFO:root:0: Epoch 1 validation loss: 351492.524743735\nINFO:root:2: Epoch 2 train loss: 13442.300618489584\nINFO:root:3: Epoch 2 train loss: 940215.9012044271\nINFO:root:1: Epoch 2 train loss: 1199524.1363118489\nINFO:root:17: Epoch 2 train loss: 651222.6943359375\nINFO:root:0: Epoch 2 train loss: 1608332.7099609375\nINFO:root:16: Epoch 2 train loss: 698582.2569986979\nINFO:root:7: Epoch 2 train loss: 5053.4192301432295\nINFO:root:6: Epoch 2 train loss: 24958.903564453125\nINFO:root:14: Epoch 2 train loss: 1022656.7141927084\nINFO:root:15: Epoch 2 train loss: 52171.24609375\nINFO:root:8: Epoch 2 train loss: 9850.778483072916\nINFO:root:12: Epoch 2 train loss: 1285330.48046875\nINFO:root:13: Epoch 2 train loss: 33317.10186767578\nINFO:root:11: Epoch 2 train loss: 29932.235188802082\nINFO:root:10: Epoch 2 train loss: 5356.63818359375\nINFO:root:5: Epoch 2 train loss: 28374.40379333496\nINFO:root:9: Epoch 2 train loss: 6293.772298177083\nINFO:root:4: Epoch 2 train loss: 670317.0849609375\nINFO:root:0: Epoch 2 validation loss: 351477.8532647353\nINFO:root:0: Epoch 3 train loss: 42380.95997111002\nINFO:root:1: Epoch 3 train loss: 753506.2681477865\nINFO:root:7: Epoch 3 train loss: 6459.05126953125\nINFO:root:17: Epoch 3 train loss: 729843.5546875\nINFO:root:6: Epoch 3 train loss: 2250.039220174154\nINFO:root:2: Epoch 3 train loss: 730870.2541097006\nINFO:root:3: Epoch 3 train loss: 6562.523173014323\nINFO:root:5: Epoch 3 train loss: 8600.165837605795\nINFO:root:4: Epoch 3 train loss: 131619.9340502421\nINFO:root:16: Epoch 3 train loss: 1354591.6763865154\nINFO:root:15: Epoch 3 train loss: 582712.2421875\nINFO:root:14: Epoch 3 train loss: 5991.4108479817705\nINFO:root:8: Epoch 3 train loss: 9350.414632161459\nINFO:root:9: Epoch 3 train loss: 13735.249572753906\nINFO:root:11: Epoch 3 train loss: 227755.5379740397\nINFO:root:10: Epoch 3 train loss: 651832.2500813802\nINFO:root:12: Epoch 3 train loss: 15028.603922526041\nINFO:root:13: Epoch 3 train loss: 19795.726888020832\nINFO:root:0: Epoch 3 validation loss: 351464.06575561117\nINFO:root:16: Epoch 4 train loss: 14836.179158528646\nINFO:root:3: Epoch 4 train loss: 771006.4184570312\nINFO:root:6: Epoch 4 train loss: 553176.1861165365\nINFO:root:2: Epoch 4 train loss: 803347.0812072754\nINFO:root:17: Epoch 4 train loss: 6182.884582519531\nINFO:root:14: Epoch 4 train loss: 1233422.1901041667\nINFO:root:15: Epoch 4 train loss: 728613.9386393229\nINFO:root:7: Epoch 4 train loss: 26513.454549153645\nINFO:root:1: Epoch 4 train loss: 1406924.0774739583\nINFO:root:5: Epoch 4 train loss: 3280.966827392578\nINFO:root:4: Epoch 4 train loss: 7696.052164713542\nINFO:root:9: Epoch 4 train loss: 17467.809768676758\nINFO:root:12: Epoch 4 train loss: 104217.9541829427\nINFO:root:11: Epoch 4 train loss: 1035738.2698567709\nINFO:root:8: Epoch 4 train loss: 575278.3490804037\nINFO:root:13: Epoch 4 train loss: 29041.942545572918\nINFO:root:10: Epoch 4 train loss: 8670.623881022135\nINFO:root:0: Epoch 4 train loss: 13634.141682942709\nINFO:root:0: Epoch 4 validation loss: 351449.4843372608\nINFO:root:15: Epoch 5 train loss: 21466.631947835285\nINFO:root:16: Epoch 5 train loss: 47034.6748046875\nINFO:root:14: Epoch 5 train loss: 35172.652994791664\nINFO:root:3: Epoch 5 train loss: 28479.81522623698\nINFO:root:4: Epoch 5 train loss: 2201403.609375\nINFO:root:5: Epoch 5 train loss: 13322.520100911459\nINFO:root:17: Epoch 5 train loss: 659716.7153320312\nINFO:root:0: Epoch 5 train loss: 9051.903635660807\nINFO:root:10: Epoch 5 train loss: 3108.3781534830728\nINFO:root:6: Epoch 5 train loss: 2835.459971110026\nINFO:root:2: Epoch 5 train loss: 53962.364501953125\nINFO:root:8: Epoch 5 train loss: 874169.5626831055\nINFO:root:13: Epoch 5 train loss: 678873.0872395834\nINFO:root:11: Epoch 5 train loss: 457.2415822347005\nINFO:root:7: Epoch 5 train loss: 1390530.8576660156\nINFO:root:9: Epoch 5 train loss: 694250.6938476562\nINFO:root:12: Epoch 5 train loss: 646633.8759765625\nINFO:root:1: Epoch 5 train loss: 1209341.0217895508\nINFO:root:0: Epoch 5 validation loss: 351433.723845171\n", "seconds": 13.711342096328735, "batch_size": 64, "nodes": 9, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 3 batches\n19 Start Epoch 0\n19: 3 batches\n1 Start Epoch 0\n1: 3 batches\n2 Start Epoch 0\n2: 3 batches\n4 Start Epoch 0\n4: 3 batches\n12 Start Epoch 0\n15 Start Epoch 0\n11 Start Epoch 0\n16 Start Epoch 0\n8 Start Epoch 0\n7 Start Epoch 0\n12: 3 batches\n15: 3 batches\n11: 3 batches\n16: 3 batches\n8: 3 batches\n7: 3 batches\n3 Start Epoch 0\n3: 3 batches\n5 Start Epoch 0\n5: 3 batches\n6 Start Epoch 0\n14 Start Epoch 0\n10 Start Epoch 0\n18 Start Epoch 0\n13 Start Epoch 0\n14: 3 batches\n10: 3 batches\n17 Start Epoch 0\n9 Start Epoch 0\n6: 3 batches\n17: 3 batches\n9: 3 batches\n18: 3 batches\n13: 3 batches\n1 Start Epoch 1\n1: 3 batches\n2 Start Epoch 1\n4 Start Epoch 1\n18 Start Epoch 1\n12 Start Epoch 1\n14 Start Epoch 1\n10 Start Epoch 1\n17 Start Epoch 1\n9 Start Epoch 1\n7 Start Epoch 1\n12: 3 batches\n15 Start Epoch 1\n11 Start Epoch 1\n16 Start Epoch 1\n8 Start Epoch 1\n6 Start Epoch 1\n3 Start Epoch 1\n5 Start Epoch 1\n19 Start Epoch 1\n10: 3 batches\n16: 3 batches\n8: 3 batches\n7: 3 batches\n3: 3 batches\n5: 3 batches\n18: 3 batches\n13 Start Epoch 1\n14: 3 batches\n19: 3 batches\n13: 3 batches\n15: 3 batches\n11: 3 batches\n17: 3 batches\n9: 3 batches\n6: 3 batches\n2: 3 batches\n4: 3 batches\n0 Start Epoch 1\n0: 3 batches\n7 Start Epoch 2\n7: 3 batches\n19 Start Epoch 2\n2 Start Epoch 2\n19: 3 batches\n3 Start Epoch 2\n2: 3 batches\n3: 3 batches\n6 Start Epoch 2\n1 Start Epoch 2\n1: 3 batches\n6: 3 batches\n5 Start Epoch 2\n5: 3 batches\n18 Start Epoch 2\n17 Start Epoch 2\n9 Start Epoch 2\n18: 3 batches\n12 Start Epoch 2\n14 Start Epoch 2\n11 Start Epoch 2\n13 Start Epoch 2\n15 Start Epoch 2\n10 Start Epoch 2\n16 Start Epoch 2\n9: 3 batches\n12: 3 batches\n14: 3 batches\n11: 3 batches\n17: 3 batches\n8 Start Epoch 2\n15: 3 batches\n10: 3 batches\n16: 3 batches\n8: 3 batches\n13: 3 batches\n4 Start Epoch 2\n4: 3 batches\n0 Start Epoch 2\n0: 3 batches\n19 Start Epoch 3\n18 Start Epoch 3\n18: 3 batches\n6 Start Epoch 3\n2 Start Epoch 3\n7 Start Epoch 3\n2: 3 batches\n19: 3 batches\n6: 3 batches\n3 Start Epoch 3\n7: 3 batches\n3: 3 batches\n1 Start Epoch 3\n1: 3 batches\n11 Start Epoch 3\n17 Start Epoch 3\n11: 3 batches\n9 Start Epoch 3\n5 Start Epoch 3\n12 Start Epoch 3\n14 Start Epoch 3\n17: 3 batches\n8 Start Epoch 3\n4 Start Epoch 3\n13 Start Epoch 3\n14: 3 batches\n8: 3 batches\n5: 3 batches\n13: 3 batches\n15 Start Epoch 3\n15: 3 batches\n9: 3 batches\n4: 3 batches\n12: 3 batches\n16 Start Epoch 3\n16: 3 batches\n10 Start Epoch 3\n10: 3 batches\n0 Start Epoch 3\n0: 3 batches\n2 Start Epoch 4\n19 Start Epoch 4\n17 Start Epoch 4\n6 Start Epoch 4\n4 Start Epoch 4\n19: 3 batches\n17: 3 batches\n7 Start Epoch 4\n2: 3 batches\n5 Start Epoch 4\n6: 3 batches\n3 Start Epoch 4\n4: 3 batches\n7: 3 batches\n3: 3 batches\n5: 3 batches\n1 Start Epoch 4\n1: 3 batches\n11 Start Epoch 4\n16 Start Epoch 4\n9 Start Epoch 4\n18 Start Epoch 4\n18: 3 batches\n12 Start Epoch 4\n11: 3 batches\n16: 3 batches\n9: 3 batches\n12: 3 batches\n13 Start Epoch 4\n13: 3 batches\n10 Start Epoch 4\n10: 3 batches\n14 Start Epoch 4\n14: 3 batches\n15 Start Epoch 4\n15: 3 batches\n8 Start Epoch 4\n8: 3 batches\n0 Start Epoch 4\n0: 3 batches\n17 Start Epoch 5\n7 Start Epoch 5\n2 Start Epoch 5\n4 Start Epoch 5\n19 Start Epoch 5\n14 Start Epoch 5\n2: 3 batches\n4: 3 batches\n18 Start Epoch 5\n14: 3 batches\n16 Start Epoch 5\n6 Start Epoch 5\n15 Start Epoch 5\n16: 3 batches\n6: 3 batches\n3 Start Epoch 5\n5 Start Epoch 5\n17: 3 batches\n7: 3 batches\n3: 3 batches\n5: 3 batches\n15: 3 batches\n1 Start Epoch 5\n1: 3 batches\n18: 3 batches\n19: 3 batches\n11 Start Epoch 5\n8 Start Epoch 5\n12 Start Epoch 5\n9 Start Epoch 5\n13 Start Epoch 5\n10 Start Epoch 5\n8: 3 batches\n12: 3 batches\n10: 3 batches\n13: 3 batches\n11: 3 batches\n9: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 705692.555440267\nINFO:root:1: Epoch 0 train loss: 10987.193277994791\nINFO:root:14: Epoch 0 train loss: 4747.6583251953125\nINFO:root:10: Epoch 0 train loss: 6890.518493652344\nINFO:root:16: Epoch 0 train loss: 5628.4532470703125\nINFO:root:8: Epoch 0 train loss: 2637.5382385253906\nINFO:root:6: Epoch 0 train loss: 12991.223795572916\nINFO:root:2: Epoch 0 train loss: 695148.3306070963\nINFO:root:4: Epoch 0 train loss: 19732.361653645832\nINFO:root:18: Epoch 0 train loss: 24393.383518218994\nINFO:root:13: Epoch 0 train loss: 727495.953821818\nINFO:root:17: Epoch 0 train loss: 72163.43983968098\nINFO:root:9: Epoch 0 train loss: 2927.9022216796875\nINFO:root:7: Epoch 0 train loss: 14260.974994659424\nINFO:root:3: Epoch 0 train loss: 252771.9115778605\nINFO:root:5: Epoch 0 train loss: 1655418.0335286458\nINFO:root:19: Epoch 0 train loss: 781098.6642862955\nINFO:root:12: Epoch 0 train loss: 7418.458658854167\nINFO:root:15: Epoch 0 train loss: 675652.0177001953\nINFO:root:11: Epoch 0 train loss: 10011.517252604166\nINFO:root:0: Epoch 0 validation loss: 890646.19367744\nINFO:root:7: Epoch 1 train loss: 581554.1506245931\nINFO:root:2: Epoch 1 train loss: 12510.805419921875\nINFO:root:3: Epoch 1 train loss: 4844.615514119466\nINFO:root:19: Epoch 1 train loss: 2985.4251874287925\nINFO:root:6: Epoch 1 train loss: 42029.944661458336\nINFO:root:1: Epoch 1 train loss: 809300.5370380083\nINFO:root:5: Epoch 1 train loss: 1654115.7521158855\nINFO:root:18: Epoch 1 train loss: 688913.1975911459\nINFO:root:13: Epoch 1 train loss: 6412.941467285156\nINFO:root:14: Epoch 1 train loss: 14586.00840250651\nINFO:root:10: Epoch 1 train loss: 2930.568545907736\nINFO:root:16: Epoch 1 train loss: 6339.414143880208\nINFO:root:8: Epoch 1 train loss: 8547.323486328125\nINFO:root:17: Epoch 1 train loss: 46212.750732421875\nINFO:root:9: Epoch 1 train loss: 653122.8758951823\nINFO:root:12: Epoch 1 train loss: 707263.12109375\nINFO:root:15: Epoch 1 train loss: 5719.426106770833\nINFO:root:11: Epoch 1 train loss: 6699.866719563802\nINFO:root:0: Epoch 1 train loss: 35583.66558329264\nINFO:root:4: Epoch 1 train loss: 11504.992345174154\nINFO:root:0: Epoch 1 validation loss: 890619.7866895437\nINFO:root:19: Epoch 2 train loss: 725635.6668294271\nINFO:root:18: Epoch 2 train loss: 233681.77864821753\nINFO:root:7: Epoch 2 train loss: 234951.17918078104\nINFO:root:2: Epoch 2 train loss: 804648.6091715494\nINFO:root:6: Epoch 2 train loss: 6623.22119140625\nINFO:root:3: Epoch 2 train loss: 4855.691660563151\nINFO:root:1: Epoch 2 train loss: 1786.5462074279785\nINFO:root:0: Epoch 2 train loss: 797309.6271540324\nINFO:root:11: Epoch 2 train loss: 3021.260711669922\nINFO:root:4: Epoch 2 train loss: 83259.33341471355\nINFO:root:13: Epoch 2 train loss: 15959.836364746094\nINFO:root:14: Epoch 2 train loss: 6765.348087946574\nINFO:root:9: Epoch 2 train loss: 671848.1142171224\nINFO:root:5: Epoch 2 train loss: 15158.899719238281\nINFO:root:12: Epoch 2 train loss: 798002.3603515625\nINFO:root:15: Epoch 2 train loss: 41536.5146484375\nINFO:root:17: Epoch 2 train loss: 1698.2664337158203\nINFO:root:8: Epoch 2 train loss: 645627.0381876627\nINFO:root:16: Epoch 2 train loss: 690119.9469401041\nINFO:root:10: Epoch 2 train loss: 6990.921813964844\nINFO:root:0: Epoch 2 validation loss: 890592.5026013581\nINFO:root:6: Epoch 3 train loss: 754466.3369140625\nINFO:root:2: Epoch 3 train loss: 305986.89900716144\nINFO:root:4: Epoch 3 train loss: 7106.206319173177\nINFO:root:19: Epoch 3 train loss: 8539.005840301514\nINFO:root:17: Epoch 3 train loss: 12687.047526041666\nINFO:root:7: Epoch 3 train loss: 660262.7262369791\nINFO:root:5: Epoch 3 train loss: 19272.781575520832\nINFO:root:3: Epoch 3 train loss: 584966.8017120361\nINFO:root:1: Epoch 3 train loss: 1441304.3247375488\nINFO:root:0: Epoch 3 train loss: 5190.719889322917\nINFO:root:18: Epoch 3 train loss: 6773.6208902994795\nINFO:root:13: Epoch 3 train loss: 12236.499755859375\nINFO:root:11: Epoch 3 train loss: 12786.521321614584\nINFO:root:16: Epoch 3 train loss: 1491949.6295572917\nINFO:root:9: Epoch 3 train loss: 729.9706420898438\nINFO:root:12: Epoch 3 train loss: 92390.4953066508\nINFO:root:10: Epoch 3 train loss: 6285.05859375\nINFO:root:14: Epoch 3 train loss: 18047.312174479168\nINFO:root:15: Epoch 3 train loss: 26231.694417317707\nINFO:root:8: Epoch 3 train loss: 6188.146308898926\nINFO:root:0: Epoch 3 validation loss: 890563.0584523152\nINFO:root:18: Epoch 4 train loss: 28747.541178385418\nINFO:root:15: Epoch 4 train loss: 702939.4637400309\nINFO:root:16: Epoch 4 train loss: 36584.81001790365\nINFO:root:6: Epoch 4 train loss: 728824.5978190104\nINFO:root:3: Epoch 4 train loss: 879431.0839436849\nINFO:root:5: Epoch 4 train loss: 1482.6377766927083\nINFO:root:19: Epoch 4 train loss: 14289.96906789144\nINFO:root:14: Epoch 4 train loss: 15559.826883951822\nINFO:root:17: Epoch 4 train loss: 5033.470275878906\nINFO:root:7: Epoch 4 train loss: 2222624.5631510415\nINFO:root:2: Epoch 4 train loss: 15639.226806640625\nINFO:root:4: Epoch 4 train loss: 230752.25173950195\nINFO:root:1: Epoch 4 train loss: 666837.690653483\nINFO:root:11: Epoch 4 train loss: 12374.052124023438\nINFO:root:8: Epoch 4 train loss: 706440.5735677084\nINFO:root:13: Epoch 4 train loss: 23111.251302083332\nINFO:root:12: Epoch 4 train loss: 21415.529947916668\nINFO:root:10: Epoch 4 train loss: 642331.782922109\nINFO:root:9: Epoch 4 train loss: 7114.135335286458\nINFO:root:0: Epoch 4 train loss: 27187.37486775716\nINFO:root:0: Epoch 4 validation loss: 890530.4269530522\nINFO:root:18: Epoch 5 train loss: 807899.5423583984\nINFO:root:19: Epoch 5 train loss: 4188.675557454427\nINFO:root:14: Epoch 5 train loss: 6551.283854166667\nINFO:root:15: Epoch 5 train loss: 547.7076975504557\nINFO:root:7: Epoch 5 train loss: 11259.7685546875\nINFO:root:6: Epoch 5 train loss: 28253.85468037923\nINFO:root:4: Epoch 5 train loss: 229247.0199025472\nINFO:root:5: Epoch 5 train loss: 5939.6583251953125\nINFO:root:17: Epoch 5 train loss: 1002.1627858479818\nINFO:root:12: Epoch 5 train loss: 810795.0603841146\nINFO:root:9: Epoch 5 train loss: 4652.260498046875\nINFO:root:11: Epoch 5 train loss: 4039.1621297200522\nINFO:root:10: Epoch 5 train loss: 11975.247131347656\nINFO:root:1: Epoch 5 train loss: 2195274.0045572915\nINFO:root:0: Epoch 5 train loss: 596624.461344401\nINFO:root:3: Epoch 5 train loss: 642748.4514160156\nINFO:root:2: Epoch 5 train loss: 693082.8225250244\nINFO:root:8: Epoch 5 train loss: 27449.26513671875\nINFO:root:16: Epoch 5 train loss: 4620.146809895833\nINFO:root:13: Epoch 5 train loss: 7246.0886637369795\nINFO:root:0: Epoch 5 validation loss: 890493.9556600894\n", "seconds": 11.74163293838501, "batch_size": 64, "nodes": 10, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 3 batches\n1 Start Epoch 0\n2 Start Epoch 0\n2: 3 batches\n21 Start Epoch 0\n21: 3 batches\n1: 3 batches\n6 Start Epoch 0\n7 Start Epoch 0\n7: 3 batches\n6: 3 batches\n16 Start Epoch 0\n8 Start Epoch 0\n8: 3 batches\n16: 3 batches\n5 Start Epoch 0\n3 Start Epoch 0\n15 Start Epoch 0\n12 Start Epoch 0\n20 Start Epoch 0\n4 Start Epoch 0\n3: 3 batches\n19 Start Epoch 0\n9 Start Epoch 0\n19: 3 batches\n14 Start Epoch 0\n9: 3 batches\n20: 3 batches\n11 Start Epoch 0\n5: 3 batches\n14: 3 batches\n13 Start Epoch 0\n10 Start Epoch 0\n4: 3 batches\n12: 3 batches\n10: 3 batches\n15: 3 batches\n13: 3 batches\n11: 3 batches\n18 Start Epoch 0\n18: 3 batches\n17 Start Epoch 0\n17: 3 batches\n4 Start Epoch 1\n2 Start Epoch 1\n7 Start Epoch 1\n2: 3 batches\n6 Start Epoch 1\n5 Start Epoch 1\n17 Start Epoch 1\n7: 3 batches\n5: 3 batches\n3 Start Epoch 1\n4: 3 batches\n3: 3 batches\n16 Start Epoch 1\n6: 3 batches\n17: 3 batches\n16: 3 batches\n14 Start Epoch 1\n8 Start Epoch 1\n13 Start Epoch 1\n20 Start Epoch 1\n10 Start Epoch 1\n19 Start Epoch 1\n14: 3 batches\n9 Start Epoch 1\n12 Start Epoch 1\n21 Start Epoch 1\n10: 3 batches\n18 Start Epoch 1\n21: 3 batches\n11 Start Epoch 1\n18: 3 batches\n15 Start Epoch 1\n8: 3 batches\n13: 3 batches\n19: 3 batches\n15: 3 batches\n9: 3 batches\n12: 3 batches\n20: 3 batches\n11: 3 batches\n1 Start Epoch 1\n1: 3 batches\n0 Start Epoch 1\n0: 3 batches\n17 Start Epoch 2\n2 Start Epoch 2\n17: 3 batches\n3 Start Epoch 2\n7 Start Epoch 2\n6 Start Epoch 2\n3: 3 batches\n2: 3 batches\n6: 3 batches\n7: 3 batches\n1 Start Epoch 2\n1: 3 batches\n12 Start Epoch 2\n19 Start Epoch 2\n14 Start Epoch 2\n9 Start Epoch 2\n12: 3 batches\n20 Start Epoch 2\n11 Start Epoch 2\n4 Start Epoch 2\n10 Start Epoch 2\n4: 3 batches\n18 Start Epoch 2\n14: 3 batches\n8 Start Epoch 2\n21 Start Epoch 2\n21: 3 batches\n11: 3 batches\n5 Start Epoch 2\n19: 3 batches\n16 Start Epoch 2\n15 Start Epoch 2\n9: 3 batches\n18: 3 batches\n16: 3 batches\n15: 3 batches\n8: 3 batches\n20: 3 batches\n10: 3 batches\n5: 3 batches\n13 Start Epoch 2\n13: 3 batches\n0 Start Epoch 2\n0: 3 batches\n17 Start Epoch 3\n7 Start Epoch 3\n2 Start Epoch 3\n7: 3 batches\n9 Start Epoch 3\n3 Start Epoch 3\n19 Start Epoch 3\n17: 3 batches\n15 Start Epoch 3\n8 Start Epoch 3\n18 Start Epoch 3\n14 Start Epoch 3\n1 Start Epoch 3\n1: 3 batches\n8: 3 batches\n2: 3 batches\n18: 3 batches\n15: 3 batches\n3: 3 batches\n19: 3 batches\n14: 3 batches\n6 Start Epoch 3\n9: 3 batches\n6: 3 batches\n21 Start Epoch 3\n11 Start Epoch 3\n4 Start Epoch 3\n12 Start Epoch 3\n12: 3 batches\n21: 3 batches\n10 Start Epoch 3\n5 Start Epoch 3\n16 Start Epoch 3\n13 Start Epoch 3\n20 Start Epoch 3\n10: 3 batches\n5: 3 batches\n13: 3 batches\n20: 3 batches\n11: 3 batches\n4: 3 batches\n16: 3 batches\n0 Start Epoch 3\n0: 3 batches\n10 Start Epoch 4\n3 Start Epoch 4\n19 Start Epoch 4\n17 Start Epoch 4\n15 Start Epoch 4\n6 Start Epoch 4\n1 Start Epoch 4\n1: 3 batches\n11 Start Epoch 4\n2 Start Epoch 4\n18 Start Epoch 4\n16 Start Epoch 4\n14 Start Epoch 4\n7 Start Epoch 4\n2: 3 batches\n18: 3 batches\n17: 3 batches\n14: 3 batches\n6: 3 batches\n10: 3 batches\n20 Start Epoch 4\n11: 3 batches\n4 Start Epoch 4\n3: 3 batches\n19: 3 batches\n16: 3 batches\n15: 3 batches\n7: 3 batches\n21 Start Epoch 4\n5 Start Epoch 4\n9 Start Epoch 4\n12 Start Epoch 4\n8 Start Epoch 4\n13 Start Epoch 4\n21: 3 batches\n5: 3 batches\n4: 3 batches\n9: 3 batches\n13: 3 batches\n20: 3 batches\n8: 3 batches\n12: 3 batches\n0 Start Epoch 4\n0: 3 batches\n18 Start Epoch 5\n18: 3 batches\n7 Start Epoch 5\n3 Start Epoch 5\n16 Start Epoch 5\n15 Start Epoch 5\n6 Start Epoch 5\n2 Start Epoch 5\n2: 3 batches\n19 Start Epoch 5\n19: 3 batches\n15: 3 batches\n7: 3 batches\n3: 3 batches\n14 Start Epoch 5\n6: 3 batches\n14: 3 batches\n16: 3 batches\n20 Start Epoch 5\n8 Start Epoch 5\n12 Start Epoch 5\n10 Start Epoch 5\n5 Start Epoch 5\n17 Start Epoch 5\n17: 3 batches\n12: 3 batches\n20: 3 batches\n10: 3 batches\n4 Start Epoch 5\n9 Start Epoch 5\n13 Start Epoch 5\n21 Start Epoch 5\n21: 3 batches\n11 Start Epoch 5\n5: 3 batches\n8: 3 batches\n13: 3 batches\n11: 3 batches\n4: 3 batches\n9: 3 batches\n1 Start Epoch 5\n1: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:6: Epoch 0 train loss: 6087.674840291341\nINFO:root:5: Epoch 0 train loss: 3690.6150245666504\nINFO:root:2: Epoch 0 train loss: 6097.808275222778\nINFO:root:7: Epoch 0 train loss: 6517.389383157094\nINFO:root:4: Epoch 0 train loss: 726059.6489636898\nINFO:root:3: Epoch 0 train loss: 669709.5474395752\nINFO:root:16: Epoch 0 train loss: 2982.6713689168296\nINFO:root:17: Epoch 0 train loss: 8781.584075927734\nINFO:root:18: Epoch 0 train loss: 8103.656901041667\nINFO:root:14: Epoch 0 train loss: 20440.95068359375\nINFO:root:8: Epoch 0 train loss: 6219.981931686401\nINFO:root:13: Epoch 0 train loss: 7715.442311604817\nINFO:root:21: Epoch 0 train loss: 2349.4886271158853\nINFO:root:11: Epoch 0 train loss: 6615.8758061726885\nINFO:root:9: Epoch 0 train loss: 108154.13541666667\nINFO:root:12: Epoch 0 train loss: 802388.648844401\nINFO:root:20: Epoch 0 train loss: 4830.097269694011\nINFO:root:10: Epoch 0 train loss: 3870.6148476203284\nINFO:root:19: Epoch 0 train loss: 6795.350362141927\nINFO:root:15: Epoch 0 train loss: 544578.6619059244\nINFO:root:0: Epoch 0 train loss: 1185109.8934733074\nINFO:root:1: Epoch 0 train loss: 645351.3657978376\nINFO:root:0: Epoch 0 validation loss: 100205.39084654041\nINFO:root:3: Epoch 1 train loss: 544196.4927012125\nINFO:root:17: Epoch 1 train loss: 4095.0811665852866\nINFO:root:7: Epoch 1 train loss: 689557.7669270834\nINFO:root:2: Epoch 1 train loss: 5255446.985921224\nINFO:root:6: Epoch 1 train loss: 9531.04224650065\nINFO:root:1: Epoch 1 train loss: 2306.8706868489585\nINFO:root:18: Epoch 1 train loss: 4900.452067057292\nINFO:root:15: Epoch 1 train loss: 841508.2578125\nINFO:root:8: Epoch 1 train loss: 15815.801279067993\nINFO:root:12: Epoch 1 train loss: 724516.114034017\nINFO:root:0: Epoch 1 train loss: 6122.628794352214\nINFO:root:21: Epoch 1 train loss: 5434.10236676534\nINFO:root:11: Epoch 1 train loss: 2664.907999674479\nINFO:root:5: Epoch 1 train loss: 80626.17305056255\nINFO:root:9: Epoch 1 train loss: 2973.6889292399087\nINFO:root:20: Epoch 1 train loss: 26789.388834635418\nINFO:root:10: Epoch 1 train loss: 582082.9526453018\nINFO:root:4: Epoch 1 train loss: 199.19243367513022\nINFO:root:19: Epoch 1 train loss: 3263.1706746419272\nINFO:root:14: Epoch 1 train loss: 564.5276489257812\nINFO:root:16: Epoch 1 train loss: 553939.3037153879\nINFO:root:13: Epoch 1 train loss: 3686.718969304711\nINFO:root:0: Epoch 1 validation loss: 100186.63876364633\nINFO:root:8: Epoch 2 train loss: 12745.014057029039\nINFO:root:2: Epoch 2 train loss: 25457.241780598957\nINFO:root:18: Epoch 2 train loss: 12331.076828082403\nINFO:root:17: Epoch 2 train loss: 578748.690112094\nINFO:root:14: Epoch 2 train loss: 130873.328125\nINFO:root:7: Epoch 2 train loss: 7371.5744222005205\nINFO:root:15: Epoch 2 train loss: 4363.759928385417\nINFO:root:9: Epoch 2 train loss: 20310.1005859375\nINFO:root:19: Epoch 2 train loss: 1203.0919647216797\nINFO:root:3: Epoch 2 train loss: 643360.6748250326\nINFO:root:1: Epoch 2 train loss: 23618.459309895832\nINFO:root:6: Epoch 2 train loss: 29226.29918416341\nINFO:root:11: Epoch 2 train loss: 6112.036804199219\nINFO:root:4: Epoch 2 train loss: 42681.04207356771\nINFO:root:13: Epoch 2 train loss: 23058.24387995402\nINFO:root:20: Epoch 2 train loss: 1536403.125447591\nINFO:root:12: Epoch 2 train loss: 2682.6161460876465\nINFO:root:21: Epoch 2 train loss: 43374.224609375\nINFO:root:10: Epoch 2 train loss: 4748.432530860106\nINFO:root:5: Epoch 2 train loss: 29771.03138224284\nINFO:root:16: Epoch 2 train loss: 26193.432647705078\nINFO:root:0: Epoch 2 train loss: 25019.807495117188\nINFO:root:0: Epoch 2 validation loss: 100168.44407539269\nINFO:root:11: Epoch 3 train loss: 8831.732869466146\nINFO:root:2: Epoch 3 train loss: 683805.7277606329\nINFO:root:19: Epoch 3 train loss: 11444.719128290812\nINFO:root:16: Epoch 3 train loss: 6736.8180745442705\nINFO:root:15: Epoch 3 train loss: 6355.162224769592\nINFO:root:6: Epoch 3 train loss: 15474.355153401693\nINFO:root:10: Epoch 3 train loss: 10253.2099609375\nINFO:root:3: Epoch 3 train loss: 27036.102489471436\nINFO:root:18: Epoch 3 train loss: 696499.3052927653\nINFO:root:17: Epoch 3 train loss: 2065.463881969452\nINFO:root:14: Epoch 3 train loss: 26483.935546875\nINFO:root:7: Epoch 3 train loss: 42675.770833333336\nINFO:root:1: Epoch 3 train loss: 5374.3494059244795\nINFO:root:21: Epoch 3 train loss: 14605.796869913736\nINFO:root:5: Epoch 3 train loss: 724896.3509508768\nINFO:root:4: Epoch 3 train loss: 7021.505644814421\nINFO:root:9: Epoch 3 train loss: 22886.920654296875\nINFO:root:12: Epoch 3 train loss: 3782.7743937174478\nINFO:root:20: Epoch 3 train loss: 227278.24277504286\nINFO:root:8: Epoch 3 train loss: 2064134.4059244792\nINFO:root:13: Epoch 3 train loss: 774006.8707580566\nINFO:root:0: Epoch 3 train loss: 19212.158432006836\nINFO:root:0: Epoch 3 validation loss: 100148.07042244884\nINFO:root:6: Epoch 4 train loss: 14138.552891731262\nINFO:root:3: Epoch 4 train loss: 8118.209241231282\nINFO:root:2: Epoch 4 train loss: 3899.247811714808\nINFO:root:18: Epoch 4 train loss: 647441.7927246094\nINFO:root:16: Epoch 4 train loss: 1274.0407759348552\nINFO:root:14: Epoch 4 train loss: 206331.9230143229\nINFO:root:7: Epoch 4 train loss: 8718.175137837728\nINFO:root:17: Epoch 4 train loss: 101473.63798014323\nINFO:root:15: Epoch 4 train loss: 19483.29276529948\nINFO:root:19: Epoch 4 train loss: 5524579.437906901\nINFO:root:8: Epoch 4 train loss: 23422.972239176434\nINFO:root:13: Epoch 4 train loss: 275935.8098958333\nINFO:root:20: Epoch 4 train loss: 25380.8349609375\nINFO:root:10: Epoch 4 train loss: 25125.45893096924\nINFO:root:5: Epoch 4 train loss: 14088.92693117261\nINFO:root:9: Epoch 4 train loss: 6243.8173828125\nINFO:root:12: Epoch 4 train loss: 6646.142128149669\nINFO:root:11: Epoch 4 train loss: 712996.1486002604\nINFO:root:4: Epoch 4 train loss: 6312.6937680142\nINFO:root:21: Epoch 4 train loss: 75720.10588987668\nINFO:root:0: Epoch 4 train loss: 3453.467300415039\nINFO:root:1: Epoch 4 train loss: 9386.900594075521\nINFO:root:0: Epoch 4 validation loss: 100126.69112516535\nINFO:root:7: Epoch 5 train loss: 27684.337727864582\nINFO:root:6: Epoch 5 train loss: 2225.606491088867\nINFO:root:14: Epoch 5 train loss: 14401.179606119791\nINFO:root:19: Epoch 5 train loss: 13709.076334635416\nINFO:root:16: Epoch 5 train loss: 690831.0598462423\nINFO:root:15: Epoch 5 train loss: 4590.060287475586\nINFO:root:18: Epoch 5 train loss: 668656.86378479\nINFO:root:17: Epoch 5 train loss: 699570.2881164551\nINFO:root:2: Epoch 5 train loss: 3442.6211878458657\nINFO:root:3: Epoch 5 train loss: 5597.48296592633\nINFO:root:8: Epoch 5 train loss: 587325.4850443205\nINFO:root:5: Epoch 5 train loss: 85097.05537923177\nINFO:root:20: Epoch 5 train loss: 9200.774256745974\nINFO:root:4: Epoch 5 train loss: 13846.172351559004\nINFO:root:12: Epoch 5 train loss: 576.220235824585\nINFO:root:21: Epoch 5 train loss: 12365.448618570963\nINFO:root:11: Epoch 5 train loss: 640.3300956090292\nINFO:root:13: Epoch 5 train loss: 545583.8243001302\nINFO:root:10: Epoch 5 train loss: 78334.32864634196\nINFO:root:1: Epoch 5 train loss: 7612.003082275391\nINFO:root:0: Epoch 5 train loss: 4678.242075602214\nINFO:root:9: Epoch 5 train loss: 16732.62353515625\nINFO:root:0: Epoch 5 validation loss: 100105.13627057805\n", "seconds": 11.577104091644287, "batch_size": 64, "nodes": 11, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n23 Start Epoch 0\n23: 2 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 2 batches\n2: 2 batches\n4 Start Epoch 0\n4: 2 batches\n3 Start Epoch 0\n8 Start Epoch 0\n3: 2 batches\n8: 2 batches\n16 Start Epoch 0\n7 Start Epoch 0\n16: 2 batches\n15 Start Epoch 0\n7: 2 batches\n15: 2 batches\n12 Start Epoch 0\n12: 2 batches\n20 Start Epoch 0\n6 Start Epoch 0\n6: 2 batches\n20: 2 batches\n19 Start Epoch 0\n19: 2 batches\n11 Start Epoch 0\n11: 2 batches\n9 Start Epoch 0\n5 Start Epoch 0\n5: 2 batches\n10 Start Epoch 0\n9: 2 batches\n17 Start Epoch 0\n10: 2 batches\n17: 2 batches\n18 Start Epoch 0\n13 Start Epoch 0\n14 Start Epoch 0\n22 Start Epoch 0\n18: 2 batches\n13: 2 batches\n21 Start Epoch 0\n14: 2 batches\n22: 2 batches\n21: 2 batches\n18 Start Epoch 1\n19 Start Epoch 1\n19: 2 batches\n18: 2 batches\n21 Start Epoch 1\n20 Start Epoch 1\n20: 2 batches\n21: 2 batches\n17 Start Epoch 1\n17: 2 batches\n23 Start Epoch 1\n22 Start Epoch 1\n1 Start Epoch 1\n1: 2 batches\n3 Start Epoch 1\n16 Start Epoch 1\n14 Start Epoch 1\n14: 2 batches\n23: 2 batches\n2 Start Epoch 1\n16: 2 batches\n22: 2 batches\n15 Start Epoch 1\n15: 2 batches\n2: 2 batches\n6 Start Epoch 1\n6: 2 batches\n3: 2 batches\n4 Start Epoch 1\n11 Start Epoch 1\n13 Start Epoch 1\n8 Start Epoch 1\n12 Start Epoch 1\n9 Start Epoch 1\n4: 2 batches\n10 Start Epoch 1\n5 Start Epoch 1\n11: 2 batches\n12: 2 batches\n8: 2 batches\n7 Start Epoch 1\n7: 2 batches\n13: 2 batches\n9: 2 batches\n5: 2 batches\n10: 2 batches\n0 Start Epoch 1\n0: 2 batches\n17 Start Epoch 2\n15 Start Epoch 2\n19 Start Epoch 2\n11 Start Epoch 2\n11: 2 batches\n15: 2 batches\n18 Start Epoch 2\n18: 2 batches\n19: 2 batches\n3 Start Epoch 2\n2 Start Epoch 2\n2: 2 batches\n7 Start Epoch 2\n7: 2 batches\n14 Start Epoch 2\n14: 2 batches\n1 Start Epoch 2\n1: 2 batches\n3: 2 batches\n12 Start Epoch 2\n6 Start Epoch 2\n10 Start Epoch 2\n5 Start Epoch 2\n10: 2 batches\n12: 2 batches\n9 Start Epoch 2\n6: 2 batches\n21 Start Epoch 2\n16 Start Epoch 2\n16: 2 batches\n22 Start Epoch 2\n4 Start Epoch 2\n8 Start Epoch 2\n21: 2 batches\n17: 2 batches\n8: 2 batches\n20 Start Epoch 2\n22: 2 batches\n4: 2 batches\n5: 2 batches\n13 Start Epoch 2\n9: 2 batches\n20: 2 batches\n13: 2 batches\n23 Start Epoch 2\n23: 2 batches\n0 Start Epoch 2\n0: 2 batches\n16 Start Epoch 3\n15 Start Epoch 3\n18 Start Epoch 3\n17 Start Epoch 3\n15: 2 batches\n19 Start Epoch 3\n17: 2 batches\n16: 2 batches\n14 Start Epoch 3\n14: 2 batches\n19: 2 batches\n18: 2 batches\n13 Start Epoch 3\n13: 2 batches\n21 Start Epoch 3\n21: 2 batches\n22 Start Epoch 3\n23 Start Epoch 3\n22: 2 batches\n23: 2 batches\n20 Start Epoch 3\n20: 2 batches\n2 Start Epoch 3\n7 Start Epoch 3\n6 Start Epoch 3\n3 Start Epoch 3\n7: 2 batches\n3: 2 batches\n6: 2 batches\n4 Start Epoch 3\n5 Start Epoch 3\n5: 2 batches\n4: 2 batches\n2: 2 batches\n8 Start Epoch 3\n8: 2 batches\n9 Start Epoch 3\n9: 2 batches\n1 Start Epoch 3\n1: 2 batches\n10 Start Epoch 3\n12 Start Epoch 3\n11 Start Epoch 3\n12: 2 batches\n11: 2 batches\n10: 2 batches\n0 Start Epoch 3\n0: 2 batches\n18 Start Epoch 4\n18: 2 batches\n19 Start Epoch 4\n19: 2 batches\n9 Start Epoch 4\n11 Start Epoch 4\n9: 2 batches\n21 Start Epoch 4\n10 Start Epoch 4\n21: 2 batches\n20 Start Epoch 4\n11: 2 batches\n20: 2 batches\n10: 2 batches\n3 Start Epoch 4\n2 Start Epoch 4\n2: 2 batches\n3: 2 batches\n7 Start Epoch 4\n14 Start Epoch 4\n12 Start Epoch 4\n16 Start Epoch 4\n14: 2 batches\n13 Start Epoch 4\n6 Start Epoch 4\n15 Start Epoch 4\n12: 2 batches\n7: 2 batches\n17 Start Epoch 4\n17: 2 batches\n13: 2 batches\n6: 2 batches\n16: 2 batches\n15: 2 batches\n22 Start Epoch 4\n8 Start Epoch 4\n5 Start Epoch 4\n4 Start Epoch 4\n5: 2 batches\n4: 2 batches\n1 Start Epoch 4\n1: 2 batches\n23 Start Epoch 4\n22: 2 batches\n23: 2 batches\n8: 2 batches\n0 Start Epoch 4\n0: 2 batches\n18 Start Epoch 5\n19 Start Epoch 5\n19: 2 batches\n18: 2 batches\n3 Start Epoch 5\n2 Start Epoch 5\n2: 2 batches\n3: 2 batches\n7 Start Epoch 5\n20 Start Epoch 5\n21 Start Epoch 5\n14 Start Epoch 5\n22 Start Epoch 5\n5 Start Epoch 5\n10 Start Epoch 5\n12 Start Epoch 5\n8 Start Epoch 5\n7: 2 batches\n11 Start Epoch 5\n13 Start Epoch 5\n9 Start Epoch 5\n6 Start Epoch 5\n21: 2 batches\n15 Start Epoch 5\n23 Start Epoch 5\n5: 2 batches\n14: 2 batches\n23: 2 batches\n4 Start Epoch 5\n10: 2 batches\n12: 2 batches\n8: 2 batches\n20: 2 batches\n6: 2 batches\n15: 2 batches\n22: 2 batches\n4: 2 batches\n11: 2 batches\n13: 2 batches\n9: 2 batches\n17 Start Epoch 5\n17: 2 batches\n16 Start Epoch 5\n16: 2 batches\n1 Start Epoch 5\n1: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:18: Epoch 0 train loss: 1887.8851318359375\nINFO:root:19: Epoch 0 train loss: 261.1683807373047\nINFO:root:20: Epoch 0 train loss: 23439.769775390625\nINFO:root:21: Epoch 0 train loss: 362349.51171875\nINFO:root:17: Epoch 0 train loss: 882252.2614746094\nINFO:root:23: Epoch 0 train loss: 11393.361572265625\nINFO:root:22: Epoch 0 train loss: 6286.329833984375\nINFO:root:3: Epoch 0 train loss: 921254.3944091797\nINFO:root:2: Epoch 0 train loss: 1286818.8500976562\nINFO:root:16: Epoch 0 train loss: 642.5125274658203\nINFO:root:15: Epoch 0 train loss: 3703.5980224609375\nINFO:root:1: Epoch 0 train loss: 3911.140869140625\nINFO:root:12: Epoch 0 train loss: 10779.01708984375\nINFO:root:9: Epoch 0 train loss: 10784.1865234375\nINFO:root:14: Epoch 0 train loss: 5039.853759765625\nINFO:root:5: Epoch 0 train loss: 927001.1022644043\nINFO:root:11: Epoch 0 train loss: 512.1189880371094\nINFO:root:4: Epoch 0 train loss: 920524.8251953125\nINFO:root:10: Epoch 0 train loss: 1159074.0848388672\nINFO:root:13: Epoch 0 train loss: 33631.6884765625\nINFO:root:8: Epoch 0 train loss: 2556.9964904785156\nINFO:root:7: Epoch 0 train loss: 21181.433227539062\nINFO:root:0: Epoch 0 train loss: 13939.074951171875\nINFO:root:6: Epoch 0 train loss: 1178085.9296875\nINFO:root:0: Epoch 0 validation loss: 81551.15570628957\nINFO:root:15: Epoch 1 train loss: 1035548.1435546875\nINFO:root:19: Epoch 1 train loss: 3893.975875854492\nINFO:root:11: Epoch 1 train loss: 1239154.25\nINFO:root:18: Epoch 1 train loss: 1054198.8891906738\nINFO:root:3: Epoch 1 train loss: 350084.4375\nINFO:root:2: Epoch 1 train loss: 14542.445861816406\nINFO:root:7: Epoch 1 train loss: 2314223.4375\nINFO:root:14: Epoch 1 train loss: 12182.54541015625\nINFO:root:1: Epoch 1 train loss: 10811.698120117188\nINFO:root:21: Epoch 1 train loss: 18824.72244644165\nINFO:root:16: Epoch 1 train loss: 1086339.6713256836\nINFO:root:5: Epoch 1 train loss: 9600.08056640625\nINFO:root:10: Epoch 1 train loss: 47357.63082885742\nINFO:root:12: Epoch 1 train loss: 19725.4892578125\nINFO:root:9: Epoch 1 train loss: 1218338.2861328125\nINFO:root:6: Epoch 1 train loss: 9102.538696289062\nINFO:root:8: Epoch 1 train loss: 5920.146697998047\nINFO:root:20: Epoch 1 train loss: 8521.441314697266\nINFO:root:17: Epoch 1 train loss: 10562.92041015625\nINFO:root:4: Epoch 1 train loss: 139268.3564453125\nINFO:root:22: Epoch 1 train loss: 1029502.0778808594\nINFO:root:13: Epoch 1 train loss: 16395.29248046875\nINFO:root:0: Epoch 1 train loss: 20071.150390625\nINFO:root:23: Epoch 1 train loss: 868452.5035705566\nINFO:root:0: Epoch 1 validation loss: 81544.87384216455\nINFO:root:16: Epoch 2 train loss: 6185.33642578125\nINFO:root:15: Epoch 2 train loss: 2075.749053955078\nINFO:root:18: Epoch 2 train loss: 20331.75048828125\nINFO:root:19: Epoch 2 train loss: 6267.305419921875\nINFO:root:17: Epoch 2 train loss: 18168.29296875\nINFO:root:14: Epoch 2 train loss: 5971.5966796875\nINFO:root:13: Epoch 2 train loss: 17733.1357421875\nINFO:root:21: Epoch 2 train loss: 16012.36328125\nINFO:root:22: Epoch 2 train loss: 924212.8155517578\nINFO:root:23: Epoch 2 train loss: 5285.505859375\nINFO:root:20: Epoch 2 train loss: 6886.083831787109\nINFO:root:7: Epoch 2 train loss: 8816.2783203125\nINFO:root:2: Epoch 2 train loss: 688.7760467529297\nINFO:root:6: Epoch 2 train loss: 10019.300048828125\nINFO:root:3: Epoch 2 train loss: 869968.8558349609\nINFO:root:0: Epoch 2 train loss: 2335243.8335876465\nINFO:root:4: Epoch 2 train loss: 1118.0957336425781\nINFO:root:5: Epoch 2 train loss: 1112045.5242919922\nINFO:root:8: Epoch 2 train loss: 6176.4751625061035\nINFO:root:9: Epoch 2 train loss: 10680.118774414062\nINFO:root:1: Epoch 2 train loss: 3235.4390258789062\nINFO:root:11: Epoch 2 train loss: 1123344.3292236328\nINFO:root:10: Epoch 2 train loss: 17308.762939453125\nINFO:root:12: Epoch 2 train loss: 8183.422668457031\nINFO:root:0: Epoch 2 validation loss: 81538.36728213153\nINFO:root:18: Epoch 3 train loss: 2121295.25\nINFO:root:19: Epoch 3 train loss: 13839.66650390625\nINFO:root:10: Epoch 3 train loss: 1110017.3383789062\nINFO:root:9: Epoch 3 train loss: 1279773.4102172852\nINFO:root:21: Epoch 3 train loss: 364192.2214355469\nINFO:root:20: Epoch 3 train loss: 4109.445556640625\nINFO:root:11: Epoch 3 train loss: 9245.264770507812\nINFO:root:2: Epoch 3 train loss: 35333.2080078125\nINFO:root:3: Epoch 3 train loss: 1963587.375\nINFO:root:7: Epoch 3 train loss: 22237.427124023438\nINFO:root:0: Epoch 3 train loss: 964141.8049316406\nINFO:root:14: Epoch 3 train loss: 1039154.8186035156\nINFO:root:13: Epoch 3 train loss: 6346.895568847656\nINFO:root:17: Epoch 3 train loss: 18729.319580078125\nINFO:root:15: Epoch 3 train loss: 6766.54541015625\nINFO:root:12: Epoch 3 train loss: 968.4967651367188\nINFO:root:6: Epoch 3 train loss: 1070926.3159179688\nINFO:root:16: Epoch 3 train loss: 816011.4267883301\nINFO:root:22: Epoch 3 train loss: 11454.7333984375\nINFO:root:4: Epoch 3 train loss: 13436.882629394531\nINFO:root:8: Epoch 3 train loss: 4411.0936279296875\nINFO:root:5: Epoch 3 train loss: 6275.321533203125\nINFO:root:1: Epoch 3 train loss: 7412.224365234375\nINFO:root:23: Epoch 3 train loss: 23035.759765625\nINFO:root:0: Epoch 3 validation loss: 81531.56159079108\nINFO:root:19: Epoch 4 train loss: 940494.5070800781\nINFO:root:18: Epoch 4 train loss: 124563.28442382812\nINFO:root:3: Epoch 4 train loss: 9991.812744140625\nINFO:root:2: Epoch 4 train loss: 1020.9020843505859\nINFO:root:21: Epoch 4 train loss: 3077.5076904296875\nINFO:root:15: Epoch 4 train loss: 5769.298568725586\nINFO:root:22: Epoch 4 train loss: 2186.0511932373047\nINFO:root:5: Epoch 4 train loss: 11380.74951171875\nINFO:root:10: Epoch 4 train loss: 10118.574462890625\nINFO:root:13: Epoch 4 train loss: 24855.5888671875\nINFO:root:8: Epoch 4 train loss: 41123.720703125\nINFO:root:7: Epoch 4 train loss: 766.2089233398438\nINFO:root:20: Epoch 4 train loss: 10632.720947265625\nINFO:root:14: Epoch 4 train loss: 3536.9573364257812\nINFO:root:23: Epoch 4 train loss: 13782.17822265625\nINFO:root:4: Epoch 4 train loss: 43555.8525390625\nINFO:root:11: Epoch 4 train loss: 964859.3359375\nINFO:root:12: Epoch 4 train loss: 3886.0160522460938\nINFO:root:9: Epoch 4 train loss: 8103.43212890625\nINFO:root:17: Epoch 4 train loss: 6367.15673828125\nINFO:root:6: Epoch 4 train loss: 2523.0538940429688\nINFO:root:16: Epoch 4 train loss: 13679.2138671875\nINFO:root:1: Epoch 4 train loss: 1155560.1477050781\nINFO:root:0: Epoch 4 train loss: 348.6494903564453\nINFO:root:0: Epoch 4 validation loss: 81524.23198721888\nINFO:root:3: Epoch 5 train loss: 1623400.28125\nINFO:root:2: Epoch 5 train loss: 7979.7010498046875\nINFO:root:5: Epoch 5 train loss: 1036824.62890625\nINFO:root:9: Epoch 5 train loss: 9336.362426757812\nINFO:root:8: Epoch 5 train loss: 929.5947570800781\nINFO:root:23: Epoch 5 train loss: 9733.36865234375\nINFO:root:22: Epoch 5 train loss: 961.3108940124512\nINFO:root:0: Epoch 5 train loss: 4907.156433105469\nINFO:root:1: Epoch 5 train loss: 15392.86328125\nINFO:root:7: Epoch 5 train loss: 8537.448608398438\nINFO:root:6: Epoch 5 train loss: 2724.2990112304688\nINFO:root:4: Epoch 5 train loss: 37736.812255859375\nINFO:root:11: Epoch 5 train loss: 531.8412322998047\nINFO:root:10: Epoch 5 train loss: 7688.2138671875\nINFO:root:12: Epoch 5 train loss: 7126.45947265625\nINFO:root:13: Epoch 5 train loss: 17058.9814453125\nINFO:root:14: Epoch 5 train loss: 9013.366943359375\nINFO:root:15: Epoch 5 train loss: 3619.5151977539062\nINFO:root:21: Epoch 5 train loss: 35823.7919921875\nINFO:root:17: Epoch 5 train loss: 2463.6813201904297\nINFO:root:20: Epoch 5 train loss: 4710.412292480469\nINFO:root:16: Epoch 5 train loss: 863291.6860351562\nINFO:root:18: Epoch 5 train loss: 1021377.1043395996\nINFO:root:19: Epoch 5 train loss: 38641.01171875\nINFO:root:0: Epoch 5 validation loss: 81516.16654514013\n", "seconds": 11.090451002120972, "batch_size": 64, "nodes": 12, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.15,192.168.2.15 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n1 Start Epoch 0\n1: 16 batches\n2 Start Epoch 0\n2: 16 batches\n0: 16 batches\n2 Start Epoch 1\n2: 16 batches\n1 Start Epoch 1\n1: 16 batches\n0 Start Epoch 1\n0: 16 batches\n1 Start Epoch 2\n2 Start Epoch 2\n2: 16 batches\n1: 16 batches\n0 Start Epoch 2\n0: 16 batches\n1 Start Epoch 3\n1: 16 batches\n2 Start Epoch 3\n2: 16 batches\n0 Start Epoch 3\n0: 16 batches\n2 Start Epoch 4\n1 Start Epoch 4\n2: 16 batches\n1: 16 batches\n0 Start Epoch 4\n0: 16 batches\n1 Start Epoch 5\n1: 16 batches\n2 Start Epoch 5\n2: 16 batches\n0 Start Epoch 5\n0: 16 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:2: Epoch 0 train loss: 382606.2200279236\nINFO:root:0: Epoch 0 train loss: 534110.701130867\nINFO:root:1: Epoch 0 train loss: 248773.98070335388\nINFO:root:0: Epoch 0 validation loss: 94717.08828110197\nINFO:root:2: Epoch 1 train loss: 399184.2787771225\nINFO:root:1: Epoch 1 train loss: 273561.83719062805\nINFO:root:0: Epoch 1 train loss: 426124.2943224907\nINFO:root:0: Epoch 1 validation loss: 94628.46177433566\nINFO:root:1: Epoch 2 train loss: 17552.106989383698\nINFO:root:0: Epoch 2 train loss: 11000.259773254395\nINFO:root:2: Epoch 2 train loss: 557938.5881772041\nINFO:root:0: Epoch 2 validation loss: 94445.0343142604\nINFO:root:0: Epoch 3 train loss: 392745.2954978943\nINFO:root:2: Epoch 3 train loss: 384663.6012649536\nINFO:root:1: Epoch 3 train loss: 261252.24659347534\nINFO:root:0: Epoch 3 validation loss: 94223.39577023531\nINFO:root:0: Epoch 4 train loss: 397896.7296142578\nINFO:root:2: Epoch 4 train loss: 495734.54913425446\nINFO:root:1: Epoch 4 train loss: 560799.7626342773\nINFO:root:0: Epoch 4 validation loss: 94011.24788225083\nINFO:root:2: Epoch 5 train loss: 149416.769408226\nINFO:root:0: Epoch 5 train loss: 429108.8091697693\nINFO:root:1: Epoch 5 train loss: 439957.5936203003\nINFO:root:0: Epoch 5 validation loss: 93823.14572428167\n", "seconds": 51.20421504974365, "batch_size": 64, "nodes": 1, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.15,192.168.2.2,192.168.2.15,192.168.2.2 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n1 Start Epoch 0\n2 Start Epoch 0\n1: 8 batches\n0: 8 batches\n2: 8 batches\n3 Start Epoch 0\n4 Start Epoch 0\n3: 8 batches\n5 Start Epoch 0\n4: 8 batches\n5: 8 batches\n2 Start Epoch 1\n1 Start Epoch 1\n2: 8 batches\n1: 8 batches\n4 Start Epoch 1\n3 Start Epoch 1\n4: 8 batches\n5 Start Epoch 1\n5: 8 batches\n3: 8 batches\n0 Start Epoch 1\n0: 8 batches\n5 Start Epoch 2\n5: 8 batches\n2 Start Epoch 2\n1 Start Epoch 2\n1: 8 batches\n2: 8 batches\n4 Start Epoch 2\n4: 8 batches\n3 Start Epoch 2\n3: 8 batches\n0 Start Epoch 2\n0: 8 batches\n2 Start Epoch 3\n2: 8 batches\n3 Start Epoch 3\n3: 8 batches\n1 Start Epoch 3\n1: 8 batches\n5 Start Epoch 3\n4 Start Epoch 3\n5: 8 batches\n4: 8 batches\n0 Start Epoch 3\n0: 8 batches\n2 Start Epoch 4\n2: 8 batches\n1 Start Epoch 4\n1: 8 batches\n5 Start Epoch 4\n3 Start Epoch 4\n5: 8 batches\n4 Start Epoch 4\n4: 8 batches\n3: 8 batches\n0 Start Epoch 4\n0: 8 batches\n1 Start Epoch 5\n4 Start Epoch 5\n5 Start Epoch 5\n3 Start Epoch 5\n3: 8 batches\n4: 8 batches\n5: 8 batches\n1: 8 batches\n2 Start Epoch 5\n2: 8 batches\n0 Start Epoch 5\n0: 8 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 9122.053569793701\nINFO:root:1: Epoch 0 train loss: 699364.7156982422\nINFO:root:2: Epoch 0 train loss: 10033.818870544434\nINFO:root:4: Epoch 0 train loss: 214858.8395690918\nINFO:root:5: Epoch 0 train loss: 597433.2477016449\nINFO:root:3: Epoch 0 train loss: 209572.9386138916\nINFO:root:0: Epoch 0 validation loss: 11198.18370703499\nINFO:root:0: Epoch 1 train loss: 121176.63290786743\nINFO:root:5: Epoch 1 train loss: 510739.99475479126\nINFO:root:2: Epoch 1 train loss: 25404.305183410645\nINFO:root:1: Epoch 1 train loss: 279269.1502380371\nINFO:root:4: Epoch 1 train loss: 236419.28954315186\nINFO:root:3: Epoch 1 train loss: 574541.0262794495\nINFO:root:0: Epoch 1 validation loss: 11180.283594864646\nINFO:root:2: Epoch 2 train loss: 400088.2944641113\nINFO:root:3: Epoch 2 train loss: 24231.884828567505\nINFO:root:1: Epoch 2 train loss: 12847.58988571167\nINFO:root:5: Epoch 2 train loss: 15007.99771118164\nINFO:root:4: Epoch 2 train loss: 263761.5831756592\nINFO:root:0: Epoch 2 train loss: 795870.922996521\nINFO:root:0: Epoch 2 validation loss: 11157.686379908231\nINFO:root:1: Epoch 3 train loss: 469360.74880981445\nINFO:root:2: Epoch 3 train loss: 4364.522762298584\nINFO:root:5: Epoch 3 train loss: 627755.3987636566\nINFO:root:4: Epoch 3 train loss: 305078.21479797363\nINFO:root:3: Epoch 3 train loss: 496607.3139343262\nINFO:root:0: Epoch 3 train loss: 285249.2915058136\nINFO:root:0: Epoch 3 validation loss: 11129.275223303972\nINFO:root:0: Epoch 4 train loss: 10979.489501953125\nINFO:root:1: Epoch 4 train loss: 279625.0274953842\nINFO:root:2: Epoch 4 train loss: 694528.6836051941\nINFO:root:5: Epoch 4 train loss: 493045.9839630127\nINFO:root:3: Epoch 4 train loss: 9449.090240478516\nINFO:root:4: Epoch 4 train loss: 22784.808155059814\nINFO:root:0: Epoch 4 validation loss: 11093.228030642558\nINFO:root:2: Epoch 5 train loss: 225578.68922042847\nINFO:root:3: Epoch 5 train loss: 874213.0303955078\nINFO:root:1: Epoch 5 train loss: 229996.9091796875\nINFO:root:0: Epoch 5 train loss: 638473.1165924072\nINFO:root:5: Epoch 5 train loss: 122018.22109985352\nINFO:root:4: Epoch 5 train loss: 222653.64739227295\nINFO:root:0: Epoch 5 validation loss: 11046.33730278344\n", "seconds": 31.346100091934204, "batch_size": 64, "nodes": 2, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.15,192.168.2.2,192.168.2.3 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 6 batches\n2 Start Epoch 0\n1 Start Epoch 0\n1: 6 batches\n2: 6 batches\n6 Start Epoch 0\n7 Start Epoch 0\n8 Start Epoch 0\n8: 6 batches\n6: 6 batches\n7: 6 batches\n5 Start Epoch 0\n5: 6 batches\n3 Start Epoch 0\n3: 6 batches\n4 Start Epoch 0\n4: 6 batches\n5 Start Epoch 1\n5: 6 batches\n2 Start Epoch 1\n2: 6 batches\n6 Start Epoch 1\n8 Start Epoch 1\n8: 6 batches\n6: 6 batches\n7 Start Epoch 1\n7: 6 batches\n4 Start Epoch 1\n4: 6 batches\n3 Start Epoch 1\n3: 6 batches\n1 Start Epoch 1\n1: 6 batches\n0 Start Epoch 1\n0: 6 batches\n3 Start Epoch 2\n3: 6 batches\n1 Start Epoch 2\n2 Start Epoch 2\n1: 6 batches\n2: 6 batches\n8 Start Epoch 2\n7 Start Epoch 2\n8: 6 batches\n7: 6 batches\n6 Start Epoch 2\n6: 6 batches\n5 Start Epoch 2\n5: 6 batches\n4 Start Epoch 2\n4: 6 batches\n0 Start Epoch 2\n0: 6 batches\n4 Start Epoch 3\n3 Start Epoch 3\n6 Start Epoch 3\n3: 6 batches\n8 Start Epoch 3\n8: 6 batches\n4: 6 batches\n6: 6 batches\n7 Start Epoch 3\n2 Start Epoch 3\n2: 6 batches\n7: 6 batches\n1 Start Epoch 3\n5 Start Epoch 3\n5: 6 batches\n1: 6 batches\n0 Start Epoch 3\n0: 6 batches\n2 Start Epoch 4\n2: 6 batches\n6 Start Epoch 4\n3 Start Epoch 4\n3: 6 batches\n6: 6 batches\n5 Start Epoch 4\n5: 6 batches\n4 Start Epoch 4\n4: 6 batches\n7 Start Epoch 4\n7: 6 batches\n8 Start Epoch 4\n1 Start Epoch 4\n1: 6 batches\n8: 6 batches\n0 Start Epoch 4\n0: 6 batches\n3 Start Epoch 5\n3: 6 batches\n4 Start Epoch 5\n6 Start Epoch 5\n5 Start Epoch 5\n7 Start Epoch 5\n7: 6 batches\n5: 6 batches\n8 Start Epoch 5\n4: 6 batches\n6: 6 batches\n8: 6 batches\n2 Start Epoch 5\n2: 6 batches\n1 Start Epoch 5\n1: 6 batches\n0 Start Epoch 5\n0: 6 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 605434.84786733\nINFO:root:2: Epoch 0 train loss: 703654.3700383505\nINFO:root:5: Epoch 0 train loss: 340060.0759302775\nINFO:root:7: Epoch 0 train loss: 538209.4573567709\nINFO:root:8: Epoch 0 train loss: 339685.78851858777\nINFO:root:6: Epoch 0 train loss: 356451.47505315143\nINFO:root:4: Epoch 0 train loss: 335681.90109761554\nINFO:root:3: Epoch 0 train loss: 10024.918332417807\nINFO:root:1: Epoch 0 train loss: 7783.784800211589\nINFO:root:0: Epoch 0 validation loss: 20191.06379988662\nINFO:root:3: Epoch 1 train loss: 336403.1440022786\nINFO:root:2: Epoch 1 train loss: 355212.7916361491\nINFO:root:0: Epoch 1 train loss: 1052433.6068929036\nINFO:root:1: Epoch 1 train loss: 634284.0748170217\nINFO:root:7: Epoch 1 train loss: 686650.6201171875\nINFO:root:8: Epoch 1 train loss: 2800.4967654546103\nINFO:root:6: Epoch 1 train loss: 636290.4079589844\nINFO:root:5: Epoch 1 train loss: 10113.92747004827\nINFO:root:4: Epoch 1 train loss: 406713.85467974347\nINFO:root:0: Epoch 1 validation loss: 20179.11122826137\nINFO:root:0: Epoch 2 train loss: 7659.171396891276\nINFO:root:3: Epoch 2 train loss: 24425.04173533122\nINFO:root:8: Epoch 2 train loss: 746349.0295817057\nINFO:root:4: Epoch 2 train loss: 117954.71561686198\nINFO:root:7: Epoch 2 train loss: 54308.97048950195\nINFO:root:6: Epoch 2 train loss: 643355.1464131674\nINFO:root:2: Epoch 2 train loss: 861166.510559082\nINFO:root:1: Epoch 2 train loss: 7948.127777099609\nINFO:root:5: Epoch 2 train loss: 369384.75147247314\nINFO:root:0: Epoch 2 validation loss: 20165.046196222625\nINFO:root:2: Epoch 3 train loss: 754581.5211385092\nINFO:root:3: Epoch 3 train loss: 16549.966267903645\nINFO:root:6: Epoch 3 train loss: 11977.346272786459\nINFO:root:5: Epoch 3 train loss: 704793.5648280779\nINFO:root:4: Epoch 3 train loss: 133733.43241373697\nINFO:root:7: Epoch 3 train loss: 679776.316655159\nINFO:root:8: Epoch 3 train loss: 328726.7252248128\nINFO:root:0: Epoch 3 train loss: 600552.5926920573\nINFO:root:1: Epoch 3 train loss: 9529.288449605307\nINFO:root:0: Epoch 3 validation loss: 20148.234088776953\nINFO:root:6: Epoch 4 train loss: 456166.4508775075\nINFO:root:8: Epoch 4 train loss: 574226.7406005859\nINFO:root:4: Epoch 4 train loss: 12528.678548177084\nINFO:root:3: Epoch 4 train loss: 1078376.6366907756\nINFO:root:7: Epoch 4 train loss: 14266.504777908325\nINFO:root:5: Epoch 4 train loss: 127683.07735188802\nINFO:root:2: Epoch 4 train loss: 857494.2689259847\nINFO:root:0: Epoch 4 train loss: 371437.5667622884\nINFO:root:1: Epoch 4 train loss: 600456.0584716797\nINFO:root:0: Epoch 4 validation loss: 20124.293985502474\nINFO:root:1: Epoch 5 train loss: 25503.572947184246\nINFO:root:0: Epoch 5 train loss: 687391.982553482\nINFO:root:6: Epoch 5 train loss: 617514.6742587885\nINFO:root:8: Epoch 5 train loss: 8544.13454691569\nINFO:root:2: Epoch 5 train loss: 448193.0319042206\nINFO:root:7: Epoch 5 train loss: 1059667.4115142822\nINFO:root:5: Epoch 5 train loss: 363711.16146564484\nINFO:root:3: Epoch 5 train loss: 679718.1587979794\nINFO:root:4: Epoch 5 train loss: 369986.7437133789\nINFO:root:0: Epoch 5 validation loss: 20092.484375673615\n", "seconds": 22.343414068222046, "batch_size": 64, "nodes": 3, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 4 batches\n2 Start Epoch 0\n1 Start Epoch 0\n1: 4 batches\n2: 4 batches\n11 Start Epoch 0\n11: 4 batches\n7 Start Epoch 0\n8 Start Epoch 0\n3 Start Epoch 0\n4 Start Epoch 0\n8: 4 batches\n3: 4 batches\n4: 4 batches\n7: 4 batches\n5 Start Epoch 0\n5: 4 batches\n9 Start Epoch 0\n10 Start Epoch 0\n10: 4 batches\n9: 4 batches\n6 Start Epoch 0\n6: 4 batches\n8 Start Epoch 1\n8: 4 batches\n2 Start Epoch 1\n2: 4 batches\n9 Start Epoch 1\n9: 4 batches\n11 Start Epoch 1\n11: 4 batches\n10 Start Epoch 1\n10: 4 batches\n1 Start Epoch 1\n1: 4 batches\n7 Start Epoch 1\n7: 4 batches\n6 Start Epoch 1\n6: 4 batches\n3 Start Epoch 1\n3: 4 batches\n5 Start Epoch 1\n5: 4 batches\n4 Start Epoch 1\n4: 4 batches\n0 Start Epoch 1\n0: 4 batches\n10 Start Epoch 2\n11 Start Epoch 2\n11: 4 batches\n10: 4 batches\n2 Start Epoch 2\n2: 4 batches\n1 Start Epoch 2\n1: 4 batches\n9 Start Epoch 2\n4 Start Epoch 2\n8 Start Epoch 2\n9: 4 batches\n5 Start Epoch 2\n7 Start Epoch 2\n5: 4 batches\n7: 4 batches\n4: 4 batches\n8: 4 batches\n6 Start Epoch 2\n6: 4 batches\n3 Start Epoch 2\n3: 4 batches\n0 Start Epoch 2\n0: 4 batches\n11 Start Epoch 3\n11: 4 batches\n1 Start Epoch 3\n1: 4 batches\n10 Start Epoch 3\n9 Start Epoch 3\n5 Start Epoch 3\n6 Start Epoch 3\n9: 4 batches\n3 Start Epoch 3\n7 Start Epoch 3\n5: 4 batches\n10: 4 batches\n4 Start Epoch 3\n2 Start Epoch 3\n2: 4 batches\n4: 4 batches\n3: 4 batches\n7: 4 batches\n6: 4 batches\n8 Start Epoch 3\n8: 4 batches\n0 Start Epoch 3\n0: 4 batches\n9 Start Epoch 4\n11 Start Epoch 4\n10 Start Epoch 4\n9: 4 batches\n10: 4 batches\n11: 4 batches\n8 Start Epoch 4\n8: 4 batches\n3 Start Epoch 4\n5 Start Epoch 4\n4 Start Epoch 4\n4: 4 batches\n3: 4 batches\n5: 4 batches\n2 Start Epoch 4\n7 Start Epoch 4\n7: 4 batches\n6 Start Epoch 4\n6: 4 batches\n2: 4 batches\n1 Start Epoch 4\n1: 4 batches\n0 Start Epoch 4\n0: 4 batches\n2 Start Epoch 5\n1 Start Epoch 5\n2: 4 batches\n1: 4 batches\n5 Start Epoch 5\n4 Start Epoch 5\n4: 4 batches\n5: 4 batches\n3 Start Epoch 5\n3: 4 batches\n11 Start Epoch 5\n11: 4 batches\n10 Start Epoch 5\n10: 4 batches\n6 Start Epoch 5\n6: 4 batches\n7 Start Epoch 5\n8 Start Epoch 5\n7: 4 batches\n8: 4 batches\n9 Start Epoch 5\n9: 4 batches\n0 Start Epoch 5\n0: 4 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:8: Epoch 0 train loss: 189235.85327148438\nINFO:root:2: Epoch 0 train loss: 4917.921646118164\nINFO:root:0: Epoch 0 train loss: 24500.75244140625\nINFO:root:9: Epoch 0 train loss: 1468.6447143554688\nINFO:root:11: Epoch 0 train loss: 6855.588066101074\nINFO:root:10: Epoch 0 train loss: 570326.5545654297\nINFO:root:1: Epoch 0 train loss: 19097.700317382812\nINFO:root:7: Epoch 0 train loss: 487682.63720703125\nINFO:root:6: Epoch 0 train loss: 60096.22100830078\nINFO:root:4: Epoch 0 train loss: 11673.662109375\nINFO:root:5: Epoch 0 train loss: 606310.2972412109\nINFO:root:3: Epoch 0 train loss: 20829.421875\nINFO:root:0: Epoch 0 validation loss: 778347.3017691546\nINFO:root:11: Epoch 1 train loss: 523763.3728027344\nINFO:root:10: Epoch 1 train loss: 588753.5501708984\nINFO:root:0: Epoch 1 train loss: 586468.9477767944\nINFO:root:1: Epoch 1 train loss: 200954.4012451172\nINFO:root:2: Epoch 1 train loss: 680170.3092956543\nINFO:root:9: Epoch 1 train loss: 559585.353515625\nINFO:root:5: Epoch 1 train loss: 548147.1513061523\nINFO:root:8: Epoch 1 train loss: 617909.4660644531\nINFO:root:4: Epoch 1 train loss: 12156.58455657959\nINFO:root:7: Epoch 1 train loss: 419674.310546875\nINFO:root:6: Epoch 1 train loss: 4599.187423706055\nINFO:root:3: Epoch 1 train loss: 688800.3243103027\nINFO:root:0: Epoch 1 validation loss: 778302.3185395036\nINFO:root:11: Epoch 2 train loss: 27093.95703125\nINFO:root:1: Epoch 2 train loss: 551685.4619445801\nINFO:root:4: Epoch 2 train loss: 7715.606918334961\nINFO:root:8: Epoch 2 train loss: 3676.0718994140625\nINFO:root:9: Epoch 2 train loss: 9778.254047393799\nINFO:root:7: Epoch 2 train loss: 552723.5380249023\nINFO:root:10: Epoch 2 train loss: 6987.425071716309\nINFO:root:3: Epoch 2 train loss: 493862.8876953125\nINFO:root:6: Epoch 2 train loss: 11073.091552734375\nINFO:root:5: Epoch 2 train loss: 71318.71459960938\nINFO:root:2: Epoch 2 train loss: 1526227.493713379\nINFO:root:0: Epoch 2 train loss: 1222758.8010406494\nINFO:root:0: Epoch 2 validation loss: 778253.2339005447\nINFO:root:11: Epoch 3 train loss: 6249.365631103516\nINFO:root:10: Epoch 3 train loss: 695228.9938964844\nINFO:root:9: Epoch 3 train loss: 519010.5759334564\nINFO:root:8: Epoch 3 train loss: 8508.653289794922\nINFO:root:0: Epoch 3 train loss: 523963.37884140015\nINFO:root:5: Epoch 3 train loss: 173048.10690307617\nINFO:root:4: Epoch 3 train loss: 1506218.8420410156\nINFO:root:3: Epoch 3 train loss: 174880.3219909668\nINFO:root:7: Epoch 3 train loss: 503232.0261001587\nINFO:root:2: Epoch 3 train loss: 3151.4197883605957\nINFO:root:6: Epoch 3 train loss: 10224.59130859375\nINFO:root:1: Epoch 3 train loss: 4540.922569274902\nINFO:root:0: Epoch 3 validation loss: 778197.846180965\nINFO:root:2: Epoch 4 train loss: 11291.071655273438\nINFO:root:0: Epoch 4 train loss: 63953.64434814453\nINFO:root:1: Epoch 4 train loss: 10752.591247558594\nINFO:root:3: Epoch 4 train loss: 10072.276489257812\nINFO:root:5: Epoch 4 train loss: 13597.733581542969\nINFO:root:4: Epoch 4 train loss: 8314.11849975586\nINFO:root:11: Epoch 4 train loss: 829632.7040405273\nINFO:root:10: Epoch 4 train loss: 1081840.6015625\nINFO:root:6: Epoch 4 train loss: 7663.7738037109375\nINFO:root:8: Epoch 4 train loss: 21270.587646484375\nINFO:root:7: Epoch 4 train loss: 11594.836456298828\nINFO:root:9: Epoch 4 train loss: 3476.399612426758\nINFO:root:0: Epoch 4 validation loss: 778129.0058572796\nINFO:root:9: Epoch 5 train loss: 7184.3487548828125\nINFO:root:10: Epoch 5 train loss: 10439.547241210938\nINFO:root:11: Epoch 5 train loss: 1546248.6955718994\nINFO:root:8: Epoch 5 train loss: 482527.38789367676\nINFO:root:7: Epoch 5 train loss: 447690.7283935547\nINFO:root:0: Epoch 5 train loss: 18431.229370117188\nINFO:root:1: Epoch 5 train loss: 561280.4555664062\nINFO:root:2: Epoch 5 train loss: 1531888.4256896973\nINFO:root:3: Epoch 5 train loss: 1117860.316040039\nINFO:root:4: Epoch 5 train loss: 35760.016357421875\nINFO:root:6: Epoch 5 train loss: 31351.3564453125\nINFO:root:5: Epoch 5 train loss: 80646.07702636719\nINFO:root:0: Epoch 5 validation loss: 778041.9667053212\n", "seconds": 18.311362981796265, "batch_size": 64, "nodes": 4, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "2 Start Epoch 0\n0 Start Epoch 0\n1 Start Epoch 0\n1: 4 batches\n0: 4 batches\n2: 4 batches\n3 Start Epoch 0\n4 Start Epoch 0\n4: 4 batches\n3: 4 batches\n13 Start Epoch 0\n14 Start Epoch 0\n14: 4 batches\n13: 4 batches\n6 Start Epoch 0\n11 Start Epoch 0\n7 Start Epoch 0\n9 Start Epoch 0\n10 Start Epoch 0\n11: 4 batches\n8 Start Epoch 0\n10: 4 batches\n6: 4 batches\n9: 4 batches\n7: 4 batches\n5 Start Epoch 0\n5: 4 batches\n12 Start Epoch 0\n12: 4 batches\n8: 4 batches\n2 Start Epoch 1\n2: 4 batches\n1 Start Epoch 1\n1: 4 batches\n5 Start Epoch 1\n5: 4 batches\n13 Start Epoch 1\n13: 4 batches\n7 Start Epoch 1\n10 Start Epoch 1\n9 Start Epoch 1\n6 Start Epoch 1\n6: 4 batches\n11 Start Epoch 1\n8 Start Epoch 1\n11: 4 batches\n10: 4 batches\n9: 4 batches\n3 Start Epoch 1\n14 Start Epoch 1\n3: 4 batches\n14: 4 batches\n12 Start Epoch 1\n12: 4 batches\n8: 4 batches\n7: 4 batches\n4 Start Epoch 1\n4: 4 batches\n0 Start Epoch 1\n0: 4 batches\n14 Start Epoch 2\n14: 4 batches\n11 Start Epoch 2\n6 Start Epoch 2\n5 Start Epoch 2\n7 Start Epoch 2\n1 Start Epoch 2\n1: 4 batches\n2 Start Epoch 2\n2: 4 batches\n11: 4 batches\n5: 4 batches\n10 Start Epoch 2\n10: 4 batches\n3 Start Epoch 2\n3: 4 batches\n4 Start Epoch 2\n4: 4 batches\n9 Start Epoch 2\n9: 4 batches\n13 Start Epoch 2\n12 Start Epoch 2\n12: 4 batches\n13: 4 batches\n8 Start Epoch 2\n8: 4 batches\n7: 4 batches\n6: 4 batches\n0 Start Epoch 2\n0: 4 batches\n2 Start Epoch 3\n2: 4 batches\n11 Start Epoch 3\n8 Start Epoch 3\n11: 4 batches\n8: 4 batches\n5 Start Epoch 3\n4 Start Epoch 3\n5: 4 batches\n3 Start Epoch 3\n3: 4 batches\n4: 4 batches\n1 Start Epoch 3\n1: 4 batches\n6 Start Epoch 3\n10 Start Epoch 3\n9 Start Epoch 3\n7 Start Epoch 3\n6: 4 batches\n10: 4 batches\n9: 4 batches\n7: 4 batches\n14 Start Epoch 3\n14: 4 batches\n13 Start Epoch 3\n12 Start Epoch 3\n13: 4 batches\n12: 4 batches\n0 Start Epoch 3\n0: 4 batches\n1 Start Epoch 4\n2 Start Epoch 4\n2: 4 batches\n1: 4 batches\n5 Start Epoch 4\n4 Start Epoch 4\n5: 4 batches\n4: 4 batches\n3 Start Epoch 4\n3: 4 batches\n6 Start Epoch 4\n13 Start Epoch 4\n11 Start Epoch 4\n11: 4 batches\n8 Start Epoch 4\n7 Start Epoch 4\n6: 4 batches\n8: 4 batches\n13: 4 batches\n9 Start Epoch 4\n14 Start Epoch 4\n14: 4 batches\n9: 4 batches\n12 Start Epoch 4\n7: 4 batches\n12: 4 batches\n10 Start Epoch 4\n10: 4 batches\n0 Start Epoch 4\n0: 4 batches\n1 Start Epoch 5\n2 Start Epoch 5\n5 Start Epoch 5\n5: 4 batches\n7 Start Epoch 5\n8 Start Epoch 5\n1: 4 batches\n2: 4 batches\n8: 4 batches\n7: 4 batches\n13 Start Epoch 5\n10 Start Epoch 5\n14 Start Epoch 5\n11 Start Epoch 5\n14: 4 batches\n10: 4 batches\n12 Start Epoch 5\n11: 4 batches\n9 Start Epoch 5\n12: 4 batches\n13: 4 batches\n9: 4 batches\n3 Start Epoch 5\n6 Start Epoch 5\n3: 4 batches\n6: 4 batches\n4 Start Epoch 5\n4: 4 batches\n0 Start Epoch 5\n0: 4 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:2: Epoch 0 train loss: 525112.2316112518\nINFO:root:1: Epoch 0 train loss: 3442.582893371582\nINFO:root:0: Epoch 0 train loss: 603393.5908880234\nINFO:root:5: Epoch 0 train loss: 482971.9488372803\nINFO:root:10: Epoch 0 train loss: 59233.79653930664\nINFO:root:6: Epoch 0 train loss: 10949.325358867645\nINFO:root:13: Epoch 0 train loss: 11044.266767501831\nINFO:root:9: Epoch 0 train loss: 433372.9478149414\nINFO:root:8: Epoch 0 train loss: 35052.096923828125\nINFO:root:7: Epoch 0 train loss: 408884.71797958016\nINFO:root:11: Epoch 0 train loss: 1615512.2881240845\nINFO:root:3: Epoch 0 train loss: 64674.676836416125\nINFO:root:14: Epoch 0 train loss: 9554.361115932465\nINFO:root:12: Epoch 0 train loss: 8262.93322616788\nINFO:root:4: Epoch 0 train loss: 4281.255744934082\nINFO:root:0: Epoch 0 validation loss: 1616880.3401598344\nINFO:root:0: Epoch 1 train loss: 10104.582370698452\nINFO:root:2: Epoch 1 train loss: 24230.143293380737\nINFO:root:14: Epoch 1 train loss: 431042.22780799866\nINFO:root:11: Epoch 1 train loss: 6340.165819168091\nINFO:root:10: Epoch 1 train loss: 5733.150621532288\nINFO:root:5: Epoch 1 train loss: 7008.835876464844\nINFO:root:3: Epoch 1 train loss: 2652.653949737549\nINFO:root:7: Epoch 1 train loss: 1125191.316619873\nINFO:root:6: Epoch 1 train loss: 546059.166349411\nINFO:root:8: Epoch 1 train loss: 60800.82721710205\nINFO:root:1: Epoch 1 train loss: 520213.55763213336\nINFO:root:4: Epoch 1 train loss: 516936.82773399353\nINFO:root:9: Epoch 1 train loss: 432731.79066467285\nINFO:root:12: Epoch 1 train loss: 5566816.6900177\nINFO:root:13: Epoch 1 train loss: 965850.5037841797\nINFO:root:0: Epoch 1 validation loss: 1616831.995565466\nINFO:root:2: Epoch 2 train loss: 5407.812418460846\nINFO:root:11: Epoch 2 train loss: 1314.8993363380432\nINFO:root:8: Epoch 2 train loss: 184420.8006273508\nINFO:root:3: Epoch 2 train loss: 70745.32952904701\nINFO:root:4: Epoch 2 train loss: 10415.588161468506\nINFO:root:5: Epoch 2 train loss: 603809.0552251022\nINFO:root:1: Epoch 2 train loss: 22265.84942626953\nINFO:root:6: Epoch 2 train loss: 519606.8271179199\nINFO:root:9: Epoch 2 train loss: 21651.371696472168\nINFO:root:10: Epoch 2 train loss: 5573.394886275462\nINFO:root:7: Epoch 2 train loss: 8541.05052947998\nINFO:root:14: Epoch 2 train loss: 2087.758756160736\nINFO:root:13: Epoch 2 train loss: 534170.9345779419\nINFO:root:12: Epoch 2 train loss: 177339.6017112271\nINFO:root:0: Epoch 2 train loss: 15520.000373840332\nINFO:root:0: Epoch 2 validation loss: 1616783.8030445545\nINFO:root:2: Epoch 3 train loss: 1023712.5668029785\nINFO:root:1: Epoch 3 train loss: 13780.304043048061\nINFO:root:5: Epoch 3 train loss: 547516.8908692598\nINFO:root:4: Epoch 3 train loss: 9128.169974803925\nINFO:root:3: Epoch 3 train loss: 517354.2925224304\nINFO:root:13: Epoch 3 train loss: 7331.918151855469\nINFO:root:11: Epoch 3 train loss: 408422.71688183397\nINFO:root:7: Epoch 3 train loss: 2199.65389251709\nINFO:root:8: Epoch 3 train loss: 7941.407383918762\nINFO:root:6: Epoch 3 train loss: 4026.8040199279785\nINFO:root:14: Epoch 3 train loss: 10406.660186767578\nINFO:root:9: Epoch 3 train loss: 13087.573458780767\nINFO:root:12: Epoch 3 train loss: 706.714394569397\nINFO:root:10: Epoch 3 train loss: 3138.882956147194\nINFO:root:0: Epoch 3 train loss: 14941.282580375671\nINFO:root:0: Epoch 3 validation loss: 1616731.3469377377\nINFO:root:1: Epoch 4 train loss: 2436.3091163635254\nINFO:root:2: Epoch 4 train loss: 521130.83726501465\nINFO:root:5: Epoch 4 train loss: 24838.827117919922\nINFO:root:7: Epoch 4 train loss: 173885.8969540596\nINFO:root:8: Epoch 4 train loss: 2125.8477783203125\nINFO:root:12: Epoch 4 train loss: 1126678.3108215332\nINFO:root:9: Epoch 4 train loss: 11460.21096611023\nINFO:root:13: Epoch 4 train loss: 6611.3079833984375\nINFO:root:11: Epoch 4 train loss: 486408.74284362793\nINFO:root:10: Epoch 4 train loss: 546887.7161015272\nINFO:root:14: Epoch 4 train loss: 434729.90188861813\nINFO:root:3: Epoch 4 train loss: 2235.857283592224\nINFO:root:6: Epoch 4 train loss: 933514.2520982623\nINFO:root:4: Epoch 4 train loss: 171936.25806617737\nINFO:root:0: Epoch 4 train loss: 4529.047100871801\nINFO:root:0: Epoch 4 validation loss: 1616668.802604961\nINFO:root:12: Epoch 5 train loss: 7830.333221435547\nINFO:root:13: Epoch 5 train loss: 483314.40646362305\nINFO:root:14: Epoch 5 train loss: 172159.7232720852\nINFO:root:0: Epoch 5 train loss: 4373.141624450684\nINFO:root:10: Epoch 5 train loss: 11073.655578613281\nINFO:root:11: Epoch 5 train loss: 517924.65361106396\nINFO:root:1: Epoch 5 train loss: 492636.52490234375\nINFO:root:2: Epoch 5 train loss: 6255.61164855957\nINFO:root:3: Epoch 5 train loss: 524604.0325763226\nINFO:root:6: Epoch 5 train loss: 600104.4909175665\nINFO:root:4: Epoch 5 train loss: 525065.9781845212\nINFO:root:5: Epoch 5 train loss: 652805.0046463013\nINFO:root:7: Epoch 5 train loss: 25970.120478630066\nINFO:root:9: Epoch 5 train loss: 572033.6492004395\nINFO:root:8: Epoch 5 train loss: 5002.068572998047\nINFO:root:0: Epoch 5 validation loss: 1616592.249456531\n", "seconds": 15.283710956573486, "batch_size": 64, "nodes": 5, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 3 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 3 batches\n2: 3 batches\n8 Start Epoch 0\n15 Start Epoch 0\n4 Start Epoch 0\n7 Start Epoch 0\n3 Start Epoch 0\n8: 3 batches\n16 Start Epoch 0\n7: 3 batches\n15: 3 batches\n4: 3 batches\n16: 3 batches\n3: 3 batches\n17 Start Epoch 0\n17: 3 batches\n6 Start Epoch 0\n6: 3 batches\n9 Start Epoch 0\n10 Start Epoch 0\n10: 3 batches\n9: 3 batches\n11 Start Epoch 0\n11: 3 batches\n5 Start Epoch 0\n5: 3 batches\n12 Start Epoch 0\n12: 3 batches\n13 Start Epoch 0\n14 Start Epoch 0\n13: 3 batches\n14: 3 batches\n2 Start Epoch 1\n12 Start Epoch 1\n17 Start Epoch 1\n17: 3 batches\n12: 3 batches\n2: 3 batches\n5 Start Epoch 1\n5: 3 batches\n4 Start Epoch 1\n4: 3 batches\n10 Start Epoch 1\n10: 3 batches\n11 Start Epoch 1\n11: 3 batches\n9 Start Epoch 1\n9: 3 batches\n1 Start Epoch 1\n1: 3 batches\n14 Start Epoch 1\n14: 3 batches\n13 Start Epoch 1\n13: 3 batches\n7 Start Epoch 1\n7: 3 batches\n8 Start Epoch 1\n8: 3 batches\n6 Start Epoch 1\n6: 3 batches\n15 Start Epoch 1\n16 Start Epoch 1\n16: 3 batches\n15: 3 batches\n3 Start Epoch 1\n3: 3 batches\n0 Start Epoch 1\n0: 3 batches\n1 Start Epoch 2\n2 Start Epoch 2\n1: 3 batches\n2: 3 batches\n3 Start Epoch 2\n3: 3 batches\n14 Start Epoch 2\n13 Start Epoch 2\n13: 3 batches\n17 Start Epoch 2\n14: 3 batches\n15 Start Epoch 2\n17: 3 batches\n16 Start Epoch 2\n16: 3 batches\n15: 3 batches\n12 Start Epoch 2\n7 Start Epoch 2\n9 Start Epoch 2\n8 Start Epoch 2\n10 Start Epoch 2\n6 Start Epoch 2\n9: 3 batches\n11 Start Epoch 2\n7: 3 batches\n8: 3 batches\n6: 3 batches\n11: 3 batches\n10: 3 batches\n12: 3 batches\n5 Start Epoch 2\n5: 3 batches\n4 Start Epoch 2\n4: 3 batches\n0 Start Epoch 2\n0: 3 batches\n17 Start Epoch 3\n17: 3 batches\n1 Start Epoch 3\n1: 3 batches\n2 Start Epoch 3\n2: 3 batches\n5 Start Epoch 3\n4 Start Epoch 3\n15 Start Epoch 3\n15: 3 batches\n16 Start Epoch 3\n16: 3 batches\n6 Start Epoch 3\n6: 3 batches\n14 Start Epoch 3\n13 Start Epoch 3\n13: 3 batches\n14: 3 batches\n7 Start Epoch 3\n8 Start Epoch 3\n4: 3 batches\n7: 3 batches\n5: 3 batches\n8: 3 batches\n3 Start Epoch 3\n3: 3 batches\n9 Start Epoch 3\n10 Start Epoch 3\n10: 3 batches\n11 Start Epoch 3\n12 Start Epoch 3\n12: 3 batches\n11: 3 batches\n9: 3 batches\n0 Start Epoch 3\n0: 3 batches\n2 Start Epoch 4\n2: 3 batches\n5 Start Epoch 4\n9 Start Epoch 4\n3 Start Epoch 4\n10 Start Epoch 4\n5: 3 batches\n15 Start Epoch 4\n17 Start Epoch 4\n4 Start Epoch 4\n15: 3 batches\n17: 3 batches\n3: 3 batches\n4: 3 batches\n16 Start Epoch 4\n16: 3 batches\n14 Start Epoch 4\n14: 3 batches\n9: 3 batches\n10: 3 batches\n11 Start Epoch 4\n11: 3 batches\n1 Start Epoch 4\n1: 3 batches\n12 Start Epoch 4\n12: 3 batches\n13 Start Epoch 4\n13: 3 batches\n8 Start Epoch 4\n8: 3 batches\n6 Start Epoch 4\n6: 3 batches\n7 Start Epoch 4\n7: 3 batches\n0 Start Epoch 4\n0: 3 batches\n2 Start Epoch 5\n1 Start Epoch 5\n1: 3 batches\n2: 3 batches\n3 Start Epoch 5\n3: 3 batches\n4 Start Epoch 5\n5 Start Epoch 5\n4: 3 batches\n5: 3 batches\n8 Start Epoch 5\n6 Start Epoch 5\n10 Start Epoch 5\n6: 3 batches\n7 Start Epoch 5\n9 Start Epoch 5\n9: 3 batches\n11 Start Epoch 5\n11: 3 batches\n12 Start Epoch 5\n12: 3 batches\n10: 3 batches\n7: 3 batches\n8: 3 batches\n17 Start Epoch 5\n16 Start Epoch 5\n17: 3 batches\n16: 3 batches\n15 Start Epoch 5\n15: 3 batches\n13 Start Epoch 5\n13: 3 batches\n14 Start Epoch 5\n14: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:2: Epoch 0 train loss: 55909.158528645836\nINFO:root:12: Epoch 0 train loss: 1364.7593078613281\nINFO:root:17: Epoch 0 train loss: 16498.104654947918\nINFO:root:10: Epoch 0 train loss: 1307.5933837890625\nINFO:root:5: Epoch 0 train loss: 9136.700236002604\nINFO:root:11: Epoch 0 train loss: 31022.261474609375\nINFO:root:4: Epoch 0 train loss: 4727.5616455078125\nINFO:root:9: Epoch 0 train loss: 9195.680745442709\nINFO:root:1: Epoch 0 train loss: 83967.37314860027\nINFO:root:14: Epoch 0 train loss: 14664.906575520834\nINFO:root:13: Epoch 0 train loss: 819148.1689453125\nINFO:root:0: Epoch 0 train loss: 7116.053548177083\nINFO:root:6: Epoch 0 train loss: 677605.4879557291\nINFO:root:7: Epoch 0 train loss: 4956.305816650391\nINFO:root:8: Epoch 0 train loss: 7878.147298177083\nINFO:root:15: Epoch 0 train loss: 1336325.7696940105\nINFO:root:16: Epoch 0 train loss: 812317.064046224\nINFO:root:3: Epoch 0 train loss: 697476.9690755209\nINFO:root:0: Epoch 0 validation loss: 44039.487657714766\nINFO:root:0: Epoch 1 train loss: 4271.937967936198\nINFO:root:1: Epoch 1 train loss: 2731.3114115397134\nINFO:root:2: Epoch 1 train loss: 7365.247538248698\nINFO:root:3: Epoch 1 train loss: 11744.786926269531\nINFO:root:13: Epoch 1 train loss: 1233746.7603352864\nINFO:root:16: Epoch 1 train loss: 587880.9182942709\nINFO:root:14: Epoch 1 train loss: 1198469.6795247395\nINFO:root:17: Epoch 1 train loss: 13288.109212239584\nINFO:root:15: Epoch 1 train loss: 9330.818806966146\nINFO:root:12: Epoch 1 train loss: 771.1173095703125\nINFO:root:7: Epoch 1 train loss: 5292.377034505208\nINFO:root:8: Epoch 1 train loss: 11703.243540445963\nINFO:root:10: Epoch 1 train loss: 4688.5407307942705\nINFO:root:11: Epoch 1 train loss: 20305.051106770832\nINFO:root:6: Epoch 1 train loss: 1205205.7662760417\nINFO:root:9: Epoch 1 train loss: 5500.408365885417\nINFO:root:4: Epoch 1 train loss: 2292118.0286458335\nINFO:root:5: Epoch 1 train loss: 727741.455156962\nINFO:root:0: Epoch 1 validation loss: 44029.6466504618\nINFO:root:0: Epoch 2 train loss: 100013.6728515625\nINFO:root:2: Epoch 2 train loss: 1009372.9768880209\nINFO:root:17: Epoch 2 train loss: 4330.012400309245\nINFO:root:4: Epoch 2 train loss: 4608.5111083984375\nINFO:root:5: Epoch 2 train loss: 16044.478678385416\nINFO:root:3: Epoch 2 train loss: 14516.385823567709\nINFO:root:1: Epoch 2 train loss: 679264.6077473959\nINFO:root:16: Epoch 2 train loss: 1013551.0915323893\nINFO:root:15: Epoch 2 train loss: 1265457.3793131511\nINFO:root:6: Epoch 2 train loss: 12585.549621582031\nINFO:root:14: Epoch 2 train loss: 13400.62050374349\nINFO:root:13: Epoch 2 train loss: 952393.1535847982\nINFO:root:7: Epoch 2 train loss: 10398.181477864584\nINFO:root:8: Epoch 2 train loss: 9327.268636067709\nINFO:root:10: Epoch 2 train loss: 9585.848510742188\nINFO:root:11: Epoch 2 train loss: 6715.064290364583\nINFO:root:9: Epoch 2 train loss: 674896.030843099\nINFO:root:12: Epoch 2 train loss: 764450.4500325521\nINFO:root:0: Epoch 2 validation loss: 44018.70744097156\nINFO:root:2: Epoch 3 train loss: 6710.604136149089\nINFO:root:9: Epoch 3 train loss: 6608.5771484375\nINFO:root:5: Epoch 3 train loss: 1640.2569783528645\nINFO:root:3: Epoch 3 train loss: 4322.176106770833\nINFO:root:17: Epoch 3 train loss: 87948.97037760417\nINFO:root:10: Epoch 3 train loss: 694139.3562672933\nINFO:root:16: Epoch 3 train loss: 2555.9171447753906\nINFO:root:11: Epoch 3 train loss: 812858.5346679688\nINFO:root:15: Epoch 3 train loss: 593018.507405599\nINFO:root:4: Epoch 3 train loss: 938367.8968556722\nINFO:root:14: Epoch 3 train loss: 1430020.958170573\nINFO:root:0: Epoch 3 train loss: 693360.8688151041\nINFO:root:1: Epoch 3 train loss: 1269014.6975911458\nINFO:root:12: Epoch 3 train loss: 6569.263051350911\nINFO:root:13: Epoch 3 train loss: 13272.62930806478\nINFO:root:7: Epoch 3 train loss: 3721.6404418945312\nINFO:root:6: Epoch 3 train loss: 804173.4967447916\nINFO:root:8: Epoch 3 train loss: 23485.389556884766\nINFO:root:0: Epoch 3 validation loss: 44006.78661674338\nINFO:root:1: Epoch 4 train loss: 1539144.5947265625\nINFO:root:2: Epoch 4 train loss: 4390.093821207683\nINFO:root:3: Epoch 4 train loss: 9743.006958007812\nINFO:root:5: Epoch 4 train loss: 563299.9756596884\nINFO:root:4: Epoch 4 train loss: 16638.6504796346\nINFO:root:7: Epoch 4 train loss: 9215.783426920572\nINFO:root:6: Epoch 4 train loss: 16209.477986653646\nINFO:root:8: Epoch 4 train loss: 2244.263142903646\nINFO:root:10: Epoch 4 train loss: 1391301.414876302\nINFO:root:11: Epoch 4 train loss: 17375.093271891277\nINFO:root:9: Epoch 4 train loss: 22677.6904296875\nINFO:root:12: Epoch 4 train loss: 16254.237121582031\nINFO:root:17: Epoch 4 train loss: 12407.284520467123\nINFO:root:16: Epoch 4 train loss: 12335.59423828125\nINFO:root:0: Epoch 4 train loss: 4436.415751139323\nINFO:root:15: Epoch 4 train loss: 28830.6953125\nINFO:root:14: Epoch 4 train loss: 997371.2421875\nINFO:root:13: Epoch 4 train loss: 78276.79488627116\nINFO:root:0: Epoch 4 validation loss: 43993.45419167445\nINFO:root:2: Epoch 5 train loss: 2331.7555338541665\nINFO:root:0: Epoch 5 train loss: 697576.3263015747\nINFO:root:1: Epoch 5 train loss: 2927.2852376302085\nINFO:root:9: Epoch 5 train loss: 8236.126729329428\nINFO:root:8: Epoch 5 train loss: 687347.4833577474\nINFO:root:13: Epoch 5 train loss: 6528.710856119792\nINFO:root:17: Epoch 5 train loss: 28293.06298828125\nINFO:root:7: Epoch 5 train loss: 1265975.2663574219\nINFO:root:12: Epoch 5 train loss: 813817.9166666666\nINFO:root:16: Epoch 5 train loss: 19236.647786458332\nINFO:root:14: Epoch 5 train loss: 2236.9723917643228\nINFO:root:11: Epoch 5 train loss: 672672.3626302084\nINFO:root:10: Epoch 5 train loss: 23403.971720377605\nINFO:root:15: Epoch 5 train loss: 706269.3169504801\nINFO:root:6: Epoch 5 train loss: 6223.420247395833\nINFO:root:4: Epoch 5 train loss: 761546.4231770834\nINFO:root:3: Epoch 5 train loss: 1446213.034016927\nINFO:root:5: Epoch 5 train loss: 1876.3548787434895\nINFO:root:0: Epoch 5 validation loss: 43977.8115706305\n", "seconds": 15.015662908554077, "batch_size": 64, "nodes": 6, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 3 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 3 batches\n2: 3 batches\n4 Start Epoch 0\n4: 3 batches\n3 Start Epoch 0\n3: 3 batches\n15 Start Epoch 0\n8 Start Epoch 0\n16 Start Epoch 0\n7 Start Epoch 0\n15: 3 batches\n7: 3 batches\n16: 3 batches\n8: 3 batches\n13 Start Epoch 0\n13: 3 batches\n6 Start Epoch 0\n5 Start Epoch 0\n6: 3 batches\n14 Start Epoch 0\n5: 3 batches\n14: 3 batches\n12 Start Epoch 0\n12: 3 batches\n19 Start Epoch 0\n19: 3 batches\n20 Start Epoch 0\n20: 3 batches\n9 Start Epoch 0\n9: 3 batches\n10 Start Epoch 0\n10: 3 batches\n11 Start Epoch 0\n11: 3 batches\n18 Start Epoch 0\n17 Start Epoch 0\n17: 3 batches\n18: 3 batches\n2 Start Epoch 1\n17 Start Epoch 1\n2: 3 batches\n5 Start Epoch 1\n8 Start Epoch 1\n17: 3 batches\n11 Start Epoch 1\n5: 3 batches\n13 Start Epoch 1\n11: 3 batches\n8: 3 batches\n14 Start Epoch 1\n13: 3 batches\n14: 3 batches\n9 Start Epoch 1\n9: 3 batches\n16 Start Epoch 1\n10 Start Epoch 1\n15 Start Epoch 1\n12 Start Epoch 1\n16: 3 batches\n10: 3 batches\n12: 3 batches\n15: 3 batches\n20 Start Epoch 1\n18 Start Epoch 1\n20: 3 batches\n18: 3 batches\n19 Start Epoch 1\n19: 3 batches\n6 Start Epoch 1\n6: 3 batches\n7 Start Epoch 1\n1 Start Epoch 1\n1: 3 batches\n7: 3 batches\n3 Start Epoch 1\n4 Start Epoch 1\n4: 3 batches\n3: 3 batches\n0 Start Epoch 1\n0: 3 batches\n7 Start Epoch 2\n5 Start Epoch 2\n7: 3 batches\n9 Start Epoch 2\n10 Start Epoch 2\n5: 3 batches\n9: 3 batches\n4 Start Epoch 2\n12 Start Epoch 2\n11 Start Epoch 2\n11: 3 batches\n10: 3 batches\n8 Start Epoch 2\n4: 3 batches\n8: 3 batches\n2 Start Epoch 2\n2: 3 batches\n12: 3 batches\n17 Start Epoch 2\n17: 3 batches\n13 Start Epoch 2\n20 Start Epoch 2\n13: 3 batches\n19 Start Epoch 2\n18 Start Epoch 2\n18: 3 batches\n14 Start Epoch 2\n19: 3 batches\n14: 3 batches\n20: 3 batches\n1 Start Epoch 2\n1: 3 batches\n6 Start Epoch 2\n6: 3 batches\n16 Start Epoch 2\n16: 3 batches\n15 Start Epoch 2\n15: 3 batches\n3 Start Epoch 2\n3: 3 batches\n0 Start Epoch 2\n0: 3 batches\n8 Start Epoch 3\n11 Start Epoch 3\n11: 3 batches\n8: 3 batches\n5 Start Epoch 3\n17 Start Epoch 3\n5: 3 batches\n17: 3 batches\n10 Start Epoch 3\n9 Start Epoch 3\n7 Start Epoch 3\n10: 3 batches\n6 Start Epoch 3\n9: 3 batches\n7: 3 batches\n6: 3 batches\n3 Start Epoch 3\n12 Start Epoch 3\n12: 3 batches\n3: 3 batches\n2 Start Epoch 3\n2: 3 batches\n1 Start Epoch 3\n1: 3 batches\n19 Start Epoch 3\n18 Start Epoch 3\n4 Start Epoch 3\n13 Start Epoch 3\n4: 3 batches\n14 Start Epoch 3\n19: 3 batches\n13: 3 batches\n18: 3 batches\n20 Start Epoch 3\n14: 3 batches\n20: 3 batches\n15 Start Epoch 3\n15: 3 batches\n16 Start Epoch 3\n16: 3 batches\n0 Start Epoch 3\n0: 3 batches\n3 Start Epoch 4\n3: 3 batches\n11 Start Epoch 4\n9 Start Epoch 4\n11: 3 batches\n9: 3 batches\n5 Start Epoch 4\n10 Start Epoch 4\n10: 3 batches\n5: 3 batches\n15 Start Epoch 4\n15: 3 batches\n7 Start Epoch 4\n7: 3 batches\n17 Start Epoch 4\n8 Start Epoch 4\n8: 3 batches\n17: 3 batches\n18 Start Epoch 4\n18: 3 batches\n16 Start Epoch 4\n16: 3 batches\n20 Start Epoch 4\n20: 3 batches\n12 Start Epoch 4\n14 Start Epoch 4\n1 Start Epoch 4\n1: 3 batches\n2 Start Epoch 4\n2: 3 batches\n19 Start Epoch 4\n12: 3 batches\n19: 3 batches\n14: 3 batches\n13 Start Epoch 4\n13: 3 batches\n4 Start Epoch 4\n4: 3 batches\n6 Start Epoch 4\n6: 3 batches\n0 Start Epoch 4\n0: 3 batches\n8 Start Epoch 5\n5 Start Epoch 5\n17 Start Epoch 5\n8: 3 batches\n5: 3 batches\n17: 3 batches\n10 Start Epoch 5\n9 Start Epoch 5\n6 Start Epoch 5\n10: 3 batches\n6: 3 batches\n11 Start Epoch 5\n11: 3 batches\n7 Start Epoch 5\n9: 3 batches\n7: 3 batches\n4 Start Epoch 5\n4: 3 batches\n3 Start Epoch 5\n18 Start Epoch 5\n3: 3 batches\n20 Start Epoch 5\n18: 3 batches\n14 Start Epoch 5\n20: 3 batches\n12 Start Epoch 5\n12: 3 batches\n14: 3 batches\n15 Start Epoch 5\n15: 3 batches\n1 Start Epoch 5\n1: 3 batches\n13 Start Epoch 5\n16 Start Epoch 5\n13: 3 batches\n16: 3 batches\n19 Start Epoch 5\n19: 3 batches\n2 Start Epoch 5\n2: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:2: Epoch 0 train loss: 7898.1591796875\nINFO:root:17: Epoch 0 train loss: 4908.695107301076\nINFO:root:11: Epoch 0 train loss: 2110.6058514912925\nINFO:root:8: Epoch 0 train loss: 2796.4230779012046\nINFO:root:13: Epoch 0 train loss: 611801.1333414713\nINFO:root:5: Epoch 0 train loss: 805852.3200073242\nINFO:root:14: Epoch 0 train loss: 77072.99340820312\nINFO:root:9: Epoch 0 train loss: 701716.8045247396\nINFO:root:16: Epoch 0 train loss: 692213.4095611572\nINFO:root:10: Epoch 0 train loss: 7007.727620442708\nINFO:root:15: Epoch 0 train loss: 4333.800130208333\nINFO:root:12: Epoch 0 train loss: 727549.5233561198\nINFO:root:20: Epoch 0 train loss: 40885.590983072914\nINFO:root:18: Epoch 0 train loss: 231640.77076212564\nINFO:root:19: Epoch 0 train loss: 2028.0807062784831\nINFO:root:0: Epoch 0 train loss: 8954.053344726562\nINFO:root:6: Epoch 0 train loss: 4686191.586751302\nINFO:root:7: Epoch 0 train loss: 648393.481101354\nINFO:root:3: Epoch 0 train loss: 229285.37622070312\nINFO:root:1: Epoch 0 train loss: 743699.9900261363\nINFO:root:4: Epoch 0 train loss: 10609.098917643229\nINFO:root:0: Epoch 0 validation loss: 482806.91315556545\nINFO:root:9: Epoch 1 train loss: 9218.621080875397\nINFO:root:10: Epoch 1 train loss: 9901.156819661459\nINFO:root:7: Epoch 1 train loss: 21803.392740885418\nINFO:root:5: Epoch 1 train loss: 15225.849981307983\nINFO:root:11: Epoch 1 train loss: 14395.072469075521\nINFO:root:8: Epoch 1 train loss: 751400.3828125\nINFO:root:4: Epoch 1 train loss: 642762.3627929688\nINFO:root:12: Epoch 1 train loss: 84349.69418334961\nINFO:root:6: Epoch 1 train loss: 822366.6731160482\nINFO:root:2: Epoch 1 train loss: 5276.950988769531\nINFO:root:17: Epoch 1 train loss: 1721.6102701822917\nINFO:root:13: Epoch 1 train loss: 6585.50537109375\nINFO:root:20: Epoch 1 train loss: 9804.512630105019\nINFO:root:19: Epoch 1 train loss: 19864.108306884766\nINFO:root:18: Epoch 1 train loss: 344590.18277994794\nINFO:root:14: Epoch 1 train loss: 1019.2335344950358\nINFO:root:1: Epoch 1 train loss: 3220.8328857421875\nINFO:root:0: Epoch 1 train loss: 30141.453125\nINFO:root:16: Epoch 1 train loss: 6723.5083567301435\nINFO:root:15: Epoch 1 train loss: 2299.094965616862\nINFO:root:3: Epoch 1 train loss: 4482.1385498046875\nINFO:root:0: Epoch 1 validation loss: 482785.1524396724\nINFO:root:8: Epoch 2 train loss: 798800.9143981934\nINFO:root:11: Epoch 2 train loss: 581646.5228678385\nINFO:root:5: Epoch 2 train loss: 9474.500610351562\nINFO:root:17: Epoch 2 train loss: 6165.740702311198\nINFO:root:10: Epoch 2 train loss: 7443.5474039713545\nINFO:root:9: Epoch 2 train loss: 16116.652862548828\nINFO:root:6: Epoch 2 train loss: 3976.945381164551\nINFO:root:7: Epoch 2 train loss: 229946.88142903647\nINFO:root:12: Epoch 2 train loss: 691927.1200968424\nINFO:root:20: Epoch 2 train loss: 333659.58349609375\nINFO:root:19: Epoch 2 train loss: 7428.164975484212\nINFO:root:3: Epoch 2 train loss: 42891.29941813151\nINFO:root:2: Epoch 2 train loss: 2384.3621215820312\nINFO:root:1: Epoch 2 train loss: 6178.155192057292\nINFO:root:14: Epoch 2 train loss: 89333.06651115417\nINFO:root:18: Epoch 2 train loss: 22060.76171875\nINFO:root:4: Epoch 2 train loss: 545757.7051798502\nINFO:root:13: Epoch 2 train loss: 9293.371907552084\nINFO:root:15: Epoch 2 train loss: 227226.23299678168\nINFO:root:16: Epoch 2 train loss: 2941.868642171224\nINFO:root:0: Epoch 2 train loss: 578265.5203552246\nINFO:root:0: Epoch 2 validation loss: 482762.4923364222\nINFO:root:11: Epoch 3 train loss: 81895.28686014812\nINFO:root:3: Epoch 3 train loss: 578534.0335693359\nINFO:root:17: Epoch 3 train loss: 2077.6314900716147\nINFO:root:9: Epoch 3 train loss: 1508112.4448242188\nINFO:root:10: Epoch 3 train loss: 3041.176863749822\nINFO:root:5: Epoch 3 train loss: 48401.549479166664\nINFO:root:15: Epoch 3 train loss: 6433.150716145833\nINFO:root:18: Epoch 3 train loss: 552050.7644449869\nINFO:root:16: Epoch 3 train loss: 73986.24544270833\nINFO:root:8: Epoch 3 train loss: 769124.7678222656\nINFO:root:7: Epoch 3 train loss: 4033.841552734375\nINFO:root:20: Epoch 3 train loss: 30544.74609375\nINFO:root:14: Epoch 3 train loss: 26504.46630859375\nINFO:root:12: Epoch 3 train loss: 812825.7127253214\nINFO:root:19: Epoch 3 train loss: 525.177490234375\nINFO:root:2: Epoch 3 train loss: 7242.798333803813\nINFO:root:1: Epoch 3 train loss: 6005.994883219401\nINFO:root:13: Epoch 3 train loss: 6132.048177083333\nINFO:root:4: Epoch 3 train loss: 43694.964223225914\nINFO:root:0: Epoch 3 train loss: 8245.695149739584\nINFO:root:6: Epoch 3 train loss: 3903.713175455729\nINFO:root:0: Epoch 3 validation loss: 482736.6315263813\nINFO:root:11: Epoch 4 train loss: 5175.448350270589\nINFO:root:8: Epoch 4 train loss: 645120.7628987631\nINFO:root:5: Epoch 4 train loss: 6401.215657552083\nINFO:root:17: Epoch 4 train loss: 2445.777618408203\nINFO:root:9: Epoch 4 train loss: 7130.161326090495\nINFO:root:10: Epoch 4 train loss: 580050.6258138021\nINFO:root:6: Epoch 4 train loss: 3826.2533365885415\nINFO:root:7: Epoch 4 train loss: 3058224.782796224\nINFO:root:4: Epoch 4 train loss: 594319.8507283529\nINFO:root:3: Epoch 4 train loss: 8713.749677578608\nINFO:root:12: Epoch 4 train loss: 654418.9924519857\nINFO:root:13: Epoch 4 train loss: 8504.779977877935\nINFO:root:14: Epoch 4 train loss: 20920.841918945312\nINFO:root:20: Epoch 4 train loss: 681291.3657603264\nINFO:root:18: Epoch 4 train loss: 9575.398966471354\nINFO:root:16: Epoch 4 train loss: 8940.330673217773\nINFO:root:15: Epoch 4 train loss: 3643.086140950521\nINFO:root:0: Epoch 4 train loss: 4116.112152099609\nINFO:root:1: Epoch 4 train loss: 681467.1060441335\nINFO:root:19: Epoch 4 train loss: 68576.08203125\nINFO:root:2: Epoch 4 train loss: 5325.5771484375\nINFO:root:0: Epoch 4 validation loss: 482706.48226025136\nINFO:root:17: Epoch 5 train loss: 642668.8735860189\nINFO:root:11: Epoch 5 train loss: 87922.14467366536\nINFO:root:7: Epoch 5 train loss: 4644.097567240397\nINFO:root:4: Epoch 5 train loss: 20411.32805633545\nINFO:root:14: Epoch 5 train loss: 612352.5789388021\nINFO:root:0: Epoch 5 train loss: 11887.366129557291\nINFO:root:10: Epoch 5 train loss: 8393.532015363375\nINFO:root:6: Epoch 5 train loss: 21107.050318400066\nINFO:root:5: Epoch 5 train loss: 2362.5159912109375\nINFO:root:13: Epoch 5 train loss: 7358.114196777344\nINFO:root:20: Epoch 5 train loss: 823847.88671875\nINFO:root:9: Epoch 5 train loss: 4722.129231770833\nINFO:root:12: Epoch 5 train loss: 5146.676400184631\nINFO:root:16: Epoch 5 train loss: 581343.717417399\nINFO:root:15: Epoch 5 train loss: 5626694.163411458\nINFO:root:3: Epoch 5 train loss: 15698.767735799154\nINFO:root:2: Epoch 5 train loss: 9471.41547648112\nINFO:root:1: Epoch 5 train loss: 7978.995686848958\nINFO:root:8: Epoch 5 train loss: 1543.9720408121746\nINFO:root:19: Epoch 5 train loss: 37001.7438659668\nINFO:root:18: Epoch 5 train loss: 8745.395499547323\nINFO:root:0: Epoch 5 validation loss: 482671.41679747455\n", "seconds": 13.094531059265137, "batch_size": 64, "nodes": 7, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 2 batches\n2: 2 batches\n5 Start Epoch 0\n5: 2 batches\n3 Start Epoch 0\n4 Start Epoch 0\n3: 2 batches\n4: 2 batches\n23 Start Epoch 0\n23: 2 batches\n6 Start Epoch 0\n18 Start Epoch 0\n18: 2 batches\n10 Start Epoch 0\n9 Start Epoch 0\n10: 2 batches\n9: 2 batches\n6: 2 batches\n16 Start Epoch 0\n16: 2 batches\n11 Start Epoch 0\n8 Start Epoch 0\n11: 2 batches\n22 Start Epoch 0\n8: 2 batches\n17 Start Epoch 0\n17: 2 batches\n21 Start Epoch 0\n22: 2 batches\n15 Start Epoch 0\n15: 2 batches\n21: 2 batches\n7 Start Epoch 0\n7: 2 batches\n13 Start Epoch 0\n14 Start Epoch 0\n13: 2 batches\n14: 2 batches\n19 Start Epoch 0\n12 Start Epoch 0\n12: 2 batches\n20 Start Epoch 0\n19: 2 batches\n20: 2 batches\n21 Start Epoch 1\n22 Start Epoch 1\n23 Start Epoch 1\n23: 2 batches\n22: 2 batches\n20 Start Epoch 1\n20: 2 batches\n21: 2 batches\n5 Start Epoch 1\n5: 2 batches\n10 Start Epoch 1\n11 Start Epoch 1\n15 Start Epoch 1\n8 Start Epoch 1\n8: 2 batches\n10: 2 batches\n17 Start Epoch 1\n3 Start Epoch 1\n11: 2 batches\n16 Start Epoch 1\n6 Start Epoch 1\n6: 2 batches\n4 Start Epoch 1\n15: 2 batches\n17: 2 batches\n7 Start Epoch 1\n3: 2 batches\n7: 2 batches\n4: 2 batches\n1 Start Epoch 1\n1: 2 batches\n16: 2 batches\n13 Start Epoch 1\n18 Start Epoch 1\n14 Start Epoch 1\n19 Start Epoch 1\n13: 2 batches\n19: 2 batches\n14: 2 batches\n18: 2 batches\n12 Start Epoch 1\n12: 2 batches\n9 Start Epoch 1\n9: 2 batches\n2 Start Epoch 1\n2: 2 batches\n0 Start Epoch 1\n0: 2 batches\n17 Start Epoch 2\n16 Start Epoch 2\n14 Start Epoch 2\n13 Start Epoch 2\n17: 2 batches\n13: 2 batches\n14: 2 batches\n15 Start Epoch 2\n15: 2 batches\n16: 2 batches\n18 Start Epoch 2\n18: 2 batches\n8 Start Epoch 2\n8: 2 batches\n4 Start Epoch 2\n20 Start Epoch 2\n20: 2 batches\n11 Start Epoch 2\n22 Start Epoch 2\n4: 2 batches\n5 Start Epoch 2\n19 Start Epoch 2\n10 Start Epoch 2\n23 Start Epoch 2\n5: 2 batches\n10: 2 batches\n21 Start Epoch 2\n6 Start Epoch 2\n7 Start Epoch 2\n1 Start Epoch 2\n1: 2 batches\n9 Start Epoch 2\n23: 2 batches\n9: 2 batches\n22: 2 batches\n7: 2 batches\n3 Start Epoch 2\n3: 2 batches\n11: 2 batches\n21: 2 batches\n6: 2 batches\n2 Start Epoch 2\n2: 2 batches\n12 Start Epoch 2\n12: 2 batches\n19: 2 batches\n0 Start Epoch 2\n0: 2 batches\n11 Start Epoch 3\n11: 2 batches\n4 Start Epoch 3\n5 Start Epoch 3\n6 Start Epoch 3\n5: 2 batches\n7 Start Epoch 3\n8 Start Epoch 3\n8: 2 batches\n6: 2 batches\n7: 2 batches\n4: 2 batches\n10 Start Epoch 3\n12 Start Epoch 3\n12: 2 batches\n9 Start Epoch 3\n9: 2 batches\n10: 2 batches\n17 Start Epoch 3\n17: 2 batches\n22 Start Epoch 3\n18 Start Epoch 3\n13 Start Epoch 3\n19 Start Epoch 3\n21 Start Epoch 3\n16 Start Epoch 3\n22: 2 batches\n14 Start Epoch 3\n19: 2 batches\n14: 2 batches\n20 Start Epoch 3\n15 Start Epoch 3\n23 Start Epoch 3\n13: 2 batches\n20: 2 batches\n15: 2 batches\n23: 2 batches\n16: 2 batches\n21: 2 batches\n18: 2 batches\n1 Start Epoch 3\n2 Start Epoch 3\n2: 2 batches\n1: 2 batches\n3 Start Epoch 3\n3: 2 batches\n0 Start Epoch 3\n0: 2 batches\n1 Start Epoch 4\n2 Start Epoch 4\n1: 2 batches\n2: 2 batches\n23 Start Epoch 4\n23: 2 batches\n8 Start Epoch 4\n12 Start Epoch 4\n20 Start Epoch 4\n20: 2 batches\n11 Start Epoch 4\n11: 2 batches\n12: 2 batches\n7 Start Epoch 4\n3 Start Epoch 4\n15 Start Epoch 4\n5 Start Epoch 4\n14 Start Epoch 4\n18 Start Epoch 4\n10 Start Epoch 4\n17 Start Epoch 4\n7: 2 batches\n16 Start Epoch 4\n16: 2 batches\n8: 2 batches\n4 Start Epoch 4\n19 Start Epoch 4\n10: 2 batches\n3: 2 batches\n14: 2 batches\n18: 2 batches\n15: 2 batches\n13 Start Epoch 4\n19: 2 batches\n9 Start Epoch 4\n17: 2 batches\n6 Start Epoch 4\n5: 2 batches\n6: 2 batches\n4: 2 batches\n13: 2 batches\n9: 2 batches\n22 Start Epoch 4\n22: 2 batches\n21 Start Epoch 4\n21: 2 batches\n0 Start Epoch 4\n0: 2 batches\n18 Start Epoch 5\n18: 2 batches\n17 Start Epoch 5\n16 Start Epoch 5\n16: 2 batches\n17: 2 batches\n12 Start Epoch 5\n12: 2 batches\n23 Start Epoch 5\n23: 2 batches\n21 Start Epoch 5\n21: 2 batches\n22 Start Epoch 5\n22: 2 batches\n20 Start Epoch 5\n20: 2 batches\n8 Start Epoch 5\n8: 2 batches\n10 Start Epoch 5\n4 Start Epoch 5\n13 Start Epoch 5\n5 Start Epoch 5\n5: 2 batches\n14 Start Epoch 5\n9 Start Epoch 5\n10: 2 batches\n7 Start Epoch 5\n4: 2 batches\n11 Start Epoch 5\n11: 2 batches\n7: 2 batches\n3 Start Epoch 5\n13: 2 batches\n9: 2 batches\n3: 2 batches\n14: 2 batches\n2 Start Epoch 5\n2: 2 batches\n1 Start Epoch 5\n1: 2 batches\n19 Start Epoch 5\n19: 2 batches\n6 Start Epoch 5\n6: 2 batches\n15 Start Epoch 5\n15: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:21: Epoch 0 train loss: 14976.25634765625\nINFO:root:22: Epoch 0 train loss: 758.6976547241211\nINFO:root:23: Epoch 0 train loss: 14466.23388671875\nINFO:root:20: Epoch 0 train loss: 5690.7452392578125\nINFO:root:5: Epoch 0 train loss: 1508.6742248535156\nINFO:root:10: Epoch 0 train loss: 922704.6069335938\nINFO:root:16: Epoch 0 train loss: 8368.327514648438\nINFO:root:11: Epoch 0 train loss: 2325.4268188476562\nINFO:root:15: Epoch 0 train loss: 4240.020782470703\nINFO:root:6: Epoch 0 train loss: 6389.871032714844\nINFO:root:17: Epoch 0 train loss: 755.5556030273438\nINFO:root:4: Epoch 0 train loss: 3184.6516723632812\nINFO:root:7: Epoch 0 train loss: 866525.9416503906\nINFO:root:3: Epoch 0 train loss: 1040128.1199951172\nINFO:root:8: Epoch 0 train loss: 17738.63525390625\nINFO:root:0: Epoch 0 train loss: 19225.0830078125\nINFO:root:1: Epoch 0 train loss: 6170.962966918945\nINFO:root:14: Epoch 0 train loss: 369053.3259277344\nINFO:root:18: Epoch 0 train loss: 14448.40771484375\nINFO:root:13: Epoch 0 train loss: 1902837.822265625\nINFO:root:19: Epoch 0 train loss: 6658.736083984375\nINFO:root:12: Epoch 0 train loss: 113958.87805175781\nINFO:root:2: Epoch 0 train loss: 15920.97509765625\nINFO:root:9: Epoch 0 train loss: 1210.1969833374023\nINFO:root:0: Epoch 0 validation loss: 294414.8070882515\nINFO:root:17: Epoch 1 train loss: 5389.306396484375\nINFO:root:16: Epoch 1 train loss: 4302.8990478515625\nINFO:root:15: Epoch 1 train loss: 8841.380859375\nINFO:root:14: Epoch 1 train loss: 10006.94995880127\nINFO:root:13: Epoch 1 train loss: 1917938.125\nINFO:root:18: Epoch 1 train loss: 7632.619323730469\nINFO:root:0: Epoch 1 train loss: 1077472.1123046875\nINFO:root:23: Epoch 1 train loss: 1202646.7014160156\nINFO:root:8: Epoch 1 train loss: 41020.908203125\nINFO:root:5: Epoch 1 train loss: 1092377.7094726562\nINFO:root:19: Epoch 1 train loss: 12184.67724609375\nINFO:root:11: Epoch 1 train loss: 1168727.27734375\nINFO:root:21: Epoch 1 train loss: 10890.126098632812\nINFO:root:4: Epoch 1 train loss: 1105388.9766845703\nINFO:root:20: Epoch 1 train loss: 3847.3583374023438\nINFO:root:9: Epoch 1 train loss: 15572.4169921875\nINFO:root:22: Epoch 1 train loss: 7624.886627197266\nINFO:root:10: Epoch 1 train loss: 873101.7895507812\nINFO:root:6: Epoch 1 train loss: 14564.66357421875\nINFO:root:7: Epoch 1 train loss: 3724.1582794189453\nINFO:root:1: Epoch 1 train loss: 867189.6099853516\nINFO:root:3: Epoch 1 train loss: 873236.0903320312\nINFO:root:2: Epoch 1 train loss: 4624.036392211914\nINFO:root:12: Epoch 1 train loss: 18026.57177734375\nINFO:root:0: Epoch 1 validation loss: 294402.02476161777\nINFO:root:11: Epoch 2 train loss: 870269.150390625\nINFO:root:4: Epoch 2 train loss: 6192.4580078125\nINFO:root:6: Epoch 2 train loss: 16005.279037475586\nINFO:root:5: Epoch 2 train loss: 1157009.6076049805\nINFO:root:7: Epoch 2 train loss: 4546.208435058594\nINFO:root:8: Epoch 2 train loss: 816471.7744445801\nINFO:root:10: Epoch 2 train loss: 2546453.61517334\nINFO:root:12: Epoch 2 train loss: 1157587.6667480469\nINFO:root:9: Epoch 2 train loss: 7734.4185791015625\nINFO:root:18: Epoch 2 train loss: 2028.13671875\nINFO:root:17: Epoch 2 train loss: 7023.306396484375\nINFO:root:23: Epoch 2 train loss: 5573.31184387207\nINFO:root:19: Epoch 2 train loss: 3839.82373046875\nINFO:root:21: Epoch 2 train loss: 8060.066680908203\nINFO:root:14: Epoch 2 train loss: 4348.11474609375\nINFO:root:20: Epoch 2 train loss: 2142.5869750976562\nINFO:root:22: Epoch 2 train loss: 12482.275756835938\nINFO:root:15: Epoch 2 train loss: 7166.4696044921875\nINFO:root:13: Epoch 2 train loss: 15918.572265625\nINFO:root:16: Epoch 2 train loss: 33287.8125\nINFO:root:1: Epoch 2 train loss: 844113.42578125\nINFO:root:0: Epoch 2 train loss: 33652.172790527344\nINFO:root:2: Epoch 2 train loss: 7109.121337890625\nINFO:root:3: Epoch 2 train loss: 12278.930419921875\nINFO:root:0: Epoch 2 validation loss: 294389.59925415926\nINFO:root:1: Epoch 3 train loss: 14511.667724609375\nINFO:root:2: Epoch 3 train loss: 27193.987915039062\nINFO:root:0: Epoch 3 train loss: 4542.339981079102\nINFO:root:16: Epoch 3 train loss: 33621.49920654297\nINFO:root:3: Epoch 3 train loss: 3285.199462890625\nINFO:root:12: Epoch 3 train loss: 1279556.098815918\nINFO:root:20: Epoch 3 train loss: 384.06156158447266\nINFO:root:11: Epoch 3 train loss: 2035.3042602539062\nINFO:root:17: Epoch 3 train loss: 10001.937255859375\nINFO:root:7: Epoch 3 train loss: 1078037.1874389648\nINFO:root:4: Epoch 3 train loss: 41300.91455078125\nINFO:root:18: Epoch 3 train loss: 163182.064453125\nINFO:root:15: Epoch 3 train loss: 1079.1927490234375\nINFO:root:8: Epoch 3 train loss: 12202.163330078125\nINFO:root:5: Epoch 3 train loss: 12435.028442382812\nINFO:root:14: Epoch 3 train loss: 5023.203842163086\nINFO:root:19: Epoch 3 train loss: 12962.70361328125\nINFO:root:10: Epoch 3 train loss: 8098.1641845703125\nINFO:root:13: Epoch 3 train loss: 3331.1936645507812\nINFO:root:9: Epoch 3 train loss: 1014496.0693359375\nINFO:root:6: Epoch 3 train loss: 884071.62890625\nINFO:root:23: Epoch 3 train loss: 9621.9716796875\nINFO:root:22: Epoch 3 train loss: 1040352.0288085938\nINFO:root:21: Epoch 3 train loss: 13459.89501953125\nINFO:root:0: Epoch 3 validation loss: 294376.86774535856\nINFO:root:18: Epoch 4 train loss: 1201695.0588989258\nINFO:root:16: Epoch 4 train loss: 329.9757385253906\nINFO:root:17: Epoch 4 train loss: 12724.74267578125\nINFO:root:12: Epoch 4 train loss: 8169.238880157471\nINFO:root:21: Epoch 4 train loss: 1227.7799530029297\nINFO:root:23: Epoch 4 train loss: 6561.3594970703125\nINFO:root:22: Epoch 4 train loss: 3426.2885208129883\nINFO:root:20: Epoch 4 train loss: 14104.65869140625\nINFO:root:11: Epoch 4 train loss: 1824.1781616210938\nINFO:root:8: Epoch 4 train loss: 536.608528137207\nINFO:root:4: Epoch 4 train loss: 20001.33544921875\nINFO:root:13: Epoch 4 train loss: 1119157.4845581055\nINFO:root:9: Epoch 4 train loss: 1081415.5661621094\nINFO:root:5: Epoch 4 train loss: 341696.01696777344\nINFO:root:3: Epoch 4 train loss: 17623.444213867188\nINFO:root:14: Epoch 4 train loss: 2348.015594482422\nINFO:root:10: Epoch 4 train loss: 999828.0039978027\nINFO:root:6: Epoch 4 train loss: 127941.00732421875\nINFO:root:7: Epoch 4 train loss: 17190.0595703125\nINFO:root:0: Epoch 4 train loss: 9179.452880859375\nINFO:root:2: Epoch 4 train loss: 45548.25607299805\nINFO:root:1: Epoch 4 train loss: 17750.849853515625\nINFO:root:19: Epoch 4 train loss: 11425.2958984375\nINFO:root:15: Epoch 4 train loss: 1421470.9530029297\nINFO:root:0: Epoch 4 validation loss: 294363.6100755642\nINFO:root:10: Epoch 5 train loss: 967835.5518798828\nINFO:root:15: Epoch 5 train loss: 6038.277648925781\nINFO:root:7: Epoch 5 train loss: 38527.70007324219\nINFO:root:4: Epoch 5 train loss: 2152002.5366210938\nINFO:root:6: Epoch 5 train loss: 9236.482482910156\nINFO:root:5: Epoch 5 train loss: 1118723.5217285156\nINFO:root:11: Epoch 5 train loss: 27786.97265625\nINFO:root:17: Epoch 5 train loss: 2237.3916397094727\nINFO:root:9: Epoch 5 train loss: 1176113.748046875\nINFO:root:16: Epoch 5 train loss: 8011.62939453125\nINFO:root:8: Epoch 5 train loss: 7270.586944580078\nINFO:root:2: Epoch 5 train loss: 869706.8942871094\nINFO:root:18: Epoch 5 train loss: 2355.113006591797\nINFO:root:3: Epoch 5 train loss: 35883.900329589844\nINFO:root:12: Epoch 5 train loss: 8119.62841796875\nINFO:root:13: Epoch 5 train loss: 9961.021484375\nINFO:root:14: Epoch 5 train loss: 12795.439208984375\nINFO:root:1: Epoch 5 train loss: 2162.8704833984375\nINFO:root:23: Epoch 5 train loss: 867854.7900390625\nINFO:root:22: Epoch 5 train loss: 28788.749877929688\nINFO:root:21: Epoch 5 train loss: 1038917.7265625\nINFO:root:19: Epoch 5 train loss: 23218.9130859375\nINFO:root:20: Epoch 5 train loss: 1087152.5407714844\nINFO:root:0: Epoch 5 train loss: 2685.810333251953\nINFO:root:0: Epoch 5 validation loss: 294349.7855148888\n", "seconds": 13.963522672653198, "batch_size": 64, "nodes": 8, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n4 Start Epoch 0\n3 Start Epoch 0\n3: 2 batches\n4: 2 batches\n19 Start Epoch 0\n20 Start Epoch 0\n19: 2 batches\n20: 2 batches\n12 Start Epoch 0\n12: 2 batches\n11 Start Epoch 0\n11: 2 batches\n1 Start Epoch 0\n2 Start Epoch 0\n2: 2 batches\n1: 2 batches\n24 Start Epoch 0\n24: 2 batches\n16 Start Epoch 0\n7 Start Epoch 0\n15 Start Epoch 0\n7: 2 batches\n15: 2 batches\n8 Start Epoch 0\n16: 2 batches\n8: 2 batches\n23 Start Epoch 0\n23: 2 batches\n18 Start Epoch 0\n18: 2 batches\n21 Start Epoch 0\n5 Start Epoch 0\n5: 2 batches\n22 Start Epoch 0\n21: 2 batches\n22: 2 batches\n6 Start Epoch 0\n6: 2 batches\n17 Start Epoch 0\n17: 2 batches\n26 Start Epoch 0\n13 Start Epoch 0\n25 Start Epoch 0\n14 Start Epoch 0\n26: 2 batches\n14: 2 batches\n25: 2 batches\n13: 2 batches\n9 Start Epoch 0\n9: 2 batches\n10 Start Epoch 0\n10: 2 batches\n1 Start Epoch 1\n2 Start Epoch 1\n1: 2 batches\n2: 2 batches\n26 Start Epoch 1\n26: 2 batches\n16 Start Epoch 1\n12 Start Epoch 1\n17 Start Epoch 1\n7 Start Epoch 1\n21 Start Epoch 1\n5 Start Epoch 1\n11 Start Epoch 1\n13 Start Epoch 1\n3 Start Epoch 1\n9 Start Epoch 1\n12: 2 batches\n17: 2 batches\n6 Start Epoch 1\n22 Start Epoch 1\n20 Start Epoch 1\n6: 2 batches\n21: 2 batches\n19 Start Epoch 1\n3: 2 batches\n11: 2 batches\n13: 2 batches\n25 Start Epoch 1\n16: 2 batches\n24 Start Epoch 1\n7: 2 batches\n22: 2 batches\n18 Start Epoch 1\n4 Start Epoch 1\n10 Start Epoch 1\n10: 2 batches\n9: 2 batches\n14 Start Epoch 1\n24: 2 batches\n8 Start Epoch 1\n23 Start Epoch 1\n20: 2 batches\n4: 2 batches\n23: 2 batches\n18: 2 batches\n5: 2 batches\n14: 2 batches\n25: 2 batches\n8: 2 batches\n19: 2 batches\n15 Start Epoch 1\n15: 2 batches\n0 Start Epoch 1\n0: 2 batches\n26 Start Epoch 2\n11 Start Epoch 2\n26: 2 batches\n17 Start Epoch 2\n17: 2 batches\n11: 2 batches\n23 Start Epoch 2\n23: 2 batches\n2 Start Epoch 2\n2: 2 batches\n6 Start Epoch 2\n5 Start Epoch 2\n16 Start Epoch 2\n6: 2 batches\n5: 2 batches\n14 Start Epoch 2\n15 Start Epoch 2\n19 Start Epoch 2\n4 Start Epoch 2\n16: 2 batches\n20 Start Epoch 2\n20: 2 batches\n12 Start Epoch 2\n12: 2 batches\n15: 2 batches\n18 Start Epoch 2\n18: 2 batches\n4: 2 batches\n13 Start Epoch 2\n13: 2 batches\n19: 2 batches\n14: 2 batches\n25 Start Epoch 2\n24 Start Epoch 2\n7 Start Epoch 2\n25: 2 batches\n3 Start Epoch 2\n24: 2 batches\n3: 2 batches\n22 Start Epoch 2\n22: 2 batches\n8 Start Epoch 2\n1 Start Epoch 2\n1: 2 batches\n10 Start Epoch 2\n7: 2 batches\n9 Start Epoch 2\n8: 2 batches\n21 Start Epoch 2\n21: 2 batches\n9: 2 batches\n10: 2 batches\n0 Start Epoch 2\n0: 2 batches\n2 Start Epoch 3\n25 Start Epoch 3\n2: 2 batches\n5 Start Epoch 3\n6 Start Epoch 3\n23 Start Epoch 3\n23: 2 batches\n6: 2 batches\n5: 2 batches\n26 Start Epoch 3\n16 Start Epoch 3\n18 Start Epoch 3\n18: 2 batches\n20 Start Epoch 3\n20: 2 batches\n26: 2 batches\n17 Start Epoch 3\n24 Start Epoch 3\n24: 2 batches\n16: 2 batches\n19 Start Epoch 3\n19: 2 batches\n4 Start Epoch 3\n17: 2 batches\n3 Start Epoch 3\n25: 2 batches\n3: 2 batches\n15 Start Epoch 3\n15: 2 batches\n4: 2 batches\n11 Start Epoch 3\n11: 2 batches\n13 Start Epoch 3\n13: 2 batches\n8 Start Epoch 3\n7 Start Epoch 3\n12 Start Epoch 3\n8: 2 batches\n12: 2 batches\n7: 2 batches\n14 Start Epoch 3\n14: 2 batches\n1 Start Epoch 3\n1: 2 batches\n22 Start Epoch 3\n22: 2 batches\n21 Start Epoch 3\n21: 2 batches\n10 Start Epoch 3\n9 Start Epoch 3\n10: 2 batches\n9: 2 batches\n0 Start Epoch 3\n0: 2 batches\n5 Start Epoch 4\n5: 2 batches\n4 Start Epoch 4\n4: 2 batches\n16 Start Epoch 4\n22 Start Epoch 4\n11 Start Epoch 4\n16: 2 batches\n22: 2 batches\n11: 2 batches\n18 Start Epoch 4\n25 Start Epoch 4\n19 Start Epoch 4\n24 Start Epoch 4\n19: 2 batches\n24: 2 batches\n15 Start Epoch 4\n26 Start Epoch 4\n17 Start Epoch 4\n18: 2 batches\n2 Start Epoch 4\n2: 2 batches\n20 Start Epoch 4\n25: 2 batches\n17: 2 batches\n15: 2 batches\n6 Start Epoch 4\n20: 2 batches\n3 Start Epoch 4\n3: 2 batches\n13 Start Epoch 4\n26: 2 batches\n6: 2 batches\n13: 2 batches\n9 Start Epoch 4\n9: 2 batches\n7 Start Epoch 4\n7: 2 batches\n14 Start Epoch 4\n12 Start Epoch 4\n8 Start Epoch 4\n12: 2 batches\n14: 2 batches\n8: 2 batches\n1 Start Epoch 4\n1: 2 batches\n23 Start Epoch 4\n23: 2 batches\n10 Start Epoch 4\n21 Start Epoch 4\n21: 2 batches\n10: 2 batches\n0 Start Epoch 4\n0: 2 batches\n5 Start Epoch 5\n5: 2 batches\n17 Start Epoch 5\n17: 2 batches\n23 Start Epoch 5\n22 Start Epoch 5\n23: 2 batches\n21 Start Epoch 5\n22: 2 batches\n21: 2 batches\n2 Start Epoch 5\n1 Start Epoch 5\n2: 2 batches\n1: 2 batches\n12 Start Epoch 5\n8 Start Epoch 5\n20 Start Epoch 5\n11 Start Epoch 5\n4 Start Epoch 5\n11: 2 batches\n12: 2 batches\n26 Start Epoch 5\n26: 2 batches\n8: 2 batches\n19 Start Epoch 5\n3 Start Epoch 5\n6 Start Epoch 5\n19: 2 batches\n4: 2 batches\n13 Start Epoch 5\n24 Start Epoch 5\n24: 2 batches\n6: 2 batches\n20: 2 batches\n3: 2 batches\n13: 2 batches\n25 Start Epoch 5\n25: 2 batches\n14 Start Epoch 5\n14: 2 batches\n16 Start Epoch 5\n16: 2 batches\n15 Start Epoch 5\n15: 2 batches\n18 Start Epoch 5\n7 Start Epoch 5\n18: 2 batches\n7: 2 batches\n10 Start Epoch 5\n9 Start Epoch 5\n10: 2 batches\n9: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:1: Epoch 0 train loss: 1537795.0\nINFO:root:2: Epoch 0 train loss: 4950.023448944092\nINFO:root:3: Epoch 0 train loss: 1815495.5598144531\nINFO:root:11: Epoch 0 train loss: 999569.5424499512\nINFO:root:13: Epoch 0 train loss: 13553.6962890625\nINFO:root:26: Epoch 0 train loss: 2167664.4375\nINFO:root:16: Epoch 0 train loss: 39350.68389892578\nINFO:root:6: Epoch 0 train loss: 9674.007568359375\nINFO:root:22: Epoch 0 train loss: 1216545.28125\nINFO:root:17: Epoch 0 train loss: 2436.7366943359375\nINFO:root:8: Epoch 0 train loss: 1403237.7866210938\nINFO:root:21: Epoch 0 train loss: 3571.724151611328\nINFO:root:18: Epoch 0 train loss: 16890.94384765625\nINFO:root:4: Epoch 0 train loss: 1199260.9824256897\nINFO:root:9: Epoch 0 train loss: 1137495.5322265625\nINFO:root:12: Epoch 0 train loss: 53455.0\nINFO:root:7: Epoch 0 train loss: 1509684.9094848633\nINFO:root:23: Epoch 0 train loss: 7569.792388916016\nINFO:root:20: Epoch 0 train loss: 893394.640625\nINFO:root:5: Epoch 0 train loss: 1442656.8839111328\nINFO:root:10: Epoch 0 train loss: 882462.90625\nINFO:root:19: Epoch 0 train loss: 3227.2391357421875\nINFO:root:25: Epoch 0 train loss: 1112912.845703125\nINFO:root:24: Epoch 0 train loss: 1217842.4753417969\nINFO:root:14: Epoch 0 train loss: 1049661.1088867188\nINFO:root:0: Epoch 0 train loss: 9015.078491210938\nINFO:root:15: Epoch 0 train loss: 615.1974563598633\nINFO:root:0: Epoch 0 validation loss: 246854.85118841575\nINFO:root:26: Epoch 1 train loss: 2327998.5\nINFO:root:17: Epoch 1 train loss: 6105.6259765625\nINFO:root:11: Epoch 1 train loss: 2135.874008178711\nINFO:root:23: Epoch 1 train loss: 1666609.0131378174\nINFO:root:24: Epoch 1 train loss: 22737.83984375\nINFO:root:2: Epoch 1 train loss: 349800.2294921875\nINFO:root:0: Epoch 1 train loss: 7901.8125\nINFO:root:6: Epoch 1 train loss: 908313.0859375\nINFO:root:18: Epoch 1 train loss: 3390.9495544433594\nINFO:root:5: Epoch 1 train loss: 13361.059173583984\nINFO:root:13: Epoch 1 train loss: 37010.417236328125\nINFO:root:15: Epoch 1 train loss: 24197.90478515625\nINFO:root:20: Epoch 1 train loss: 2307712.5\nINFO:root:12: Epoch 1 train loss: 5005.210876464844\nINFO:root:16: Epoch 1 train loss: 3342.9327697753906\nINFO:root:19: Epoch 1 train loss: 9311.063232421875\nINFO:root:14: Epoch 1 train loss: 9813.410888671875\nINFO:root:4: Epoch 1 train loss: 7886.1517333984375\nINFO:root:25: Epoch 1 train loss: 2129241.75\nINFO:root:7: Epoch 1 train loss: 8037.57861328125\nINFO:root:3: Epoch 1 train loss: 6928.51708984375\nINFO:root:10: Epoch 1 train loss: 2616.2664184570312\nINFO:root:8: Epoch 1 train loss: 4296.343078613281\nINFO:root:1: Epoch 1 train loss: 17744.76979827881\nINFO:root:22: Epoch 1 train loss: 1135004.3232421875\nINFO:root:9: Epoch 1 train loss: 21433.794921875\nINFO:root:21: Epoch 1 train loss: 8978.484069824219\nINFO:root:0: Epoch 1 validation loss: 246845.56701649155\nINFO:root:2: Epoch 2 train loss: 353323.4921875\nINFO:root:0: Epoch 2 train loss: 976373.8466796875\nINFO:root:17: Epoch 2 train loss: 9017.405517578125\nINFO:root:6: Epoch 2 train loss: 7140.942481994629\nINFO:root:23: Epoch 2 train loss: 1404219.8345947266\nINFO:root:19: Epoch 2 train loss: 9025.750122070312\nINFO:root:5: Epoch 2 train loss: 162853.0830078125\nINFO:root:25: Epoch 2 train loss: 17087.73974609375\nINFO:root:15: Epoch 2 train loss: 1512262.3212890625\nINFO:root:18: Epoch 2 train loss: 12236.291625976562\nINFO:root:26: Epoch 2 train loss: 1090756.6066894531\nINFO:root:16: Epoch 2 train loss: 26393.14453125\nINFO:root:20: Epoch 2 train loss: 3863.1466064453125\nINFO:root:3: Epoch 2 train loss: 124549.41357421875\nINFO:root:4: Epoch 2 train loss: 9434.6083984375\nINFO:root:11: Epoch 2 train loss: 2697.462158203125\nINFO:root:24: Epoch 2 train loss: 199516.9140625\nINFO:root:13: Epoch 2 train loss: 7956.591552734375\nINFO:root:8: Epoch 2 train loss: 13964.752563476562\nINFO:root:7: Epoch 2 train loss: 3199.2510986328125\nINFO:root:12: Epoch 2 train loss: 10558.1201171875\nINFO:root:14: Epoch 2 train loss: 1201846.9760742188\nINFO:root:1: Epoch 2 train loss: 10510.71484375\nINFO:root:22: Epoch 2 train loss: 12546.4853515625\nINFO:root:21: Epoch 2 train loss: 130361.1494140625\nINFO:root:9: Epoch 2 train loss: 612.4305725097656\nINFO:root:10: Epoch 2 train loss: 861776.2626037598\nINFO:root:0: Epoch 2 validation loss: 246836.0225370561\nINFO:root:5: Epoch 3 train loss: 4427.729049682617\nINFO:root:4: Epoch 3 train loss: 5020.933685302734\nINFO:root:26: Epoch 3 train loss: 481761.82342529297\nINFO:root:16: Epoch 3 train loss: 1003438.4038391113\nINFO:root:22: Epoch 3 train loss: 20099.7734375\nINFO:root:19: Epoch 3 train loss: 26838.3369140625\nINFO:root:11: Epoch 3 train loss: 3527.9993896484375\nINFO:root:24: Epoch 3 train loss: 2318.9575805664062\nINFO:root:18: Epoch 3 train loss: 1583487.470703125\nINFO:root:25: Epoch 3 train loss: 8363.1259765625\nINFO:root:2: Epoch 3 train loss: 9244.486206054688\nINFO:root:20: Epoch 3 train loss: 5974.77587890625\nINFO:root:17: Epoch 3 train loss: 23960.5927734375\nINFO:root:15: Epoch 3 train loss: 15730.814208984375\nINFO:root:3: Epoch 3 train loss: 8695.69482421875\nINFO:root:13: Epoch 3 train loss: 5668.866943359375\nINFO:root:6: Epoch 3 train loss: 12575.83154296875\nINFO:root:9: Epoch 3 train loss: 2950.4150314331055\nINFO:root:14: Epoch 3 train loss: 32394.16796875\nINFO:root:7: Epoch 3 train loss: 2202.685028076172\nINFO:root:12: Epoch 3 train loss: 19968.9296875\nINFO:root:8: Epoch 3 train loss: 813276.1897583008\nINFO:root:0: Epoch 3 train loss: 10273.317016601562\nINFO:root:1: Epoch 3 train loss: 1352285.0576171875\nINFO:root:10: Epoch 3 train loss: 1178.9862365722656\nINFO:root:21: Epoch 3 train loss: 12556.484375\nINFO:root:23: Epoch 3 train loss: 1784.478744506836\nINFO:root:0: Epoch 3 validation loss: 246826.30078998246\nINFO:root:5: Epoch 4 train loss: 22113.370971679688\nINFO:root:17: Epoch 4 train loss: 7316.79736328125\nINFO:root:22: Epoch 4 train loss: 858.7344970703125\nINFO:root:21: Epoch 4 train loss: 3818.0845489501953\nINFO:root:23: Epoch 4 train loss: 17821.904296875\nINFO:root:2: Epoch 4 train loss: 345.2616195678711\nINFO:root:1: Epoch 4 train loss: 22830.410400390625\nINFO:root:8: Epoch 4 train loss: 7199.857307434082\nINFO:root:19: Epoch 4 train loss: 2604974.326171875\nINFO:root:4: Epoch 4 train loss: 6887.525390625\nINFO:root:11: Epoch 4 train loss: 41737.4853515625\nINFO:root:12: Epoch 4 train loss: 165410.892578125\nINFO:root:24: Epoch 4 train loss: 10907.979858398438\nINFO:root:26: Epoch 4 train loss: 5229.225967407227\nINFO:root:3: Epoch 4 train loss: 1437795.7942504883\nINFO:root:20: Epoch 4 train loss: 4422.235656738281\nINFO:root:25: Epoch 4 train loss: 1527168.44921875\nINFO:root:6: Epoch 4 train loss: 1203635.9838867188\nINFO:root:13: Epoch 4 train loss: 1914628.6826171875\nINFO:root:14: Epoch 4 train loss: 36017.393798828125\nINFO:root:15: Epoch 4 train loss: 10461.08999633789\nINFO:root:16: Epoch 4 train loss: 496127.7265625\nINFO:root:18: Epoch 4 train loss: 3629.3485412597656\nINFO:root:0: Epoch 4 train loss: 1239.601806640625\nINFO:root:7: Epoch 4 train loss: 870995.1030273438\nINFO:root:10: Epoch 4 train loss: 12191.45703125\nINFO:root:9: Epoch 4 train loss: 11347.736099243164\nINFO:root:0: Epoch 4 validation loss: 246816.34935242875\nINFO:root:23: Epoch 5 train loss: 1397050.6009521484\nINFO:root:4: Epoch 5 train loss: 3495.4760131835938\nINFO:root:11: Epoch 5 train loss: 1200631.6431884766\nINFO:root:26: Epoch 5 train loss: 4329.507080078125\nINFO:root:5: Epoch 5 train loss: 6980.060302734375\nINFO:root:10: Epoch 5 train loss: 14442.31088256836\nINFO:root:3: Epoch 5 train loss: 867782.9272460938\nINFO:root:9: Epoch 5 train loss: 1425890.83984375\nINFO:root:2: Epoch 5 train loss: 8702.874053955078\nINFO:root:12: Epoch 5 train loss: 13364.325256347656\nINFO:root:17: Epoch 5 train loss: 1444323.2827148438\nINFO:root:22: Epoch 5 train loss: 862174.0723571777\nINFO:root:18: Epoch 5 train loss: 3057416.6416015625\nINFO:root:16: Epoch 5 train loss: 2871.092529296875\nINFO:root:21: Epoch 5 train loss: 725.41796875\nINFO:root:20: Epoch 5 train loss: 1201075.2111816406\nINFO:root:25: Epoch 5 train loss: 497.5160675048828\nINFO:root:19: Epoch 5 train loss: 13877.143798828125\nINFO:root:0: Epoch 5 train loss: 872018.819519043\nINFO:root:13: Epoch 5 train loss: 871345.0029296875\nINFO:root:24: Epoch 5 train loss: 158465.40258789062\nINFO:root:15: Epoch 5 train loss: 1679710.0126953125\nINFO:root:8: Epoch 5 train loss: 1858146.330078125\nINFO:root:14: Epoch 5 train loss: 18076.23388671875\nINFO:root:7: Epoch 5 train loss: 57630.49609375\nINFO:root:6: Epoch 5 train loss: 820910.572265625\nINFO:root:1: Epoch 5 train loss: 19546.865814208984\nINFO:root:0: Epoch 5 validation loss: 246806.32849723974\n", "seconds": 14.575392007827759, "batch_size": 64, "nodes": 9, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 2 batches\n2: 2 batches\n3 Start Epoch 0\n4 Start Epoch 0\n4: 2 batches\n3: 2 batches\n27 Start Epoch 0\n28 Start Epoch 0\n27: 2 batches\n28: 2 batches\n11 Start Epoch 0\n6 Start Epoch 0\n11: 2 batches\n6: 2 batches\n19 Start Epoch 0\n12 Start Epoch 0\n20 Start Epoch 0\n5 Start Epoch 0\n19: 2 batches\n20: 2 batches\n5: 2 batches\n12: 2 batches\n29 Start Epoch 0\n29: 2 batches\n21 Start Epoch 0\n22 Start Epoch 0\n21: 2 batches\n13 Start Epoch 0\n13: 2 batches\n14 Start Epoch 0\n14: 2 batches\n22: 2 batches\n24 Start Epoch 0\n15 Start Epoch 0\n24: 2 batches\n16 Start Epoch 0\n7 Start Epoch 0\n23 Start Epoch 0\n16: 2 batches\n8 Start Epoch 0\n7: 2 batches\n15: 2 batches\n8: 2 batches\n23: 2 batches\n18 Start Epoch 0\n18: 2 batches\n17 Start Epoch 0\n17: 2 batches\n26 Start Epoch 0\n10 Start Epoch 0\n10: 2 batches\n25 Start Epoch 0\n25: 2 batches\n9 Start Epoch 0\n26: 2 batches\n9: 2 batches\n10 Start Epoch 1\n29 Start Epoch 1\n29: 2 batches\n24 Start Epoch 1\n10: 2 batches\n8 Start Epoch 1\n17 Start Epoch 1\n7 Start Epoch 1\n17: 2 batches\n24: 2 batches\n9 Start Epoch 1\n7: 2 batches\n3 Start Epoch 1\n8: 2 batches\n26 Start Epoch 1\n4 Start Epoch 1\n9: 2 batches\n26: 2 batches\n4: 2 batches\n3: 2 batches\n5 Start Epoch 1\n5: 2 batches\n1 Start Epoch 1\n12 Start Epoch 1\n18 Start Epoch 1\n12: 2 batches\n16 Start Epoch 1\n20 Start Epoch 1\n16: 2 batches\n15 Start Epoch 1\n20: 2 batches\n18: 2 batches\n22 Start Epoch 1\n22: 2 batches\n15: 2 batches\n23 Start Epoch 1\n23: 2 batches\n1: 2 batches\n13 Start Epoch 1\n13: 2 batches\n21 Start Epoch 1\n21: 2 batches\n2 Start Epoch 1\n2: 2 batches\n14 Start Epoch 1\n14: 2 batches\n19 Start Epoch 1\n19: 2 batches\n11 Start Epoch 1\n25 Start Epoch 1\n25: 2 batches\n11: 2 batches\n6 Start Epoch 1\n28 Start Epoch 1\n6: 2 batches\n27 Start Epoch 1\n27: 2 batches\n28: 2 batches\n0 Start Epoch 1\n0: 2 batches\n29 Start Epoch 2\n28 Start Epoch 2\n29: 2 batches\n22 Start Epoch 2\n22: 2 batches\n5 Start Epoch 2\n5: 2 batches\n10 Start Epoch 2\n10: 2 batches\n28: 2 batches\n27 Start Epoch 2\n21 Start Epoch 2\n27: 2 batches\n26 Start Epoch 2\n21: 2 batches\n17 Start Epoch 2\n17: 2 batches\n25 Start Epoch 2\n11 Start Epoch 2\n11: 2 batches\n26: 2 batches\n25: 2 batches\n18 Start Epoch 2\n19 Start Epoch 2\n19: 2 batches\n20 Start Epoch 2\n20: 2 batches\n3 Start Epoch 2\n6 Start Epoch 2\n18: 2 batches\n4 Start Epoch 2\n6: 2 batches\n3: 2 batches\n12 Start Epoch 2\n4: 2 batches\n14 Start Epoch 2\n14: 2 batches\n12: 2 batches\n9 Start Epoch 2\n13 Start Epoch 2\n15 Start Epoch 2\n16 Start Epoch 2\n13: 2 batches\n24 Start Epoch 2\n16: 2 batches\n15: 2 batches\n24: 2 batches\n8 Start Epoch 2\n7 Start Epoch 2\n8: 2 batches\n7: 2 batches\n1 Start Epoch 2\n1: 2 batches\n2 Start Epoch 2\n2: 2 batches\n9: 2 batches\n23 Start Epoch 2\n23: 2 batches\n0 Start Epoch 2\n0: 2 batches\n28 Start Epoch 3\n29 Start Epoch 3\n29: 2 batches\n28: 2 batches\n22 Start Epoch 3\n22: 2 batches\n10 Start Epoch 3\n10: 2 batches\n27 Start Epoch 3\n27: 2 batches\n11 Start Epoch 3\n11: 2 batches\n26 Start Epoch 3\n26: 2 batches\n6 Start Epoch 3\n21 Start Epoch 3\n21: 2 batches\n17 Start Epoch 3\n25 Start Epoch 3\n6: 2 batches\n25: 2 batches\n8 Start Epoch 3\n18 Start Epoch 3\n7 Start Epoch 3\n19 Start Epoch 3\n19: 2 batches\n14 Start Epoch 3\n8: 2 batches\n20 Start Epoch 3\n7: 2 batches\n20: 2 batches\n12 Start Epoch 3\n13 Start Epoch 3\n13: 2 batches\n18: 2 batches\n14: 2 batches\n12: 2 batches\n17: 2 batches\n5 Start Epoch 3\n24 Start Epoch 3\n24: 2 batches\n16 Start Epoch 3\n15 Start Epoch 3\n16: 2 batches\n15: 2 batches\n5: 2 batches\n4 Start Epoch 3\n4: 2 batches\n1 Start Epoch 3\n1: 2 batches\n2 Start Epoch 3\n2: 2 batches\n23 Start Epoch 3\n23: 2 batches\n9 Start Epoch 3\n9: 2 batches\n3 Start Epoch 3\n3: 2 batches\n0 Start Epoch 3\n0: 2 batches\n10 Start Epoch 4\n5 Start Epoch 4\n11 Start Epoch 4\n11: 2 batches\n29 Start Epoch 4\n10: 2 batches\n29: 2 batches\n5: 2 batches\n22 Start Epoch 4\n27 Start Epoch 4\n22: 2 batches\n27: 2 batches\n28 Start Epoch 4\n23 Start Epoch 4\n28: 2 batches\n23: 2 batches\n1 Start Epoch 4\n1: 2 batches\n26 Start Epoch 4\n9 Start Epoch 4\n12 Start Epoch 4\n26: 2 batches\n3 Start Epoch 4\n9: 2 batches\n12: 2 batches\n4 Start Epoch 4\n8 Start Epoch 4\n20 Start Epoch 4\n25 Start Epoch 4\n3: 2 batches\n7 Start Epoch 4\n19 Start Epoch 4\n25: 2 batches\n4: 2 batches\n8: 2 batches\n20: 2 batches\n7: 2 batches\n19: 2 batches\n24 Start Epoch 4\n6 Start Epoch 4\n18 Start Epoch 4\n24: 2 batches\n6: 2 batches\n18: 2 batches\n2 Start Epoch 4\n2: 2 batches\n21 Start Epoch 4\n21: 2 batches\n14 Start Epoch 4\n14: 2 batches\n15 Start Epoch 4\n13 Start Epoch 4\n16 Start Epoch 4\n15: 2 batches\n13: 2 batches\n16: 2 batches\n17 Start Epoch 4\n17: 2 batches\n0 Start Epoch 4\n0: 2 batches\n11 Start Epoch 5\n11: 2 batches\n29 Start Epoch 5\n29: 2 batches\n3 Start Epoch 5\n3: 2 batches\n5 Start Epoch 5\n21 Start Epoch 5\n5: 2 batches\n22 Start Epoch 5\n21: 2 batches\n22: 2 batches\n14 Start Epoch 5\n14: 2 batches\n27 Start Epoch 5\n27: 2 batches\n15 Start Epoch 5\n15: 2 batches\n28 Start Epoch 5\n7 Start Epoch 5\n28: 2 batches\n7: 2 batches\n8 Start Epoch 5\n16 Start Epoch 5\n16: 2 batches\n6 Start Epoch 5\n19 Start Epoch 5\n6: 2 batches\n20 Start Epoch 5\n26 Start Epoch 5\n8: 2 batches\n19: 2 batches\n24 Start Epoch 5\n20: 2 batches\n26: 2 batches\n24: 2 batches\n25 Start Epoch 5\n25: 2 batches\n17 Start Epoch 5\n1 Start Epoch 5\n1: 2 batches\n17: 2 batches\n2 Start Epoch 5\n2: 2 batches\n12 Start Epoch 5\n13 Start Epoch 5\n13: 2 batches\n12: 2 batches\n23 Start Epoch 5\n23: 2 batches\n4 Start Epoch 5\n4: 2 batches\n9 Start Epoch 5\n9: 2 batches\n10 Start Epoch 5\n10: 2 batches\n18 Start Epoch 5\n18: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:8: Epoch 0 train loss: 2901.2481079101562\nINFO:root:29: Epoch 0 train loss: 16657.34130859375\nINFO:root:10: Epoch 0 train loss: 18956.357421875\nINFO:root:24: Epoch 0 train loss: 5610.2896728515625\nINFO:root:5: Epoch 0 train loss: 2205940.55078125\nINFO:root:7: Epoch 0 train loss: 5204.267822265625\nINFO:root:17: Epoch 0 train loss: 2963.551025390625\nINFO:root:3: Epoch 0 train loss: 11100.48974609375\nINFO:root:4: Epoch 0 train loss: 10843.72314453125\nINFO:root:9: Epoch 0 train loss: 7089.7137451171875\nINFO:root:26: Epoch 0 train loss: 116777.02392578125\nINFO:root:1: Epoch 0 train loss: 6483.87126159668\nINFO:root:20: Epoch 0 train loss: 499.5015354156494\nINFO:root:12: Epoch 0 train loss: 1834303.9331054688\nINFO:root:16: Epoch 0 train loss: 20625.99560546875\nINFO:root:18: Epoch 0 train loss: 2182068.4375\nINFO:root:15: Epoch 0 train loss: 8737.247314453125\nINFO:root:23: Epoch 0 train loss: 10926.34033203125\nINFO:root:22: Epoch 0 train loss: 37576.168212890625\nINFO:root:13: Epoch 0 train loss: 2247.64306640625\nINFO:root:21: Epoch 0 train loss: 22357.6962890625\nINFO:root:2: Epoch 0 train loss: 999458.5489349365\nINFO:root:0: Epoch 0 train loss: 9079.4169921875\nINFO:root:14: Epoch 0 train loss: 10411.38916015625\nINFO:root:19: Epoch 0 train loss: 345300.99237060547\nINFO:root:11: Epoch 0 train loss: 631099.9428710938\nINFO:root:25: Epoch 0 train loss: 19608.244873046875\nINFO:root:6: Epoch 0 train loss: 1954.4829711914062\nINFO:root:27: Epoch 0 train loss: 11052.030517578125\nINFO:root:28: Epoch 0 train loss: 16924.978759765625\nINFO:root:0: Epoch 0 validation loss: 679412.7360837457\nINFO:root:28: Epoch 1 train loss: 1206833.1748046875\nINFO:root:29: Epoch 1 train loss: 7386.60205078125\nINFO:root:22: Epoch 1 train loss: 19035.63037109375\nINFO:root:21: Epoch 1 train loss: 30063.410278320312\nINFO:root:5: Epoch 1 train loss: 17971.56787109375\nINFO:root:0: Epoch 1 train loss: 2170.3201293945312\nINFO:root:10: Epoch 1 train loss: 20077.52978515625\nINFO:root:27: Epoch 1 train loss: 1853592.419921875\nINFO:root:23: Epoch 1 train loss: 3897.908447265625\nINFO:root:25: Epoch 1 train loss: 5150.600830078125\nINFO:root:17: Epoch 1 train loss: 2523.853759765625\nINFO:root:26: Epoch 1 train loss: 10863.589477539062\nINFO:root:11: Epoch 1 train loss: 6627.129180908203\nINFO:root:19: Epoch 1 train loss: 3450.855712890625\nINFO:root:20: Epoch 1 train loss: 13299.24462890625\nINFO:root:18: Epoch 1 train loss: 964366.8132095337\nINFO:root:6: Epoch 1 train loss: 13936.894775390625\nINFO:root:4: Epoch 1 train loss: 1120750.6960449219\nINFO:root:3: Epoch 1 train loss: 1833.6326904296875\nINFO:root:12: Epoch 1 train loss: 1033714.3283081055\nINFO:root:14: Epoch 1 train loss: 1194.1620330810547\nINFO:root:9: Epoch 1 train loss: 1050.8935089111328\nINFO:root:16: Epoch 1 train loss: 14579.18408203125\nINFO:root:13: Epoch 1 train loss: 1106040.1328125\nINFO:root:15: Epoch 1 train loss: 797.3154296875\nINFO:root:24: Epoch 1 train loss: 2930.155418395996\nINFO:root:7: Epoch 1 train loss: 975761.1311035156\nINFO:root:8: Epoch 1 train loss: 2115702.21875\nINFO:root:1: Epoch 1 train loss: 3293.4298400878906\nINFO:root:2: Epoch 1 train loss: 2259.2638549804688\nINFO:root:0: Epoch 1 validation loss: 679394.504009417\nINFO:root:29: Epoch 2 train loss: 8126.55615234375\nINFO:root:28: Epoch 2 train loss: 18227.44873046875\nINFO:root:22: Epoch 2 train loss: 1823.1986694335938\nINFO:root:10: Epoch 2 train loss: 2812.4487438201904\nINFO:root:27: Epoch 2 train loss: 10287.6357421875\nINFO:root:0: Epoch 2 train loss: 9583.2060546875\nINFO:root:21: Epoch 2 train loss: 1214.3168029785156\nINFO:root:11: Epoch 2 train loss: 1086206.2814331055\nINFO:root:25: Epoch 2 train loss: 633.0521850585938\nINFO:root:26: Epoch 2 train loss: 41227.809326171875\nINFO:root:6: Epoch 2 train loss: 8162.326684951782\nINFO:root:23: Epoch 2 train loss: 2613.173828125\nINFO:root:17: Epoch 2 train loss: 5428.907897949219\nINFO:root:20: Epoch 2 train loss: 4475.543869018555\nINFO:root:8: Epoch 2 train loss: 37945.405822753906\nINFO:root:19: Epoch 2 train loss: 6939.37255859375\nINFO:root:18: Epoch 2 train loss: 5663.717529296875\nINFO:root:13: Epoch 2 train loss: 3341.2786865234375\nINFO:root:7: Epoch 2 train loss: 28413.89453125\nINFO:root:14: Epoch 2 train loss: 1401502.015625\nINFO:root:12: Epoch 2 train loss: 1235.7447319030762\nINFO:root:5: Epoch 2 train loss: 4929.188262939453\nINFO:root:4: Epoch 2 train loss: 2077.0311279296875\nINFO:root:24: Epoch 2 train loss: 3452.9915771484375\nINFO:root:16: Epoch 2 train loss: 813329.2820777893\nINFO:root:15: Epoch 2 train loss: 7575.29638671875\nINFO:root:1: Epoch 2 train loss: 726.7623901367188\nINFO:root:2: Epoch 2 train loss: 5844.7587890625\nINFO:root:9: Epoch 2 train loss: 15891.64176940918\nINFO:root:3: Epoch 2 train loss: 814570.125\nINFO:root:0: Epoch 2 validation loss: 679375.8803559679\nINFO:root:5: Epoch 3 train loss: 2844.8751831054688\nINFO:root:10: Epoch 3 train loss: 24777.509887695312\nINFO:root:11: Epoch 3 train loss: 19332.89881515503\nINFO:root:29: Epoch 3 train loss: 1339.02783203125\nINFO:root:23: Epoch 3 train loss: 1673711.8287353516\nINFO:root:22: Epoch 3 train loss: 4562.718276977539\nINFO:root:27: Epoch 3 train loss: 1761610.1203613281\nINFO:root:28: Epoch 3 train loss: 2526800.4375\nINFO:root:1: Epoch 3 train loss: 37455.5546875\nINFO:root:0: Epoch 3 train loss: 2501.978515625\nINFO:root:8: Epoch 3 train loss: 5086.186706542969\nINFO:root:19: Epoch 3 train loss: 5138.643890380859\nINFO:root:21: Epoch 3 train loss: 4231.3109130859375\nINFO:root:12: Epoch 3 train loss: 16971.461669921875\nINFO:root:26: Epoch 3 train loss: 6353.2861328125\nINFO:root:4: Epoch 3 train loss: 35151.029296875\nINFO:root:9: Epoch 3 train loss: 7898.880142211914\nINFO:root:3: Epoch 3 train loss: 977173.8466796875\nINFO:root:7: Epoch 3 train loss: 2473.1588745117188\nINFO:root:18: Epoch 3 train loss: 14692.909118652344\nINFO:root:6: Epoch 3 train loss: 27224.705017089844\nINFO:root:20: Epoch 3 train loss: 2289.772903442383\nINFO:root:25: Epoch 3 train loss: 7628.155517578125\nINFO:root:24: Epoch 3 train loss: 8050.877746582031\nINFO:root:2: Epoch 3 train loss: 10499.39208984375\nINFO:root:13: Epoch 3 train loss: 17145.733642578125\nINFO:root:17: Epoch 3 train loss: 22972.14896774292\nINFO:root:14: Epoch 3 train loss: 5047.101745605469\nINFO:root:15: Epoch 3 train loss: 19535.96337890625\nINFO:root:16: Epoch 3 train loss: 9588.59765625\nINFO:root:0: Epoch 3 validation loss: 679356.3602224501\nINFO:root:11: Epoch 4 train loss: 4011.6024475097656\nINFO:root:29: Epoch 4 train loss: 10738.044921875\nINFO:root:3: Epoch 4 train loss: 44381.16432952881\nINFO:root:5: Epoch 4 train loss: 7867.73193359375\nINFO:root:22: Epoch 4 train loss: 15190.63916015625\nINFO:root:21: Epoch 4 train loss: 915.5140991210938\nINFO:root:14: Epoch 4 train loss: 18931.1455078125\nINFO:root:27: Epoch 4 train loss: 5110.552734375\nINFO:root:15: Epoch 4 train loss: 5270.114166259766\nINFO:root:28: Epoch 4 train loss: 9780.76611328125\nINFO:root:7: Epoch 4 train loss: 869221.5346679688\nINFO:root:8: Epoch 4 train loss: 2702.3819580078125\nINFO:root:19: Epoch 4 train loss: 2611.5360260009766\nINFO:root:16: Epoch 4 train loss: 11850.735858917236\nINFO:root:20: Epoch 4 train loss: 24382.401123046875\nINFO:root:26: Epoch 4 train loss: 18105.925048828125\nINFO:root:6: Epoch 4 train loss: 13919.744354248047\nINFO:root:24: Epoch 4 train loss: 1349.0680694580078\nINFO:root:25: Epoch 4 train loss: 1985687.5954589844\nINFO:root:17: Epoch 4 train loss: 7210.603271484375\nINFO:root:1: Epoch 4 train loss: 2142.485595703125\nINFO:root:0: Epoch 4 train loss: 6541.02880859375\nINFO:root:2: Epoch 4 train loss: 68524.560546875\nINFO:root:12: Epoch 4 train loss: 949.5256118774414\nINFO:root:13: Epoch 4 train loss: 1575734.8964233398\nINFO:root:23: Epoch 4 train loss: 1435.4169311523438\nINFO:root:4: Epoch 4 train loss: 4345.273681640625\nINFO:root:10: Epoch 4 train loss: 964256.9392089844\nINFO:root:9: Epoch 4 train loss: 11733.728515625\nINFO:root:18: Epoch 4 train loss: 1103.0501098632812\nINFO:root:0: Epoch 4 validation loss: 679335.5699397662\nINFO:root:29: Epoch 5 train loss: 8527.71728515625\nINFO:root:5: Epoch 5 train loss: 340477.10998535156\nINFO:root:21: Epoch 5 train loss: 5241.83292388916\nINFO:root:16: Epoch 5 train loss: 4439.0276222229\nINFO:root:28: Epoch 5 train loss: 1037052.9779052734\nINFO:root:11: Epoch 5 train loss: 34565.220703125\nINFO:root:9: Epoch 5 train loss: 9304.41455078125\nINFO:root:10: Epoch 5 train loss: 10890.4072265625\nINFO:root:18: Epoch 5 train loss: 24663.27197265625\nINFO:root:12: Epoch 5 train loss: 1084307.4083251953\nINFO:root:27: Epoch 5 train loss: 366870.01953125\nINFO:root:6: Epoch 5 train loss: 9235.651428222656\nINFO:root:1: Epoch 5 train loss: 12014.998779296875\nINFO:root:2: Epoch 5 train loss: 2037.0089416503906\nINFO:root:0: Epoch 5 train loss: 631136.078125\nINFO:root:4: Epoch 5 train loss: 1036375.2951965332\nINFO:root:22: Epoch 5 train loss: 5274.442008972168\nINFO:root:3: Epoch 5 train loss: 28403.84619140625\nINFO:root:19: Epoch 5 train loss: 22085.9189453125\nINFO:root:24: Epoch 5 train loss: 1707.8881530761719\nINFO:root:25: Epoch 5 train loss: 4467.736145019531\nINFO:root:26: Epoch 5 train loss: 8458.041015625\nINFO:root:8: Epoch 5 train loss: 16185.9453125\nINFO:root:15: Epoch 5 train loss: 4778.64599609375\nINFO:root:14: Epoch 5 train loss: 81905.5078125\nINFO:root:13: Epoch 5 train loss: 1679.0169677734375\nINFO:root:23: Epoch 5 train loss: 1202.1786041259766\nINFO:root:7: Epoch 5 train loss: 5899.5450439453125\nINFO:root:17: Epoch 5 train loss: 2683.6875610351562\nINFO:root:20: Epoch 5 train loss: 7359.81201171875\nINFO:root:0: Epoch 5 validation loss: 679312.644418531\n", "seconds": 10.225231885910034, "batch_size": 64, "nodes": 10, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n2 Start Epoch 0\n2: 2 batches\n1 Start Epoch 0\n1: 2 batches\n3 Start Epoch 0\n4 Start Epoch 0\n3: 2 batches\n4: 2 batches\n32 Start Epoch 0\n23 Start Epoch 0\n32: 2 batches\n24 Start Epoch 0\n8 Start Epoch 0\n15 Start Epoch 0\n15: 2 batches\n23: 2 batches\n31 Start Epoch 0\n24: 2 batches\n7 Start Epoch 0\n16 Start Epoch 0\n31: 2 batches\n8: 2 batches\n7: 2 batches\n16: 2 batches\n11 Start Epoch 0\n11: 2 batches\n19 Start Epoch 0\n27 Start Epoch 0\n12 Start Epoch 0\n20 Start Epoch 0\n28 Start Epoch 0\n12: 2 batches\n19: 2 batches\n27: 2 batches\n20: 2 batches\n28: 2 batches\n6 Start Epoch 0\n6: 2 batches\n5 Start Epoch 0\n5: 2 batches\n9 Start Epoch 0\n18 Start Epoch 0\n25 Start Epoch 0\n10 Start Epoch 0\n9: 2 batches\n17 Start Epoch 0\n26 Start Epoch 0\n18: 2 batches\n10: 2 batches\n17: 2 batches\n25: 2 batches\n26: 2 batches\n29 Start Epoch 0\n29: 2 batches\n30 Start Epoch 0\n14 Start Epoch 0\n30: 2 batches\n13 Start Epoch 0\n21 Start Epoch 0\n14: 2 batches\n22 Start Epoch 0\n21: 2 batches\n13: 2 batches\n22: 2 batches\n23 Start Epoch 1\n3 Start Epoch 1\n11 Start Epoch 1\n23: 2 batches\n27 Start Epoch 1\n3: 2 batches\n11: 2 batches\n29 Start Epoch 1\n2 Start Epoch 1\n1 Start Epoch 1\n1: 2 batches\n2: 2 batches\n19 Start Epoch 1\n27: 2 batches\n14 Start Epoch 1\n4 Start Epoch 1\n10 Start Epoch 1\n21 Start Epoch 1\n30 Start Epoch 1\n10: 2 batches\n17 Start Epoch 1\n21: 2 batches\n26 Start Epoch 1\n19: 2 batches\n29: 2 batches\n7 Start Epoch 1\n4: 2 batches\n15 Start Epoch 1\n32 Start Epoch 1\n26: 2 batches\n28 Start Epoch 1\n28: 2 batches\n14: 2 batches\n6 Start Epoch 1\n5 Start Epoch 1\n9 Start Epoch 1\n15: 2 batches\n22 Start Epoch 1\n32: 2 batches\n13 Start Epoch 1\n7: 2 batches\n18 Start Epoch 1\n13: 2 batches\n6: 2 batches\n5: 2 batches\n17: 2 batches\n22: 2 batches\n31 Start Epoch 1\n18: 2 batches\n12 Start Epoch 1\n30: 2 batches\n12: 2 batches\n31: 2 batches\n16 Start Epoch 1\n24 Start Epoch 1\n20 Start Epoch 1\n8 Start Epoch 1\n16: 2 batches\n24: 2 batches\n20: 2 batches\n8: 2 batches\n25 Start Epoch 1\n25: 2 batches\n9: 2 batches\n0 Start Epoch 1\n0: 2 batches\n3 Start Epoch 2\n3: 2 batches\n11 Start Epoch 2\n11: 2 batches\n4 Start Epoch 2\n4: 2 batches\n21 Start Epoch 2\n1 Start Epoch 2\n2 Start Epoch 2\n2: 2 batches\n1: 2 batches\n21: 2 batches\n9 Start Epoch 2\n15 Start Epoch 2\n25 Start Epoch 2\n29 Start Epoch 2\n29: 2 batches\n9: 2 batches\n15: 2 batches\n22 Start Epoch 2\n30 Start Epoch 2\n25: 2 batches\n7 Start Epoch 2\n22: 2 batches\n31 Start Epoch 2\n10 Start Epoch 2\n17 Start Epoch 2\n31: 2 batches\n24 Start Epoch 2\n13 Start Epoch 2\n8 Start Epoch 2\n18 Start Epoch 2\n27 Start Epoch 2\n12 Start Epoch 2\n6 Start Epoch 2\n10: 2 batches\n17: 2 batches\n30: 2 batches\n24: 2 batches\n20 Start Epoch 2\n27: 2 batches\n14 Start Epoch 2\n8: 2 batches\n18: 2 batches\n13: 2 batches\n7: 2 batches\n16 Start Epoch 2\n14: 2 batches\n6: 2 batches\n16: 2 batches\n23 Start Epoch 2\n20: 2 batches\n12: 2 batches\n19 Start Epoch 2\n28 Start Epoch 2\n19: 2 batches\n28: 2 batches\n26 Start Epoch 2\n32 Start Epoch 2\n5 Start Epoch 2\n32: 2 batches\n26: 2 batches\n5: 2 batches\n23: 2 batches\n0 Start Epoch 2\n0: 2 batches\n23 Start Epoch 3\n23: 2 batches\n25 Start Epoch 3\n26 Start Epoch 3\n25: 2 batches\n27 Start Epoch 3\n29 Start Epoch 3\n10 Start Epoch 3\n10: 2 batches\n3 Start Epoch 3\n3: 2 batches\n2 Start Epoch 3\n2: 2 batches\n26: 2 batches\n29: 2 batches\n4 Start Epoch 3\n9 Start Epoch 3\n21 Start Epoch 3\n27: 2 batches\n28 Start Epoch 3\n28: 2 batches\n8 Start Epoch 3\n9: 2 batches\n17 Start Epoch 3\n21: 2 batches\n31 Start Epoch 3\n32 Start Epoch 3\n19 Start Epoch 3\n12 Start Epoch 3\n7 Start Epoch 3\n5 Start Epoch 3\n18 Start Epoch 3\n13 Start Epoch 3\n8: 2 batches\n5: 2 batches\n11 Start Epoch 3\n15 Start Epoch 3\n22 Start Epoch 3\n32: 2 batches\n19: 2 batches\n13: 2 batches\n7: 2 batches\n4: 2 batches\n11: 2 batches\n17: 2 batches\n22: 2 batches\n31: 2 batches\n18: 2 batches\n14 Start Epoch 3\n15: 2 batches\n1 Start Epoch 3\n1: 2 batches\n16 Start Epoch 3\n20 Start Epoch 3\n12: 2 batches\n16: 2 batches\n20: 2 batches\n14: 2 batches\n30 Start Epoch 3\n24 Start Epoch 3\n6 Start Epoch 3\n24: 2 batches\n6: 2 batches\n30: 2 batches\n0 Start Epoch 3\n0: 2 batches\n32 Start Epoch 4\n32: 2 batches\n2 Start Epoch 4\n1 Start Epoch 4\n26 Start Epoch 4\n23 Start Epoch 4\n29 Start Epoch 4\n23: 2 batches\n26: 2 batches\n20 Start Epoch 4\n29: 2 batches\n20: 2 batches\n5 Start Epoch 4\n10 Start Epoch 4\n3 Start Epoch 4\n3: 2 batches\n19 Start Epoch 4\n2: 2 batches\n10: 2 batches\n19: 2 batches\n5: 2 batches\n1: 2 batches\n11 Start Epoch 4\n27 Start Epoch 4\n12 Start Epoch 4\n8 Start Epoch 4\n12: 2 batches\n8: 2 batches\n11: 2 batches\n22 Start Epoch 4\n27: 2 batches\n21 Start Epoch 4\n28 Start Epoch 4\n9 Start Epoch 4\n22: 2 batches\n28: 2 batches\n9: 2 batches\n21: 2 batches\n7 Start Epoch 4\n7: 2 batches\n6 Start Epoch 4\n6: 2 batches\n14 Start Epoch 4\n14: 2 batches\n13 Start Epoch 4\n13: 2 batches\n16 Start Epoch 4\n30 Start Epoch 4\n15 Start Epoch 4\n30: 2 batches\n15: 2 batches\n17 Start Epoch 4\n17: 2 batches\n16: 2 batches\n31 Start Epoch 4\n31: 2 batches\n25 Start Epoch 4\n25: 2 batches\n4 Start Epoch 4\n4: 2 batches\n18 Start Epoch 4\n18: 2 batches\n24 Start Epoch 4\n24: 2 batches\n0 Start Epoch 4\n0: 2 batches\n10 Start Epoch 5\n11 Start Epoch 5\n10: 2 batches\n11: 2 batches\n9 Start Epoch 5\n15 Start Epoch 5\n9: 2 batches\n15: 2 batches\n12 Start Epoch 5\n14 Start Epoch 5\n27 Start Epoch 5\n12: 2 batches\n27: 2 batches\n23 Start Epoch 5\n13 Start Epoch 5\n7 Start Epoch 5\n7: 2 batches\n5 Start Epoch 5\n13: 2 batches\n5: 2 batches\n14: 2 batches\n8 Start Epoch 5\n4 Start Epoch 5\n4: 2 batches\n21 Start Epoch 5\n3 Start Epoch 5\n21: 2 batches\n3: 2 batches\n8: 2 batches\n23: 2 batches\n32 Start Epoch 5\n28 Start Epoch 5\n6 Start Epoch 5\n32: 2 batches\n25 Start Epoch 5\n28: 2 batches\n6: 2 batches\n25: 2 batches\n29 Start Epoch 5\n26 Start Epoch 5\n26: 2 batches\n20 Start Epoch 5\n18 Start Epoch 5\n18: 2 batches\n20: 2 batches\n19 Start Epoch 5\n31 Start Epoch 5\n19: 2 batches\n16 Start Epoch 5\n29: 2 batches\n16: 2 batches\n30 Start Epoch 5\n30: 2 batches\n31: 2 batches\n24 Start Epoch 5\n17 Start Epoch 5\n24: 2 batches\n17: 2 batches\n1 Start Epoch 5\n1: 2 batches\n22 Start Epoch 5\n22: 2 batches\n2 Start Epoch 5\n2: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:29: Epoch 0 train loss: 6049.0784912109375\nINFO:root:28: Epoch 0 train loss: 12639.9560546875\nINFO:root:3: Epoch 0 train loss: 7705.599945068359\nINFO:root:11: Epoch 0 train loss: 1091.7767486572266\nINFO:root:23: Epoch 0 train loss: 961.0105895996094\nINFO:root:27: Epoch 0 train loss: 14892.428955078125\nINFO:root:19: Epoch 0 train loss: 3796.8184814453125\nINFO:root:1: Epoch 0 train loss: 4849.724884033203\nINFO:root:2: Epoch 0 train loss: 338.86247634887695\nINFO:root:14: Epoch 0 train loss: 4761.481384277344\nINFO:root:7: Epoch 0 train loss: 20001.927750587463\nINFO:root:4: Epoch 0 train loss: 341298.5061035156\nINFO:root:10: Epoch 0 train loss: 875312.6333007812\nINFO:root:17: Epoch 0 train loss: 17359.958526611328\nINFO:root:21: Epoch 0 train loss: 8238.644287109375\nINFO:root:30: Epoch 0 train loss: 7619.285583496094\nINFO:root:6: Epoch 0 train loss: 2421065.7681884766\nINFO:root:15: Epoch 0 train loss: 7637.405267715454\nINFO:root:26: Epoch 0 train loss: 8409.395751953125\nINFO:root:32: Epoch 0 train loss: 2469150.1127929688\nINFO:root:13: Epoch 0 train loss: 348.3711242675781\nINFO:root:5: Epoch 0 train loss: 281420.08251953125\nINFO:root:9: Epoch 0 train loss: 13056.759765625\nINFO:root:22: Epoch 0 train loss: 1965790.8197479248\nINFO:root:18: Epoch 0 train loss: 13003.68994140625\nINFO:root:31: Epoch 0 train loss: 5722.803512573242\nINFO:root:12: Epoch 0 train loss: 17333.136596679688\nINFO:root:0: Epoch 0 train loss: 5160.521240234375\nINFO:root:16: Epoch 0 train loss: 8461.449523925781\nINFO:root:24: Epoch 0 train loss: 1302.15625\nINFO:root:20: Epoch 0 train loss: 25186.439208984375\nINFO:root:8: Epoch 0 train loss: 7700.311790466309\nINFO:root:25: Epoch 0 train loss: 1009051.234375\nINFO:root:0: Epoch 0 validation loss: 2242897.9490136476\nINFO:root:3: Epoch 1 train loss: 119977.62927246094\nINFO:root:11: Epoch 1 train loss: 358902.94140625\nINFO:root:4: Epoch 1 train loss: 343943.35205078125\nINFO:root:21: Epoch 1 train loss: 221.39550399780273\nINFO:root:2: Epoch 1 train loss: 2081.510498046875\nINFO:root:1: Epoch 1 train loss: 2504.611831665039\nINFO:root:7: Epoch 1 train loss: 37470.63671875\nINFO:root:9: Epoch 1 train loss: 12958.08808708191\nINFO:root:15: Epoch 1 train loss: 120716.62280273438\nINFO:root:30: Epoch 1 train loss: 10760.7392578125\nINFO:root:25: Epoch 1 train loss: 40468.4873046875\nINFO:root:29: Epoch 1 train loss: 10346.871337890625\nINFO:root:22: Epoch 1 train loss: 904722.662109375\nINFO:root:31: Epoch 1 train loss: 4401.84049987793\nINFO:root:12: Epoch 1 train loss: 12152.175903320312\nINFO:root:8: Epoch 1 train loss: 3569.947769165039\nINFO:root:19: Epoch 1 train loss: 5534.40185546875\nINFO:root:14: Epoch 1 train loss: 1749.5538635253906\nINFO:root:6: Epoch 1 train loss: 6266.95947265625\nINFO:root:18: Epoch 1 train loss: 3490.2346954345703\nINFO:root:13: Epoch 1 train loss: 20054.99201965332\nINFO:root:10: Epoch 1 train loss: 7284.893249511719\nINFO:root:17: Epoch 1 train loss: 15327.240478515625\nINFO:root:24: Epoch 1 train loss: 1368.4652099609375\nINFO:root:20: Epoch 1 train loss: 19149.419921875\nINFO:root:27: Epoch 1 train loss: 12424.637481689453\nINFO:root:16: Epoch 1 train loss: 16583.87060546875\nINFO:root:23: Epoch 1 train loss: 341606.2482910156\nINFO:root:28: Epoch 1 train loss: 8599.694458007812\nINFO:root:32: Epoch 1 train loss: 2212.2286224365234\nINFO:root:5: Epoch 1 train loss: 14368.64013671875\nINFO:root:26: Epoch 1 train loss: 5245.318145751953\nINFO:root:0: Epoch 1 train loss: 2172.4490966796875\nINFO:root:0: Epoch 1 validation loss: 2242867.280077956\nINFO:root:23: Epoch 2 train loss: 11941.78515625\nINFO:root:26: Epoch 2 train loss: 5078.5660400390625\nINFO:root:25: Epoch 2 train loss: 5558.7950439453125\nINFO:root:29: Epoch 2 train loss: 1749.8499450683594\nINFO:root:27: Epoch 2 train loss: 7292.4793701171875\nINFO:root:28: Epoch 2 train loss: 6373.860076904297\nINFO:root:10: Epoch 2 train loss: 7029.0333251953125\nINFO:root:3: Epoch 2 train loss: 3838.69482421875\nINFO:root:0: Epoch 2 train loss: 6086.9658203125\nINFO:root:2: Epoch 2 train loss: 39251.6875\nINFO:root:19: Epoch 2 train loss: 7665.1654052734375\nINFO:root:13: Epoch 2 train loss: 5879.37939453125\nINFO:root:7: Epoch 2 train loss: 21826.86683654785\nINFO:root:4: Epoch 2 train loss: 3094.9038124084473\nINFO:root:9: Epoch 2 train loss: 2667408.755859375\nINFO:root:15: Epoch 2 train loss: 6693.455871582031\nINFO:root:21: Epoch 2 train loss: 1191.9636306762695\nINFO:root:32: Epoch 2 train loss: 5418.370849609375\nINFO:root:17: Epoch 2 train loss: 17037.618408203125\nINFO:root:31: Epoch 2 train loss: 587.1183013916016\nINFO:root:20: Epoch 2 train loss: 5465.6663818359375\nINFO:root:12: Epoch 2 train loss: 838936.5639648438\nINFO:root:8: Epoch 2 train loss: 14641.483642578125\nINFO:root:18: Epoch 2 train loss: 16939.14208984375\nINFO:root:14: Epoch 2 train loss: 21998.20458984375\nINFO:root:5: Epoch 2 train loss: 6121.153564453125\nINFO:root:11: Epoch 2 train loss: 3838.277099609375\nINFO:root:16: Epoch 2 train loss: 347917.8212890625\nINFO:root:22: Epoch 2 train loss: 4011.9632263183594\nINFO:root:1: Epoch 2 train loss: 9937.322143554688\nINFO:root:30: Epoch 2 train loss: 5089.1904296875\nINFO:root:24: Epoch 2 train loss: 2671020.4033203125\nINFO:root:6: Epoch 2 train loss: 981.556396484375\nINFO:root:0: Epoch 2 validation loss: 2242836.402225876\nINFO:root:32: Epoch 3 train loss: 668.973876953125\nINFO:root:1: Epoch 3 train loss: 711.8945770263672\nINFO:root:2: Epoch 3 train loss: 5637.25998210907\nINFO:root:29: Epoch 3 train loss: 3299.811653137207\nINFO:root:23: Epoch 3 train loss: 7067.04035949707\nINFO:root:26: Epoch 3 train loss: 2542278.7157592773\nINFO:root:19: Epoch 3 train loss: 43802.5947265625\nINFO:root:3: Epoch 3 train loss: 3004.1336059570312\nINFO:root:20: Epoch 3 train loss: 3244.760482788086\nINFO:root:10: Epoch 3 train loss: 13492.101371765137\nINFO:root:5: Epoch 3 train loss: 949.4792175292969\nINFO:root:0: Epoch 3 train loss: 22864.013671875\nINFO:root:22: Epoch 3 train loss: 30457.0546875\nINFO:root:27: Epoch 3 train loss: 963898.9389343262\nINFO:root:12: Epoch 3 train loss: 12207.88525390625\nINFO:root:8: Epoch 3 train loss: 1106048.46875\nINFO:root:11: Epoch 3 train loss: 831.8387260437012\nINFO:root:21: Epoch 3 train loss: 12776.825759887695\nINFO:root:28: Epoch 3 train loss: 31768.2392578125\nINFO:root:9: Epoch 3 train loss: 5693.5147705078125\nINFO:root:6: Epoch 3 train loss: 566.0350646972656\nINFO:root:7: Epoch 3 train loss: 18845.279296875\nINFO:root:14: Epoch 3 train loss: 4374.692657470703\nINFO:root:13: Epoch 3 train loss: 875648.3603515625\nINFO:root:16: Epoch 3 train loss: 3182.263885498047\nINFO:root:15: Epoch 3 train loss: 915675.6640625\nINFO:root:17: Epoch 3 train loss: 5509.360595703125\nINFO:root:30: Epoch 3 train loss: 1228.8462753295898\nINFO:root:31: Epoch 3 train loss: 13116.6982421875\nINFO:root:25: Epoch 3 train loss: 2287.0821685791016\nINFO:root:4: Epoch 3 train loss: 633.7760162353516\nINFO:root:18: Epoch 3 train loss: 2776.2435302734375\nINFO:root:24: Epoch 3 train loss: 2350.5283203125\nINFO:root:0: Epoch 3 validation loss: 2242805.4503822913\nINFO:root:11: Epoch 4 train loss: 2544292.7177734375\nINFO:root:10: Epoch 4 train loss: 10432.143798828125\nINFO:root:15: Epoch 4 train loss: 1589.938117980957\nINFO:root:12: Epoch 4 train loss: 997.843017578125\nINFO:root:9: Epoch 4 train loss: 2164.5870361328125\nINFO:root:14: Epoch 4 train loss: 2341443.25\nINFO:root:13: Epoch 4 train loss: 84882.88793945312\nINFO:root:8: Epoch 4 train loss: 900.9390335083008\nINFO:root:27: Epoch 4 train loss: 820743.4526367188\nINFO:root:7: Epoch 4 train loss: 1101721.5079345703\nINFO:root:23: Epoch 4 train loss: 3530.8846435546875\nINFO:root:5: Epoch 4 train loss: 6139.185546875\nINFO:root:4: Epoch 4 train loss: 814296.68409729\nINFO:root:21: Epoch 4 train loss: 7820.31787109375\nINFO:root:3: Epoch 4 train loss: 19644.0107421875\nINFO:root:32: Epoch 4 train loss: 19768.162109375\nINFO:root:25: Epoch 4 train loss: 2388.041229248047\nINFO:root:28: Epoch 4 train loss: 2368269.767425537\nINFO:root:26: Epoch 4 train loss: 4811.68994140625\nINFO:root:29: Epoch 4 train loss: 4336.175491333008\nINFO:root:6: Epoch 4 train loss: 125724.94498443604\nINFO:root:19: Epoch 4 train loss: 9414.386474609375\nINFO:root:18: Epoch 4 train loss: 7052.800720214844\nINFO:root:20: Epoch 4 train loss: 810.9727783203125\nINFO:root:16: Epoch 4 train loss: 566.8984375\nINFO:root:31: Epoch 4 train loss: 829.0740051269531\nINFO:root:0: Epoch 4 train loss: 9523.63671875\nINFO:root:30: Epoch 4 train loss: 92800.30517578125\nINFO:root:24: Epoch 4 train loss: 2799.4937744140625\nINFO:root:17: Epoch 4 train loss: 6931.0335693359375\nINFO:root:1: Epoch 4 train loss: 120438.58048629761\nINFO:root:22: Epoch 4 train loss: 11319.43359375\nINFO:root:2: Epoch 4 train loss: 10126.853271484375\nINFO:root:0: Epoch 4 validation loss: 2242773.5594492275\nINFO:root:24: Epoch 5 train loss: 112886.10293579102\nINFO:root:18: Epoch 5 train loss: 500.01224517822266\nINFO:root:17: Epoch 5 train loss: 8230.977155685425\nINFO:root:20: Epoch 5 train loss: 24049.21923828125\nINFO:root:13: Epoch 5 train loss: 4526.318817138672\nINFO:root:12: Epoch 5 train loss: 3027.1165771484375\nINFO:root:14: Epoch 5 train loss: 360241.841796875\nINFO:root:15: Epoch 5 train loss: 9145.300537109375\nINFO:root:29: Epoch 5 train loss: 11707.856811523438\nINFO:root:16: Epoch 5 train loss: 26202.828125\nINFO:root:27: Epoch 5 train loss: 2462347.4521484375\nINFO:root:28: Epoch 5 train loss: 3456.434814453125\nINFO:root:5: Epoch 5 train loss: 8083.27197265625\nINFO:root:23: Epoch 5 train loss: 36422.306732177734\nINFO:root:3: Epoch 5 train loss: 1010.5083618164062\nINFO:root:26: Epoch 5 train loss: 15232.582885742188\nINFO:root:30: Epoch 5 train loss: 3328.3251972198486\nINFO:root:25: Epoch 5 train loss: 12540.351318359375\nINFO:root:32: Epoch 5 train loss: 18120.819091796875\nINFO:root:31: Epoch 5 train loss: 3168.4688110351562\nINFO:root:7: Epoch 5 train loss: 11125.318359375\nINFO:root:4: Epoch 5 train loss: 24442.2294921875\nINFO:root:6: Epoch 5 train loss: 12548.498046875\nINFO:root:22: Epoch 5 train loss: 3540.395538330078\nINFO:root:1: Epoch 5 train loss: 7524.848327636719\nINFO:root:11: Epoch 5 train loss: 290437.1259765625\nINFO:root:19: Epoch 5 train loss: 1015995.0244140625\nINFO:root:2: Epoch 5 train loss: 2431.741958618164\nINFO:root:21: Epoch 5 train loss: 15180.04345703125\nINFO:root:0: Epoch 5 train loss: 15614.545288085938\nINFO:root:10: Epoch 5 train loss: 26547.580078125\nINFO:root:9: Epoch 5 train loss: 13182.49203491211\nINFO:root:8: Epoch 5 train loss: 2669972.7880859375\nINFO:root:0: Epoch 5 validation loss: 2242739.487404562\n", "seconds": 10.61322808265686, "batch_size": 64, "nodes": 11, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 2 batches\n2: 2 batches\n35 Start Epoch 0\n3 Start Epoch 0\n4 Start Epoch 0\n3: 2 batches\n4: 2 batches\n35: 2 batches\n24 Start Epoch 0\n24: 2 batches\n5 Start Epoch 0\n5: 2 batches\n23 Start Epoch 0\n32 Start Epoch 0\n23: 2 batches\n31 Start Epoch 0\n32: 2 batches\n31: 2 batches\n15 Start Epoch 0\n6 Start Epoch 0\n16 Start Epoch 0\n7 Start Epoch 0\n15: 2 batches\n7: 2 batches\n16: 2 batches\n6: 2 batches\n9 Start Epoch 0\n10 Start Epoch 0\n10: 2 batches\n8 Start Epoch 0\n9: 2 batches\n18 Start Epoch 0\n8: 2 batches\n26 Start Epoch 0\n17 Start Epoch 0\n18: 2 batches\n28 Start Epoch 0\n34 Start Epoch 0\n25 Start Epoch 0\n17: 2 batches\n26: 2 batches\n27 Start Epoch 0\n33 Start Epoch 0\n27: 2 batches\n34: 2 batches\n25: 2 batches\n33: 2 batches\n28: 2 batches\n12 Start Epoch 0\n11 Start Epoch 0\n12: 2 batches\n11: 2 batches\n19 Start Epoch 0\n29 Start Epoch 0\n20 Start Epoch 0\n29: 2 batches\n20: 2 batches\n19: 2 batches\n13 Start Epoch 0\n30 Start Epoch 0\n21 Start Epoch 0\n13: 2 batches\n22 Start Epoch 0\n30: 2 batches\n14 Start Epoch 0\n22: 2 batches\n14: 2 batches\n21: 2 batches\n3 Start Epoch 1\n3: 2 batches\n4 Start Epoch 1\n28 Start Epoch 1\n4: 2 batches\n28: 2 batches\n23 Start Epoch 1\n9 Start Epoch 1\n9: 2 batches\n23: 2 batches\n29 Start Epoch 1\n29: 2 batches\n11 Start Epoch 1\n11: 2 batches\n10 Start Epoch 1\n10: 2 batches\n34 Start Epoch 1\n34: 2 batches\n6 Start Epoch 1\n26 Start Epoch 1\n26: 2 batches\n1 Start Epoch 1\n1: 2 batches\n35 Start Epoch 1\n21 Start Epoch 1\n6: 2 batches\n35: 2 batches\n20 Start Epoch 1\n30 Start Epoch 1\n22 Start Epoch 1\n20: 2 batches\n32 Start Epoch 1\n21: 2 batches\n8 Start Epoch 1\n32: 2 batches\n22: 2 batches\n13 Start Epoch 1\n16 Start Epoch 1\n31 Start Epoch 1\n7 Start Epoch 1\n14 Start Epoch 1\n15 Start Epoch 1\n13: 2 batches\n15: 2 batches\n31: 2 batches\n8: 2 batches\n30: 2 batches\n7: 2 batches\n14: 2 batches\n16: 2 batches\n12 Start Epoch 1\n12: 2 batches\n27 Start Epoch 1\n27: 2 batches\n24 Start Epoch 1\n24: 2 batches\n25 Start Epoch 1\n33 Start Epoch 1\n33: 2 batches\n25: 2 batches\n19 Start Epoch 1\n18 Start Epoch 1\n18: 2 batches\n19: 2 batches\n17 Start Epoch 1\n17: 2 batches\n5 Start Epoch 1\n5: 2 batches\n2 Start Epoch 1\n2: 2 batches\n0 Start Epoch 1\n0: 2 batches\n23 Start Epoch 2\n23: 2 batches\n17 Start Epoch 2\n17: 2 batches\n29 Start Epoch 2\n28 Start Epoch 2\n28: 2 batches\n27 Start Epoch 2\n29: 2 batches\n27: 2 batches\n10 Start Epoch 2\n11 Start Epoch 2\n10: 2 batches\n11: 2 batches\n9 Start Epoch 2\n9: 2 batches\n18 Start Epoch 2\n18: 2 batches\n26 Start Epoch 2\n21 Start Epoch 2\n13 Start Epoch 2\n21: 2 batches\n14 Start Epoch 2\n26: 2 batches\n20 Start Epoch 2\n13: 2 batches\n20: 2 batches\n14: 2 batches\n15 Start Epoch 2\n16 Start Epoch 2\n15: 2 batches\n32 Start Epoch 2\n30 Start Epoch 2\n32: 2 batches\n30: 2 batches\n31 Start Epoch 2\n16: 2 batches\n31: 2 batches\n8 Start Epoch 2\n8: 2 batches\n19 Start Epoch 2\n24 Start Epoch 2\n19: 2 batches\n4 Start Epoch 2\n5 Start Epoch 2\n33 Start Epoch 2\n4: 2 batches\n24: 2 batches\n5: 2 batches\n3 Start Epoch 2\n3: 2 batches\n35 Start Epoch 2\n6 Start Epoch 2\n35: 2 batches\n6: 2 batches\n7 Start Epoch 2\n7: 2 batches\n1 Start Epoch 2\n1: 2 batches\n34 Start Epoch 2\n33: 2 batches\n34: 2 batches\n25 Start Epoch 2\n25: 2 batches\n2 Start Epoch 2\n2: 2 batches\n22 Start Epoch 2\n22: 2 batches\n12 Start Epoch 2\n12: 2 batches\n0 Start Epoch 2\n0: 2 batches\n10 Start Epoch 3\n4 Start Epoch 3\n22 Start Epoch 3\n10: 2 batches\n4: 2 batches\n22: 2 batches\n3 Start Epoch 3\n21 Start Epoch 3\n11 Start Epoch 3\n21: 2 batches\n11: 2 batches\n3: 2 batches\n5 Start Epoch 3\n8 Start Epoch 3\n12 Start Epoch 3\n8: 2 batches\n26 Start Epoch 3\n5: 2 batches\n12: 2 batches\n25 Start Epoch 3\n17 Start Epoch 3\n25: 2 batches\n16 Start Epoch 3\n28 Start Epoch 3\n28: 2 batches\n30 Start Epoch 3\n26: 2 batches\n17: 2 batches\n32 Start Epoch 3\n16: 2 batches\n34 Start Epoch 3\n35 Start Epoch 3\n18 Start Epoch 3\n32: 2 batches\n20 Start Epoch 3\n31 Start Epoch 3\n29 Start Epoch 3\n29: 2 batches\n33 Start Epoch 3\n30: 2 batches\n27 Start Epoch 3\n27: 2 batches\n34: 2 batches\n20: 2 batches\n33: 2 batches\n18: 2 batches\n31: 2 batches\n35: 2 batches\n19 Start Epoch 3\n19: 2 batches\n9 Start Epoch 3\n9: 2 batches\n13 Start Epoch 3\n24 Start Epoch 3\n14 Start Epoch 3\n13: 2 batches\n24: 2 batches\n14: 2 batches\n7 Start Epoch 3\n6 Start Epoch 3\n7: 2 batches\n2 Start Epoch 3\n2: 2 batches\n6: 2 batches\n23 Start Epoch 3\n23: 2 batches\n1 Start Epoch 3\n1: 2 batches\n15 Start Epoch 3\n15: 2 batches\n0 Start Epoch 3\n0: 2 batches\n32 Start Epoch 4\n32: 2 batches\n27 Start Epoch 4\n27: 2 batches\n22 Start Epoch 4\n10 Start Epoch 4\n22: 2 batches\n10: 2 batches\n28 Start Epoch 4\n28: 2 batches\n5 Start Epoch 4\n5: 2 batches\n15 Start Epoch 4\n18 Start Epoch 4\n30 Start Epoch 4\n23 Start Epoch 4\n14 Start Epoch 4\n14: 2 batches\n25 Start Epoch 4\n15: 2 batches\n11 Start Epoch 4\n18: 2 batches\n30: 2 batches\n23: 2 batches\n6 Start Epoch 4\n11: 2 batches\n34 Start Epoch 4\n8 Start Epoch 4\n17 Start Epoch 4\n35 Start Epoch 4\n31 Start Epoch 4\n21 Start Epoch 4\n8: 2 batches\n13 Start Epoch 4\n26 Start Epoch 4\n26: 2 batches\n31: 2 batches\n21: 2 batches\n6: 2 batches\n13: 2 batches\n24 Start Epoch 4\n17: 2 batches\n34: 2 batches\n35: 2 batches\n24: 2 batches\n16 Start Epoch 4\n33 Start Epoch 4\n12 Start Epoch 4\n25: 2 batches\n33: 2 batches\n12: 2 batches\n16: 2 batches\n9 Start Epoch 4\n7 Start Epoch 4\n9: 2 batches\n19 Start Epoch 4\n7: 2 batches\n19: 2 batches\n20 Start Epoch 4\n20: 2 batches\n29 Start Epoch 4\n29: 2 batches\n2 Start Epoch 4\n2: 2 batches\n1 Start Epoch 4\n1: 2 batches\n3 Start Epoch 4\n3: 2 batches\n4 Start Epoch 4\n4: 2 batches\n0 Start Epoch 4\n0: 2 batches\n4 Start Epoch 5\n4: 2 batches\n29 Start Epoch 5\n23 Start Epoch 5\n29: 2 batches\n23: 2 batches\n3 Start Epoch 5\n3: 2 batches\n28 Start Epoch 5\n28: 2 batches\n11 Start Epoch 5\n11: 2 batches\n27 Start Epoch 5\n27: 2 batches\n17 Start Epoch 5\n9 Start Epoch 5\n30 Start Epoch 5\n33 Start Epoch 5\n19 Start Epoch 5\n30: 2 batches\n21 Start Epoch 5\n12 Start Epoch 5\n17: 2 batches\n10 Start Epoch 5\n34 Start Epoch 5\n19: 2 batches\n22 Start Epoch 5\n14 Start Epoch 5\n26 Start Epoch 5\n14: 2 batches\n25 Start Epoch 5\n9: 2 batches\n33: 2 batches\n31 Start Epoch 5\n22: 2 batches\n12: 2 batches\n25: 2 batches\n20 Start Epoch 5\n21: 2 batches\n34: 2 batches\n18 Start Epoch 5\n26: 2 batches\n35 Start Epoch 5\n18: 2 batches\n24 Start Epoch 5\n24: 2 batches\n35: 2 batches\n20: 2 batches\n2 Start Epoch 5\n2: 2 batches\n1 Start Epoch 5\n1: 2 batches\n32 Start Epoch 5\n31: 2 batches\n10: 2 batches\n7 Start Epoch 5\n7: 2 batches\n8 Start Epoch 5\n8: 2 batches\n6 Start Epoch 5\n16 Start Epoch 5\n15 Start Epoch 5\n15: 2 batches\n16: 2 batches\n6: 2 batches\n32: 2 batches\n5 Start Epoch 5\n5: 2 batches\n13 Start Epoch 5\n13: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:3: Epoch 0 train loss: 24061.412536621094\nINFO:root:4: Epoch 0 train loss: 1200653.7123317719\nINFO:root:28: Epoch 0 train loss: 28823.075439453125\nINFO:root:23: Epoch 0 train loss: 33422.01735019684\nINFO:root:9: Epoch 0 train loss: 72220.97351074219\nINFO:root:29: Epoch 0 train loss: 24233.056659698486\nINFO:root:11: Epoch 0 train loss: 14195.991439819336\nINFO:root:10: Epoch 0 train loss: 6482.058349609375\nINFO:root:34: Epoch 0 train loss: 3480324.922729492\nINFO:root:35: Epoch 0 train loss: 3664.8021545410156\nINFO:root:26: Epoch 0 train loss: 11132.089965820312\nINFO:root:30: Epoch 0 train loss: 6212.824605166912\nINFO:root:22: Epoch 0 train loss: 17721.23779296875\nINFO:root:6: Epoch 0 train loss: 2328.804916381836\nINFO:root:32: Epoch 0 train loss: 11793.526397705078\nINFO:root:21: Epoch 0 train loss: 155.89856719970703\nINFO:root:1: Epoch 0 train loss: 2409.4708709716797\nINFO:root:20: Epoch 0 train loss: 11579.510498046875\nINFO:root:31: Epoch 0 train loss: 5507.645093917847\nINFO:root:12: Epoch 0 train loss: 7561.247314453125\nINFO:root:8: Epoch 0 train loss: 118611.94958496094\nINFO:root:14: Epoch 0 train loss: 868724.3935546875\nINFO:root:16: Epoch 0 train loss: 871635.2592773438\nINFO:root:13: Epoch 0 train loss: 2769485.190612793\nINFO:root:15: Epoch 0 train loss: 10309.034469604492\nINFO:root:7: Epoch 0 train loss: 2604.38671875\nINFO:root:27: Epoch 0 train loss: 20147.8125\nINFO:root:24: Epoch 0 train loss: 54.73270320892334\nINFO:root:25: Epoch 0 train loss: 409.5988311767578\nINFO:root:33: Epoch 0 train loss: 4233.3087158203125\nINFO:root:18: Epoch 0 train loss: 6891.499618530273\nINFO:root:19: Epoch 0 train loss: 5355.7998046875\nINFO:root:17: Epoch 0 train loss: 1206033.3345947266\nINFO:root:0: Epoch 0 train loss: 2747.555558204651\nINFO:root:5: Epoch 0 train loss: 424.73584365844727\nINFO:root:2: Epoch 0 train loss: 3119.5719451904297\nINFO:root:0: Epoch 0 validation loss: 41423.87848053731\nINFO:root:23: Epoch 1 train loss: 1405.1175689697266\nINFO:root:27: Epoch 1 train loss: 1048672.7827148438\nINFO:root:17: Epoch 1 train loss: 15449.62890625\nINFO:root:28: Epoch 1 train loss: 124045.02734375\nINFO:root:29: Epoch 1 train loss: 10130.6923828125\nINFO:root:10: Epoch 1 train loss: 18737.580932617188\nINFO:root:11: Epoch 1 train loss: 1373.8201904296875\nINFO:root:9: Epoch 1 train loss: 14585.808227539062\nINFO:root:18: Epoch 1 train loss: 480.56822204589844\nINFO:root:26: Epoch 1 train loss: 985747.7537841797\nINFO:root:14: Epoch 1 train loss: 999497.9277496338\nINFO:root:21: Epoch 1 train loss: 1087874.2934570312\nINFO:root:13: Epoch 1 train loss: 29067.313326239586\nINFO:root:20: Epoch 1 train loss: 3626.915985107422\nINFO:root:16: Epoch 1 train loss: 15699.759033203125\nINFO:root:31: Epoch 1 train loss: 33315.602478027344\nINFO:root:15: Epoch 1 train loss: 1007.3425769805908\nINFO:root:30: Epoch 1 train loss: 207.59238076210022\nINFO:root:32: Epoch 1 train loss: 2048.2405395507812\nINFO:root:19: Epoch 1 train loss: 33066.52297973633\nINFO:root:8: Epoch 1 train loss: 2082068.2818584442\nINFO:root:24: Epoch 1 train loss: 1045480.4099502563\nINFO:root:5: Epoch 1 train loss: 8605.483646392822\nINFO:root:3: Epoch 1 train loss: 3091.2755432128906\nINFO:root:4: Epoch 1 train loss: 967029.9968719482\nINFO:root:33: Epoch 1 train loss: 3484867.806640625\nINFO:root:35: Epoch 1 train loss: 23687.867553710938\nINFO:root:6: Epoch 1 train loss: 1056694.80078125\nINFO:root:7: Epoch 1 train loss: 2978.4503240585327\nINFO:root:1: Epoch 1 train loss: 17249.896942138672\nINFO:root:34: Epoch 1 train loss: 3480076.603881836\nINFO:root:25: Epoch 1 train loss: 1082928.5300292969\nINFO:root:2: Epoch 1 train loss: 591.5978317260742\nINFO:root:0: Epoch 1 train loss: 3242796.7833251953\nINFO:root:22: Epoch 1 train loss: 178.7727374434471\nINFO:root:12: Epoch 1 train loss: 1202118.6377393007\nINFO:root:0: Epoch 1 validation loss: 41420.424315663426\nINFO:root:4: Epoch 2 train loss: 4885.061059951782\nINFO:root:22: Epoch 2 train loss: 1199870.5652151108\nINFO:root:10: Epoch 2 train loss: 865852.6640625\nINFO:root:21: Epoch 2 train loss: 1032100.6220703125\nINFO:root:11: Epoch 2 train loss: 5527.137451171875\nINFO:root:3: Epoch 2 train loss: 963076.3529052734\nINFO:root:5: Epoch 2 train loss: 5154.595458984375\nINFO:root:8: Epoch 2 train loss: 3654303.528442383\nINFO:root:12: Epoch 2 train loss: 861661.1643562317\nINFO:root:26: Epoch 2 train loss: 7388.665296554565\nINFO:root:25: Epoch 2 train loss: 14744.548828125\nINFO:root:16: Epoch 2 train loss: 8266.315185546875\nINFO:root:31: Epoch 2 train loss: 949.4468688964844\nINFO:root:17: Epoch 2 train loss: 21292.434448242188\nINFO:root:32: Epoch 2 train loss: 371.4516906738281\nINFO:root:33: Epoch 2 train loss: 8193.552001953125\nINFO:root:34: Epoch 2 train loss: 1016442.119140625\nINFO:root:20: Epoch 2 train loss: 38257.319580078125\nINFO:root:30: Epoch 2 train loss: 6239.548034667969\nINFO:root:27: Epoch 2 train loss: 1200973.4465332031\nINFO:root:35: Epoch 2 train loss: 17485.587646484375\nINFO:root:19: Epoch 2 train loss: 464.10606384277344\nINFO:root:28: Epoch 2 train loss: 835489.4787597656\nINFO:root:18: Epoch 2 train loss: 1154.5942077636719\nINFO:root:29: Epoch 2 train loss: 8010.407470703125\nINFO:root:0: Epoch 2 train loss: 1982.380615234375\nINFO:root:9: Epoch 2 train loss: 4523981.625\nINFO:root:14: Epoch 2 train loss: 1220.999220609665\nINFO:root:24: Epoch 2 train loss: 3097.67551612854\nINFO:root:13: Epoch 2 train loss: 10531.436767578125\nINFO:root:7: Epoch 2 train loss: 17643.582885742188\nINFO:root:6: Epoch 2 train loss: 16374.175231933594\nINFO:root:2: Epoch 2 train loss: 1085908.6118164062\nINFO:root:23: Epoch 2 train loss: 10448.59033203125\nINFO:root:1: Epoch 2 train loss: 16038.059875488281\nINFO:root:15: Epoch 2 train loss: 1430929.334197998\nINFO:root:0: Epoch 2 validation loss: 41417.019990751025\nINFO:root:32: Epoch 3 train loss: 9762.680969238281\nINFO:root:27: Epoch 3 train loss: 3650884.937942505\nINFO:root:22: Epoch 3 train loss: 119609.98598480225\nINFO:root:10: Epoch 3 train loss: 849.7418518066406\nINFO:root:28: Epoch 3 train loss: 6395.5814208984375\nINFO:root:5: Epoch 3 train loss: 14374.969360351562\nINFO:root:15: Epoch 3 train loss: 861219.7673721313\nINFO:root:11: Epoch 3 train loss: 1043493.0213928223\nINFO:root:33: Epoch 3 train loss: 1239.2260131835938\nINFO:root:18: Epoch 3 train loss: 871418.4003448486\nINFO:root:30: Epoch 3 train loss: 4463.012130737305\nINFO:root:23: Epoch 3 train loss: 2100820.0625\nINFO:root:6: Epoch 3 train loss: 3594.520378112793\nINFO:root:14: Epoch 3 train loss: 10394.404907226562\nINFO:root:24: Epoch 3 train loss: 23686.812255859375\nINFO:root:26: Epoch 3 train loss: 832795.2783203125\nINFO:root:9: Epoch 3 train loss: 29424.896728515625\nINFO:root:34: Epoch 3 train loss: 142.76244735717773\nINFO:root:8: Epoch 3 train loss: 5691.8531494140625\nINFO:root:35: Epoch 3 train loss: 3120.3104858398438\nINFO:root:31: Epoch 3 train loss: 1214165.2998046875\nINFO:root:21: Epoch 3 train loss: 17542.833404541016\nINFO:root:13: Epoch 3 train loss: 23601.126953125\nINFO:root:25: Epoch 3 train loss: 22283.247619628906\nINFO:root:17: Epoch 3 train loss: 1203329.541015625\nINFO:root:12: Epoch 3 train loss: 1006431.6392059326\nINFO:root:16: Epoch 3 train loss: 22122.247314453125\nINFO:root:20: Epoch 3 train loss: 406.3964538574219\nINFO:root:7: Epoch 3 train loss: 4343.9390869140625\nINFO:root:19: Epoch 3 train loss: 36905.3173828125\nINFO:root:29: Epoch 3 train loss: 9614.714477539062\nINFO:root:1: Epoch 3 train loss: 27073.464477539062\nINFO:root:0: Epoch 3 train loss: 7635.6666259765625\nINFO:root:2: Epoch 3 train loss: 3481091.7626953125\nINFO:root:3: Epoch 3 train loss: 28562.697265625\nINFO:root:4: Epoch 3 train loss: 34754.652572631836\nINFO:root:0: Epoch 3 validation loss: 41413.50150041606\nINFO:root:4: Epoch 4 train loss: 1039429.0243225098\nINFO:root:29: Epoch 4 train loss: 869593.3217773438\nINFO:root:23: Epoch 4 train loss: 3145.5496826171875\nINFO:root:3: Epoch 4 train loss: 2763.639186859131\nINFO:root:28: Epoch 4 train loss: 2672.7379150390625\nINFO:root:11: Epoch 4 train loss: 20807.770141601562\nINFO:root:27: Epoch 4 train loss: 9659.24251639098\nINFO:root:12: Epoch 4 train loss: 21053.138153076172\nINFO:root:24: Epoch 4 train loss: 5837.994709014893\nINFO:root:17: Epoch 4 train loss: 8035.661224365234\nINFO:root:9: Epoch 4 train loss: 23991.28173828125\nINFO:root:33: Epoch 4 train loss: 1047270.7294921875\nINFO:root:20: Epoch 4 train loss: 13106.469821929932\nINFO:root:30: Epoch 4 train loss: 744.3731994628906\nINFO:root:22: Epoch 4 train loss: 12047.532836914062\nINFO:root:34: Epoch 4 train loss: 19543.976196289062\nINFO:root:19: Epoch 4 train loss: 77450.9697265625\nINFO:root:21: Epoch 4 train loss: 1676.0141296386719\nINFO:root:14: Epoch 4 train loss: 341.9950866699219\nINFO:root:25: Epoch 4 train loss: 340545.8313655853\nINFO:root:26: Epoch 4 train loss: 6093.630920410156\nINFO:root:10: Epoch 4 train loss: 58496.5439453125\nINFO:root:31: Epoch 4 train loss: 1476.2443237304688\nINFO:root:18: Epoch 4 train loss: 353874.77164268494\nINFO:root:35: Epoch 4 train loss: 2176.425594806671\nINFO:root:1: Epoch 4 train loss: 65102.607421875\nINFO:root:2: Epoch 4 train loss: 821994.408203125\nINFO:root:32: Epoch 4 train loss: 11089.559326171875\nINFO:root:6: Epoch 4 train loss: 386798.876953125\nINFO:root:7: Epoch 4 train loss: 1036565.4677734375\nINFO:root:8: Epoch 4 train loss: 5086.3145751953125\nINFO:root:16: Epoch 4 train loss: 4700.747406005859\nINFO:root:15: Epoch 4 train loss: 5752.2847900390625\nINFO:root:5: Epoch 4 train loss: 830814.3369674683\nINFO:root:0: Epoch 4 train loss: 1521.5283508300781\nINFO:root:13: Epoch 4 train loss: 9578.239013671875\nINFO:root:0: Epoch 4 validation loss: 41409.836491731905\nINFO:root:29: Epoch 5 train loss: 10804.00634765625\nINFO:root:21: Epoch 5 train loss: 16215.7685546875\nINFO:root:27: Epoch 5 train loss: 2977.4525146484375\nINFO:root:28: Epoch 5 train loss: 23677.2841796875\nINFO:root:23: Epoch 5 train loss: 20451.86328125\nINFO:root:17: Epoch 5 train loss: 6962.5048828125\nINFO:root:13: Epoch 5 train loss: 2285.3284301757812\nINFO:root:16: Epoch 5 train loss: 1913842.939819336\nINFO:root:18: Epoch 5 train loss: 1864380.7504062653\nINFO:root:12: Epoch 5 train loss: 2525.2786560058594\nINFO:root:35: Epoch 5 train loss: 10294.944091796875\nINFO:root:34: Epoch 5 train loss: 1276.0979614257812\nINFO:root:26: Epoch 5 train loss: 713.8362274169922\nINFO:root:19: Epoch 5 train loss: 341172.1336994171\nINFO:root:32: Epoch 5 train loss: 868361.9841918945\nINFO:root:24: Epoch 5 train loss: 1227.597412109375\nINFO:root:30: Epoch 5 train loss: 24345.26446533203\nINFO:root:31: Epoch 5 train loss: 833.0000939369202\nINFO:root:0: Epoch 5 train loss: 4681.168609619141\nINFO:root:25: Epoch 5 train loss: 2667.750385284424\nINFO:root:22: Epoch 5 train loss: 1594.0207328796387\nINFO:root:3: Epoch 5 train loss: 2841.281692504883\nINFO:root:5: Epoch 5 train loss: 7874.399040222168\nINFO:root:33: Epoch 5 train loss: 1105.4941711425781\nINFO:root:15: Epoch 5 train loss: 4582.664237976074\nINFO:root:11: Epoch 5 train loss: 1153818.9271669388\nINFO:root:20: Epoch 5 train loss: 862314.1164460182\nINFO:root:7: Epoch 5 train loss: 23851.9365234375\nINFO:root:8: Epoch 5 train loss: 36100.38803100586\nINFO:root:6: Epoch 5 train loss: 7740.2900390625\nINFO:root:1: Epoch 5 train loss: 1813.7220916748047\nINFO:root:14: Epoch 5 train loss: 420.35577392578125\nINFO:root:2: Epoch 5 train loss: 1150103.1796875\nINFO:root:9: Epoch 5 train loss: 3736.2160263061523\nINFO:root:10: Epoch 5 train loss: 5808.572021484375\nINFO:root:4: Epoch 5 train loss: 366182.751953125\nINFO:root:0: Epoch 5 validation loss: 41406.054945141266\n", "seconds": 10.617935180664062, "batch_size": 64, "nodes": 12, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.15,192.168.2.15,192.168.2.15 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n2 Start Epoch 0\n3 Start Epoch 0\n2: 12 batches\n0: 12 batches\n1 Start Epoch 0\n3: 12 batches\n1: 12 batches\n2 Start Epoch 1\n2: 12 batches\n1 Start Epoch 1\n1: 12 batches\n3 Start Epoch 1\n3: 12 batches\n0 Start Epoch 1\n0: 12 batches\n3 Start Epoch 2\n3: 12 batches\n1 Start Epoch 2\n2 Start Epoch 2\n1: 12 batches\n2: 12 batches\n0 Start Epoch 2\n0: 12 batches\n2 Start Epoch 3\n1 Start Epoch 3\n2: 12 batches\n3 Start Epoch 3\n1: 12 batches\n3: 12 batches\n0 Start Epoch 3\n0: 12 batches\n1 Start Epoch 4\n1: 12 batches\n2 Start Epoch 4\n3 Start Epoch 4\n2: 12 batches\n3: 12 batches\n0 Start Epoch 4\n0: 12 batches\n1 Start Epoch 5\n1: 12 batches\n3 Start Epoch 5\n3: 12 batches\n2 Start Epoch 5\n2: 12 batches\n0 Start Epoch 5\n0: 12 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:2: Epoch 0 train loss: 592401.4585164388\nINFO:root:0: Epoch 0 train loss: 326927.57665507\nINFO:root:1: Epoch 0 train loss: 147817.62763468424\nINFO:root:3: Epoch 0 train loss: 178764.7436504364\nINFO:root:0: Epoch 0 validation loss: 2069676.0573443915\nINFO:root:0: Epoch 1 train loss: 224211.18372599283\nINFO:root:3: Epoch 1 train loss: 380909.77609761554\nINFO:root:1: Epoch 1 train loss: 388240.5683746338\nINFO:root:2: Epoch 1 train loss: 474035.6442159017\nINFO:root:0: Epoch 1 validation loss: 2069362.613319062\nINFO:root:0: Epoch 2 train loss: 705205.9101053873\nINFO:root:3: Epoch 2 train loss: 514440.9979451497\nINFO:root:1: Epoch 2 train loss: 289591.6232554118\nINFO:root:2: Epoch 2 train loss: 356188.4325230916\nINFO:root:0: Epoch 2 validation loss: 2068863.9392902276\nINFO:root:1: Epoch 3 train loss: 484187.02554448444\nINFO:root:0: Epoch 3 train loss: 286040.9783630371\nINFO:root:2: Epoch 3 train loss: 184275.48396809897\nINFO:root:3: Epoch 3 train loss: 182202.44305419922\nINFO:root:0: Epoch 3 validation loss: 2068179.2958893818\nINFO:root:1: Epoch 4 train loss: 300156.1756006877\nINFO:root:3: Epoch 4 train loss: 356902.45893160504\nINFO:root:0: Epoch 4 train loss: 216268.18306477866\nINFO:root:2: Epoch 4 train loss: 537917.8843129476\nINFO:root:0: Epoch 4 validation loss: 2067421.2743090596\nINFO:root:3: Epoch 5 train loss: 161892.6793874105\nINFO:root:1: Epoch 5 train loss: 456872.18918863934\nINFO:root:0: Epoch 5 train loss: 484260.1492462158\nINFO:root:2: Epoch 5 train loss: 199668.46523539224\nINFO:root:0: Epoch 5 validation loss: 2066684.684208755\n", "seconds": 56.815572023391724, "batch_size": 64, "nodes": 1, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.15,192.168.2.2,192.168.2.15,192.168.2.2,192.168.2.15,192.168.2.2 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 6 batches\n1 Start Epoch 0\n1: 6 batches\n5 Start Epoch 0\n6 Start Epoch 0\n6: 6 batches\n5: 6 batches\n2 Start Epoch 0\n2: 6 batches\n7 Start Epoch 0\n7: 6 batches\n3 Start Epoch 0\n3: 6 batches\n4 Start Epoch 0\n4: 6 batches\n7 Start Epoch 1\n6 Start Epoch 1\n7: 6 batches\n6: 6 batches\n1 Start Epoch 1\n1: 6 batches\n3 Start Epoch 1\n3: 6 batches\n2 Start Epoch 1\n2: 6 batches\n5 Start Epoch 1\n5: 6 batches\n4 Start Epoch 1\n4: 6 batches\n0 Start Epoch 1\n0: 6 batches\n5 Start Epoch 2\n6 Start Epoch 2\n6: 6 batches\n7 Start Epoch 2\n7: 6 batches\n5: 6 batches\n3 Start Epoch 2\n1 Start Epoch 2\n2 Start Epoch 2\n2: 6 batches\n1: 6 batches\n3: 6 batches\n4 Start Epoch 2\n4: 6 batches\n0 Start Epoch 2\n0: 6 batches\n6 Start Epoch 3\n4 Start Epoch 3\n4: 6 batches\n5 Start Epoch 3\n6: 6 batches\n7 Start Epoch 3\n7: 6 batches\n5: 6 batches\n3 Start Epoch 3\n3: 6 batches\n2 Start Epoch 3\n1 Start Epoch 3\n2: 6 batches\n1: 6 batches\n0 Start Epoch 3\n0: 6 batches\n1 Start Epoch 4\n1: 6 batches\n2 Start Epoch 4\n2: 6 batches\n5 Start Epoch 4\n3 Start Epoch 4\n6 Start Epoch 4\n3: 6 batches\n5: 6 batches\n6: 6 batches\n7 Start Epoch 4\n7: 6 batches\n4 Start Epoch 4\n4: 6 batches\n0 Start Epoch 4\n0: 6 batches\n3 Start Epoch 5\n2 Start Epoch 5\n2: 6 batches\n1 Start Epoch 5\n1: 6 batches\n3: 6 batches\n5 Start Epoch 5\n4 Start Epoch 5\n5: 6 batches\n4: 6 batches\n7 Start Epoch 5\n7: 6 batches\n6 Start Epoch 5\n6: 6 batches\n0 Start Epoch 5\n0: 6 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:6: Epoch 0 train loss: 345879.38962809247\nINFO:root:7: Epoch 0 train loss: 328940.26383463544\nINFO:root:0: Epoch 0 train loss: 10375.95677693685\nINFO:root:1: Epoch 0 train loss: 8492.118245442709\nINFO:root:3: Epoch 0 train loss: 130905.90545654297\nINFO:root:2: Epoch 0 train loss: 373554.5897216797\nINFO:root:4: Epoch 0 train loss: 358345.6423339844\nINFO:root:5: Epoch 0 train loss: 9876.686258951822\nINFO:root:0: Epoch 0 validation loss: 13556.094809785964\nINFO:root:6: Epoch 1 train loss: 3690.5548197428384\nINFO:root:7: Epoch 1 train loss: 686925.7157173157\nINFO:root:5: Epoch 1 train loss: 22642.95021565755\nINFO:root:2: Epoch 1 train loss: 343293.93814086914\nINFO:root:3: Epoch 1 train loss: 613518.4045918783\nINFO:root:1: Epoch 1 train loss: 13390.487991333008\nINFO:root:0: Epoch 1 train loss: 766642.9983317057\nINFO:root:4: Epoch 1 train loss: 14549.019002278646\nINFO:root:0: Epoch 1 validation loss: 13545.301190461834\nINFO:root:5: Epoch 2 train loss: 285220.56288655597\nINFO:root:4: Epoch 2 train loss: 637335.4134521484\nINFO:root:6: Epoch 2 train loss: 405384.81261189777\nINFO:root:7: Epoch 2 train loss: 809376.6818033854\nINFO:root:3: Epoch 2 train loss: 294583.842569987\nINFO:root:0: Epoch 2 train loss: 382622.04477945965\nINFO:root:2: Epoch 2 train loss: 343623.6909586589\nINFO:root:1: Epoch 2 train loss: 4420.044204711914\nINFO:root:0: Epoch 2 validation loss: 13533.818693427305\nINFO:root:1: Epoch 3 train loss: 17105.86328125\nINFO:root:0: Epoch 3 train loss: 9718.113749186197\nINFO:root:2: Epoch 3 train loss: 119101.74307250977\nINFO:root:3: Epoch 3 train loss: 284992.1830647786\nINFO:root:5: Epoch 3 train loss: 358761.38119506836\nINFO:root:6: Epoch 3 train loss: 4422.566848754883\nINFO:root:7: Epoch 3 train loss: 457668.42686971027\nINFO:root:4: Epoch 3 train loss: 707740.8337402344\nINFO:root:0: Epoch 3 validation loss: 13520.288007525021\nINFO:root:0: Epoch 4 train loss: 369999.49916585285\nINFO:root:3: Epoch 4 train loss: 67462.69997151692\nINFO:root:2: Epoch 4 train loss: 341947.2975260417\nINFO:root:1: Epoch 4 train loss: 330824.6464335124\nINFO:root:4: Epoch 4 train loss: 683590.735941569\nINFO:root:5: Epoch 4 train loss: 399542.5104980469\nINFO:root:7: Epoch 4 train loss: 365051.92108154297\nINFO:root:6: Epoch 4 train loss: 405975.88043340045\nINFO:root:0: Epoch 4 validation loss: 13501.841967993256\nINFO:root:6: Epoch 5 train loss: 7275.7421875\nINFO:root:5: Epoch 5 train loss: 304639.75322977704\nINFO:root:4: Epoch 5 train loss: 772843.2717285156\nINFO:root:3: Epoch 5 train loss: 736808.709777832\nINFO:root:2: Epoch 5 train loss: 362993.0107421875\nINFO:root:1: Epoch 5 train loss: 473290.4915364583\nINFO:root:7: Epoch 5 train loss: 4339.2490971883135\nINFO:root:0: Epoch 5 train loss: 670577.3323567709\nINFO:root:0: Epoch 5 validation loss: 13475.482191327703\n", "seconds": 30.532790899276733, "batch_size": 64, "nodes": 2, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.15,192.168.2.2,192.168.2.3 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "8 Start Epoch 0\n8: 4 batches\n1 Start Epoch 0\n1: 4 batches\n2 Start Epoch 0\n2: 4 batches\n3 Start Epoch 0\n3: 4 batches\n6 Start Epoch 0\n6: 4 batches\n7 Start Epoch 0\n7: 4 batches\n4 Start Epoch 0\n4: 4 batches\n5 Start Epoch 0\n5: 4 batches\n9 Start Epoch 0\n10 Start Epoch 0\n9: 4 batches\n10: 4 batches\n0 Start Epoch 0\n0: 4 batches\n11 Start Epoch 0\n11: 4 batches\n11 Start Epoch 1\n11: 4 batches\n10 Start Epoch 1\n10: 4 batches\n1 Start Epoch 1\n1: 4 batches\n8 Start Epoch 1\n9 Start Epoch 1\n9: 4 batches\n8: 4 batches\n2 Start Epoch 1\n7 Start Epoch 1\n7: 4 batches\n6 Start Epoch 1\n6: 4 batches\n5 Start Epoch 1\n5: 4 batches\n4 Start Epoch 1\n4: 4 batches\n3 Start Epoch 1\n3: 4 batches\n2: 4 batches\n0 Start Epoch 1\n0: 4 batches\n5 Start Epoch 2\n5: 4 batches\n3 Start Epoch 2\n2 Start Epoch 2\n2: 4 batches\n3: 4 batches\n8 Start Epoch 2\n1 Start Epoch 2\n4 Start Epoch 2\n6 Start Epoch 2\n1: 4 batches\n4: 4 batches\n6: 4 batches\n7 Start Epoch 2\n7: 4 batches\n9 Start Epoch 2\n9: 4 batches\n8: 4 batches\n11 Start Epoch 2\n10 Start Epoch 2\n10: 4 batches\n11: 4 batches\n0 Start Epoch 2\n0: 4 batches\n3 Start Epoch 3\n3: 4 batches\n5 Start Epoch 3\n4 Start Epoch 3\n4: 4 batches\n5: 4 batches\n8 Start Epoch 3\n8: 4 batches\n9 Start Epoch 3\n6 Start Epoch 3\n9: 4 batches\n6: 4 batches\n7 Start Epoch 3\n7: 4 batches\n2 Start Epoch 3\n2: 4 batches\n1 Start Epoch 3\n1: 4 batches\n11 Start Epoch 3\n11: 4 batches\n10 Start Epoch 3\n10: 4 batches\n0 Start Epoch 3\n0: 4 batches\n1 Start Epoch 4\n11 Start Epoch 4\n10 Start Epoch 4\n10: 4 batches\n1: 4 batches\n3 Start Epoch 4\n4 Start Epoch 4\n5 Start Epoch 4\n6 Start Epoch 4\n5: 4 batches\n6: 4 batches\n7 Start Epoch 4\n7: 4 batches\n3: 4 batches\n4: 4 batches\n2 Start Epoch 4\n2: 4 batches\n11: 4 batches\n8 Start Epoch 4\n9 Start Epoch 4\n8: 4 batches\n9: 4 batches\n0 Start Epoch 4\n0: 4 batches\n7 Start Epoch 5\n7: 4 batches\n11 Start Epoch 5\n9 Start Epoch 5\n8 Start Epoch 5\n11: 4 batches\n9: 4 batches\n8: 4 batches\n3 Start Epoch 5\n3: 4 batches\n1 Start Epoch 5\n1: 4 batches\n10 Start Epoch 5\n2 Start Epoch 5\n2: 4 batches\n10: 4 batches\n4 Start Epoch 5\n4: 4 batches\n6 Start Epoch 5\n6: 4 batches\n5 Start Epoch 5\n5: 4 batches\n0 Start Epoch 5\n0: 4 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 604422.5777664185\nINFO:root:11: Epoch 0 train loss: 519004.2044906616\nINFO:root:10: Epoch 0 train loss: 902920.189453125\nINFO:root:1: Epoch 0 train loss: 18809.735107421875\nINFO:root:9: Epoch 0 train loss: 5629.764831542969\nINFO:root:8: Epoch 0 train loss: 1010656.7228546143\nINFO:root:3: Epoch 0 train loss: 410651.4993286133\nINFO:root:2: Epoch 0 train loss: 9856.179260253906\nINFO:root:7: Epoch 0 train loss: 5094.934310913086\nINFO:root:5: Epoch 0 train loss: 15938.640684127808\nINFO:root:6: Epoch 0 train loss: 1721.6449279785156\nINFO:root:4: Epoch 0 train loss: 74285.30932235718\nINFO:root:0: Epoch 0 validation loss: 673038.8354224087\nINFO:root:5: Epoch 1 train loss: 1116306.5346679688\nINFO:root:3: Epoch 1 train loss: 10272.361938476562\nINFO:root:2: Epoch 1 train loss: 3685.1762924194336\nINFO:root:8: Epoch 1 train loss: 10729.847961425781\nINFO:root:9: Epoch 1 train loss: 5139.451698303223\nINFO:root:7: Epoch 1 train loss: 3426.9954833984375\nINFO:root:6: Epoch 1 train loss: 4060.278018951416\nINFO:root:4: Epoch 1 train loss: 751131.3492431641\nINFO:root:1: Epoch 1 train loss: 611809.0265197754\nINFO:root:0: Epoch 1 train loss: 206496.63891601562\nINFO:root:11: Epoch 1 train loss: 532920.241607666\nINFO:root:10: Epoch 1 train loss: 1124094.4754180908\nINFO:root:0: Epoch 1 validation loss: 673003.0825390759\nINFO:root:3: Epoch 2 train loss: 603257.8910255432\nINFO:root:5: Epoch 2 train loss: 546925.2349281311\nINFO:root:4: Epoch 2 train loss: 1078301.4020996094\nINFO:root:8: Epoch 2 train loss: 14545.21090888977\nINFO:root:6: Epoch 2 train loss: 410767.43908691406\nINFO:root:9: Epoch 2 train loss: 6358.028991699219\nINFO:root:7: Epoch 2 train loss: 5813.275787353516\nINFO:root:2: Epoch 2 train loss: 76227.7578125\nINFO:root:1: Epoch 2 train loss: 62524.57751464844\nINFO:root:11: Epoch 2 train loss: 8494.517700195312\nINFO:root:10: Epoch 2 train loss: 602918.1001586914\nINFO:root:0: Epoch 2 train loss: 10600.05908203125\nINFO:root:0: Epoch 2 validation loss: 672963.9255141729\nINFO:root:1: Epoch 3 train loss: 16089.039916992188\nINFO:root:0: Epoch 3 train loss: 177076.28771972656\nINFO:root:10: Epoch 3 train loss: 1134738.1080322266\nINFO:root:11: Epoch 3 train loss: 15379.544006347656\nINFO:root:3: Epoch 3 train loss: 657329.7385864258\nINFO:root:5: Epoch 3 train loss: 8454.798370361328\nINFO:root:4: Epoch 3 train loss: 505219.5576095581\nINFO:root:6: Epoch 3 train loss: 726238.7575683594\nINFO:root:7: Epoch 3 train loss: 508361.5926513672\nINFO:root:2: Epoch 3 train loss: 7394.36848449707\nINFO:root:9: Epoch 3 train loss: 65598.07739257812\nINFO:root:8: Epoch 3 train loss: 4620.283599853516\nINFO:root:0: Epoch 3 validation loss: 672918.9551226475\nINFO:root:7: Epoch 4 train loss: 9124.91667175293\nINFO:root:9: Epoch 4 train loss: 4736.449287414551\nINFO:root:11: Epoch 4 train loss: 7967.606170654297\nINFO:root:8: Epoch 4 train loss: 13584.485717773438\nINFO:root:0: Epoch 4 train loss: 5489.323547363281\nINFO:root:3: Epoch 4 train loss: 440442.9126663208\nINFO:root:1: Epoch 4 train loss: 587398.6682128906\nINFO:root:10: Epoch 4 train loss: 7331.523666381836\nINFO:root:2: Epoch 4 train loss: 4392.7372970581055\nINFO:root:4: Epoch 4 train loss: 5452.426330566406\nINFO:root:6: Epoch 4 train loss: 14895.375366210938\nINFO:root:5: Epoch 4 train loss: 22615.06036376953\nINFO:root:0: Epoch 4 validation loss: 672866.1389207948\nINFO:root:10: Epoch 5 train loss: 552154.2045898438\nINFO:root:11: Epoch 5 train loss: 955545.2717285156\nINFO:root:3: Epoch 5 train loss: 555338.6544189453\nINFO:root:2: Epoch 5 train loss: 6507.0500202178955\nINFO:root:1: Epoch 5 train loss: 16928.754638671875\nINFO:root:8: Epoch 5 train loss: 10016.82568359375\nINFO:root:6: Epoch 5 train loss: 914024.2874145508\nINFO:root:7: Epoch 5 train loss: 412665.9655151367\nINFO:root:9: Epoch 5 train loss: 63170.893951416016\nINFO:root:5: Epoch 5 train loss: 15904.536743164062\nINFO:root:0: Epoch 5 train loss: 13134.586547851562\nINFO:root:4: Epoch 5 train loss: 176848.47241210938\nINFO:root:0: Epoch 5 validation loss: 672800.4334520512\n", "seconds": 22.554600954055786, "batch_size": 64, "nodes": 3, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 3 batches\n15 Start Epoch 0\n15: 3 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 3 batches\n2: 3 batches\n8 Start Epoch 0\n12 Start Epoch 0\n8: 3 batches\n12: 3 batches\n4 Start Epoch 0\n4: 3 batches\n7 Start Epoch 0\n7: 3 batches\n3 Start Epoch 0\n3: 3 batches\n5 Start Epoch 0\n6 Start Epoch 0\n6: 3 batches\n9 Start Epoch 0\n9: 3 batches\n10 Start Epoch 0\n10: 3 batches\n11 Start Epoch 0\n11: 3 batches\n5: 3 batches\n13 Start Epoch 0\n13: 3 batches\n14 Start Epoch 0\n14: 3 batches\n13 Start Epoch 1\n15 Start Epoch 1\n15: 3 batches\n13: 3 batches\n14 Start Epoch 1\n14: 3 batches\n1 Start Epoch 1\n1: 3 batches\n12 Start Epoch 1\n12: 3 batches\n11 Start Epoch 1\n9 Start Epoch 1\n10 Start Epoch 1\n11: 3 batches\n9: 3 batches\n8 Start Epoch 1\n8: 3 batches\n10: 3 batches\n7 Start Epoch 1\n7: 3 batches\n2 Start Epoch 1\n5 Start Epoch 1\n6 Start Epoch 1\n4 Start Epoch 1\n6: 3 batches\n4: 3 batches\n2: 3 batches\n5: 3 batches\n3 Start Epoch 1\n3: 3 batches\n0 Start Epoch 1\n0: 3 batches\n3 Start Epoch 2\n3: 3 batches\n11 Start Epoch 2\n5 Start Epoch 2\n11: 3 batches\n14 Start Epoch 2\n4 Start Epoch 2\n15 Start Epoch 2\n4: 3 batches\n5: 3 batches\n6 Start Epoch 2\n6: 3 batches\n7 Start Epoch 2\n7: 3 batches\n15: 3 batches\n14: 3 batches\n10 Start Epoch 2\n10: 3 batches\n12 Start Epoch 2\n12: 3 batches\n9 Start Epoch 2\n1 Start Epoch 2\n1: 3 batches\n9: 3 batches\n8 Start Epoch 2\n8: 3 batches\n13 Start Epoch 2\n13: 3 batches\n2 Start Epoch 2\n2: 3 batches\n0 Start Epoch 2\n0: 3 batches\n7 Start Epoch 3\n7: 3 batches\n6 Start Epoch 3\n6: 3 batches\n10 Start Epoch 3\n10: 3 batches\n11 Start Epoch 3\n11: 3 batches\n9 Start Epoch 3\n9: 3 batches\n13 Start Epoch 3\n12 Start Epoch 3\n15 Start Epoch 3\n13: 3 batches\n12: 3 batches\n14 Start Epoch 3\n14: 3 batches\n1 Start Epoch 3\n1: 3 batches\n3 Start Epoch 3\n2 Start Epoch 3\n2: 3 batches\n3: 3 batches\n15: 3 batches\n4 Start Epoch 3\n4: 3 batches\n5 Start Epoch 3\n5: 3 batches\n8 Start Epoch 3\n8: 3 batches\n0 Start Epoch 3\n0: 3 batches\n7 Start Epoch 4\n6 Start Epoch 4\n6: 3 batches\n7: 3 batches\n9 Start Epoch 4\n9: 3 batches\n8 Start Epoch 4\n8: 3 batches\n5 Start Epoch 4\n5: 3 batches\n1 Start Epoch 4\n2 Start Epoch 4\n1: 3 batches\n4 Start Epoch 4\n4: 3 batches\n10 Start Epoch 4\n12 Start Epoch 4\n14 Start Epoch 4\n13 Start Epoch 4\n13: 3 batches\n12: 3 batches\n15 Start Epoch 4\n15: 3 batches\n2: 3 batches\n3 Start Epoch 4\n3: 3 batches\n11 Start Epoch 4\n11: 3 batches\n14: 3 batches\n10: 3 batches\n0 Start Epoch 4\n0: 3 batches\n5 Start Epoch 5\n6 Start Epoch 5\n6: 3 batches\n5: 3 batches\n7 Start Epoch 5\n7: 3 batches\n11 Start Epoch 5\n8 Start Epoch 5\n10 Start Epoch 5\n10: 3 batches\n11: 3 batches\n9 Start Epoch 5\n9: 3 batches\n8: 3 batches\n12 Start Epoch 5\n12: 3 batches\n13 Start Epoch 5\n13: 3 batches\n15 Start Epoch 5\n15: 3 batches\n3 Start Epoch 5\n3: 3 batches\n1 Start Epoch 5\n1: 3 batches\n2 Start Epoch 5\n2: 3 batches\n4 Start Epoch 5\n4: 3 batches\n14 Start Epoch 5\n14: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:13: Epoch 0 train loss: 2112.9498697916665\nINFO:root:15: Epoch 0 train loss: 646009.6842854818\nINFO:root:14: Epoch 0 train loss: 723699.0794270834\nINFO:root:1: Epoch 0 train loss: 662184.7843424479\nINFO:root:0: Epoch 0 train loss: 3786.2613118489585\nINFO:root:12: Epoch 0 train loss: 3885.8357137044272\nINFO:root:8: Epoch 0 train loss: 711016.1875\nINFO:root:11: Epoch 0 train loss: 4356.866256713867\nINFO:root:9: Epoch 0 train loss: 16900.864583333332\nINFO:root:10: Epoch 0 train loss: 777495.4682617188\nINFO:root:7: Epoch 0 train loss: 9502.119140625\nINFO:root:2: Epoch 0 train loss: 5899.4195556640625\nINFO:root:6: Epoch 0 train loss: 671279.9860026041\nINFO:root:4: Epoch 0 train loss: 17023.837310791016\nINFO:root:5: Epoch 0 train loss: 11354.539632161459\nINFO:root:3: Epoch 0 train loss: 1445251.9479166667\nINFO:root:0: Epoch 0 validation loss: 243939086.26617762\nINFO:root:3: Epoch 1 train loss: 650960.5084635416\nINFO:root:4: Epoch 1 train loss: 3935.35009765625\nINFO:root:11: Epoch 1 train loss: 543477.685546875\nINFO:root:15: Epoch 1 train loss: 827503.3567708334\nINFO:root:5: Epoch 1 train loss: 765455.4925130209\nINFO:root:14: Epoch 1 train loss: 8952.3483988444\nINFO:root:6: Epoch 1 train loss: 695185.5753580729\nINFO:root:7: Epoch 1 train loss: 2546886.2083333335\nINFO:root:10: Epoch 1 train loss: 2226.6177368164062\nINFO:root:12: Epoch 1 train loss: 7899.9435628255205\nINFO:root:9: Epoch 1 train loss: 9460.431111653646\nINFO:root:8: Epoch 1 train loss: 764096.8282877604\nINFO:root:1: Epoch 1 train loss: 4235.044677734375\nINFO:root:0: Epoch 1 train loss: 666171.5369466146\nINFO:root:13: Epoch 1 train loss: 715128.5447591146\nINFO:root:2: Epoch 1 train loss: 14129.442189534506\nINFO:root:0: Epoch 1 validation loss: 243938836.43811172\nINFO:root:7: Epoch 2 train loss: 675160.1733398438\nINFO:root:6: Epoch 2 train loss: 13122.049072265625\nINFO:root:10: Epoch 2 train loss: 749339.2890625\nINFO:root:11: Epoch 2 train loss: 741174.0854899088\nINFO:root:9: Epoch 2 train loss: 21374.424479166668\nINFO:root:15: Epoch 2 train loss: 5350.3774820963545\nINFO:root:13: Epoch 2 train loss: 6149.801350911458\nINFO:root:12: Epoch 2 train loss: 637887.0600179037\nINFO:root:14: Epoch 2 train loss: 13252.3095703125\nINFO:root:0: Epoch 2 train loss: 13722.586100260416\nINFO:root:1: Epoch 2 train loss: 4439.056747436523\nINFO:root:3: Epoch 2 train loss: 14199.355794270834\nINFO:root:2: Epoch 2 train loss: 4516.768798828125\nINFO:root:4: Epoch 2 train loss: 21663.703125\nINFO:root:5: Epoch 2 train loss: 884704.1673583984\nINFO:root:8: Epoch 2 train loss: 652970.9521280924\nINFO:root:0: Epoch 2 validation loss: 243938620.11700442\nINFO:root:7: Epoch 3 train loss: 228633.46559143066\nINFO:root:6: Epoch 3 train loss: 3290.1118977864585\nINFO:root:9: Epoch 3 train loss: 3367.9877319335938\nINFO:root:8: Epoch 3 train loss: 586200.9709269205\nINFO:root:5: Epoch 3 train loss: 667096.6705729166\nINFO:root:2: Epoch 3 train loss: 1335188.6459960938\nINFO:root:0: Epoch 3 train loss: 17388.389322916668\nINFO:root:1: Epoch 3 train loss: 697034.7725423177\nINFO:root:3: Epoch 3 train loss: 618355.5517578125\nINFO:root:4: Epoch 3 train loss: 752496.2633463541\nINFO:root:10: Epoch 3 train loss: 3624.272092183431\nINFO:root:14: Epoch 3 train loss: 8439.062703450521\nINFO:root:11: Epoch 3 train loss: 30502.527180989582\nINFO:root:15: Epoch 3 train loss: 1010569.9126485189\nINFO:root:13: Epoch 3 train loss: 808220.5573527018\nINFO:root:12: Epoch 3 train loss: 4181.410990397136\nINFO:root:0: Epoch 3 validation loss: 243938418.76069868\nINFO:root:6: Epoch 4 train loss: 751445.3614603678\nINFO:root:5: Epoch 4 train loss: 924719.8896484375\nINFO:root:7: Epoch 4 train loss: 18877.420450846355\nINFO:root:11: Epoch 4 train loss: 7987.398274739583\nINFO:root:8: Epoch 4 train loss: 4384.745768229167\nINFO:root:9: Epoch 4 train loss: 715106.9102579752\nINFO:root:10: Epoch 4 train loss: 752499.6446533203\nINFO:root:1: Epoch 4 train loss: 803965.0207112631\nINFO:root:0: Epoch 4 train loss: 3184.2151692708335\nINFO:root:13: Epoch 4 train loss: 6940.328837076823\nINFO:root:12: Epoch 4 train loss: 15269.42333984375\nINFO:root:15: Epoch 4 train loss: 547795.1140950521\nINFO:root:2: Epoch 4 train loss: 831791.4625651041\nINFO:root:3: Epoch 4 train loss: 33595.874186197914\nINFO:root:4: Epoch 4 train loss: 7017.187255859375\nINFO:root:14: Epoch 4 train loss: 6928.913330078125\nINFO:root:0: Epoch 4 validation loss: 243938213.81444484\nINFO:root:3: Epoch 5 train loss: 642882.7451731364\nINFO:root:8: Epoch 5 train loss: 730811.1466878256\nINFO:root:9: Epoch 5 train loss: 9746.527669270834\nINFO:root:14: Epoch 5 train loss: 4653.797373453776\nINFO:root:5: Epoch 5 train loss: 735737.744140625\nINFO:root:13: Epoch 5 train loss: 4414.345458984375\nINFO:root:7: Epoch 5 train loss: 744406.6887817383\nINFO:root:4: Epoch 5 train loss: 8223.73828125\nINFO:root:6: Epoch 5 train loss: 1321564.9147135417\nINFO:root:15: Epoch 5 train loss: 691257.5967203776\nINFO:root:1: Epoch 5 train loss: 1122223.3805338542\nINFO:root:0: Epoch 5 train loss: 14569.39224243164\nINFO:root:2: Epoch 5 train loss: 2489.3895467122397\nINFO:root:11: Epoch 5 train loss: 1307077.9505208333\nINFO:root:10: Epoch 5 train loss: 21204.988911946613\nINFO:root:12: Epoch 5 train loss: 8536.417643229166\nINFO:root:0: Epoch 5 validation loss: 243937916.39667967\n", "seconds": 18.857465982437134, "batch_size": 64, "nodes": 4, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 3 batches\n2 Start Epoch 0\n2: 3 batches\n3 Start Epoch 0\n3: 3 batches\n11 Start Epoch 0\n19 Start Epoch 0\n19: 3 batches\n8 Start Epoch 0\n16 Start Epoch 0\n16: 3 batches\n1 Start Epoch 0\n1: 3 batches\n7 Start Epoch 0\n7: 3 batches\n4 Start Epoch 0\n4: 3 batches\n15 Start Epoch 0\n15: 3 batches\n12 Start Epoch 0\n12: 3 batches\n11: 3 batches\n8: 3 batches\n13 Start Epoch 0\n14 Start Epoch 0\n14: 3 batches\n5 Start Epoch 0\n6 Start Epoch 0\n13: 3 batches\n5: 3 batches\n6: 3 batches\n9 Start Epoch 0\n10 Start Epoch 0\n9: 3 batches\n10: 3 batches\n17 Start Epoch 0\n17: 3 batches\n18 Start Epoch 0\n18: 3 batches\n7 Start Epoch 1\n7: 3 batches\n11 Start Epoch 1\n9 Start Epoch 1\n9: 3 batches\n11: 3 batches\n3 Start Epoch 1\n3: 3 batches\n18 Start Epoch 1\n4 Start Epoch 1\n8 Start Epoch 1\n12 Start Epoch 1\n4: 3 batches\n8: 3 batches\n19 Start Epoch 1\n19: 3 batches\n13 Start Epoch 1\n18: 3 batches\n12: 3 batches\n13: 3 batches\n14 Start Epoch 1\n15 Start Epoch 1\n15: 3 batches\n14: 3 batches\n16 Start Epoch 1\n16: 3 batches\n10 Start Epoch 1\n10: 3 batches\n17 Start Epoch 1\n17: 3 batches\n5 Start Epoch 1\n5: 3 batches\n6 Start Epoch 1\n6: 3 batches\n1 Start Epoch 1\n2 Start Epoch 1\n1: 3 batches\n2: 3 batches\n0 Start Epoch 1\n0: 3 batches\n3 Start Epoch 2\n3: 3 batches\n5 Start Epoch 2\n11 Start Epoch 2\n13 Start Epoch 2\n4 Start Epoch 2\n10 Start Epoch 2\n15 Start Epoch 2\n4: 3 batches\n10: 3 batches\n13: 3 batches\n5: 3 batches\n11: 3 batches\n1 Start Epoch 2\n15: 3 batches\n12 Start Epoch 2\n12: 3 batches\n1: 3 batches\n9 Start Epoch 2\n9: 3 batches\n14 Start Epoch 2\n14: 3 batches\n7 Start Epoch 2\n7: 3 batches\n19 Start Epoch 2\n19: 3 batches\n17 Start Epoch 2\n17: 3 batches\n6 Start Epoch 2\n6: 3 batches\n18 Start Epoch 2\n18: 3 batches\n2 Start Epoch 2\n2: 3 batches\n8 Start Epoch 2\n8: 3 batches\n16 Start Epoch 2\n16: 3 batches\n0 Start Epoch 2\n0: 3 batches\n1 Start Epoch 3\n1: 3 batches\n17 Start Epoch 3\n17: 3 batches\n19 Start Epoch 3\n19: 3 batches\n18 Start Epoch 3\n18: 3 batches\n13 Start Epoch 3\n15 Start Epoch 3\n15: 3 batches\n13: 3 batches\n14 Start Epoch 3\n14: 3 batches\n16 Start Epoch 3\n16: 3 batches\n2 Start Epoch 3\n3 Start Epoch 3\n3: 3 batches\n12 Start Epoch 3\n8 Start Epoch 3\n11 Start Epoch 3\n8: 3 batches\n11: 3 batches\n10 Start Epoch 3\n9 Start Epoch 3\n9: 3 batches\n10: 3 batches\n2: 3 batches\n6 Start Epoch 3\n6: 3 batches\n7 Start Epoch 3\n7: 3 batches\n4 Start Epoch 3\n4: 3 batches\n5 Start Epoch 3\n5: 3 batches\n12: 3 batches\n0 Start Epoch 3\n0: 3 batches\n15 Start Epoch 4\n15: 3 batches\n17 Start Epoch 4\n17: 3 batches\n16 Start Epoch 4\n16: 3 batches\n12 Start Epoch 4\n12: 3 batches\n13 Start Epoch 4\n13: 3 batches\n2 Start Epoch 4\n2: 3 batches\n10 Start Epoch 4\n11 Start Epoch 4\n10: 3 batches\n14 Start Epoch 4\n14: 3 batches\n8 Start Epoch 4\n8: 3 batches\n11: 3 batches\n9 Start Epoch 4\n9: 3 batches\n6 Start Epoch 4\n6: 3 batches\n7 Start Epoch 4\n7: 3 batches\n4 Start Epoch 4\n4: 3 batches\n5 Start Epoch 4\n5: 3 batches\n3 Start Epoch 4\n3: 3 batches\n18 Start Epoch 4\n18: 3 batches\n1 Start Epoch 4\n1: 3 batches\n19 Start Epoch 4\n19: 3 batches\n0 Start Epoch 4\n0: 3 batches\n10 Start Epoch 5\n11 Start Epoch 5\n7 Start Epoch 5\n7: 3 batches\n11: 3 batches\n4 Start Epoch 5\n4: 3 batches\n10: 3 batches\n3 Start Epoch 5\n3: 3 batches\n16 Start Epoch 5\n5 Start Epoch 5\n5: 3 batches\n16: 3 batches\n15 Start Epoch 5\n15: 3 batches\n12 Start Epoch 5\n12: 3 batches\n19 Start Epoch 5\n19: 3 batches\n6 Start Epoch 5\n6: 3 batches\n1 Start Epoch 5\n1: 3 batches\n17 Start Epoch 5\n17: 3 batches\n18 Start Epoch 5\n18: 3 batches\n14 Start Epoch 5\n14: 3 batches\n13 Start Epoch 5\n13: 3 batches\n2 Start Epoch 5\n2: 3 batches\n9 Start Epoch 5\n9: 3 batches\n8 Start Epoch 5\n8: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:7: Epoch 0 train loss: 1957527.5231730144\nINFO:root:11: Epoch 0 train loss: 903655.1613871256\nINFO:root:9: Epoch 0 train loss: 6294.8258056640625\nINFO:root:8: Epoch 0 train loss: 9657.0673828125\nINFO:root:3: Epoch 0 train loss: 2038957.7915039062\nINFO:root:19: Epoch 0 train loss: 18702.847056070965\nINFO:root:13: Epoch 0 train loss: 21253.79061126709\nINFO:root:4: Epoch 0 train loss: 9607.474632263184\nINFO:root:10: Epoch 0 train loss: 29863.453857421875\nINFO:root:18: Epoch 0 train loss: 3652.1511255900064\nINFO:root:12: Epoch 0 train loss: 549143.8099772135\nINFO:root:14: Epoch 0 train loss: 4949.0537109375\nINFO:root:15: Epoch 0 train loss: 693902.3644129435\nINFO:root:16: Epoch 0 train loss: 9313.013122558594\nINFO:root:17: Epoch 0 train loss: 11486.667032877604\nINFO:root:5: Epoch 0 train loss: 9323.496673583984\nINFO:root:6: Epoch 0 train loss: 65652.73356119792\nINFO:root:1: Epoch 0 train loss: 817373.638671875\nINFO:root:2: Epoch 0 train loss: 1643.2882385253906\nINFO:root:0: Epoch 0 train loss: 23405.661458333332\nINFO:root:0: Epoch 0 validation loss: 580986.0780499985\nINFO:root:1: Epoch 1 train loss: 5556.763854980469\nINFO:root:3: Epoch 1 train loss: 2382585.8084309897\nINFO:root:5: Epoch 1 train loss: 693999.0856730143\nINFO:root:0: Epoch 1 train loss: 8979.387326876322\nINFO:root:10: Epoch 1 train loss: 1617.6741790771484\nINFO:root:4: Epoch 1 train loss: 9202.499397277832\nINFO:root:11: Epoch 1 train loss: 545103.6516113281\nINFO:root:15: Epoch 1 train loss: 4340.490753173828\nINFO:root:13: Epoch 1 train loss: 6284.639241536458\nINFO:root:12: Epoch 1 train loss: 6307.585225423177\nINFO:root:9: Epoch 1 train loss: 803976.0765177408\nINFO:root:14: Epoch 1 train loss: 9319.790771484375\nINFO:root:7: Epoch 1 train loss: 15174.43603769938\nINFO:root:19: Epoch 1 train loss: 814.4560991923014\nINFO:root:17: Epoch 1 train loss: 11488.120930989584\nINFO:root:6: Epoch 1 train loss: 4222.4798583984375\nINFO:root:18: Epoch 1 train loss: 8854.146118164062\nINFO:root:2: Epoch 1 train loss: 725886.4465332031\nINFO:root:8: Epoch 1 train loss: 74918.3262163798\nINFO:root:16: Epoch 1 train loss: 2440082.993815104\nINFO:root:0: Epoch 1 validation loss: 580959.5621429265\nINFO:root:0: Epoch 2 train loss: 29022.877604166668\nINFO:root:1: Epoch 2 train loss: 2072.2043253580728\nINFO:root:17: Epoch 2 train loss: 39757.513020833336\nINFO:root:19: Epoch 2 train loss: 734963.315999349\nINFO:root:18: Epoch 2 train loss: 6690.10400390625\nINFO:root:13: Epoch 2 train loss: 723488.9918212891\nINFO:root:15: Epoch 2 train loss: 6703.62109375\nINFO:root:14: Epoch 2 train loss: 2577.6704305013022\nINFO:root:16: Epoch 2 train loss: 4029.796132405599\nINFO:root:2: Epoch 2 train loss: 79596.20146814983\nINFO:root:3: Epoch 2 train loss: 51067.541666666664\nINFO:root:12: Epoch 2 train loss: 1083.865010579427\nINFO:root:11: Epoch 2 train loss: 12250.175862630209\nINFO:root:8: Epoch 2 train loss: 3678.759999593099\nINFO:root:10: Epoch 2 train loss: 3128.9981689453125\nINFO:root:9: Epoch 2 train loss: 17758.19014485677\nINFO:root:5: Epoch 2 train loss: 799213.0332234701\nINFO:root:7: Epoch 2 train loss: 813507.0794270834\nINFO:root:6: Epoch 2 train loss: 85419.61741129558\nINFO:root:4: Epoch 2 train loss: 228638.05989583334\nINFO:root:0: Epoch 2 validation loss: 580931.0341579654\nINFO:root:15: Epoch 3 train loss: 5716.554522196452\nINFO:root:17: Epoch 3 train loss: 22780.195088704426\nINFO:root:16: Epoch 3 train loss: 3521.04150390625\nINFO:root:12: Epoch 3 train loss: 725363.6732737223\nINFO:root:13: Epoch 3 train loss: 30489.445638020832\nINFO:root:2: Epoch 3 train loss: 4380.892252604167\nINFO:root:11: Epoch 3 train loss: 8053.597483317058\nINFO:root:10: Epoch 3 train loss: 14041.167266845703\nINFO:root:0: Epoch 3 train loss: 612.6216201782227\nINFO:root:14: Epoch 3 train loss: 689478.9779459635\nINFO:root:8: Epoch 3 train loss: 1213664.5611495972\nINFO:root:9: Epoch 3 train loss: 813834.1101379395\nINFO:root:5: Epoch 3 train loss: 12153.098416646322\nINFO:root:7: Epoch 3 train loss: 13597.462270100912\nINFO:root:6: Epoch 3 train loss: 10435.880940755209\nINFO:root:4: Epoch 3 train loss: 22277.995768229168\nINFO:root:3: Epoch 3 train loss: 803163.953297933\nINFO:root:18: Epoch 3 train loss: 5782.505289713542\nINFO:root:1: Epoch 3 train loss: 26258.494791666668\nINFO:root:19: Epoch 3 train loss: 4166.90478515625\nINFO:root:0: Epoch 3 validation loss: 580898.9456220465\nINFO:root:3: Epoch 4 train loss: 1133.611063639323\nINFO:root:0: Epoch 4 train loss: 7970.973225911458\nINFO:root:10: Epoch 4 train loss: 7118.55810546875\nINFO:root:11: Epoch 4 train loss: 239371.39794921875\nINFO:root:4: Epoch 4 train loss: 7362.012776692708\nINFO:root:7: Epoch 4 train loss: 656332.2809244791\nINFO:root:16: Epoch 4 train loss: 728921.9352213541\nINFO:root:5: Epoch 4 train loss: 11880.347493489584\nINFO:root:6: Epoch 4 train loss: 12047.563934326172\nINFO:root:15: Epoch 4 train loss: 3092641.8450520835\nINFO:root:12: Epoch 4 train loss: 693403.3076985677\nINFO:root:19: Epoch 4 train loss: 2207.822998046875\nINFO:root:1: Epoch 4 train loss: 10104.319173177084\nINFO:root:17: Epoch 4 train loss: 592602.5487467448\nINFO:root:18: Epoch 4 train loss: 1393586.7412109375\nINFO:root:14: Epoch 4 train loss: 15038.797200520834\nINFO:root:13: Epoch 4 train loss: 7135.445322672526\nINFO:root:2: Epoch 4 train loss: 1188699.0408528645\nINFO:root:9: Epoch 4 train loss: 805986.5782267252\nINFO:root:8: Epoch 4 train loss: 643866.3440348307\nINFO:root:0: Epoch 4 validation loss: 580862.3785470217\nINFO:root:16: Epoch 5 train loss: 1768814.0100911458\nINFO:root:19: Epoch 5 train loss: 6208.866678873698\nINFO:root:17: Epoch 5 train loss: 10420.392395019531\nINFO:root:18: Epoch 5 train loss: 6069.07373046875\nINFO:root:1: Epoch 5 train loss: 6598.324756622314\nINFO:root:0: Epoch 5 train loss: 17190.882146199543\nINFO:root:15: Epoch 5 train loss: 91259.51521809895\nINFO:root:11: Epoch 5 train loss: 10256.531372070312\nINFO:root:4: Epoch 5 train loss: 576014.5755615234\nINFO:root:5: Epoch 5 train loss: 3045.2424240112305\nINFO:root:3: Epoch 5 train loss: 1167.3631490071614\nINFO:root:2: Epoch 5 train loss: 709568.0519002279\nINFO:root:13: Epoch 5 train loss: 7573.5274658203125\nINFO:root:12: Epoch 5 train loss: 42417.562337239586\nINFO:root:14: Epoch 5 train loss: 4894.972279866536\nINFO:root:6: Epoch 5 train loss: 23924.374745368958\nINFO:root:7: Epoch 5 train loss: 39101.50956217448\nINFO:root:10: Epoch 5 train loss: 617332.7243143717\nINFO:root:8: Epoch 5 train loss: 688906.4934552511\nINFO:root:9: Epoch 5 train loss: 1384296.0143229167\nINFO:root:0: Epoch 5 validation loss: 580820.9314463054\n", "seconds": 14.514817953109741, "batch_size": 64, "nodes": 5, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 2 batches\n2: 2 batches\n16 Start Epoch 0\n19 Start Epoch 0\n19: 2 batches\n16: 2 batches\n3 Start Epoch 0\n3: 2 batches\n23 Start Epoch 0\n23: 2 batches\n20 Start Epoch 0\n20: 2 batches\n17 Start Epoch 0\n17: 2 batches\n18 Start Epoch 0\n18: 2 batches\n12 Start Epoch 0\n12: 2 batches\n13 Start Epoch 0\n13: 2 batches\n8 Start Epoch 0\n8: 2 batches\n4 Start Epoch 0\n4: 2 batches\n14 Start Epoch 0\n14: 2 batches\n9 Start Epoch 0\n9: 2 batches\n5 Start Epoch 0\n5: 2 batches\n15 Start Epoch 0\n15: 2 batches\n6 Start Epoch 0\n6: 2 batches\n10 Start Epoch 0\n10: 2 batches\n11 Start Epoch 0\n11: 2 batches\n7 Start Epoch 0\n7: 2 batches\n21 Start Epoch 0\n22 Start Epoch 0\n21: 2 batches\n22: 2 batches\n2 Start Epoch 1\n2: 2 batches\n19 Start Epoch 1\n23 Start Epoch 1\n12 Start Epoch 1\n12: 2 batches\n23: 2 batches\n13 Start Epoch 1\n13: 2 batches\n19: 2 batches\n4 Start Epoch 1\n18 Start Epoch 1\n8 Start Epoch 1\n9 Start Epoch 1\n5 Start Epoch 1\n18: 2 batches\n22 Start Epoch 1\n10 Start Epoch 1\n6 Start Epoch 1\n16 Start Epoch 1\n10: 2 batches\n4: 2 batches\n20 Start Epoch 1\n9: 2 batches\n5: 2 batches\n16: 2 batches\n21 Start Epoch 1\n22: 2 batches\n11 Start Epoch 1\n7 Start Epoch 1\n11: 2 batches\n20: 2 batches\n8: 2 batches\n1 Start Epoch 1\n1: 2 batches\n21: 2 batches\n17 Start Epoch 1\n17: 2 batches\n3 Start Epoch 1\n3: 2 batches\n7: 2 batches\n6: 2 batches\n14 Start Epoch 1\n14: 2 batches\n15 Start Epoch 1\n15: 2 batches\n0 Start Epoch 1\n0: 2 batches\n3 Start Epoch 2\n3: 2 batches\n17 Start Epoch 2\n6 Start Epoch 2\n6: 2 batches\n17: 2 batches\n5 Start Epoch 2\n5: 2 batches\n16 Start Epoch 2\n20 Start Epoch 2\n20: 2 batches\n16: 2 batches\n18 Start Epoch 2\n18: 2 batches\n19 Start Epoch 2\n19: 2 batches\n11 Start Epoch 2\n11: 2 batches\n8 Start Epoch 2\n8: 2 batches\n7 Start Epoch 2\n7: 2 batches\n4 Start Epoch 2\n4: 2 batches\n15 Start Epoch 2\n14 Start Epoch 2\n14: 2 batches\n15: 2 batches\n12 Start Epoch 2\n12: 2 batches\n13 Start Epoch 2\n13: 2 batches\n21 Start Epoch 2\n21: 2 batches\n9 Start Epoch 2\n9: 2 batches\n10 Start Epoch 2\n10: 2 batches\n22 Start Epoch 2\n22: 2 batches\n2 Start Epoch 2\n1 Start Epoch 2\n1: 2 batches\n2: 2 batches\n23 Start Epoch 2\n23: 2 batches\n0 Start Epoch 2\n0: 2 batches\n13 Start Epoch 3\n15 Start Epoch 3\n13: 2 batches\n14 Start Epoch 3\n14: 2 batches\n15: 2 batches\n16 Start Epoch 3\n16: 2 batches\n6 Start Epoch 3\n1 Start Epoch 3\n7 Start Epoch 3\n1: 2 batches\n23 Start Epoch 3\n6: 2 batches\n3 Start Epoch 3\n23: 2 batches\n3: 2 batches\n2 Start Epoch 3\n2: 2 batches\n20 Start Epoch 3\n20: 2 batches\n18 Start Epoch 3\n12 Start Epoch 3\n12: 2 batches\n7: 2 batches\n18: 2 batches\n22 Start Epoch 3\n22: 2 batches\n21 Start Epoch 3\n5 Start Epoch 3\n5: 2 batches\n21: 2 batches\n19 Start Epoch 3\n19: 2 batches\n9 Start Epoch 3\n9: 2 batches\n10 Start Epoch 3\n10: 2 batches\n8 Start Epoch 3\n8: 2 batches\n11 Start Epoch 3\n11: 2 batches\n4 Start Epoch 3\n17 Start Epoch 3\n4: 2 batches\n17: 2 batches\n0 Start Epoch 3\n0: 2 batches\n1 Start Epoch 4\n2 Start Epoch 4\n1: 2 batches\n5 Start Epoch 4\n2: 2 batches\n5: 2 batches\n18 Start Epoch 4\n18: 2 batches\n14 Start Epoch 4\n11 Start Epoch 4\n4 Start Epoch 4\n15 Start Epoch 4\n10 Start Epoch 4\n4: 2 batches\n19 Start Epoch 4\n19: 2 batches\n20 Start Epoch 4\n15: 2 batches\n10: 2 batches\n14: 2 batches\n11: 2 batches\n22 Start Epoch 4\n22: 2 batches\n21 Start Epoch 4\n21: 2 batches\n20: 2 batches\n23 Start Epoch 4\n23: 2 batches\n3 Start Epoch 4\n12 Start Epoch 4\n12: 2 batches\n3: 2 batches\n7 Start Epoch 4\n6 Start Epoch 4\n9 Start Epoch 4\n6: 2 batches\n9: 2 batches\n7: 2 batches\n8 Start Epoch 4\n8: 2 batches\n17 Start Epoch 4\n17: 2 batches\n16 Start Epoch 4\n16: 2 batches\n13 Start Epoch 4\n13: 2 batches\n0 Start Epoch 4\n0: 2 batches\n3 Start Epoch 5\n2 Start Epoch 5\n9 Start Epoch 5\n11 Start Epoch 5\n9: 2 batches\n3: 2 batches\n2: 2 batches\n8 Start Epoch 5\n8: 2 batches\n5 Start Epoch 5\n6 Start Epoch 5\n6: 2 batches\n7 Start Epoch 5\n7: 2 batches\n5: 2 batches\n4 Start Epoch 5\n4: 2 batches\n1 Start Epoch 5\n1: 2 batches\n16 Start Epoch 5\n20 Start Epoch 5\n10 Start Epoch 5\n10: 2 batches\n16: 2 batches\n20: 2 batches\n17 Start Epoch 5\n17: 2 batches\n18 Start Epoch 5\n19 Start Epoch 5\n19: 2 batches\n18: 2 batches\n21 Start Epoch 5\n23 Start Epoch 5\n11: 2 batches\n12 Start Epoch 5\n13 Start Epoch 5\n13: 2 batches\n12: 2 batches\n15 Start Epoch 5\n15: 2 batches\n14 Start Epoch 5\n14: 2 batches\n22 Start Epoch 5\n21: 2 batches\n22: 2 batches\n23: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 13711.226318359375\nINFO:root:2: Epoch 0 train loss: 1207187.59375\nINFO:root:13: Epoch 0 train loss: 4405.569580078125\nINFO:root:11: Epoch 0 train loss: 11078.835510253906\nINFO:root:5: Epoch 0 train loss: 36337.6220703125\nINFO:root:23: Epoch 0 train loss: 3100.5953369140625\nINFO:root:9: Epoch 0 train loss: 21502.59521484375\nINFO:root:6: Epoch 0 train loss: 870258.7990722656\nINFO:root:18: Epoch 0 train loss: 2918.83056640625\nINFO:root:19: Epoch 0 train loss: 2319.85152053833\nINFO:root:10: Epoch 0 train loss: 5000.5611572265625\nINFO:root:4: Epoch 0 train loss: 2473.508834838867\nINFO:root:8: Epoch 0 train loss: 25321.2685546875\nINFO:root:7: Epoch 0 train loss: 22314.6640625\nINFO:root:21: Epoch 0 train loss: 6205.2528076171875\nINFO:root:12: Epoch 0 train loss: 14507.421020507812\nINFO:root:22: Epoch 0 train loss: 5417.029739379883\nINFO:root:20: Epoch 0 train loss: 3195.5589599609375\nINFO:root:16: Epoch 0 train loss: 4740.205322265625\nINFO:root:1: Epoch 0 train loss: 1017714.333984375\nINFO:root:17: Epoch 0 train loss: 118123.96875\nINFO:root:3: Epoch 0 train loss: 869532.0975036621\nINFO:root:14: Epoch 0 train loss: 1107937.3015136719\nINFO:root:15: Epoch 0 train loss: 969.3048706054688\nINFO:root:0: Epoch 0 validation loss: 807509.7438469674\nINFO:root:3: Epoch 1 train loss: 3455.884063720703\nINFO:root:16: Epoch 1 train loss: 1227450.51171875\nINFO:root:17: Epoch 1 train loss: 4744.534729003906\nINFO:root:5: Epoch 1 train loss: 1067190.8038330078\nINFO:root:6: Epoch 1 train loss: 3700.989501953125\nINFO:root:20: Epoch 1 train loss: 1090007.3159179688\nINFO:root:19: Epoch 1 train loss: 11267.95361328125\nINFO:root:18: Epoch 1 train loss: 7850.3597412109375\nINFO:root:8: Epoch 1 train loss: 800.621826171875\nINFO:root:11: Epoch 1 train loss: 2020834.4638671875\nINFO:root:7: Epoch 1 train loss: 9046.9375\nINFO:root:4: Epoch 1 train loss: 13641.76220703125\nINFO:root:15: Epoch 1 train loss: 1005.4736785888672\nINFO:root:13: Epoch 1 train loss: 6284.77197265625\nINFO:root:12: Epoch 1 train loss: 21665.260498046875\nINFO:root:14: Epoch 1 train loss: 881702.4666137695\nINFO:root:21: Epoch 1 train loss: 12661.47543334961\nINFO:root:9: Epoch 1 train loss: 32250.7216796875\nINFO:root:10: Epoch 1 train loss: 12512.0068359375\nINFO:root:22: Epoch 1 train loss: 4750.548522949219\nINFO:root:2: Epoch 1 train loss: 298.56646728515625\nINFO:root:0: Epoch 1 train loss: 976369.986328125\nINFO:root:1: Epoch 1 train loss: 1185.3767395019531\nINFO:root:23: Epoch 1 train loss: 528.8859176635742\nINFO:root:0: Epoch 1 validation loss: 807492.8095097921\nINFO:root:13: Epoch 2 train loss: 21526.87890625\nINFO:root:14: Epoch 2 train loss: 2316655.609375\nINFO:root:15: Epoch 2 train loss: 833664.6188964844\nINFO:root:16: Epoch 2 train loss: 1029381.6225585938\nINFO:root:6: Epoch 2 train loss: 1028654.8111572266\nINFO:root:7: Epoch 2 train loss: 5917.5418701171875\nINFO:root:23: Epoch 2 train loss: 48181.99938964844\nINFO:root:1: Epoch 2 train loss: 32160.47265625\nINFO:root:3: Epoch 2 train loss: 871443.927947998\nINFO:root:0: Epoch 2 train loss: 142141.6640625\nINFO:root:2: Epoch 2 train loss: 362551.21252441406\nINFO:root:20: Epoch 2 train loss: 4909.359577178955\nINFO:root:18: Epoch 2 train loss: 869604.712890625\nINFO:root:12: Epoch 2 train loss: 1031217.2338867188\nINFO:root:22: Epoch 2 train loss: 1098100.385192871\nINFO:root:5: Epoch 2 train loss: 886440.4831542969\nINFO:root:21: Epoch 2 train loss: 4043.427001953125\nINFO:root:19: Epoch 2 train loss: 370467.2615966797\nINFO:root:11: Epoch 2 train loss: 869987.4558105469\nINFO:root:9: Epoch 2 train loss: 8355.908935546875\nINFO:root:10: Epoch 2 train loss: 9783.649658203125\nINFO:root:8: Epoch 2 train loss: 6014.56298828125\nINFO:root:4: Epoch 2 train loss: 42099.77734375\nINFO:root:17: Epoch 2 train loss: 4920.0177001953125\nINFO:root:0: Epoch 2 validation loss: 807475.8474006477\nINFO:root:2: Epoch 3 train loss: 16636.26921081543\nINFO:root:1: Epoch 3 train loss: 2637.2994232177734\nINFO:root:5: Epoch 3 train loss: 362924.11376953125\nINFO:root:4: Epoch 3 train loss: 1090556.5869140625\nINFO:root:23: Epoch 3 train loss: 30522.935302734375\nINFO:root:14: Epoch 3 train loss: 1946147.9748535156\nINFO:root:11: Epoch 3 train loss: 5494.11572265625\nINFO:root:0: Epoch 3 train loss: 11197.685668945312\nINFO:root:20: Epoch 3 train loss: 12037.328796386719\nINFO:root:15: Epoch 3 train loss: 10457.377197265625\nINFO:root:10: Epoch 3 train loss: 875275.453125\nINFO:root:18: Epoch 3 train loss: 10556.629638671875\nINFO:root:21: Epoch 3 train loss: 14095.484619140625\nINFO:root:22: Epoch 3 train loss: 1363.2796020507812\nINFO:root:19: Epoch 3 train loss: 8326.552070617676\nINFO:root:3: Epoch 3 train loss: 2622.1962280273438\nINFO:root:12: Epoch 3 train loss: 4106.4783935546875\nINFO:root:7: Epoch 3 train loss: 1538.6445770263672\nINFO:root:6: Epoch 3 train loss: 3755.4404296875\nINFO:root:8: Epoch 3 train loss: 11511.5380859375\nINFO:root:9: Epoch 3 train loss: 338.3763427734375\nINFO:root:17: Epoch 3 train loss: 1166288.666229248\nINFO:root:16: Epoch 3 train loss: 5513.7666015625\nINFO:root:13: Epoch 3 train loss: 12289.983154296875\nINFO:root:0: Epoch 3 validation loss: 807458.1426913403\nINFO:root:3: Epoch 4 train loss: 1000227.9369659424\nINFO:root:2: Epoch 4 train loss: 1974.8405151367188\nINFO:root:8: Epoch 4 train loss: 1967729.5219726562\nINFO:root:11: Epoch 4 train loss: 12301.607421875\nINFO:root:9: Epoch 4 train loss: 14913.4365234375\nINFO:root:7: Epoch 4 train loss: 840837.91015625\nINFO:root:5: Epoch 4 train loss: 2232.9813385009766\nINFO:root:4: Epoch 4 train loss: 7611.55810546875\nINFO:root:6: Epoch 4 train loss: 29804.9599609375\nINFO:root:1: Epoch 4 train loss: 24031.327880859375\nINFO:root:0: Epoch 4 train loss: 2866.585906982422\nINFO:root:16: Epoch 4 train loss: 20239.8837890625\nINFO:root:22: Epoch 4 train loss: 3225.9727783203125\nINFO:root:10: Epoch 4 train loss: 363234.6271972656\nINFO:root:20: Epoch 4 train loss: 13816.43505859375\nINFO:root:17: Epoch 4 train loss: 17720.45458984375\nINFO:root:19: Epoch 4 train loss: 565.8190765380859\nINFO:root:18: Epoch 4 train loss: 1165380.791015625\nINFO:root:21: Epoch 4 train loss: 1035562.81640625\nINFO:root:23: Epoch 4 train loss: 1097209.20703125\nINFO:root:12: Epoch 4 train loss: 9828.858795166016\nINFO:root:13: Epoch 4 train loss: 21329.833435058594\nINFO:root:14: Epoch 4 train loss: 9762.717651367188\nINFO:root:15: Epoch 4 train loss: 867680.3299560547\nINFO:root:0: Epoch 4 validation loss: 807439.2226087556\nINFO:root:15: Epoch 5 train loss: 7844.826904296875\nINFO:root:7: Epoch 5 train loss: 348761.06942749023\nINFO:root:6: Epoch 5 train loss: 1836.2518005371094\nINFO:root:3: Epoch 5 train loss: 1201615.7426757812\nINFO:root:0: Epoch 5 train loss: 8540.919677734375\nINFO:root:23: Epoch 5 train loss: 16659.08935546875\nINFO:root:21: Epoch 5 train loss: 1362.782958984375\nINFO:root:22: Epoch 5 train loss: 1371.0970764160156\nINFO:root:14: Epoch 5 train loss: 12751.2607421875\nINFO:root:13: Epoch 5 train loss: 1127649.7578125\nINFO:root:16: Epoch 5 train loss: 806.2838439941406\nINFO:root:18: Epoch 5 train loss: 11273.877319335938\nINFO:root:19: Epoch 5 train loss: 599.0881233215332\nINFO:root:20: Epoch 5 train loss: 11597.518493652344\nINFO:root:8: Epoch 5 train loss: 814688.9851074219\nINFO:root:9: Epoch 5 train loss: 4513.8167724609375\nINFO:root:2: Epoch 5 train loss: 15889.596618652344\nINFO:root:11: Epoch 5 train loss: 2352832.375\nINFO:root:5: Epoch 5 train loss: 8420.119506835938\nINFO:root:10: Epoch 5 train loss: 3825.6585083007812\nINFO:root:4: Epoch 5 train loss: 35363.82470703125\nINFO:root:1: Epoch 5 train loss: 1005015.3872070312\nINFO:root:17: Epoch 5 train loss: 30961.905242919922\nINFO:root:12: Epoch 5 train loss: 4334.7347412109375\nINFO:root:0: Epoch 5 validation loss: 807418.9029939884\n", "seconds": 13.766449689865112, "batch_size": 64, "nodes": 6, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n1 Start Epoch 0\n1: 2 batches\n2 Start Epoch 0\n2: 2 batches\n27 Start Epoch 0\n27: 2 batches\n12 Start Epoch 0\n12: 2 batches\n14 Start Epoch 0\n14: 2 batches\n13 Start Epoch 0\n13: 2 batches\n19 Start Epoch 0\n4 Start Epoch 0\n19: 2 batches\n4: 2 batches\n20 Start Epoch 0\n6 Start Epoch 0\n20: 2 batches\n6: 2 batches\n11 Start Epoch 0\n5 Start Epoch 0\n22 Start Epoch 0\n21 Start Epoch 0\n11: 2 batches\n3 Start Epoch 0\n5: 2 batches\n22: 2 batches\n21: 2 batches\n3: 2 batches\n23 Start Epoch 0\n23: 2 batches\n15 Start Epoch 0\n15: 2 batches\n8 Start Epoch 0\n8: 2 batches\n16 Start Epoch 0\n24 Start Epoch 0\n16: 2 batches\n24: 2 batches\n7 Start Epoch 0\n7: 2 batches\n9 Start Epoch 0\n10 Start Epoch 0\n10: 2 batches\n9: 2 batches\n25 Start Epoch 0\n26 Start Epoch 0\n26: 2 batches\n17 Start Epoch 0\n18 Start Epoch 0\n25: 2 batches\n18: 2 batches\n17: 2 batches\n1 Start Epoch 1\n1: 2 batches\n27 Start Epoch 1\n25 Start Epoch 1\n27: 2 batches\n26 Start Epoch 1\n16 Start Epoch 1\n21 Start Epoch 1\n19 Start Epoch 1\n19: 2 batches\n20 Start Epoch 1\n17 Start Epoch 1\n22 Start Epoch 1\n20: 2 batches\n16: 2 batches\n18 Start Epoch 1\n21: 2 batches\n23 Start Epoch 1\n18: 2 batches\n17: 2 batches\n23: 2 batches\n22: 2 batches\n26: 2 batches\n25: 2 batches\n12 Start Epoch 1\n13 Start Epoch 1\n14 Start Epoch 1\n14: 2 batches\n12: 2 batches\n15 Start Epoch 1\n15: 2 batches\n13: 2 batches\n2 Start Epoch 1\n2: 2 batches\n3 Start Epoch 1\n3: 2 batches\n5 Start Epoch 1\n6 Start Epoch 1\n6: 2 batches\n7 Start Epoch 1\n5: 2 batches\n7: 2 batches\n11 Start Epoch 1\n11: 2 batches\n4 Start Epoch 1\n4: 2 batches\n24 Start Epoch 1\n24: 2 batches\n8 Start Epoch 1\n8: 2 batches\n10 Start Epoch 1\n10: 2 batches\n9 Start Epoch 1\n9: 2 batches\n0 Start Epoch 1\n0: 2 batches\n27 Start Epoch 2\n26 Start Epoch 2\n3 Start Epoch 2\n3: 2 batches\n18 Start Epoch 2\n23 Start Epoch 2\n26: 2 batches\n23: 2 batches\n27: 2 batches\n2 Start Epoch 2\n19 Start Epoch 2\n12 Start Epoch 2\n19: 2 batches\n10 Start Epoch 2\n22 Start Epoch 2\n2: 2 batches\n8 Start Epoch 2\n22: 2 batches\n14 Start Epoch 2\n17 Start Epoch 2\n9 Start Epoch 2\n7 Start Epoch 2\n13 Start Epoch 2\n10: 2 batches\n7: 2 batches\n20 Start Epoch 2\n24 Start Epoch 2\n12: 2 batches\n8: 2 batches\n20: 2 batches\n24: 2 batches\n14: 2 batches\n16 Start Epoch 2\n16: 2 batches\n18: 2 batches\n11 Start Epoch 2\n15 Start Epoch 2\n15: 2 batches\n17: 2 batches\n11: 2 batches\n21 Start Epoch 2\n13: 2 batches\n9: 2 batches\n5 Start Epoch 2\n21: 2 batches\n4 Start Epoch 2\n6 Start Epoch 2\n4: 2 batches\n6: 2 batches\n5: 2 batches\n25 Start Epoch 2\n25: 2 batches\n1 Start Epoch 2\n1: 2 batches\n0 Start Epoch 2\n0: 2 batches\n11 Start Epoch 3\n11: 2 batches\n21 Start Epoch 3\n20 Start Epoch 3\n14 Start Epoch 3\n21: 2 batches\n13 Start Epoch 3\n20: 2 batches\n27 Start Epoch 3\n25 Start Epoch 3\n27: 2 batches\n25: 2 batches\n26 Start Epoch 3\n26: 2 batches\n24 Start Epoch 3\n24: 2 batches\n19 Start Epoch 3\n16 Start Epoch 3\n19: 2 batches\n16: 2 batches\n18 Start Epoch 3\n18: 2 batches\n17 Start Epoch 3\n17: 2 batches\n14: 2 batches\n15 Start Epoch 3\n15: 2 batches\n13: 2 batches\n10 Start Epoch 3\n10: 2 batches\n23 Start Epoch 3\n23: 2 batches\n7 Start Epoch 3\n7: 2 batches\n22 Start Epoch 3\n22: 2 batches\n12 Start Epoch 3\n12: 2 batches\n5 Start Epoch 3\n6 Start Epoch 3\n6: 2 batches\n1 Start Epoch 3\n2 Start Epoch 3\n3 Start Epoch 3\n5: 2 batches\n3: 2 batches\n2: 2 batches\n8 Start Epoch 3\n9 Start Epoch 3\n8: 2 batches\n9: 2 batches\n1: 2 batches\n4 Start Epoch 3\n4: 2 batches\n0 Start Epoch 3\n0: 2 batches\n11 Start Epoch 4\n10 Start Epoch 4\n11: 2 batches\n10: 2 batches\n13 Start Epoch 4\n14 Start Epoch 4\n12 Start Epoch 4\n14: 2 batches\n12: 2 batches\n15 Start Epoch 4\n15: 2 batches\n13: 2 batches\n8 Start Epoch 4\n8: 2 batches\n9 Start Epoch 4\n9: 2 batches\n7 Start Epoch 4\n7: 2 batches\n6 Start Epoch 4\n6: 2 batches\n22 Start Epoch 4\n21 Start Epoch 4\n22: 2 batches\n23 Start Epoch 4\n23: 2 batches\n21: 2 batches\n20 Start Epoch 4\n20: 2 batches\n2 Start Epoch 4\n2: 2 batches\n25 Start Epoch 4\n27 Start Epoch 4\n19 Start Epoch 4\n1 Start Epoch 4\n19: 2 batches\n1: 2 batches\n27: 2 batches\n18 Start Epoch 4\n25: 2 batches\n24 Start Epoch 4\n26 Start Epoch 4\n4 Start Epoch 4\n24: 2 batches\n5 Start Epoch 4\n5: 2 batches\n26: 2 batches\n4: 2 batches\n18: 2 batches\n16 Start Epoch 4\n16: 2 batches\n17 Start Epoch 4\n17: 2 batches\n3 Start Epoch 4\n3: 2 batches\n0 Start Epoch 4\n0: 2 batches\n19 Start Epoch 5\n23 Start Epoch 5\n19: 2 batches\n23: 2 batches\n22 Start Epoch 5\n22: 2 batches\n21 Start Epoch 5\n7 Start Epoch 5\n20 Start Epoch 5\n7: 2 batches\n13 Start Epoch 5\n20: 2 batches\n14 Start Epoch 5\n18 Start Epoch 5\n27 Start Epoch 5\n14: 2 batches\n17 Start Epoch 5\n10 Start Epoch 5\n15 Start Epoch 5\n16 Start Epoch 5\n16: 2 batches\n8 Start Epoch 5\n24 Start Epoch 5\n11 Start Epoch 5\n26 Start Epoch 5\n26: 2 batches\n15: 2 batches\n18: 2 batches\n24: 2 batches\n13: 2 batches\n17: 2 batches\n8: 2 batches\n11: 2 batches\n25 Start Epoch 5\n25: 2 batches\n10: 2 batches\n27: 2 batches\n5 Start Epoch 5\n6 Start Epoch 5\n6: 2 batches\n5: 2 batches\n4 Start Epoch 5\n1 Start Epoch 5\n1: 2 batches\n2 Start Epoch 5\n3 Start Epoch 5\n3: 2 batches\n9 Start Epoch 5\n9: 2 batches\n2: 2 batches\n21: 2 batches\n4: 2 batches\n12 Start Epoch 5\n12: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:1: Epoch 0 train loss: 4845.67431640625\nINFO:root:0: Epoch 0 train loss: 6461.758544921875\nINFO:root:26: Epoch 0 train loss: 32161.72216796875\nINFO:root:25: Epoch 0 train loss: 3925.6602783203125\nINFO:root:27: Epoch 0 train loss: 1219.2490539550781\nINFO:root:19: Epoch 0 train loss: 6781.93115234375\nINFO:root:21: Epoch 0 train loss: 347859.9255371094\nINFO:root:16: Epoch 0 train loss: 2085048.195678711\nINFO:root:22: Epoch 0 train loss: 20923.306640625\nINFO:root:18: Epoch 0 train loss: 42130.1435546875\nINFO:root:23: Epoch 0 train loss: 8588.30322265625\nINFO:root:20: Epoch 0 train loss: 12703.6826171875\nINFO:root:17: Epoch 0 train loss: 1108.6115417480469\nINFO:root:7: Epoch 0 train loss: 533332.58203125\nINFO:root:13: Epoch 0 train loss: 5946.0428466796875\nINFO:root:14: Epoch 0 train loss: 12507.9423828125\nINFO:root:15: Epoch 0 train loss: 1848.2832489013672\nINFO:root:12: Epoch 0 train loss: 463.3441390991211\nINFO:root:3: Epoch 0 train loss: 4727.482416152954\nINFO:root:2: Epoch 0 train loss: 1213784.8386230469\nINFO:root:5: Epoch 0 train loss: 2838655.2985839844\nINFO:root:6: Epoch 0 train loss: 20300.8671875\nINFO:root:11: Epoch 0 train loss: 1000442.9741821289\nINFO:root:4: Epoch 0 train loss: 3714.0411376953125\nINFO:root:24: Epoch 0 train loss: 7225.961669921875\nINFO:root:10: Epoch 0 train loss: 184.05188751220703\nINFO:root:9: Epoch 0 train loss: 3794.3658752441406\nINFO:root:8: Epoch 0 train loss: 3758.5089721679688\nINFO:root:0: Epoch 0 validation loss: 99836.13996558014\nINFO:root:27: Epoch 1 train loss: 27225.974609375\nINFO:root:26: Epoch 1 train loss: 3824.5377197265625\nINFO:root:19: Epoch 1 train loss: 2900.3598022460938\nINFO:root:10: Epoch 1 train loss: 1155.72216796875\nINFO:root:23: Epoch 1 train loss: 113114.31150817871\nINFO:root:15: Epoch 1 train loss: 6810.5205078125\nINFO:root:3: Epoch 1 train loss: 2053.5459594726562\nINFO:root:12: Epoch 1 train loss: 2052697.0085601807\nINFO:root:9: Epoch 1 train loss: 2320.879150390625\nINFO:root:18: Epoch 1 train loss: 1066066.109375\nINFO:root:8: Epoch 1 train loss: 1092839.3461914062\nINFO:root:13: Epoch 1 train loss: 1423628.6946868896\nINFO:root:2: Epoch 1 train loss: 1649.1323852539062\nINFO:root:11: Epoch 1 train loss: 15365.633712768555\nINFO:root:22: Epoch 1 train loss: 11169.24951171875\nINFO:root:14: Epoch 1 train loss: 2955.5406494140625\nINFO:root:7: Epoch 1 train loss: 817443.9358520508\nINFO:root:17: Epoch 1 train loss: 1524850.286567688\nINFO:root:20: Epoch 1 train loss: 20332.76513671875\nINFO:root:0: Epoch 1 train loss: 1666457.0771484375\nINFO:root:24: Epoch 1 train loss: 551858.232421875\nINFO:root:16: Epoch 1 train loss: 1468542.87109375\nINFO:root:4: Epoch 1 train loss: 8573.546813964844\nINFO:root:5: Epoch 1 train loss: 13925.30029296875\nINFO:root:21: Epoch 1 train loss: 20000.3623046875\nINFO:root:6: Epoch 1 train loss: 1497710.4462890625\nINFO:root:25: Epoch 1 train loss: 33699.63961791992\nINFO:root:1: Epoch 1 train loss: 9968.809326171875\nINFO:root:0: Epoch 1 validation loss: 99825.57368566163\nINFO:root:11: Epoch 2 train loss: 3261.0667724609375\nINFO:root:20: Epoch 2 train loss: 3366.3908081054688\nINFO:root:14: Epoch 2 train loss: 8040.857177734375\nINFO:root:21: Epoch 2 train loss: 1044843.0122070312\nINFO:root:15: Epoch 2 train loss: 23694.676513671875\nINFO:root:27: Epoch 2 train loss: 570245.92578125\nINFO:root:13: Epoch 2 train loss: 2596689.3828125\nINFO:root:26: Epoch 2 train loss: 378.0252151489258\nINFO:root:25: Epoch 2 train loss: 32489.2060546875\nINFO:root:24: Epoch 2 train loss: 431.0970916748047\nINFO:root:16: Epoch 2 train loss: 1358459.14453125\nINFO:root:18: Epoch 2 train loss: 11022.84243774414\nINFO:root:19: Epoch 2 train loss: 1233.6221313476562\nINFO:root:17: Epoch 2 train loss: 17154.4345703125\nINFO:root:0: Epoch 2 train loss: 1374453.4621582031\nINFO:root:10: Epoch 2 train loss: 60669.86636352539\nINFO:root:23: Epoch 2 train loss: 1010937.0049743652\nINFO:root:7: Epoch 2 train loss: 7994.2559814453125\nINFO:root:22: Epoch 2 train loss: 1924.0229797363281\nINFO:root:12: Epoch 2 train loss: 17693.5732421875\nINFO:root:1: Epoch 2 train loss: 4437.9229736328125\nINFO:root:5: Epoch 2 train loss: 41824.7109375\nINFO:root:6: Epoch 2 train loss: 1087843.309791565\nINFO:root:3: Epoch 2 train loss: 4203.07421875\nINFO:root:2: Epoch 2 train loss: 10798.073280334473\nINFO:root:9: Epoch 2 train loss: 7012.0355224609375\nINFO:root:8: Epoch 2 train loss: 1528588.0283203125\nINFO:root:4: Epoch 2 train loss: 24209.776123046875\nINFO:root:0: Epoch 2 validation loss: 99814.7464885535\nINFO:root:11: Epoch 3 train loss: 1956.6823272705078\nINFO:root:10: Epoch 3 train loss: 6503.8369140625\nINFO:root:15: Epoch 3 train loss: 10819.117431640625\nINFO:root:12: Epoch 3 train loss: 4531.560089111328\nINFO:root:13: Epoch 3 train loss: 1834379.8598632812\nINFO:root:14: Epoch 3 train loss: 2393.9682006835938\nINFO:root:9: Epoch 3 train loss: 1036988.3347167969\nINFO:root:8: Epoch 3 train loss: 23829.89794921875\nINFO:root:7: Epoch 3 train loss: 29341.954833984375\nINFO:root:6: Epoch 3 train loss: 48403.479919433594\nINFO:root:21: Epoch 3 train loss: 5154.072601318359\nINFO:root:22: Epoch 3 train loss: 15044.731262207031\nINFO:root:23: Epoch 3 train loss: 23333.6259765625\nINFO:root:20: Epoch 3 train loss: 4712.977478027344\nINFO:root:2: Epoch 3 train loss: 1235.212158203125\nINFO:root:0: Epoch 3 train loss: 22661.8017578125\nINFO:root:25: Epoch 3 train loss: 4227.2762451171875\nINFO:root:19: Epoch 3 train loss: 9032.573333740234\nINFO:root:18: Epoch 3 train loss: 1468722.5434570312\nINFO:root:1: Epoch 3 train loss: 1523837.1218261719\nINFO:root:27: Epoch 3 train loss: 177069.04083251953\nINFO:root:26: Epoch 3 train loss: 15338.314453125\nINFO:root:24: Epoch 3 train loss: 29803.30078125\nINFO:root:4: Epoch 3 train loss: 4970.9749755859375\nINFO:root:5: Epoch 3 train loss: 3861.483856201172\nINFO:root:16: Epoch 3 train loss: 976.6613464355469\nINFO:root:17: Epoch 3 train loss: 9669.967407226562\nINFO:root:3: Epoch 3 train loss: 3226.119140625\nINFO:root:0: Epoch 3 validation loss: 99803.77681235455\nINFO:root:19: Epoch 4 train loss: 8276.644165039062\nINFO:root:22: Epoch 4 train loss: 1056653.1640625\nINFO:root:23: Epoch 4 train loss: 3182.579803466797\nINFO:root:21: Epoch 4 train loss: 340411.9289550781\nINFO:root:13: Epoch 4 train loss: 1317845.2827148438\nINFO:root:7: Epoch 4 train loss: 3322.4143676757812\nINFO:root:14: Epoch 4 train loss: 1085328.9381484985\nINFO:root:16: Epoch 4 train loss: 1258.6513061523438\nINFO:root:9: Epoch 4 train loss: 6155.360107421875\nINFO:root:20: Epoch 4 train loss: 6515.2757568359375\nINFO:root:24: Epoch 4 train loss: 999432.6787109375\nINFO:root:25: Epoch 4 train loss: 1199230.3728637695\nINFO:root:15: Epoch 4 train loss: 9230.47705078125\nINFO:root:18: Epoch 4 train loss: 24831.7412109375\nINFO:root:11: Epoch 4 train loss: 21749.73777770996\nINFO:root:27: Epoch 4 train loss: 3074.7565307617188\nINFO:root:17: Epoch 4 train loss: 4863.386535644531\nINFO:root:10: Epoch 4 train loss: 1308.6878967285156\nINFO:root:26: Epoch 4 train loss: 790.2072143554688\nINFO:root:8: Epoch 4 train loss: 5635.780319213867\nINFO:root:4: Epoch 4 train loss: 113166.71337890625\nINFO:root:6: Epoch 4 train loss: 564.8429565429688\nINFO:root:5: Epoch 4 train loss: 1244100.5737304688\nINFO:root:1: Epoch 4 train loss: 2896.490478515625\nINFO:root:2: Epoch 4 train loss: 12865.210418701172\nINFO:root:3: Epoch 4 train loss: 1523056.1555480957\nINFO:root:0: Epoch 4 train loss: 1706.4648742675781\nINFO:root:12: Epoch 4 train loss: 16214.38070678711\nINFO:root:0: Epoch 4 validation loss: 99792.58075225767\nINFO:root:14: Epoch 5 train loss: 2634.270263671875\nINFO:root:9: Epoch 5 train loss: 1367.1594848632812\nINFO:root:15: Epoch 5 train loss: 1825167.5852050781\nINFO:root:11: Epoch 5 train loss: 1048885.7919921875\nINFO:root:10: Epoch 5 train loss: 1036578.916015625\nINFO:root:13: Epoch 5 train loss: 114549.96347045898\nINFO:root:16: Epoch 5 train loss: 6630.7657470703125\nINFO:root:12: Epoch 5 train loss: 2438110.1875\nINFO:root:17: Epoch 5 train loss: 11973.84130859375\nINFO:root:2: Epoch 5 train loss: 1316834.4934539795\nINFO:root:6: Epoch 5 train loss: 1315615.3186035156\nINFO:root:21: Epoch 5 train loss: 1827074.966873169\nINFO:root:7: Epoch 5 train loss: 14592.106338500977\nINFO:root:20: Epoch 5 train loss: 2624.7460327148438\nINFO:root:5: Epoch 5 train loss: 4930.809875488281\nINFO:root:19: Epoch 5 train loss: 29910.504180908203\nINFO:root:4: Epoch 5 train loss: 373861.4436645508\nINFO:root:23: Epoch 5 train loss: 7328.888847351074\nINFO:root:22: Epoch 5 train loss: 1588568.8404541016\nINFO:root:24: Epoch 5 train loss: 1673288.9521484375\nINFO:root:26: Epoch 5 train loss: 12821.21337890625\nINFO:root:25: Epoch 5 train loss: 1112477.826171875\nINFO:root:27: Epoch 5 train loss: 1040713.80078125\nINFO:root:3: Epoch 5 train loss: 117700.91961669922\nINFO:root:18: Epoch 5 train loss: 1093074.4419555664\nINFO:root:1: Epoch 5 train loss: 3445.05126953125\nINFO:root:8: Epoch 5 train loss: 34265.3876953125\nINFO:root:0: Epoch 5 train loss: 1072192.806640625\nINFO:root:0: Epoch 5 validation loss: 99781.18397540676\n", "seconds": 16.48903512954712, "batch_size": 64, "nodes": 7, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n2 Start Epoch 0\n2: 2 batches\n1 Start Epoch 0\n1: 2 batches\n4 Start Epoch 0\n4: 2 batches\n3 Start Epoch 0\n31 Start Epoch 0\n31: 2 batches\n3: 2 batches\n5 Start Epoch 0\n5: 2 batches\n6 Start Epoch 0\n6: 2 batches\n7 Start Epoch 0\n7: 2 batches\n8 Start Epoch 0\n16 Start Epoch 0\n16: 2 batches\n8: 2 batches\n24 Start Epoch 0\n27 Start Epoch 0\n27: 2 batches\n28 Start Epoch 0\n24: 2 batches\n28: 2 batches\n11 Start Epoch 0\n23 Start Epoch 0\n23: 2 batches\n11: 2 batches\n20 Start Epoch 0\n20: 2 batches\n21 Start Epoch 0\n22 Start Epoch 0\n21: 2 batches\n22: 2 batches\n19 Start Epoch 0\n19: 2 batches\n9 Start Epoch 0\n10 Start Epoch 0\n25 Start Epoch 0\n9: 2 batches\n26 Start Epoch 0\n10: 2 batches\n25: 2 batches\n17 Start Epoch 0\n17: 2 batches\n26: 2 batches\n29 Start Epoch 0\n29: 2 batches\n30 Start Epoch 0\n12 Start Epoch 0\n12: 2 batches\n18 Start Epoch 0\n15 Start Epoch 0\n15: 2 batches\n30: 2 batches\n13 Start Epoch 0\n14 Start Epoch 0\n13: 2 batches\n14: 2 batches\n18: 2 batches\n31 Start Epoch 1\n31: 2 batches\n7 Start Epoch 1\n14 Start Epoch 1\n7: 2 batches\n15 Start Epoch 1\n15: 2 batches\n4 Start Epoch 1\n5 Start Epoch 1\n6 Start Epoch 1\n4: 2 batches\n5: 2 batches\n6: 2 batches\n1 Start Epoch 1\n1: 2 batches\n2 Start Epoch 1\n2: 2 batches\n3 Start Epoch 1\n3: 2 batches\n23 Start Epoch 1\n23: 2 batches\n27 Start Epoch 1\n12 Start Epoch 1\n8 Start Epoch 1\n8: 2 batches\n28 Start Epoch 1\n28: 2 batches\n27: 2 batches\n12: 2 batches\n10 Start Epoch 1\n10: 2 batches\n30 Start Epoch 1\n30: 2 batches\n16 Start Epoch 1\n19 Start Epoch 1\n26 Start Epoch 1\n13 Start Epoch 1\n16: 2 batches\n9 Start Epoch 1\n9: 2 batches\n13: 2 batches\n24 Start Epoch 1\n24: 2 batches\n26: 2 batches\n25 Start Epoch 1\n25: 2 batches\n18 Start Epoch 1\n18: 2 batches\n19: 2 batches\n17 Start Epoch 1\n17: 2 batches\n29 Start Epoch 1\n29: 2 batches\n14: 2 batches\n11 Start Epoch 1\n11: 2 batches\n20 Start Epoch 1\n22 Start Epoch 1\n20: 2 batches\n22: 2 batches\n21 Start Epoch 1\n21: 2 batches\n0 Start Epoch 1\n0: 2 batches\n11 Start Epoch 2\n11: 2 batches\n7 Start Epoch 2\n7: 2 batches\n13 Start Epoch 2\n14 Start Epoch 2\n23 Start Epoch 2\n23: 2 batches\n24 Start Epoch 2\n25 Start Epoch 2\n25: 2 batches\n19 Start Epoch 2\n24: 2 batches\n8 Start Epoch 2\n10 Start Epoch 2\n10: 2 batches\n9 Start Epoch 2\n9: 2 batches\n8: 2 batches\n20 Start Epoch 2\n20: 2 batches\n16 Start Epoch 2\n16: 2 batches\n18 Start Epoch 2\n18: 2 batches\n17 Start Epoch 2\n17: 2 batches\n19: 2 batches\n15 Start Epoch 2\n15: 2 batches\n14: 2 batches\n13: 2 batches\n31 Start Epoch 2\n31: 2 batches\n2 Start Epoch 2\n2: 2 batches\n22 Start Epoch 2\n22: 2 batches\n21 Start Epoch 2\n21: 2 batches\n3 Start Epoch 2\n3: 2 batches\n5 Start Epoch 2\n5: 2 batches\n4 Start Epoch 2\n4: 2 batches\n1 Start Epoch 2\n1: 2 batches\n6 Start Epoch 2\n27 Start Epoch 2\n27: 2 batches\n6: 2 batches\n29 Start Epoch 2\n28 Start Epoch 2\n30 Start Epoch 2\n30: 2 batches\n28: 2 batches\n12 Start Epoch 2\n12: 2 batches\n26 Start Epoch 2\n26: 2 batches\n29: 2 batches\n0 Start Epoch 2\n0: 2 batches\n3 Start Epoch 3\n3: 2 batches\n31 Start Epoch 3\n7 Start Epoch 3\n20 Start Epoch 3\n14 Start Epoch 3\n31: 2 batches\n7: 2 batches\n15 Start Epoch 3\n20: 2 batches\n14: 2 batches\n21 Start Epoch 3\n15: 2 batches\n22 Start Epoch 3\n22: 2 batches\n21: 2 batches\n24 Start Epoch 3\n5 Start Epoch 3\n24: 2 batches\n5: 2 batches\n2 Start Epoch 3\n2: 2 batches\n19 Start Epoch 3\n16 Start Epoch 3\n17 Start Epoch 3\n17: 2 batches\n19: 2 batches\n13 Start Epoch 3\n13: 2 batches\n12 Start Epoch 3\n12: 2 batches\n29 Start Epoch 3\n28 Start Epoch 3\n28: 2 batches\n29: 2 batches\n1 Start Epoch 3\n18 Start Epoch 3\n1: 2 batches\n18: 2 batches\n27 Start Epoch 3\n27: 2 batches\n30 Start Epoch 3\n30: 2 batches\n26 Start Epoch 3\n26: 2 batches\n4 Start Epoch 3\n4: 2 batches\n6 Start Epoch 3\n6: 2 batches\n11 Start Epoch 3\n11: 2 batches\n10 Start Epoch 3\n10: 2 batches\n8 Start Epoch 3\n8: 2 batches\n9 Start Epoch 3\n9: 2 batches\n25 Start Epoch 3\n25: 2 batches\n16: 2 batches\n23 Start Epoch 3\n23: 2 batches\n0 Start Epoch 3\n0: 2 batches\n31 Start Epoch 4\n31: 2 batches\n30 Start Epoch 4\n29 Start Epoch 4\n23 Start Epoch 4\n23: 2 batches\n30: 2 batches\n11 Start Epoch 4\n11: 2 batches\n19 Start Epoch 4\n21 Start Epoch 4\n21: 2 batches\n19: 2 batches\n27 Start Epoch 4\n20 Start Epoch 4\n26 Start Epoch 4\n26: 2 batches\n9 Start Epoch 4\n6 Start Epoch 4\n10 Start Epoch 4\n7 Start Epoch 4\n27: 2 batches\n10: 2 batches\n4 Start Epoch 4\n7: 2 batches\n9: 2 batches\n4: 2 batches\n5 Start Epoch 4\n5: 2 batches\n22 Start Epoch 4\n22: 2 batches\n6: 2 batches\n20: 2 batches\n1 Start Epoch 4\n1: 2 batches\n3 Start Epoch 4\n3: 2 batches\n2 Start Epoch 4\n2: 2 batches\n18 Start Epoch 4\n17 Start Epoch 4\n17: 2 batches\n18: 2 batches\n16 Start Epoch 4\n16: 2 batches\n24 Start Epoch 4\n24: 2 batches\n25 Start Epoch 4\n25: 2 batches\n8 Start Epoch 4\n8: 2 batches\n29: 2 batches\n28 Start Epoch 4\n14 Start Epoch 4\n28: 2 batches\n14: 2 batches\n15 Start Epoch 4\n15: 2 batches\n12 Start Epoch 4\n12: 2 batches\n13 Start Epoch 4\n13: 2 batches\n0 Start Epoch 4\n0: 2 batches\n23 Start Epoch 5\n23: 2 batches\n31 Start Epoch 5\n31: 2 batches\n14 Start Epoch 5\n14: 2 batches\n15 Start Epoch 5\n15: 2 batches\n19 Start Epoch 5\n25 Start Epoch 5\n19: 2 batches\n21 Start Epoch 5\n25: 2 batches\n20 Start Epoch 5\n13 Start Epoch 5\n20: 2 batches\n27 Start Epoch 5\n12 Start Epoch 5\n8 Start Epoch 5\n8: 2 batches\n29 Start Epoch 5\n13: 2 batches\n30 Start Epoch 5\n5 Start Epoch 5\n5: 2 batches\n22 Start Epoch 5\n26 Start Epoch 5\n12: 2 batches\n11 Start Epoch 5\n11: 2 batches\n30: 2 batches\n4 Start Epoch 5\n4: 2 batches\n22: 2 batches\n26: 2 batches\n28 Start Epoch 5\n7 Start Epoch 5\n7: 2 batches\n29: 2 batches\n28: 2 batches\n2 Start Epoch 5\n2: 2 batches\n3 Start Epoch 5\n3: 2 batches\n27: 2 batches\n21: 2 batches\n24 Start Epoch 5\n17 Start Epoch 5\n18 Start Epoch 5\n18: 2 batches\n17: 2 batches\n16 Start Epoch 5\n16: 2 batches\n1 Start Epoch 5\n1: 2 batches\n24: 2 batches\n10 Start Epoch 5\n10: 2 batches\n9 Start Epoch 5\n9: 2 batches\n6 Start Epoch 5\n6: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:15: Epoch 0 train loss: 9324.744873046875\nINFO:root:7: Epoch 0 train loss: 8489.936950683594\nINFO:root:14: Epoch 0 train loss: 1213167.1244239807\nINFO:root:31: Epoch 0 train loss: 817921.4955368042\nINFO:root:6: Epoch 0 train loss: 15614.97119140625\nINFO:root:4: Epoch 0 train loss: 13469.34228515625\nINFO:root:5: Epoch 0 train loss: 2647118.674926758\nINFO:root:3: Epoch 0 train loss: 5969.115633010864\nINFO:root:1: Epoch 0 train loss: 7610.5286865234375\nINFO:root:2: Epoch 0 train loss: 4605.217987060547\nINFO:root:0: Epoch 0 train loss: 1283867.265625\nINFO:root:12: Epoch 0 train loss: 5797.22216796875\nINFO:root:8: Epoch 0 train loss: 838004.009765625\nINFO:root:28: Epoch 0 train loss: 1214.4358215332031\nINFO:root:16: Epoch 0 train loss: 35068.0625\nINFO:root:19: Epoch 0 train loss: 8391.168647766113\nINFO:root:23: Epoch 0 train loss: 19713.5986328125\nINFO:root:27: Epoch 0 train loss: 2835400.5\nINFO:root:9: Epoch 0 train loss: 7198.08984375\nINFO:root:30: Epoch 0 train loss: 162.19289016723633\nINFO:root:26: Epoch 0 train loss: 1032835.7383289337\nINFO:root:13: Epoch 0 train loss: 8697.391845703125\nINFO:root:10: Epoch 0 train loss: 1916307.8564453125\nINFO:root:24: Epoch 0 train loss: 15230.7158203125\nINFO:root:25: Epoch 0 train loss: 2138787.218109131\nINFO:root:17: Epoch 0 train loss: 7111.3017578125\nINFO:root:18: Epoch 0 train loss: 613.3016357421875\nINFO:root:29: Epoch 0 train loss: 2116.5462646484375\nINFO:root:22: Epoch 0 train loss: 17211.8837890625\nINFO:root:11: Epoch 0 train loss: 390.95835876464844\nINFO:root:20: Epoch 0 train loss: 15093.7333984375\nINFO:root:21: Epoch 0 train loss: 878053.9117126465\nINFO:root:0: Epoch 0 validation loss: 124726.94123147494\nINFO:root:11: Epoch 1 train loss: 2788.4851684570312\nINFO:root:14: Epoch 1 train loss: 1905995.138671875\nINFO:root:7: Epoch 1 train loss: 26547.96240234375\nINFO:root:15: Epoch 1 train loss: 1006582.544921875\nINFO:root:13: Epoch 1 train loss: 3799.2105712890625\nINFO:root:24: Epoch 1 train loss: 1092223.5356445312\nINFO:root:25: Epoch 1 train loss: 882660.0009765625\nINFO:root:23: Epoch 1 train loss: 718.3343505859375\nINFO:root:19: Epoch 1 train loss: 30047.521484375\nINFO:root:9: Epoch 1 train loss: 5955.440490722656\nINFO:root:10: Epoch 1 train loss: 17562.012939453125\nINFO:root:8: Epoch 1 train loss: 191.10010147094727\nINFO:root:20: Epoch 1 train loss: 26149.7890625\nINFO:root:17: Epoch 1 train loss: 14180.3857421875\nINFO:root:18: Epoch 1 train loss: 26389.4951171875\nINFO:root:16: Epoch 1 train loss: 14821.25830078125\nINFO:root:2: Epoch 1 train loss: 4649.716552734375\nINFO:root:31: Epoch 1 train loss: 2250711.78125\nINFO:root:21: Epoch 1 train loss: 1002053.8033905029\nINFO:root:22: Epoch 1 train loss: 4309.599700927734\nINFO:root:3: Epoch 1 train loss: 1677241.4129638672\nINFO:root:0: Epoch 1 train loss: 879935.271484375\nINFO:root:5: Epoch 1 train loss: 10970.2333984375\nINFO:root:4: Epoch 1 train loss: 2184.8291091918945\nINFO:root:1: Epoch 1 train loss: 11264.42529296875\nINFO:root:6: Epoch 1 train loss: 8068.3345947265625\nINFO:root:27: Epoch 1 train loss: 13799.686279296875\nINFO:root:30: Epoch 1 train loss: 16645.19775390625\nINFO:root:29: Epoch 1 train loss: 814231.6504554749\nINFO:root:28: Epoch 1 train loss: 2400284.466796875\nINFO:root:12: Epoch 1 train loss: 10217.984741210938\nINFO:root:26: Epoch 1 train loss: 2476.853317260742\nINFO:root:0: Epoch 1 validation loss: 124716.17712717237\nINFO:root:3: Epoch 2 train loss: 1912079.74609375\nINFO:root:7: Epoch 2 train loss: 1901282.730834961\nINFO:root:21: Epoch 2 train loss: 3699.2328491210938\nINFO:root:15: Epoch 2 train loss: 1903409.9177246094\nINFO:root:31: Epoch 2 train loss: 11414.13525390625\nINFO:root:20: Epoch 2 train loss: 6085.869598388672\nINFO:root:14: Epoch 2 train loss: 15109.826232910156\nINFO:root:22: Epoch 2 train loss: 9046.990356445312\nINFO:root:24: Epoch 2 train loss: 4441.64762878418\nINFO:root:5: Epoch 2 train loss: 6209.831787109375\nINFO:root:0: Epoch 2 train loss: 905739.21484375\nINFO:root:16: Epoch 2 train loss: 2981.2943801879883\nINFO:root:19: Epoch 2 train loss: 2544.3330154418945\nINFO:root:2: Epoch 2 train loss: 864734.4624023438\nINFO:root:17: Epoch 2 train loss: 3692.7353515625\nINFO:root:13: Epoch 2 train loss: 2203.986328125\nINFO:root:12: Epoch 2 train loss: 1728.105224609375\nINFO:root:28: Epoch 2 train loss: 2154.21630859375\nINFO:root:29: Epoch 2 train loss: 6153.772216796875\nINFO:root:1: Epoch 2 train loss: 7793.036376953125\nINFO:root:18: Epoch 2 train loss: 3520.8747329711914\nINFO:root:27: Epoch 2 train loss: 2646711.9965820312\nINFO:root:30: Epoch 2 train loss: 1441.336555480957\nINFO:root:26: Epoch 2 train loss: 2281103.4693603516\nINFO:root:4: Epoch 2 train loss: 6115.301818847656\nINFO:root:6: Epoch 2 train loss: 13329.244583129883\nINFO:root:9: Epoch 2 train loss: 3258.4114379882812\nINFO:root:10: Epoch 2 train loss: 502.7604217529297\nINFO:root:8: Epoch 2 train loss: 2935.0894775390625\nINFO:root:11: Epoch 2 train loss: 11942.598754882812\nINFO:root:25: Epoch 2 train loss: 1032922.5112686157\nINFO:root:23: Epoch 2 train loss: 1006019.0269775391\nINFO:root:0: Epoch 2 validation loss: 124705.40824258\nINFO:root:31: Epoch 3 train loss: 4100.8582763671875\nINFO:root:23: Epoch 3 train loss: 24744.6708984375\nINFO:root:30: Epoch 3 train loss: 9811.112060546875\nINFO:root:29: Epoch 3 train loss: 5028892.5625\nINFO:root:11: Epoch 3 train loss: 1795140.4929199219\nINFO:root:5: Epoch 3 train loss: 13781.434814453125\nINFO:root:19: Epoch 3 train loss: 1225040.626953125\nINFO:root:21: Epoch 3 train loss: 29679.381591796875\nINFO:root:26: Epoch 3 train loss: 10892.11361694336\nINFO:root:7: Epoch 3 train loss: 1106.1314086914062\nINFO:root:27: Epoch 3 train loss: 385.17288970947266\nINFO:root:9: Epoch 3 train loss: 1006802.3286132812\nINFO:root:6: Epoch 3 train loss: 1903074.0595703125\nINFO:root:20: Epoch 3 train loss: 3685.0631713867188\nINFO:root:10: Epoch 3 train loss: 1100378.884765625\nINFO:root:4: Epoch 3 train loss: 5990.457916259766\nINFO:root:22: Epoch 3 train loss: 21955.561401367188\nINFO:root:3: Epoch 3 train loss: 7004.5006103515625\nINFO:root:1: Epoch 3 train loss: 43383.25592803955\nINFO:root:2: Epoch 3 train loss: 11244.14404296875\nINFO:root:17: Epoch 3 train loss: 18128.71337890625\nINFO:root:18: Epoch 3 train loss: 23169.160704135895\nINFO:root:0: Epoch 3 train loss: 1944.339584350586\nINFO:root:25: Epoch 3 train loss: 124983.697265625\nINFO:root:16: Epoch 3 train loss: 29161.76123046875\nINFO:root:24: Epoch 3 train loss: 3029.542640686035\nINFO:root:8: Epoch 3 train loss: 14617.441299438477\nINFO:root:14: Epoch 3 train loss: 45912.86650085449\nINFO:root:28: Epoch 3 train loss: 74962.29956054688\nINFO:root:15: Epoch 3 train loss: 3964.6458740234375\nINFO:root:12: Epoch 3 train loss: 666.7149200439453\nINFO:root:13: Epoch 3 train loss: 2461.2664184570312\nINFO:root:0: Epoch 3 validation loss: 124694.37222700156\nINFO:root:23: Epoch 4 train loss: 4037.70361328125\nINFO:root:31: Epoch 4 train loss: 8800.258239746094\nINFO:root:15: Epoch 4 train loss: 5885.560791015625\nINFO:root:14: Epoch 4 train loss: 4959.416015625\nINFO:root:19: Epoch 4 train loss: 5599.211669921875\nINFO:root:20: Epoch 4 train loss: 2211122.9360351562\nINFO:root:25: Epoch 4 train loss: 17287.390014648438\nINFO:root:12: Epoch 4 train loss: 4467.166019439697\nINFO:root:21: Epoch 4 train loss: 10835.441650390625\nINFO:root:29: Epoch 4 train loss: 2298932.54296875\nINFO:root:13: Epoch 4 train loss: 1615.8785400390625\nINFO:root:27: Epoch 4 train loss: 26036.76416015625\nINFO:root:30: Epoch 4 train loss: 17872.183227539062\nINFO:root:4: Epoch 4 train loss: 2653209.046875\nINFO:root:5: Epoch 4 train loss: 3025905.4008789062\nINFO:root:28: Epoch 4 train loss: 4031.1234741210938\nINFO:root:7: Epoch 4 train loss: 2391094.998779297\nINFO:root:22: Epoch 4 train loss: 7105.6070556640625\nINFO:root:26: Epoch 4 train loss: 11778.970458984375\nINFO:root:11: Epoch 4 train loss: 18156.203247070312\nINFO:root:8: Epoch 4 train loss: 1016274.1728515625\nINFO:root:3: Epoch 4 train loss: 115471.0361328125\nINFO:root:2: Epoch 4 train loss: 29238.986785888672\nINFO:root:0: Epoch 4 train loss: 13062.656066894531\nINFO:root:17: Epoch 4 train loss: 354597.8984375\nINFO:root:24: Epoch 4 train loss: 4739.096366882324\nINFO:root:16: Epoch 4 train loss: 12565.677780151367\nINFO:root:18: Epoch 4 train loss: 9383.35205078125\nINFO:root:1: Epoch 4 train loss: 812034.780456543\nINFO:root:10: Epoch 4 train loss: 10856.539001464844\nINFO:root:9: Epoch 4 train loss: 13535.65185546875\nINFO:root:6: Epoch 4 train loss: 142826.18359375\nINFO:root:0: Epoch 4 validation loss: 124682.51506906195\nINFO:root:23: Epoch 5 train loss: 986176.1162109375\nINFO:root:31: Epoch 5 train loss: 33607.06652832031\nINFO:root:21: Epoch 5 train loss: 112663.80895996094\nINFO:root:22: Epoch 5 train loss: 4231.159423828125\nINFO:root:20: Epoch 5 train loss: 1793276.9084472656\nINFO:root:8: Epoch 5 train loss: 2727.5776443481445\nINFO:root:15: Epoch 5 train loss: 3016.924072265625\nINFO:root:14: Epoch 5 train loss: 14646.014770507812\nINFO:root:11: Epoch 5 train loss: 3554.102783203125\nINFO:root:10: Epoch 5 train loss: 829535.0185546875\nINFO:root:24: Epoch 5 train loss: 10928.98031616211\nINFO:root:25: Epoch 5 train loss: 2211193.2641601562\nINFO:root:12: Epoch 5 train loss: 17529.111083984375\nINFO:root:30: Epoch 5 train loss: 1963059.7153625488\nINFO:root:29: Epoch 5 train loss: 6995.9881591796875\nINFO:root:28: Epoch 5 train loss: 4736.765110015869\nINFO:root:27: Epoch 5 train loss: 1662.8212280273438\nINFO:root:13: Epoch 5 train loss: 11022.519592285156\nINFO:root:9: Epoch 5 train loss: 23920.665588378906\nINFO:root:6: Epoch 5 train loss: 1810464.6743164062\nINFO:root:7: Epoch 5 train loss: 814767.8622245789\nINFO:root:3: Epoch 5 train loss: 720.1443176269531\nINFO:root:0: Epoch 5 train loss: 962613.0736961365\nINFO:root:1: Epoch 5 train loss: 5697.512268066406\nINFO:root:26: Epoch 5 train loss: 3780.686721801758\nINFO:root:4: Epoch 5 train loss: 39746.72966384888\nINFO:root:5: Epoch 5 train loss: 9915.08984375\nINFO:root:2: Epoch 5 train loss: 1803730.5478515625\nINFO:root:19: Epoch 5 train loss: 2471.903890609741\nINFO:root:16: Epoch 5 train loss: 822867.4325561523\nINFO:root:18: Epoch 5 train loss: 1309.0282592773438\nINFO:root:17: Epoch 5 train loss: 4982.338973999023\nINFO:root:0: Epoch 5 validation loss: 124670.02925379702\n", "seconds": 12.007961988449097, "batch_size": 64, "nodes": 8, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n2 Start Epoch 0\n2: 2 batches\n1 Start Epoch 0\n1: 2 batches\n3 Start Epoch 0\n4 Start Epoch 0\n3: 2 batches\n35 Start Epoch 0\n35: 2 batches\n24 Start Epoch 0\n8 Start Epoch 0\n23 Start Epoch 0\n24: 2 batches\n8: 2 batches\n23: 2 batches\n4: 2 batches\n6 Start Epoch 0\n7 Start Epoch 0\n6: 2 batches\n7: 2 batches\n5 Start Epoch 0\n15 Start Epoch 0\n15: 2 batches\n5: 2 batches\n31 Start Epoch 0\n31: 2 batches\n32 Start Epoch 0\n32: 2 batches\n16 Start Epoch 0\n16: 2 batches\n9 Start Epoch 0\n25 Start Epoch 0\n18 Start Epoch 0\n10 Start Epoch 0\n9: 2 batches\n26 Start Epoch 0\n18: 2 batches\n26: 2 batches\n10: 2 batches\n17 Start Epoch 0\n34 Start Epoch 0\n25: 2 batches\n34: 2 batches\n33 Start Epoch 0\n33: 2 batches\n13 Start Epoch 0\n14 Start Epoch 0\n12 Start Epoch 0\n12: 2 batches\n13: 2 batches\n14: 2 batches\n11 Start Epoch 0\n11: 2 batches\n20 Start Epoch 0\n28 Start Epoch 0\n28: 2 batches\n20: 2 batches\n27 Start Epoch 0\n27: 2 batches\n22 Start Epoch 0\n21 Start Epoch 0\n22: 2 batches\n21: 2 batches\n17: 2 batches\n19 Start Epoch 0\n19: 2 batches\n29 Start Epoch 0\n30 Start Epoch 0\n29: 2 batches\n30: 2 batches\n32 Start Epoch 1\n32: 2 batches\n27 Start Epoch 1\n27: 2 batches\n31 Start Epoch 1\n31: 2 batches\n29 Start Epoch 1\n29: 2 batches\n28 Start Epoch 1\n28: 2 batches\n30 Start Epoch 1\n30: 2 batches\n26 Start Epoch 1\n26: 2 batches\n33 Start Epoch 1\n33: 2 batches\n2 Start Epoch 1\n2: 2 batches\n6 Start Epoch 1\n8 Start Epoch 1\n19 Start Epoch 1\n15 Start Epoch 1\n11 Start Epoch 1\n22 Start Epoch 1\n18 Start Epoch 1\n6: 2 batches\n4 Start Epoch 1\n15: 2 batches\n11: 2 batches\n23 Start Epoch 1\n18: 2 batches\n19: 2 batches\n4: 2 batches\n8: 2 batches\n21 Start Epoch 1\n12 Start Epoch 1\n21: 2 batches\n7 Start Epoch 1\n12: 2 batches\n22: 2 batches\n7: 2 batches\n10 Start Epoch 1\n9 Start Epoch 1\n10: 2 batches\n5 Start Epoch 1\n5: 2 batches\n9: 2 batches\n1 Start Epoch 1\n1: 2 batches\n3 Start Epoch 1\n3: 2 batches\n24 Start Epoch 1\n24: 2 batches\n20 Start Epoch 1\n16 Start Epoch 1\n23: 2 batches\n17 Start Epoch 1\n13 Start Epoch 1\n16: 2 batches\n13: 2 batches\n20: 2 batches\n25 Start Epoch 1\n25: 2 batches\n17: 2 batches\n14 Start Epoch 1\n14: 2 batches\n35 Start Epoch 1\n35: 2 batches\n34 Start Epoch 1\n34: 2 batches\n0 Start Epoch 1\n0: 2 batches\n35 Start Epoch 2\n31 Start Epoch 2\n31: 2 batches\n11 Start Epoch 2\n15 Start Epoch 2\n9 Start Epoch 2\n15: 2 batches\n9: 2 batches\n29 Start Epoch 2\n11: 2 batches\n28 Start Epoch 2\n25 Start Epoch 2\n3 Start Epoch 2\n13 Start Epoch 2\n10 Start Epoch 2\n28: 2 batches\n10: 2 batches\n22 Start Epoch 2\n29: 2 batches\n25: 2 batches\n17 Start Epoch 2\n23 Start Epoch 2\n17: 2 batches\n12 Start Epoch 2\n30 Start Epoch 2\n3: 2 batches\n35: 2 batches\n13: 2 batches\n23: 2 batches\n30: 2 batches\n24 Start Epoch 2\n7 Start Epoch 2\n7: 2 batches\n22: 2 batches\n32 Start Epoch 2\n24: 2 batches\n32: 2 batches\n19 Start Epoch 2\n4 Start Epoch 2\n4: 2 batches\n20 Start Epoch 2\n27 Start Epoch 2\n34 Start Epoch 2\n27: 2 batches\n18 Start Epoch 2\n21 Start Epoch 2\n20: 2 batches\n34: 2 batches\n19: 2 batches\n21: 2 batches\n33 Start Epoch 2\n26 Start Epoch 2\n18: 2 batches\n26: 2 batches\n16 Start Epoch 2\n33: 2 batches\n16: 2 batches\n1 Start Epoch 2\n1: 2 batches\n2 Start Epoch 2\n14 Start Epoch 2\n14: 2 batches\n5 Start Epoch 2\n12: 2 batches\n6 Start Epoch 2\n5: 2 batches\n2: 2 batches\n6: 2 batches\n8 Start Epoch 2\n8: 2 batches\n0 Start Epoch 2\n0: 2 batches\n15 Start Epoch 3\n15: 2 batches\n11 Start Epoch 3\n9 Start Epoch 3\n9: 2 batches\n11: 2 batches\n14 Start Epoch 3\n12 Start Epoch 3\n12: 2 batches\n14: 2 batches\n18 Start Epoch 3\n19 Start Epoch 3\n19: 2 batches\n16 Start Epoch 3\n16: 2 batches\n17 Start Epoch 3\n17: 2 batches\n18: 2 batches\n13 Start Epoch 3\n13: 2 batches\n35 Start Epoch 3\n6 Start Epoch 3\n35: 2 batches\n7 Start Epoch 3\n7: 2 batches\n3 Start Epoch 3\n3: 2 batches\n2 Start Epoch 3\n2: 2 batches\n1 Start Epoch 3\n1: 2 batches\n10 Start Epoch 3\n10: 2 batches\n31 Start Epoch 3\n31: 2 batches\n6: 2 batches\n25 Start Epoch 3\n8 Start Epoch 3\n8: 2 batches\n33 Start Epoch 3\n20 Start Epoch 3\n30 Start Epoch 3\n30: 2 batches\n33: 2 batches\n25: 2 batches\n23 Start Epoch 3\n23: 2 batches\n34 Start Epoch 3\n29 Start Epoch 3\n26 Start Epoch 3\n32 Start Epoch 3\n26: 2 batches\n22 Start Epoch 3\n28 Start Epoch 3\n28: 2 batches\n34: 2 batches\n27 Start Epoch 3\n21 Start Epoch 3\n29: 2 batches\n32: 2 batches\n27: 2 batches\n21: 2 batches\n20: 2 batches\n24 Start Epoch 3\n22: 2 batches\n24: 2 batches\n5 Start Epoch 3\n5: 2 batches\n4 Start Epoch 3\n4: 2 batches\n0 Start Epoch 3\n0: 2 batches\n15 Start Epoch 4\n15: 2 batches\n14 Start Epoch 4\n14: 2 batches\n16 Start Epoch 4\n17 Start Epoch 4\n16: 2 batches\n17: 2 batches\n3 Start Epoch 4\n7 Start Epoch 4\n3: 2 batches\n7: 2 batches\n35 Start Epoch 4\n35: 2 batches\n31 Start Epoch 4\n2 Start Epoch 4\n2: 2 batches\n1 Start Epoch 4\n1: 2 batches\n30 Start Epoch 4\n25 Start Epoch 4\n25: 2 batches\n13 Start Epoch 4\n20 Start Epoch 4\n5 Start Epoch 4\n13: 2 batches\n33 Start Epoch 4\n29 Start Epoch 4\n33: 2 batches\n24 Start Epoch 4\n24: 2 batches\n4 Start Epoch 4\n4: 2 batches\n9 Start Epoch 4\n11 Start Epoch 4\n30: 2 batches\n32 Start Epoch 4\n20: 2 batches\n29: 2 batches\n32: 2 batches\n6 Start Epoch 4\n11: 2 batches\n9: 2 batches\n8 Start Epoch 4\n8: 2 batches\n28 Start Epoch 4\n31: 2 batches\n28: 2 batches\n26 Start Epoch 4\n26: 2 batches\n22 Start Epoch 4\n21 Start Epoch 4\n22: 2 batches\n21: 2 batches\n27 Start Epoch 4\n23 Start Epoch 4\n27: 2 batches\n10 Start Epoch 4\n5: 2 batches\n18 Start Epoch 4\n19 Start Epoch 4\n19: 2 batches\n18: 2 batches\n34 Start Epoch 4\n34: 2 batches\n6: 2 batches\n10: 2 batches\n23: 2 batches\n12 Start Epoch 4\n12: 2 batches\n0 Start Epoch 4\n0: 2 batches\n3 Start Epoch 5\n3: 2 batches\n15 Start Epoch 5\n6 Start Epoch 5\n6: 2 batches\n15: 2 batches\n30 Start Epoch 5\n7 Start Epoch 5\n31 Start Epoch 5\n30: 2 batches\n31: 2 batches\n7: 2 batches\n35 Start Epoch 5\n32 Start Epoch 5\n33 Start Epoch 5\n32: 2 batches\n33: 2 batches\n35: 2 batches\n4 Start Epoch 5\n5 Start Epoch 5\n4: 2 batches\n2 Start Epoch 5\n5: 2 batches\n14 Start Epoch 5\n14: 2 batches\n34 Start Epoch 5\n34: 2 batches\n20 Start Epoch 5\n23 Start Epoch 5\n8 Start Epoch 5\n27 Start Epoch 5\n9 Start Epoch 5\n17 Start Epoch 5\n9: 2 batches\n20: 2 batches\n8: 2 batches\n23: 2 batches\n24 Start Epoch 5\n16 Start Epoch 5\n17: 2 batches\n16: 2 batches\n27: 2 batches\n24: 2 batches\n1 Start Epoch 5\n1: 2 batches\n2: 2 batches\n18 Start Epoch 5\n18: 2 batches\n26 Start Epoch 5\n25 Start Epoch 5\n26: 2 batches\n25: 2 batches\n10 Start Epoch 5\n10: 2 batches\n19 Start Epoch 5\n22 Start Epoch 5\n22: 2 batches\n19: 2 batches\n11 Start Epoch 5\n11: 2 batches\n21 Start Epoch 5\n21: 2 batches\n13 Start Epoch 5\n13: 2 batches\n12 Start Epoch 5\n12: 2 batches\n29 Start Epoch 5\n29: 2 batches\n28 Start Epoch 5\n28: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:32: Epoch 0 train loss: 8975.271484375\nINFO:root:27: Epoch 0 train loss: 1149138.783203125\nINFO:root:30: Epoch 0 train loss: 17475.94704437256\nINFO:root:31: Epoch 0 train loss: 9424.628845214844\nINFO:root:26: Epoch 0 train loss: 14463.099853515625\nINFO:root:28: Epoch 0 train loss: 45918.10498046875\nINFO:root:29: Epoch 0 train loss: 4387.5733642578125\nINFO:root:33: Epoch 0 train loss: 1179.959732055664\nINFO:root:1: Epoch 0 train loss: 6255.717498779297\nINFO:root:11: Epoch 0 train loss: 5489.293212890625\nINFO:root:2: Epoch 0 train loss: 27513.347290039062\nINFO:root:21: Epoch 0 train loss: 17585.706787109375\nINFO:root:18: Epoch 0 train loss: 26502.293823242188\nINFO:root:6: Epoch 0 train loss: 7630.5528564453125\nINFO:root:22: Epoch 0 train loss: 869193.7875976562\nINFO:root:19: Epoch 0 train loss: 15402.487670898438\nINFO:root:4: Epoch 0 train loss: 13576.797241210938\nINFO:root:8: Epoch 0 train loss: 4136.392822265625\nINFO:root:15: Epoch 0 train loss: 2187.0279021263123\nINFO:root:23: Epoch 0 train loss: 1833811.013671875\nINFO:root:12: Epoch 0 train loss: 4910.978256225586\nINFO:root:7: Epoch 0 train loss: 813110.7976074219\nINFO:root:10: Epoch 0 train loss: 1883.0277404785156\nINFO:root:9: Epoch 0 train loss: 3930.4035034179688\nINFO:root:5: Epoch 0 train loss: 3569.722412109375\nINFO:root:17: Epoch 0 train loss: 19277.87274169922\nINFO:root:3: Epoch 0 train loss: 1234087.56640625\nINFO:root:20: Epoch 0 train loss: 918.2384185791016\nINFO:root:35: Epoch 0 train loss: 51279.9736328125\nINFO:root:16: Epoch 0 train loss: 2271.0186157226562\nINFO:root:13: Epoch 0 train loss: 16207.66845703125\nINFO:root:14: Epoch 0 train loss: 4476.9486083984375\nINFO:root:24: Epoch 0 train loss: 4056.7880249023438\nINFO:root:25: Epoch 0 train loss: 350557.501953125\nINFO:root:0: Epoch 0 train loss: 19704.216369628906\nINFO:root:34: Epoch 0 train loss: 3259.018096923828\nINFO:root:0: Epoch 0 validation loss: 456775.8407554095\nINFO:root:15: Epoch 1 train loss: 4183.819488525391\nINFO:root:11: Epoch 1 train loss: 3706.5371704101562\nINFO:root:31: Epoch 1 train loss: 10765.091796875\nINFO:root:35: Epoch 1 train loss: 1433562.75390625\nINFO:root:9: Epoch 1 train loss: 3856.770683288574\nINFO:root:10: Epoch 1 train loss: 1441.55908203125\nINFO:root:29: Epoch 1 train loss: 1733.2960205078125\nINFO:root:28: Epoch 1 train loss: 7482.467189788818\nINFO:root:13: Epoch 1 train loss: 2356.083261489868\nINFO:root:23: Epoch 1 train loss: 9172.427185058594\nINFO:root:25: Epoch 1 train loss: 1087348.2153320312\nINFO:root:16: Epoch 1 train loss: 6021.0\nINFO:root:3: Epoch 1 train loss: 137593.24923706055\nINFO:root:17: Epoch 1 train loss: 7736.3763427734375\nINFO:root:22: Epoch 1 train loss: 19927.313842773438\nINFO:root:12: Epoch 1 train loss: 5439.3118896484375\nINFO:root:30: Epoch 1 train loss: 116477.505859375\nINFO:root:0: Epoch 1 train loss: 35065.600189208984\nINFO:root:24: Epoch 1 train loss: 7791.669845581055\nINFO:root:7: Epoch 1 train loss: 10742.068603515625\nINFO:root:32: Epoch 1 train loss: 1274.2574462890625\nINFO:root:20: Epoch 1 train loss: 1084998.4816360474\nINFO:root:19: Epoch 1 train loss: 1286.1869506835938\nINFO:root:4: Epoch 1 train loss: 962592.7036094666\nINFO:root:21: Epoch 1 train loss: 3920.8081665039062\nINFO:root:27: Epoch 1 train loss: 3366776.6412353516\nINFO:root:34: Epoch 1 train loss: 6553.846435546875\nINFO:root:18: Epoch 1 train loss: 861579.3397464752\nINFO:root:26: Epoch 1 train loss: 814017.6477661133\nINFO:root:33: Epoch 1 train loss: 2268.5780782699585\nINFO:root:1: Epoch 1 train loss: 22749.444915771484\nINFO:root:2: Epoch 1 train loss: 5796.429998397827\nINFO:root:5: Epoch 1 train loss: 8568.539068222046\nINFO:root:6: Epoch 1 train loss: 10305.07421875\nINFO:root:14: Epoch 1 train loss: 814914.1250095367\nINFO:root:8: Epoch 1 train loss: 4014.93017578125\nINFO:root:0: Epoch 1 validation loss: 456753.1877554008\nINFO:root:15: Epoch 2 train loss: 25058.787841796875\nINFO:root:11: Epoch 2 train loss: 6664.761926651001\nINFO:root:9: Epoch 2 train loss: 4510422.66796875\nINFO:root:10: Epoch 2 train loss: 23560.429062843323\nINFO:root:14: Epoch 2 train loss: 2147.637763977051\nINFO:root:12: Epoch 2 train loss: 21201.484497070312\nINFO:root:16: Epoch 2 train loss: 2773.43701171875\nINFO:root:19: Epoch 2 train loss: 120104.61611938477\nINFO:root:18: Epoch 2 train loss: 1008618.087890625\nINFO:root:17: Epoch 2 train loss: 15723.482330322266\nINFO:root:13: Epoch 2 train loss: 28260.49609375\nINFO:root:35: Epoch 2 train loss: 3591.1521224975586\nINFO:root:7: Epoch 2 train loss: 389072.7626953125\nINFO:root:6: Epoch 2 train loss: 14456.34439086914\nINFO:root:3: Epoch 2 train loss: 861446.5211257935\nINFO:root:1: Epoch 2 train loss: 4244980.0625\nINFO:root:2: Epoch 2 train loss: 6715.377166748047\nINFO:root:0: Epoch 2 train loss: 814328.89239645\nINFO:root:20: Epoch 2 train loss: 10532.1513671875\nINFO:root:33: Epoch 2 train loss: 1119210.9162597656\nINFO:root:25: Epoch 2 train loss: 8137.880065917969\nINFO:root:23: Epoch 2 train loss: 10718.007202148438\nINFO:root:31: Epoch 2 train loss: 3647818.135864258\nINFO:root:8: Epoch 2 train loss: 863714.1493136883\nINFO:root:30: Epoch 2 train loss: 261.90081787109375\nINFO:root:34: Epoch 2 train loss: 6452.7978515625\nINFO:root:26: Epoch 2 train loss: 2846.6400260925293\nINFO:root:27: Epoch 2 train loss: 379697.67333984375\nINFO:root:29: Epoch 2 train loss: 15991.255126953125\nINFO:root:21: Epoch 2 train loss: 23226.777587890625\nINFO:root:32: Epoch 2 train loss: 2150.0599975585938\nINFO:root:22: Epoch 2 train loss: 34936.68338775635\nINFO:root:28: Epoch 2 train loss: 2904757.2495117188\nINFO:root:24: Epoch 2 train loss: 13589.1650390625\nINFO:root:5: Epoch 2 train loss: 2597.0736389160156\nINFO:root:4: Epoch 2 train loss: 1182210.40625\nINFO:root:0: Epoch 2 validation loss: 456730.03921075433\nINFO:root:15: Epoch 3 train loss: 3459.532470703125\nINFO:root:14: Epoch 3 train loss: 1197638.004699707\nINFO:root:17: Epoch 3 train loss: 3368418.2602539062\nINFO:root:16: Epoch 3 train loss: 2904027.2255859375\nINFO:root:3: Epoch 3 train loss: 870068.3608398438\nINFO:root:7: Epoch 3 train loss: 1033458.6041259766\nINFO:root:35: Epoch 3 train loss: 2901860.778076172\nINFO:root:31: Epoch 3 train loss: 228.91547393798828\nINFO:root:1: Epoch 3 train loss: 983719.1201171875\nINFO:root:2: Epoch 3 train loss: 9186.891967773438\nINFO:root:0: Epoch 3 train loss: 21649.092834472656\nINFO:root:5: Epoch 3 train loss: 816993.8491210938\nINFO:root:13: Epoch 3 train loss: 6477.913118362427\nINFO:root:11: Epoch 3 train loss: 33106.2141418457\nINFO:root:20: Epoch 3 train loss: 338580.3835325241\nINFO:root:33: Epoch 3 train loss: 3491158.7451171875\nINFO:root:25: Epoch 3 train loss: 232.53665924072266\nINFO:root:30: Epoch 3 train loss: 17614.044372558594\nINFO:root:32: Epoch 3 train loss: 839.246789932251\nINFO:root:4: Epoch 3 train loss: 65528.85217285156\nINFO:root:9: Epoch 3 train loss: 1147118.9853515625\nINFO:root:8: Epoch 3 train loss: 178.27665328979492\nINFO:root:29: Epoch 3 train loss: 3432.893310546875\nINFO:root:24: Epoch 3 train loss: 11572.67626953125\nINFO:root:6: Epoch 3 train loss: 1055982.6640625\nINFO:root:28: Epoch 3 train loss: 1199047.159145102\nINFO:root:26: Epoch 3 train loss: 2734.4422607421875\nINFO:root:21: Epoch 3 train loss: 760.7930908203125\nINFO:root:22: Epoch 3 train loss: 1812.0174255371094\nINFO:root:23: Epoch 3 train loss: 118967.96166992188\nINFO:root:27: Epoch 3 train loss: 970.2799682617188\nINFO:root:10: Epoch 3 train loss: 2406.776128768921\nINFO:root:18: Epoch 3 train loss: 9854.653564453125\nINFO:root:19: Epoch 3 train loss: 15189.5234375\nINFO:root:34: Epoch 3 train loss: 1915.270263671875\nINFO:root:12: Epoch 3 train loss: 12272.8564453125\nINFO:root:0: Epoch 3 validation loss: 456706.8392560929\nINFO:root:3: Epoch 4 train loss: 3665588.7998046875\nINFO:root:15: Epoch 4 train loss: 84928.1689453125\nINFO:root:7: Epoch 4 train loss: 6291.4510498046875\nINFO:root:6: Epoch 4 train loss: 2743824.958984375\nINFO:root:31: Epoch 4 train loss: 5331.654466629028\nINFO:root:30: Epoch 4 train loss: 13821.6689453125\nINFO:root:33: Epoch 4 train loss: 21377.8935546875\nINFO:root:32: Epoch 4 train loss: 6297.700096130371\nINFO:root:35: Epoch 4 train loss: 9374.177879333496\nINFO:root:4: Epoch 4 train loss: 2367.768298149109\nINFO:root:5: Epoch 4 train loss: 42295.05236816406\nINFO:root:2: Epoch 4 train loss: 2945.0486907958984\nINFO:root:14: Epoch 4 train loss: 5478.779388427734\nINFO:root:34: Epoch 4 train loss: 16265.814178466797\nINFO:root:20: Epoch 4 train loss: 9935.639087677002\nINFO:root:8: Epoch 4 train loss: 1964.3873748779297\nINFO:root:23: Epoch 4 train loss: 21554.21905517578\nINFO:root:27: Epoch 4 train loss: 1139127.713470459\nINFO:root:17: Epoch 4 train loss: 6229.562042236328\nINFO:root:24: Epoch 4 train loss: 1610.0277099609375\nINFO:root:9: Epoch 4 train loss: 1117784.1340332031\nINFO:root:16: Epoch 4 train loss: 17151.592651367188\nINFO:root:1: Epoch 4 train loss: 11192.063842773438\nINFO:root:18: Epoch 4 train loss: 6536.069389343262\nINFO:root:0: Epoch 4 train loss: 2900820.2333984375\nINFO:root:26: Epoch 4 train loss: 2096.8417358398438\nINFO:root:25: Epoch 4 train loss: 6229.47705078125\nINFO:root:10: Epoch 4 train loss: 8792.70556640625\nINFO:root:19: Epoch 4 train loss: 12458.421875\nINFO:root:21: Epoch 4 train loss: 3667.223511695862\nINFO:root:22: Epoch 4 train loss: 29477.995849609375\nINFO:root:11: Epoch 4 train loss: 1196861.4991149902\nINFO:root:13: Epoch 4 train loss: 8734.643371582031\nINFO:root:12: Epoch 4 train loss: 1089282.0451660156\nINFO:root:29: Epoch 4 train loss: 1933.8730010986328\nINFO:root:28: Epoch 4 train loss: 1075128.59375\nINFO:root:0: Epoch 4 validation loss: 456682.7306984938\nINFO:root:31: Epoch 5 train loss: 7489.708038330078\nINFO:root:3: Epoch 5 train loss: 22483.526336669922\nINFO:root:19: Epoch 5 train loss: 1081.9561157226562\nINFO:root:7: Epoch 5 train loss: 115750.33837890625\nINFO:root:5: Epoch 5 train loss: 382863.830078125\nINFO:root:15: Epoch 5 train loss: 13266.088562011719\nINFO:root:6: Epoch 5 train loss: 560.9214611053467\nINFO:root:0: Epoch 5 train loss: 29333.18798828125\nINFO:root:2: Epoch 5 train loss: 2662.6845932006836\nINFO:root:35: Epoch 5 train loss: 593.0800399780273\nINFO:root:21: Epoch 5 train loss: 276.6913194656372\nINFO:root:25: Epoch 5 train loss: 18596.021530151367\nINFO:root:20: Epoch 5 train loss: 1140546.7623291016\nINFO:root:8: Epoch 5 train loss: 22945.806640625\nINFO:root:11: Epoch 5 train loss: 1087238.1520385742\nINFO:root:9: Epoch 5 train loss: 3525675.6013183594\nINFO:root:13: Epoch 5 train loss: 1221519.423828125\nINFO:root:17: Epoch 5 train loss: 4877.272218704224\nINFO:root:12: Epoch 5 train loss: 1205435.69140625\nINFO:root:16: Epoch 5 train loss: 12876.829893112183\nINFO:root:26: Epoch 5 train loss: 5590.8974609375\nINFO:root:18: Epoch 5 train loss: 23563.548828125\nINFO:root:28: Epoch 5 train loss: 453.79088592529297\nINFO:root:29: Epoch 5 train loss: 6081.517904281616\nINFO:root:33: Epoch 5 train loss: 1014840.5439453125\nINFO:root:32: Epoch 5 train loss: 7915.708243370056\nINFO:root:34: Epoch 5 train loss: 16115.327331542969\nINFO:root:1: Epoch 5 train loss: 860.1594467163086\nINFO:root:30: Epoch 5 train loss: 8110.211090087891\nINFO:root:10: Epoch 5 train loss: 9105.722045898438\nINFO:root:4: Epoch 5 train loss: 118735.94482421875\nINFO:root:14: Epoch 5 train loss: 871701.9809570312\nINFO:root:23: Epoch 5 train loss: 3832.593994140625\nINFO:root:22: Epoch 5 train loss: 887814.0947265625\nINFO:root:27: Epoch 5 train loss: 7342.078338623047\nINFO:root:24: Epoch 5 train loss: 2754.003158569336\nINFO:root:0: Epoch 5 validation loss: 456657.2236214537\n", "seconds": 11.450453996658325, "batch_size": 64, "nodes": 9, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n2 Start Epoch 0\n1 Start Epoch 0\n1: 2 batches\n2: 2 batches\n4 Start Epoch 0\n4: 2 batches\n39 Start Epoch 0\n39: 2 batches\n3 Start Epoch 0\n3: 2 batches\n6 Start Epoch 0\n5 Start Epoch 0\n5: 2 batches\n6: 2 batches\n7 Start Epoch 0\n7: 2 batches\n8 Start Epoch 0\n8: 2 batches\n27 Start Epoch 0\n36 Start Epoch 0\n11 Start Epoch 0\n36: 2 batches\n23 Start Epoch 0\n27: 2 batches\n11: 2 batches\n24 Start Epoch 0\n23: 2 batches\n24: 2 batches\n16 Start Epoch 0\n16: 2 batches\n28 Start Epoch 0\n28: 2 batches\n12 Start Epoch 0\n12: 2 batches\n35 Start Epoch 0\n35: 2 batches\n19 Start Epoch 0\n37 Start Epoch 0\n13 Start Epoch 0\n13: 2 batches\n19: 2 batches\n20 Start Epoch 0\n29 Start Epoch 0\n29: 2 batches\n32 Start Epoch 0\n32: 2 batches\n37: 2 batches\n20: 2 batches\n30 Start Epoch 0\n30: 2 batches\n38 Start Epoch 0\n14 Start Epoch 0\n14: 2 batches\n38: 2 batches\n17 Start Epoch 0\n21 Start Epoch 0\n25 Start Epoch 0\n33 Start Epoch 0\n31 Start Epoch 0\n31: 2 batches\n9 Start Epoch 0\n15 Start Epoch 0\n15: 2 batches\n18 Start Epoch 0\n18: 2 batches\n22 Start Epoch 0\n26 Start Epoch 0\n34 Start Epoch 0\n10 Start Epoch 0\n22: 2 batches\n25: 2 batches\n34: 2 batches\n9: 2 batches\n17: 2 batches\n21: 2 batches\n26: 2 batches\n33: 2 batches\n10: 2 batches\n35 Start Epoch 1\n38 Start Epoch 1\n35: 2 batches\n38: 2 batches\n12 Start Epoch 1\n13 Start Epoch 1\n14 Start Epoch 1\n12: 2 batches\n13: 2 batches\n14: 2 batches\n15 Start Epoch 1\n37 Start Epoch 1\n15: 2 batches\n37: 2 batches\n1 Start Epoch 1\n1: 2 batches\n24 Start Epoch 1\n24: 2 batches\n27 Start Epoch 1\n27: 2 batches\n17 Start Epoch 1\n17: 2 batches\n34 Start Epoch 1\n32 Start Epoch 1\n19 Start Epoch 1\n19: 2 batches\n22 Start Epoch 1\n20 Start Epoch 1\n33 Start Epoch 1\n21 Start Epoch 1\n34: 2 batches\n33: 2 batches\n18 Start Epoch 1\n20: 2 batches\n21: 2 batches\n32: 2 batches\n18: 2 batches\n23 Start Epoch 1\n23: 2 batches\n22: 2 batches\n28 Start Epoch 1\n28: 2 batches\n29 Start Epoch 1\n29: 2 batches\n30 Start Epoch 1\n30: 2 batches\n31 Start Epoch 1\n31: 2 batches\n26 Start Epoch 1\n26: 2 batches\n25 Start Epoch 1\n25: 2 batches\n39 Start Epoch 1\n39: 2 batches\n36 Start Epoch 1\n36: 2 batches\n11 Start Epoch 1\n11: 2 batches\n16 Start Epoch 1\n16: 2 batches\n6 Start Epoch 1\n7 Start Epoch 1\n7: 2 batches\n6: 2 batches\n9 Start Epoch 1\n10 Start Epoch 1\n9: 2 batches\n10: 2 batches\n8 Start Epoch 1\n8: 2 batches\n2 Start Epoch 1\n2: 2 batches\n5 Start Epoch 1\n5: 2 batches\n4 Start Epoch 1\n4: 2 batches\n3 Start Epoch 1\n3: 2 batches\n0 Start Epoch 1\n0: 2 batches\n39 Start Epoch 2\n39: 2 batches\n1 Start Epoch 2\n1: 2 batches\n6 Start Epoch 2\n27 Start Epoch 2\n7 Start Epoch 2\n27: 2 batches\n7: 2 batches\n24 Start Epoch 2\n24: 2 batches\n14 Start Epoch 2\n15 Start Epoch 2\n13 Start Epoch 2\n13: 2 batches\n14: 2 batches\n15: 2 batches\n35 Start Epoch 2\n35: 2 batches\n26 Start Epoch 2\n32 Start Epoch 2\n32: 2 batches\n26: 2 batches\n8 Start Epoch 2\n9 Start Epoch 2\n9: 2 batches\n8: 2 batches\n17 Start Epoch 2\n30 Start Epoch 2\n19 Start Epoch 2\n31 Start Epoch 2\n31: 2 batches\n16 Start Epoch 2\n16: 2 batches\n17: 2 batches\n29 Start Epoch 2\n29: 2 batches\n18 Start Epoch 2\n18: 2 batches\n23 Start Epoch 2\n28 Start Epoch 2\n11 Start Epoch 2\n19: 2 batches\n11: 2 batches\n10 Start Epoch 2\n10: 2 batches\n20 Start Epoch 2\n20: 2 batches\n33 Start Epoch 2\n33: 2 batches\n3 Start Epoch 2\n3: 2 batches\n2 Start Epoch 2\n2: 2 batches\n34 Start Epoch 2\n34: 2 batches\n21 Start Epoch 2\n21: 2 batches\n23: 2 batches\n12 Start Epoch 2\n12: 2 batches\n22 Start Epoch 2\n22: 2 batches\n38 Start Epoch 2\n38: 2 batches\n30: 2 batches\n28: 2 batches\n25 Start Epoch 2\n25: 2 batches\n36 Start Epoch 2\n36: 2 batches\n5 Start Epoch 2\n5: 2 batches\n4 Start Epoch 2\n4: 2 batches\n6: 2 batches\n37 Start Epoch 2\n37: 2 batches\n0 Start Epoch 2\n0: 2 batches\n27 Start Epoch 3\n27: 2 batches\n35 Start Epoch 3\n35: 2 batches\n39 Start Epoch 3\n23 Start Epoch 3\n23: 2 batches\n36 Start Epoch 3\n36: 2 batches\n39: 2 batches\n15 Start Epoch 3\n15: 2 batches\n24 Start Epoch 3\n24: 2 batches\n3 Start Epoch 3\n2 Start Epoch 3\n2: 2 batches\n13 Start Epoch 3\n12 Start Epoch 3\n12: 2 batches\n13: 2 batches\n5 Start Epoch 3\n7 Start Epoch 3\n5: 2 batches\n7: 2 batches\n26 Start Epoch 3\n26: 2 batches\n4 Start Epoch 3\n25 Start Epoch 3\n4: 2 batches\n25: 2 batches\n3: 2 batches\n28 Start Epoch 3\n28: 2 batches\n6 Start Epoch 3\n6: 2 batches\n30 Start Epoch 3\n19 Start Epoch 3\n33 Start Epoch 3\n33: 2 batches\n31 Start Epoch 3\n31: 2 batches\n34 Start Epoch 3\n34: 2 batches\n9 Start Epoch 3\n9: 2 batches\n22 Start Epoch 3\n21 Start Epoch 3\n21: 2 batches\n22: 2 batches\n20 Start Epoch 3\n10 Start Epoch 3\n20: 2 batches\n10: 2 batches\n11 Start Epoch 3\n11: 2 batches\n30: 2 batches\n29 Start Epoch 3\n29: 2 batches\n1 Start Epoch 3\n1: 2 batches\n38 Start Epoch 3\n38: 2 batches\n37 Start Epoch 3\n37: 2 batches\n16 Start Epoch 3\n16: 2 batches\n18 Start Epoch 3\n18: 2 batches\n19: 2 batches\n17 Start Epoch 3\n17: 2 batches\n8 Start Epoch 3\n8: 2 batches\n32 Start Epoch 3\n32: 2 batches\n14 Start Epoch 3\n14: 2 batches\n0 Start Epoch 3\n0: 2 batches\n39 Start Epoch 4\n39: 2 batches\n15 Start Epoch 4\n15: 2 batches\n12 Start Epoch 4\n13 Start Epoch 4\n13: 2 batches\n12: 2 batches\n26 Start Epoch 4\n27 Start Epoch 4\n29 Start Epoch 4\n29: 2 batches\n22 Start Epoch 4\n26: 2 batches\n22: 2 batches\n1 Start Epoch 4\n1: 2 batches\n27: 2 batches\n28 Start Epoch 4\n23 Start Epoch 4\n28: 2 batches\n14 Start Epoch 4\n14: 2 batches\n23: 2 batches\n18 Start Epoch 4\n18: 2 batches\n17 Start Epoch 4\n17: 2 batches\n16 Start Epoch 4\n21 Start Epoch 4\n21: 2 batches\n19 Start Epoch 4\n16: 2 batches\n31 Start Epoch 4\n19: 2 batches\n31: 2 batches\n32 Start Epoch 4\n33 Start Epoch 4\n24 Start Epoch 4\n32: 2 batches\n33: 2 batches\n25 Start Epoch 4\n25: 2 batches\n34 Start Epoch 4\n3 Start Epoch 4\n3: 2 batches\n2 Start Epoch 4\n2: 2 batches\n24: 2 batches\n34: 2 batches\n7 Start Epoch 4\n20 Start Epoch 4\n30 Start Epoch 4\n38 Start Epoch 4\n10 Start Epoch 4\n38: 2 batches\n7: 2 batches\n20: 2 batches\n35 Start Epoch 4\n30: 2 batches\n9 Start Epoch 4\n35: 2 batches\n37 Start Epoch 4\n4 Start Epoch 4\n9: 2 batches\n10: 2 batches\n5 Start Epoch 4\n5: 2 batches\n37: 2 batches\n11 Start Epoch 4\n36 Start Epoch 4\n6 Start Epoch 4\n6: 2 batches\n11: 2 batches\n36: 2 batches\n4: 2 batches\n8 Start Epoch 4\n8: 2 batches\n0 Start Epoch 4\n0: 2 batches\n7 Start Epoch 5\n15 Start Epoch 5\n7: 2 batches\n39 Start Epoch 5\n12 Start Epoch 5\n12: 2 batches\n38 Start Epoch 5\n15: 2 batches\n39: 2 batches\n37 Start Epoch 5\n36 Start Epoch 5\n37: 2 batches\n20 Start Epoch 5\n27 Start Epoch 5\n13 Start Epoch 5\n18 Start Epoch 5\n20: 2 batches\n27: 2 batches\n35 Start Epoch 5\n11 Start Epoch 5\n13: 2 batches\n19 Start Epoch 5\n6 Start Epoch 5\n24 Start Epoch 5\n33 Start Epoch 5\n10 Start Epoch 5\n14 Start Epoch 5\n19: 2 batches\n5 Start Epoch 5\n21 Start Epoch 5\n11: 2 batches\n14: 2 batches\n18: 2 batches\n6: 2 batches\n21: 2 batches\n35: 2 batches\n28 Start Epoch 5\n28: 2 batches\n25 Start Epoch 5\n33: 2 batches\n29 Start Epoch 5\n29: 2 batches\n10: 2 batches\n5: 2 batches\n34 Start Epoch 5\n9 Start Epoch 5\n4 Start Epoch 5\n4: 2 batches\n25: 2 batches\n24: 2 batches\n9: 2 batches\n17 Start Epoch 5\n32 Start Epoch 5\n17: 2 batches\n22 Start Epoch 5\n26 Start Epoch 5\n26: 2 batches\n8 Start Epoch 5\n16 Start Epoch 5\n23 Start Epoch 5\n32: 2 batches\n22: 2 batches\n34: 2 batches\n8: 2 batches\n16: 2 batches\n31 Start Epoch 5\n23: 2 batches\n31: 2 batches\n3 Start Epoch 5\n3: 2 batches\n1 Start Epoch 5\n1: 2 batches\n2 Start Epoch 5\n2: 2 batches\n30 Start Epoch 5\n36: 2 batches\n38: 2 batches\n30: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:35: Epoch 0 train loss: 7359.1993408203125\nINFO:root:38: Epoch 0 train loss: 5014536.584472656\nINFO:root:13: Epoch 0 train loss: 1035477.2815914154\nINFO:root:14: Epoch 0 train loss: 4051.446044921875\nINFO:root:12: Epoch 0 train loss: 320.524453163147\nINFO:root:15: Epoch 0 train loss: 1007181.0014305115\nINFO:root:37: Epoch 0 train loss: 13053.41357421875\nINFO:root:1: Epoch 0 train loss: 12677.462524414062\nINFO:root:17: Epoch 0 train loss: 21476.699226379395\nINFO:root:22: Epoch 0 train loss: 826336.7528381348\nINFO:root:24: Epoch 0 train loss: 1330.4273681640625\nINFO:root:32: Epoch 0 train loss: 1085295.4664764404\nINFO:root:19: Epoch 0 train loss: 866309.9584960938\nINFO:root:21: Epoch 0 train loss: 1658.3161010742188\nINFO:root:0: Epoch 0 train loss: 15679.457397460938\nINFO:root:33: Epoch 0 train loss: 22461.7749710083\nINFO:root:23: Epoch 0 train loss: 1947.2786407470703\nINFO:root:34: Epoch 0 train loss: 6630.12939453125\nINFO:root:20: Epoch 0 train loss: 10023.257141113281\nINFO:root:27: Epoch 0 train loss: 1032979.1334037781\nINFO:root:18: Epoch 0 train loss: 3865.694091796875\nINFO:root:30: Epoch 0 train loss: 1418.129977107048\nINFO:root:29: Epoch 0 train loss: 1967.3394680023193\nINFO:root:28: Epoch 0 train loss: 5597997.047668457\nINFO:root:31: Epoch 0 train loss: 15851.290283203125\nINFO:root:26: Epoch 0 train loss: 10218.20556640625\nINFO:root:25: Epoch 0 train loss: 33211.25630044937\nINFO:root:36: Epoch 0 train loss: 1085705.3031921387\nINFO:root:39: Epoch 0 train loss: 2264.3644409179688\nINFO:root:11: Epoch 0 train loss: 1202.7347679138184\nINFO:root:16: Epoch 0 train loss: 549.2332153320312\nINFO:root:6: Epoch 0 train loss: 4750.703063964844\nINFO:root:7: Epoch 0 train loss: 25751.314964294434\nINFO:root:10: Epoch 0 train loss: 5337.266489982605\nINFO:root:9: Epoch 0 train loss: 1124536.58984375\nINFO:root:8: Epoch 0 train loss: 356.98486328125\nINFO:root:2: Epoch 0 train loss: 26174.9326171875\nINFO:root:5: Epoch 0 train loss: 19339.082412719727\nINFO:root:4: Epoch 0 train loss: 6867.902893066406\nINFO:root:3: Epoch 0 train loss: 16382.7705078125\nINFO:root:0: Epoch 0 validation loss: 2192175.7784306984\nINFO:root:39: Epoch 1 train loss: 6753.695556640625\nINFO:root:0: Epoch 1 train loss: 1967474.7352905273\nINFO:root:1: Epoch 1 train loss: 37962.741943359375\nINFO:root:7: Epoch 1 train loss: 993.455628156662\nINFO:root:6: Epoch 1 train loss: 3104.155586242676\nINFO:root:27: Epoch 1 train loss: 850.4636945724487\nINFO:root:15: Epoch 1 train loss: 25471.230834960938\nINFO:root:13: Epoch 1 train loss: 47449.733337402344\nINFO:root:24: Epoch 1 train loss: 151.6445255279541\nINFO:root:14: Epoch 1 train loss: 1008793.55859375\nINFO:root:26: Epoch 1 train loss: 811909.5575628281\nINFO:root:32: Epoch 1 train loss: 126.52026772499084\nINFO:root:35: Epoch 1 train loss: 20366.481895446777\nINFO:root:8: Epoch 1 train loss: 2415.019686535001\nINFO:root:9: Epoch 1 train loss: 4725108.904327393\nINFO:root:16: Epoch 1 train loss: 15804.25927734375\nINFO:root:18: Epoch 1 train loss: 999513.7989579439\nINFO:root:19: Epoch 1 train loss: 131602.638671875\nINFO:root:17: Epoch 1 train loss: 5597931.8963012695\nINFO:root:31: Epoch 1 train loss: 6949.718571662903\nINFO:root:30: Epoch 1 train loss: 669007.852722168\nINFO:root:29: Epoch 1 train loss: 65301.806884765625\nINFO:root:23: Epoch 1 train loss: 1451.2005004882812\nINFO:root:28: Epoch 1 train loss: 999417.0052261353\nINFO:root:11: Epoch 1 train loss: 9010.419677734375\nINFO:root:10: Epoch 1 train loss: 8309.037841796875\nINFO:root:20: Epoch 1 train loss: 6883.614314079285\nINFO:root:33: Epoch 1 train loss: 1197003.9242191315\nINFO:root:34: Epoch 1 train loss: 8109.9329833984375\nINFO:root:3: Epoch 1 train loss: 37731.70458984375\nINFO:root:2: Epoch 1 train loss: 8101.018141448498\nINFO:root:21: Epoch 1 train loss: 116837.98803710938\nINFO:root:12: Epoch 1 train loss: 112220.25326156616\nINFO:root:22: Epoch 1 train loss: 9665.056213378906\nINFO:root:38: Epoch 1 train loss: 1201611.4462890625\nINFO:root:25: Epoch 1 train loss: 29389.11328125\nINFO:root:36: Epoch 1 train loss: 13932.165216445923\nINFO:root:5: Epoch 1 train loss: 11465.23910522461\nINFO:root:4: Epoch 1 train loss: 91402.57836914062\nINFO:root:37: Epoch 1 train loss: 775.7288064956665\nINFO:root:0: Epoch 1 validation loss: 2192143.0843261313\nINFO:root:27: Epoch 2 train loss: 397.2949275970459\nINFO:root:0: Epoch 2 train loss: 1637.5101928710938\nINFO:root:35: Epoch 2 train loss: 2041.0087985992432\nINFO:root:39: Epoch 2 train loss: 5813738.764007568\nINFO:root:23: Epoch 2 train loss: 20984.200073242188\nINFO:root:36: Epoch 2 train loss: 223.6177978515625\nINFO:root:15: Epoch 2 train loss: 4105.332685947418\nINFO:root:12: Epoch 2 train loss: 2666.497583389282\nINFO:root:24: Epoch 2 train loss: 8804.723876953125\nINFO:root:3: Epoch 2 train loss: 11480.919921875\nINFO:root:2: Epoch 2 train loss: 22225.828125\nINFO:root:4: Epoch 2 train loss: 2300.479965209961\nINFO:root:7: Epoch 2 train loss: 13555.360321044922\nINFO:root:13: Epoch 2 train loss: 9940.342163085938\nINFO:root:5: Epoch 2 train loss: 862633.3856840134\nINFO:root:26: Epoch 2 train loss: 8579.387842178345\nINFO:root:25: Epoch 2 train loss: 461.9943017959595\nINFO:root:28: Epoch 2 train loss: 2980.3010864257812\nINFO:root:6: Epoch 2 train loss: 826697.4357299805\nINFO:root:30: Epoch 2 train loss: 1034008.3043365479\nINFO:root:19: Epoch 2 train loss: 432.93844985961914\nINFO:root:31: Epoch 2 train loss: 6197.231250762939\nINFO:root:33: Epoch 2 train loss: 827965.1865234375\nINFO:root:34: Epoch 2 train loss: 3884.1954956054688\nINFO:root:9: Epoch 2 train loss: 43536.2646484375\nINFO:root:22: Epoch 2 train loss: 195.9495849609375\nINFO:root:21: Epoch 2 train loss: 6437.0911865234375\nINFO:root:10: Epoch 2 train loss: 1205016.0200181007\nINFO:root:20: Epoch 2 train loss: 390.3528366088867\nINFO:root:29: Epoch 2 train loss: 2621.0055084228516\nINFO:root:11: Epoch 2 train loss: 7026.137673854828\nINFO:root:1: Epoch 2 train loss: 2216.112735748291\nINFO:root:38: Epoch 2 train loss: 1087744.6495933533\nINFO:root:37: Epoch 2 train loss: 2101.5870971679688\nINFO:root:16: Epoch 2 train loss: 11715.621039390564\nINFO:root:18: Epoch 2 train loss: 19341.06446838379\nINFO:root:17: Epoch 2 train loss: 4129.642822265625\nINFO:root:8: Epoch 2 train loss: 2775255.0033569336\nINFO:root:32: Epoch 2 train loss: 23230.386474609375\nINFO:root:14: Epoch 2 train loss: 7828.372329711914\nINFO:root:0: Epoch 2 validation loss: 2192108.478610767\nINFO:root:39: Epoch 3 train loss: 3075.9755859375\nINFO:root:15: Epoch 3 train loss: 1001991.4632641077\nINFO:root:12: Epoch 3 train loss: 7679.999005198479\nINFO:root:13: Epoch 3 train loss: 46202.2265625\nINFO:root:26: Epoch 3 train loss: 17075.16259765625\nINFO:root:28: Epoch 3 train loss: 7558.2764892578125\nINFO:root:27: Epoch 3 train loss: 14607.901077270508\nINFO:root:29: Epoch 3 train loss: 343911.6815185547\nINFO:root:22: Epoch 3 train loss: 3822.8180541992188\nINFO:root:23: Epoch 3 train loss: 604.0933952331543\nINFO:root:14: Epoch 3 train loss: 816740.2464809418\nINFO:root:1: Epoch 3 train loss: 5613347.1806640625\nINFO:root:18: Epoch 3 train loss: 2525.185326293111\nINFO:root:17: Epoch 3 train loss: 13223.224365234375\nINFO:root:21: Epoch 3 train loss: 7188.34521484375\nINFO:root:16: Epoch 3 train loss: 6589.247314453125\nINFO:root:0: Epoch 3 train loss: 19006.40234375\nINFO:root:19: Epoch 3 train loss: 4647.386299133301\nINFO:root:31: Epoch 3 train loss: 3425.0950660705566\nINFO:root:32: Epoch 3 train loss: 6612.241455078125\nINFO:root:25: Epoch 3 train loss: 9936.627059936523\nINFO:root:33: Epoch 3 train loss: 822127.490234375\nINFO:root:34: Epoch 3 train loss: 2659.8661499023438\nINFO:root:24: Epoch 3 train loss: 11066.901947021484\nINFO:root:3: Epoch 3 train loss: 29810.3427734375\nINFO:root:2: Epoch 3 train loss: 2839.1938190460205\nINFO:root:30: Epoch 3 train loss: 3783.02508354187\nINFO:root:9: Epoch 3 train loss: 4038.041259765625\nINFO:root:38: Epoch 3 train loss: 1062.3702545166016\nINFO:root:7: Epoch 3 train loss: 19320.691375732422\nINFO:root:20: Epoch 3 train loss: 10295.524192810059\nINFO:root:35: Epoch 3 train loss: 33902.18306350708\nINFO:root:10: Epoch 3 train loss: 37300.775939941406\nINFO:root:37: Epoch 3 train loss: 112760.59275817871\nINFO:root:5: Epoch 3 train loss: 3993.4164781570435\nINFO:root:36: Epoch 3 train loss: 813965.3470802307\nINFO:root:6: Epoch 3 train loss: 1825838.7042236328\nINFO:root:11: Epoch 3 train loss: 5654.326416015625\nINFO:root:4: Epoch 3 train loss: 3631.63427066803\nINFO:root:8: Epoch 3 train loss: 1081.4815322756767\nINFO:root:0: Epoch 3 validation loss: 2192071.658640145\nINFO:root:37: Epoch 4 train loss: 1762.70947265625\nINFO:root:15: Epoch 4 train loss: 6717797.0\nINFO:root:7: Epoch 4 train loss: 616.2906951904297\nINFO:root:38: Epoch 4 train loss: 349658.0625\nINFO:root:12: Epoch 4 train loss: 5933.498531341553\nINFO:root:39: Epoch 4 train loss: 557.2673969268799\nINFO:root:36: Epoch 4 train loss: 1422.2317504882812\nINFO:root:19: Epoch 4 train loss: 8588.541928768158\nINFO:root:5: Epoch 4 train loss: 2025.7974586486816\nINFO:root:20: Epoch 4 train loss: 1199125.0375976562\nINFO:root:27: Epoch 4 train loss: 8991.598690032959\nINFO:root:35: Epoch 4 train loss: 1209.5719146728516\nINFO:root:9: Epoch 4 train loss: 3115.1840782165527\nINFO:root:13: Epoch 4 train loss: 4844.881618976593\nINFO:root:34: Epoch 4 train loss: 3592.3172340393066\nINFO:root:11: Epoch 4 train loss: 2972.514129638672\nINFO:root:14: Epoch 4 train loss: 7187.757228851318\nINFO:root:18: Epoch 4 train loss: 2583.7480454444885\nINFO:root:6: Epoch 4 train loss: 41.25082492828369\nINFO:root:4: Epoch 4 train loss: 1083099.2455644608\nINFO:root:29: Epoch 4 train loss: 709.5416889190674\nINFO:root:10: Epoch 4 train loss: 7494.809997558594\nINFO:root:25: Epoch 4 train loss: 854.9264526367188\nINFO:root:33: Epoch 4 train loss: 2196.2921180725098\nINFO:root:31: Epoch 4 train loss: 59566.76953125\nINFO:root:21: Epoch 4 train loss: 6634.307041168213\nINFO:root:28: Epoch 4 train loss: 5412.883004188538\nINFO:root:24: Epoch 4 train loss: 6627.770466804504\nINFO:root:23: Epoch 4 train loss: 751.4791259765625\nINFO:root:17: Epoch 4 train loss: 9776.035898208618\nINFO:root:16: Epoch 4 train loss: 11223.610595703125\nINFO:root:22: Epoch 4 train loss: 24193.87451171875\nINFO:root:32: Epoch 4 train loss: 343843.8603515625\nINFO:root:8: Epoch 4 train loss: 1357.0686950683594\nINFO:root:26: Epoch 4 train loss: 42651.987200737\nINFO:root:30: Epoch 4 train loss: 2806.236114501953\nINFO:root:0: Epoch 4 train loss: 7450.353477478027\nINFO:root:3: Epoch 4 train loss: 121234.27697753906\nINFO:root:1: Epoch 4 train loss: 1330.556095123291\nINFO:root:2: Epoch 4 train loss: 2141.4066162109375\nINFO:root:0: Epoch 4 validation loss: 2192032.1350174127\nINFO:root:31: Epoch 5 train loss: 10236.39990234375\nINFO:root:36: Epoch 5 train loss: 3471.119873046875\nINFO:root:37: Epoch 5 train loss: 4014.6171264648438\nINFO:root:12: Epoch 5 train loss: 3886.023492395878\nINFO:root:15: Epoch 5 train loss: 4769.635994255543\nINFO:root:39: Epoch 5 train loss: 40555.830078125\nINFO:root:27: Epoch 5 train loss: 433.2446041107178\nINFO:root:16: Epoch 5 train loss: 1679086.0717658997\nINFO:root:26: Epoch 5 train loss: 26447.17364501953\nINFO:root:14: Epoch 5 train loss: 37523.9501953125\nINFO:root:13: Epoch 5 train loss: 1003122.7400817871\nINFO:root:17: Epoch 5 train loss: 33546.00881958008\nINFO:root:23: Epoch 5 train loss: 6661.66877746582\nINFO:root:9: Epoch 5 train loss: 5825922.255859375\nINFO:root:29: Epoch 5 train loss: 341225.41717529297\nINFO:root:8: Epoch 5 train loss: 1373.640042245388\nINFO:root:21: Epoch 5 train loss: 281.61351776123047\nINFO:root:28: Epoch 5 train loss: 4638.4312744140625\nINFO:root:30: Epoch 5 train loss: 4739644.2451171875\nINFO:root:7: Epoch 5 train loss: 4229.2652587890625\nINFO:root:32: Epoch 5 train loss: 8406.939598083496\nINFO:root:34: Epoch 5 train loss: 9110.158220291138\nINFO:root:11: Epoch 5 train loss: 6015298.94140625\nINFO:root:18: Epoch 5 train loss: 6131.59619140625\nINFO:root:35: Epoch 5 train loss: 2550.8681030273438\nINFO:root:1: Epoch 5 train loss: 112700.48669433594\nINFO:root:0: Epoch 5 train loss: 412.3616180419922\nINFO:root:20: Epoch 5 train loss: 2008.7954216003418\nINFO:root:33: Epoch 5 train loss: 28004.348205566406\nINFO:root:10: Epoch 5 train loss: 1100757.970703125\nINFO:root:38: Epoch 5 train loss: 38209.701171875\nINFO:root:22: Epoch 5 train loss: 821059.3540039062\nINFO:root:25: Epoch 5 train loss: 1833.5443420410156\nINFO:root:24: Epoch 5 train loss: 817426.8432922363\nINFO:root:5: Epoch 5 train loss: 1101.8978881835938\nINFO:root:6: Epoch 5 train loss: 1401.1575317382812\nINFO:root:4: Epoch 5 train loss: 9762.543273925781\nINFO:root:19: Epoch 5 train loss: 6975929.8876953125\nINFO:root:3: Epoch 5 train loss: 394.01373195648193\nINFO:root:2: Epoch 5 train loss: 1719.4281299114227\nINFO:root:0: Epoch 5 validation loss: 2191989.478564191\n", "seconds": 12.407721042633057, "batch_size": 64, "nodes": 10, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n1 Start Epoch 0\n2 Start Epoch 0\n2: 2 batches\n1: 2 batches\n3 Start Epoch 0\n3: 2 batches\n4 Start Epoch 0\n4: 2 batches\n43 Start Epoch 0\n43: 2 batches\n5 Start Epoch 0\n6 Start Epoch 0\n5: 2 batches\n6: 2 batches\n7 Start Epoch 0\n7: 2 batches\n8 Start Epoch 0\n8: 2 batches\n36 Start Epoch 0\n40 Start Epoch 0\n28 Start Epoch 0\n12 Start Epoch 0\n36: 2 batches\n40: 2 batches\n28: 2 batches\n11 Start Epoch 0\n12: 2 batches\n27 Start Epoch 0\n11: 2 batches\n20 Start Epoch 0\n19 Start Epoch 0\n35 Start Epoch 0\n31 Start Epoch 0\n24 Start Epoch 0\n15 Start Epoch 0\n23 Start Epoch 0\n16 Start Epoch 0\n35: 2 batches\n31: 2 batches\n27: 2 batches\n15: 2 batches\n23: 2 batches\n16: 2 batches\n32 Start Epoch 0\n39 Start Epoch 0\n24: 2 batches\n20: 2 batches\n19: 2 batches\n32: 2 batches\n39: 2 batches\n17 Start Epoch 0\n33 Start Epoch 0\n9 Start Epoch 0\n10 Start Epoch 0\n18 Start Epoch 0\n34 Start Epoch 0\n9: 2 batches\n17: 2 batches\n34: 2 batches\n18: 2 batches\n10: 2 batches\n33: 2 batches\n29 Start Epoch 0\n13 Start Epoch 0\n14 Start Epoch 0\n21 Start Epoch 0\n13: 2 batches\n22 Start Epoch 0\n29: 2 batches\n14: 2 batches\n21: 2 batches\n30 Start Epoch 0\n22: 2 batches\n30: 2 batches\n37 Start Epoch 0\n38 Start Epoch 0\n37: 2 batches\n38: 2 batches\n26 Start Epoch 0\n25 Start Epoch 0\n25: 2 batches\n26: 2 batches\n41 Start Epoch 0\n42 Start Epoch 0\n41: 2 batches\n42: 2 batches\n3 Start Epoch 1\n3: 2 batches\n14 Start Epoch 1\n9 Start Epoch 1\n14: 2 batches\n8 Start Epoch 1\n8: 2 batches\n12 Start Epoch 1\n9: 2 batches\n4 Start Epoch 1\n2 Start Epoch 1\n6 Start Epoch 1\n2: 2 batches\n5 Start Epoch 1\n6: 2 batches\n5: 2 batches\n7 Start Epoch 1\n7: 2 batches\n4: 2 batches\n25 Start Epoch 1\n24 Start Epoch 1\n10 Start Epoch 1\n19 Start Epoch 1\n19: 2 batches\n24: 2 batches\n11 Start Epoch 1\n10: 2 batches\n25: 2 batches\n11: 2 batches\n12: 2 batches\n15 Start Epoch 1\n13 Start Epoch 1\n13: 2 batches\n15: 2 batches\n20 Start Epoch 1\n20: 2 batches\n23 Start Epoch 1\n23: 2 batches\n39 Start Epoch 1\n36 Start Epoch 1\n36: 2 batches\n39: 2 batches\n16 Start Epoch 1\n16: 2 batches\n35 Start Epoch 1\n34 Start Epoch 1\n35: 2 batches\n21 Start Epoch 1\n22 Start Epoch 1\n42 Start Epoch 1\n42: 2 batches\n41 Start Epoch 1\n41: 2 batches\n22: 2 batches\n21: 2 batches\n43 Start Epoch 1\n27 Start Epoch 1\n26 Start Epoch 1\n27: 2 batches\n1 Start Epoch 1\n1: 2 batches\n26: 2 batches\n43: 2 batches\n17 Start Epoch 1\n17: 2 batches\n31 Start Epoch 1\n29 Start Epoch 1\n28 Start Epoch 1\n31: 2 batches\n29: 2 batches\n30 Start Epoch 1\n30: 2 batches\n28: 2 batches\n33 Start Epoch 1\n33: 2 batches\n34: 2 batches\n18 Start Epoch 1\n38 Start Epoch 1\n32 Start Epoch 1\n40 Start Epoch 1\n32: 2 batches\n38: 2 batches\n40: 2 batches\n18: 2 batches\n37 Start Epoch 1\n37: 2 batches\n0 Start Epoch 1\n0: 2 batches\n15 Start Epoch 2\n7 Start Epoch 2\n15: 2 batches\n7: 2 batches\n16 Start Epoch 2\n16: 2 batches\n11 Start Epoch 2\n31 Start Epoch 2\n11: 2 batches\n19 Start Epoch 2\n6 Start Epoch 2\n4 Start Epoch 2\n36 Start Epoch 2\n43 Start Epoch 2\n31: 2 batches\n23 Start Epoch 2\n19: 2 batches\n6: 2 batches\n37 Start Epoch 2\n42 Start Epoch 2\n37: 2 batches\n42: 2 batches\n29 Start Epoch 2\n27 Start Epoch 2\n20 Start Epoch 2\n35 Start Epoch 2\n29: 2 batches\n25 Start Epoch 2\n21 Start Epoch 2\n34 Start Epoch 2\n5 Start Epoch 2\n36: 2 batches\n43: 2 batches\n27: 2 batches\n9 Start Epoch 2\n21: 2 batches\n33 Start Epoch 2\n4: 2 batches\n25: 2 batches\n23: 2 batches\n35: 2 batches\n5: 2 batches\n30 Start Epoch 2\n34: 2 batches\n30: 2 batches\n26 Start Epoch 2\n9: 2 batches\n22 Start Epoch 2\n32 Start Epoch 2\n38 Start Epoch 2\n41 Start Epoch 2\n26: 2 batches\n8 Start Epoch 2\n22: 2 batches\n32: 2 batches\n38: 2 batches\n28 Start Epoch 2\n8: 2 batches\n20: 2 batches\n28: 2 batches\n33: 2 batches\n39 Start Epoch 2\n39: 2 batches\n2 Start Epoch 2\n2: 2 batches\n1 Start Epoch 2\n1: 2 batches\n3 Start Epoch 2\n3: 2 batches\n41: 2 batches\n18 Start Epoch 2\n10 Start Epoch 2\n17 Start Epoch 2\n24 Start Epoch 2\n40 Start Epoch 2\n24: 2 batches\n10: 2 batches\n14 Start Epoch 2\n18: 2 batches\n17: 2 batches\n40: 2 batches\n12 Start Epoch 2\n12: 2 batches\n14: 2 batches\n13 Start Epoch 2\n13: 2 batches\n0 Start Epoch 2\n0: 2 batches\n27 Start Epoch 3\n27: 2 batches\n28 Start Epoch 3\n28: 2 batches\n29 Start Epoch 3\n29: 2 batches\n13 Start Epoch 3\n12 Start Epoch 3\n15 Start Epoch 3\n15: 2 batches\n12: 2 batches\n14 Start Epoch 3\n13: 2 batches\n14: 2 batches\n18 Start Epoch 3\n11 Start Epoch 3\n23 Start Epoch 3\n21 Start Epoch 3\n26 Start Epoch 3\n10 Start Epoch 3\n25 Start Epoch 3\n10: 2 batches\n26: 2 batches\n11: 2 batches\n24 Start Epoch 3\n25: 2 batches\n24: 2 batches\n23: 2 batches\n22 Start Epoch 3\n22: 2 batches\n21: 2 batches\n20 Start Epoch 3\n20: 2 batches\n32 Start Epoch 3\n6 Start Epoch 3\n7 Start Epoch 3\n43 Start Epoch 3\n33 Start Epoch 3\n43: 2 batches\n30 Start Epoch 3\n31 Start Epoch 3\n7: 2 batches\n31: 2 batches\n32: 2 batches\n33: 2 batches\n6: 2 batches\n30: 2 batches\n1 Start Epoch 3\n1: 2 batches\n2 Start Epoch 3\n2: 2 batches\n3 Start Epoch 3\n3: 2 batches\n18: 2 batches\n36 Start Epoch 3\n41 Start Epoch 3\n16 Start Epoch 3\n34 Start Epoch 3\n36: 2 batches\n41: 2 batches\n16: 2 batches\n35 Start Epoch 3\n37 Start Epoch 3\n42 Start Epoch 3\n34: 2 batches\n42: 2 batches\n17 Start Epoch 3\n35: 2 batches\n37: 2 batches\n9 Start Epoch 3\n17: 2 batches\n40 Start Epoch 3\n8 Start Epoch 3\n8: 2 batches\n19 Start Epoch 3\n40: 2 batches\n9: 2 batches\n19: 2 batches\n38 Start Epoch 3\n38: 2 batches\n39 Start Epoch 3\n39: 2 batches\n5 Start Epoch 3\n4 Start Epoch 3\n4: 2 batches\n5: 2 batches\n0 Start Epoch 3\n0: 2 batches\n15 Start Epoch 4\n14 Start Epoch 4\n6 Start Epoch 4\n6: 2 batches\n7 Start Epoch 4\n7: 2 batches\n9 Start Epoch 4\n8 Start Epoch 4\n32 Start Epoch 4\n33 Start Epoch 4\n42 Start Epoch 4\n8: 2 batches\n9: 2 batches\n16 Start Epoch 4\n43 Start Epoch 4\n16: 2 batches\n33: 2 batches\n39 Start Epoch 4\n39: 2 batches\n42: 2 batches\n25 Start Epoch 4\n19 Start Epoch 4\n27 Start Epoch 4\n19: 2 batches\n43: 2 batches\n25: 2 batches\n24 Start Epoch 4\n22 Start Epoch 4\n27: 2 batches\n20 Start Epoch 4\n23 Start Epoch 4\n24: 2 batches\n23: 2 batches\n31 Start Epoch 4\n10 Start Epoch 4\n10: 2 batches\n22: 2 batches\n29 Start Epoch 4\n21 Start Epoch 4\n30 Start Epoch 4\n31: 2 batches\n1 Start Epoch 4\n1: 2 batches\n2 Start Epoch 4\n2: 2 batches\n3 Start Epoch 4\n3: 2 batches\n21: 2 batches\n4 Start Epoch 4\n29: 2 batches\n20: 2 batches\n17 Start Epoch 4\n5 Start Epoch 4\n5: 2 batches\n37 Start Epoch 4\n41 Start Epoch 4\n30: 2 batches\n26 Start Epoch 4\n11 Start Epoch 4\n12 Start Epoch 4\n12: 2 batches\n28 Start Epoch 4\n26: 2 batches\n11: 2 batches\n14: 2 batches\n17: 2 batches\n35 Start Epoch 4\n37: 2 batches\n15: 2 batches\n34 Start Epoch 4\n41: 2 batches\n28: 2 batches\n4: 2 batches\n38 Start Epoch 4\n40 Start Epoch 4\n13 Start Epoch 4\n13: 2 batches\n18 Start Epoch 4\n35: 2 batches\n18: 2 batches\n34: 2 batches\n38: 2 batches\n40: 2 batches\n32: 2 batches\n36 Start Epoch 4\n36: 2 batches\n0 Start Epoch 4\n0: 2 batches\n12 Start Epoch 5\n15 Start Epoch 5\n15: 2 batches\n13 Start Epoch 5\n13: 2 batches\n7 Start Epoch 5\n7: 2 batches\n12: 2 batches\n14 Start Epoch 5\n14: 2 batches\n6 Start Epoch 5\n6: 2 batches\n4 Start Epoch 5\n4: 2 batches\n9 Start Epoch 5\n10 Start Epoch 5\n9: 2 batches\n16 Start Epoch 5\n10: 2 batches\n11 Start Epoch 5\n11: 2 batches\n2 Start Epoch 5\n2: 2 batches\n1 Start Epoch 5\n1: 2 batches\n16: 2 batches\n30 Start Epoch 5\n8 Start Epoch 5\n23 Start Epoch 5\n24 Start Epoch 5\n8: 2 batches\n23: 2 batches\n18 Start Epoch 5\n35 Start Epoch 5\n38 Start Epoch 5\n41 Start Epoch 5\n30: 2 batches\n41: 2 batches\n25 Start Epoch 5\n25: 2 batches\n35: 2 batches\n39 Start Epoch 5\n39: 2 batches\n42 Start Epoch 5\n29 Start Epoch 5\n24: 2 batches\n20 Start Epoch 5\n18: 2 batches\n38: 2 batches\n42: 2 batches\n29: 2 batches\n19 Start Epoch 5\n33 Start Epoch 5\n21 Start Epoch 5\n19: 2 batches\n32 Start Epoch 5\n20: 2 batches\n33: 2 batches\n5 Start Epoch 5\n5: 2 batches\n36 Start Epoch 5\n36: 2 batches\n40 Start Epoch 5\n31 Start Epoch 5\n27 Start Epoch 5\n17 Start Epoch 5\n32: 2 batches\n28 Start Epoch 5\n27: 2 batches\n21: 2 batches\n17: 2 batches\n43 Start Epoch 5\n22 Start Epoch 5\n34 Start Epoch 5\n37 Start Epoch 5\n43: 2 batches\n31: 2 batches\n34: 2 batches\n37: 2 batches\n40: 2 batches\n28: 2 batches\n22: 2 batches\n26 Start Epoch 5\n3 Start Epoch 5\n3: 2 batches\n26: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:14: Epoch 0 train loss: 22515.68888759613\nINFO:root:3: Epoch 0 train loss: 3116.2218017578125\nINFO:root:15: Epoch 0 train loss: 2681.4424839019775\nINFO:root:9: Epoch 0 train loss: 2618.335711941123\nINFO:root:5: Epoch 0 train loss: 6552.387878417969\nINFO:root:12: Epoch 0 train loss: 1587.8111865520477\nINFO:root:23: Epoch 0 train loss: 1964490.234375\nINFO:root:8: Epoch 0 train loss: 651.0647204518318\nINFO:root:6: Epoch 0 train loss: 36.1697795689106\nINFO:root:7: Epoch 0 train loss: 17479.14044189453\nINFO:root:11: Epoch 0 train loss: 1740.8849334716797\nINFO:root:4: Epoch 0 train loss: 2523.9131469726562\nINFO:root:2: Epoch 0 train loss: 446.9569934606552\nINFO:root:24: Epoch 0 train loss: 3585.9186952114105\nINFO:root:19: Epoch 0 train loss: 452664.49896240234\nINFO:root:25: Epoch 0 train loss: 597.7401580810547\nINFO:root:10: Epoch 0 train loss: 177339.634765625\nINFO:root:13: Epoch 0 train loss: 770.816162109375\nINFO:root:20: Epoch 0 train loss: 390.1556587219238\nINFO:root:39: Epoch 0 train loss: 1274.5535531044006\nINFO:root:36: Epoch 0 train loss: 390.3217468261719\nINFO:root:16: Epoch 0 train loss: 19231.56829436496\nINFO:root:0: Epoch 0 train loss: 812092.3125248322\nINFO:root:35: Epoch 0 train loss: 718.4598088833518\nINFO:root:34: Epoch 0 train loss: 5656.5880126953125\nINFO:root:21: Epoch 0 train loss: 20805.72941350937\nINFO:root:42: Epoch 0 train loss: 3084.084499708253\nINFO:root:41: Epoch 0 train loss: 6899.047825098038\nINFO:root:22: Epoch 0 train loss: 2043.3493205308914\nINFO:root:43: Epoch 0 train loss: 39520.374671936035\nINFO:root:27: Epoch 0 train loss: 9893.47552887653\nINFO:root:26: Epoch 0 train loss: 337.40490538250924\nINFO:root:1: Epoch 0 train loss: 433.68727016448975\nINFO:root:18: Epoch 0 train loss: 12916.954376220703\nINFO:root:31: Epoch 0 train loss: 1046.5753812789917\nINFO:root:28: Epoch 0 train loss: 11333.935784339905\nINFO:root:17: Epoch 0 train loss: 1084625.500024218\nINFO:root:30: Epoch 0 train loss: 1694.0797319412231\nINFO:root:29: Epoch 0 train loss: 9172.148559570312\nINFO:root:33: Epoch 0 train loss: 1326.0713025029472\nINFO:root:32: Epoch 0 train loss: 866904.5327892303\nINFO:root:40: Epoch 0 train loss: 1424.8871421813965\nINFO:root:38: Epoch 0 train loss: 854.3993091583252\nINFO:root:37: Epoch 0 train loss: 3236.2511138916016\nINFO:root:0: Epoch 0 validation loss: 15317.002549125757\nINFO:root:15: Epoch 1 train loss: 1316.8046071876452\nINFO:root:7: Epoch 1 train loss: 16535.72423197329\nINFO:root:20: Epoch 1 train loss: 2676.7598419189453\nINFO:root:16: Epoch 1 train loss: 993.922352473066\nINFO:root:6: Epoch 1 train loss: 390.75217294692993\nINFO:root:11: Epoch 1 train loss: 3533.103910923004\nINFO:root:21: Epoch 1 train loss: 12910.649841308594\nINFO:root:34: Epoch 1 train loss: 1869.6335424929857\nINFO:root:4: Epoch 1 train loss: 5746.066479282141\nINFO:root:36: Epoch 1 train loss: 13788869.840820312\nINFO:root:42: Epoch 1 train loss: 1234.565668106079\nINFO:root:31: Epoch 1 train loss: 3463.361831665039\nINFO:root:43: Epoch 1 train loss: 4595.070495605469\nINFO:root:26: Epoch 1 train loss: 343381.2364686169\nINFO:root:23: Epoch 1 train loss: 7341.924851627788\nINFO:root:35: Epoch 1 train loss: 395.40275382995605\nINFO:root:37: Epoch 1 train loss: 1324.0767831206322\nINFO:root:22: Epoch 1 train loss: 1809.160629272461\nINFO:root:19: Epoch 1 train loss: 1002330.578453958\nINFO:root:32: Epoch 1 train loss: 1287.2517091408372\nINFO:root:27: Epoch 1 train loss: 340909.1359577179\nINFO:root:25: Epoch 1 train loss: 1827600.8749360144\nINFO:root:33: Epoch 1 train loss: 114123.60078430176\nINFO:root:29: Epoch 1 train loss: 20064.5498046875\nINFO:root:5: Epoch 1 train loss: 217.13545989990234\nINFO:root:9: Epoch 1 train loss: 2477.9977865219116\nINFO:root:30: Epoch 1 train loss: 346787.19609355927\nINFO:root:18: Epoch 1 train loss: 20317.068725585938\nINFO:root:8: Epoch 1 train loss: 2295.3561401367188\nINFO:root:38: Epoch 1 train loss: 27624.77099609375\nINFO:root:41: Epoch 1 train loss: 12383.942993164062\nINFO:root:28: Epoch 1 train loss: 22839.44012451172\nINFO:root:39: Epoch 1 train loss: 16062.767333984375\nINFO:root:17: Epoch 1 train loss: 1000719.632344678\nINFO:root:1: Epoch 1 train loss: 3992.572723388672\nINFO:root:2: Epoch 1 train loss: 1201005.659663856\nINFO:root:0: Epoch 1 train loss: 908.5241603851318\nINFO:root:3: Epoch 1 train loss: 855.2407836914062\nINFO:root:24: Epoch 1 train loss: 97350.927734375\nINFO:root:10: Epoch 1 train loss: 15630.757554843207\nINFO:root:14: Epoch 1 train loss: 5203.3964920043945\nINFO:root:12: Epoch 1 train loss: 14224.221862792969\nINFO:root:40: Epoch 1 train loss: 138.0085310563445\nINFO:root:13: Epoch 1 train loss: 3420.931092977524\nINFO:root:0: Epoch 1 validation loss: 15313.723442276314\nINFO:root:27: Epoch 2 train loss: 5010.023231506348\nINFO:root:28: Epoch 2 train loss: 1695.4387000352144\nINFO:root:12: Epoch 2 train loss: 1098071.2630271912\nINFO:root:29: Epoch 2 train loss: 1581.0588190453927\nINFO:root:13: Epoch 2 train loss: 11758.343861804678\nINFO:root:14: Epoch 2 train loss: 4817.62252497673\nINFO:root:15: Epoch 2 train loss: 1089963.234375\nINFO:root:10: Epoch 2 train loss: 10810.967407226562\nINFO:root:21: Epoch 2 train loss: 22177.546798706055\nINFO:root:18: Epoch 2 train loss: 4114.502280738205\nINFO:root:26: Epoch 2 train loss: 372994.08984375\nINFO:root:25: Epoch 2 train loss: 1499.9560203552246\nINFO:root:11: Epoch 2 train loss: 1644.4164814688265\nINFO:root:23: Epoch 2 train loss: 3252.3854579925537\nINFO:root:24: Epoch 2 train loss: 747.0624885559082\nINFO:root:22: Epoch 2 train loss: 586.0415344238281\nINFO:root:20: Epoch 2 train loss: 4365.467025756836\nINFO:root:43: Epoch 2 train loss: 2201.360814332962\nINFO:root:30: Epoch 2 train loss: 135614.6005859375\nINFO:root:32: Epoch 2 train loss: 4530.190639927983\nINFO:root:31: Epoch 2 train loss: 1008.9061889648438\nINFO:root:6: Epoch 2 train loss: 963499.1875960837\nINFO:root:33: Epoch 2 train loss: 21134.90342375636\nINFO:root:7: Epoch 2 train loss: 16141.28369140625\nINFO:root:1: Epoch 2 train loss: 1035561.9047403336\nINFO:root:2: Epoch 2 train loss: 33190.9814453125\nINFO:root:3: Epoch 2 train loss: 813.3388938903809\nINFO:root:36: Epoch 2 train loss: 864883.6890957918\nINFO:root:41: Epoch 2 train loss: 5441.567046165466\nINFO:root:34: Epoch 2 train loss: 1942.4956558711128\nINFO:root:16: Epoch 2 train loss: 5290.857103591086\nINFO:root:35: Epoch 2 train loss: 19068.45043373108\nINFO:root:37: Epoch 2 train loss: 128.46372377872467\nINFO:root:42: Epoch 2 train loss: 5313.817344665527\nINFO:root:8: Epoch 2 train loss: 6896.833740234375\nINFO:root:17: Epoch 2 train loss: 2219.375503540039\nINFO:root:9: Epoch 2 train loss: 4514.1939697265625\nINFO:root:40: Epoch 2 train loss: 4217.358289718628\nINFO:root:19: Epoch 2 train loss: 545.5037593841553\nINFO:root:0: Epoch 2 train loss: 5013.954407930374\nINFO:root:38: Epoch 2 train loss: 1197065.5001182768\nINFO:root:39: Epoch 2 train loss: 7713.353515625\nINFO:root:5: Epoch 2 train loss: 863169.4561634064\nINFO:root:4: Epoch 2 train loss: 2035.2369899749756\nINFO:root:0: Epoch 2 validation loss: 15310.53784402736\nINFO:root:15: Epoch 3 train loss: 2195933.8394961357\nINFO:root:14: Epoch 3 train loss: 120.51187663571909\nINFO:root:6: Epoch 3 train loss: 817108.4372341633\nINFO:root:7: Epoch 3 train loss: 18365.449244499207\nINFO:root:9: Epoch 3 train loss: 8033.165882110596\nINFO:root:8: Epoch 3 train loss: 1548.6695468574762\nINFO:root:32: Epoch 3 train loss: 1075.6070041656494\nINFO:root:33: Epoch 3 train loss: 5740.41748046875\nINFO:root:39: Epoch 3 train loss: 723.316766217351\nINFO:root:42: Epoch 3 train loss: 167.94126835744828\nINFO:root:19: Epoch 3 train loss: 375832.515625\nINFO:root:24: Epoch 3 train loss: 1729.8158569335938\nINFO:root:16: Epoch 3 train loss: 113364.8896484375\nINFO:root:25: Epoch 3 train loss: 338591.3696594238\nINFO:root:27: Epoch 3 train loss: 33340.776611328125\nINFO:root:22: Epoch 3 train loss: 7422.048812866211\nINFO:root:38: Epoch 3 train loss: 1265.3390772962448\nINFO:root:43: Epoch 3 train loss: 522.6005743741989\nINFO:root:23: Epoch 3 train loss: 5483.079427719116\nINFO:root:20: Epoch 3 train loss: 222.06543636322021\nINFO:root:30: Epoch 3 train loss: 44394.602294921875\nINFO:root:21: Epoch 3 train loss: 23623.20947265625\nINFO:root:29: Epoch 3 train loss: 284.9487208724022\nINFO:root:28: Epoch 3 train loss: 4071.7354125976562\nINFO:root:10: Epoch 3 train loss: 227.76307106018066\nINFO:root:31: Epoch 3 train loss: 314.8858108520508\nINFO:root:1: Epoch 3 train loss: 126.2278561592102\nINFO:root:2: Epoch 3 train loss: 1928.267321869731\nINFO:root:3: Epoch 3 train loss: 7384.247703552246\nINFO:root:0: Epoch 3 train loss: 9664.274230957031\nINFO:root:37: Epoch 3 train loss: 17985.184509277344\nINFO:root:41: Epoch 3 train loss: 555.6149082034826\nINFO:root:26: Epoch 3 train loss: 64.54450607299805\nINFO:root:11: Epoch 3 train loss: 17697.7265625\nINFO:root:17: Epoch 3 train loss: 15505.351616859436\nINFO:root:35: Epoch 3 train loss: 7128.5843505859375\nINFO:root:34: Epoch 3 train loss: 413.7316454485408\nINFO:root:40: Epoch 3 train loss: 6901.550964355469\nINFO:root:5: Epoch 3 train loss: 1842.4129905700684\nINFO:root:18: Epoch 3 train loss: 15991438.0625\nINFO:root:4: Epoch 3 train loss: 6435.68379572648\nINFO:root:36: Epoch 3 train loss: 1199261.3676919937\nINFO:root:12: Epoch 3 train loss: 4294.689650644694\nINFO:root:13: Epoch 3 train loss: 1522.665356109268\nINFO:root:0: Epoch 3 validation loss: 15307.210486836153\nINFO:root:15: Epoch 4 train loss: 5022.504911925644\nINFO:root:13: Epoch 4 train loss: 4485.6512451171875\nINFO:root:7: Epoch 4 train loss: 119455.42446136475\nINFO:root:12: Epoch 4 train loss: 5389.3408851623535\nINFO:root:14: Epoch 4 train loss: 154.2200996875763\nINFO:root:6: Epoch 4 train loss: 8413.925197601318\nINFO:root:4: Epoch 4 train loss: 415.49476623535156\nINFO:root:11: Epoch 4 train loss: 9507.891922235489\nINFO:root:9: Epoch 4 train loss: 1780.9358367919922\nINFO:root:16: Epoch 4 train loss: 2215.1600284576416\nINFO:root:10: Epoch 4 train loss: 2508.509250640869\nINFO:root:2: Epoch 4 train loss: 6187.823764918139\nINFO:root:1: Epoch 4 train loss: 2217.468638420105\nINFO:root:0: Epoch 4 train loss: 7027.459869384766\nINFO:root:23: Epoch 4 train loss: 1220613.2702445984\nINFO:root:35: Epoch 4 train loss: 19319.364861547947\nINFO:root:38: Epoch 4 train loss: 3351.293996810913\nINFO:root:41: Epoch 4 train loss: 1039130.1952133179\nINFO:root:30: Epoch 4 train loss: 5870.173599243164\nINFO:root:24: Epoch 4 train loss: 623.5335235595703\nINFO:root:8: Epoch 4 train loss: 328.980188369751\nINFO:root:39: Epoch 4 train loss: 6026.854562759399\nINFO:root:42: Epoch 4 train loss: 861410.7514168619\nINFO:root:25: Epoch 4 train loss: 19163285.94921875\nINFO:root:18: Epoch 4 train loss: 770.7906951904297\nINFO:root:33: Epoch 4 train loss: 77.48725333518814\nINFO:root:29: Epoch 4 train loss: 3676.608186483383\nINFO:root:20: Epoch 4 train loss: 119236.46635580063\nINFO:root:19: Epoch 4 train loss: 1198475.5564575195\nINFO:root:32: Epoch 4 train loss: 1215544.837890625\nINFO:root:21: Epoch 4 train loss: 2881.1022338867188\nINFO:root:40: Epoch 4 train loss: 2438.3661499023438\nINFO:root:28: Epoch 4 train loss: 23969.752075195312\nINFO:root:27: Epoch 4 train loss: 334.296420365572\nINFO:root:5: Epoch 4 train loss: 5704.484069824219\nINFO:root:36: Epoch 4 train loss: 421.411828994751\nINFO:root:17: Epoch 4 train loss: 5733.4329833984375\nINFO:root:43: Epoch 4 train loss: 21805.845234684646\nINFO:root:31: Epoch 4 train loss: 1090326.9501953125\nINFO:root:26: Epoch 4 train loss: 1201909.0078125\nINFO:root:22: Epoch 4 train loss: 1634.0662670135498\nINFO:root:34: Epoch 4 train loss: 2272.521934837103\nINFO:root:37: Epoch 4 train loss: 1200002.742278099\nINFO:root:3: Epoch 4 train loss: 1536.3198356628418\nINFO:root:0: Epoch 4 validation loss: 15303.841493588712\nINFO:root:35: Epoch 5 train loss: 2358.9839537143707\nINFO:root:34: Epoch 5 train loss: 1181.2604885101318\nINFO:root:31: Epoch 5 train loss: 8019.130343377008\nINFO:root:30: Epoch 5 train loss: 11316.94174194336\nINFO:root:37: Epoch 5 train loss: 3366.313791129738\nINFO:root:36: Epoch 5 train loss: 2196997.686234057\nINFO:root:32: Epoch 5 train loss: 1085720.8882837296\nINFO:root:33: Epoch 5 train loss: 1201158.7135373354\nINFO:root:27: Epoch 5 train loss: 11501.984810423397\nINFO:root:28: Epoch 5 train loss: 5143.33621068066\nINFO:root:29: Epoch 5 train loss: 5944.778564453125\nINFO:root:26: Epoch 5 train loss: 5436924.8203125\nINFO:root:7: Epoch 5 train loss: 8870.184168815613\nINFO:root:3: Epoch 5 train loss: 8828.166763305664\nINFO:root:2: Epoch 5 train loss: 4147.555442810059\nINFO:root:23: Epoch 5 train loss: 7757.575218200684\nINFO:root:39: Epoch 5 train loss: 12377.322769165039\nINFO:root:38: Epoch 5 train loss: 267.1812471229932\nINFO:root:25: Epoch 5 train loss: 12651.37872865796\nINFO:root:15: Epoch 5 train loss: 21311.429956342792\nINFO:root:24: Epoch 5 train loss: 7769.2293701171875\nINFO:root:12: Epoch 5 train loss: 2863.04736328125\nINFO:root:0: Epoch 5 train loss: 5318.012622117996\nINFO:root:1: Epoch 5 train loss: 238.12693446874619\nINFO:root:16: Epoch 5 train loss: 131665.68927001953\nINFO:root:17: Epoch 5 train loss: 5524.699394226074\nINFO:root:13: Epoch 5 train loss: 818074.236811161\nINFO:root:42: Epoch 5 train loss: 3863.7661023139954\nINFO:root:40: Epoch 5 train loss: 9382.657958984375\nINFO:root:41: Epoch 5 train loss: 10559.169555664062\nINFO:root:21: Epoch 5 train loss: 1854.6284484863281\nINFO:root:43: Epoch 5 train loss: 4643.343239036214\nINFO:root:6: Epoch 5 train loss: 3192.040225982666\nINFO:root:4: Epoch 5 train loss: 999540.6254294849\nINFO:root:9: Epoch 5 train loss: 13228.807373046875\nINFO:root:8: Epoch 5 train loss: 1860842.5317001343\nINFO:root:5: Epoch 5 train loss: 2827.835235595703\nINFO:root:10: Epoch 5 train loss: 1143.8175266076578\nINFO:root:11: Epoch 5 train loss: 71368.048828125\nINFO:root:14: Epoch 5 train loss: 17330667.361328125\nINFO:root:22: Epoch 5 train loss: 1778.4396343231201\nINFO:root:18: Epoch 5 train loss: 1199591.8654403687\nINFO:root:19: Epoch 5 train loss: 8764.088342692005\nINFO:root:20: Epoch 5 train loss: 1091445.2595405579\nINFO:root:0: Epoch 5 validation loss: 15300.300519377764\n", "seconds": 13.012986898422241, "batch_size": 64, "nodes": 11, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 64 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n47 Start Epoch 0\n47: 1 batches\n2 Start Epoch 0\n1 Start Epoch 0\n2: 1 batches\n1: 1 batches\n3 Start Epoch 0\n39 Start Epoch 0\n3: 1 batches\n31 Start Epoch 0\n31: 1 batches\n39: 1 batches\n8 Start Epoch 0\n32 Start Epoch 0\n15 Start Epoch 0\n8: 1 batches\n16 Start Epoch 0\n24 Start Epoch 0\n16: 1 batches\n32: 1 batches\n40 Start Epoch 0\n4 Start Epoch 0\n15: 1 batches\n40: 1 batches\n7 Start Epoch 0\n23 Start Epoch 0\n24: 1 batches\n4: 1 batches\n23: 1 batches\n7: 1 batches\n36 Start Epoch 0\n36: 1 batches\n20 Start Epoch 0\n11 Start Epoch 0\n20: 1 batches\n35 Start Epoch 0\n5 Start Epoch 0\n19 Start Epoch 0\n35: 1 batches\n6 Start Epoch 0\n12 Start Epoch 0\n12: 1 batches\n11: 1 batches\n19: 1 batches\n6: 1 batches\n5: 1 batches\n9 Start Epoch 0\n10 Start Epoch 0\n9: 1 batches\n10: 1 batches\n17 Start Epoch 0\n18 Start Epoch 0\n34 Start Epoch 0\n17: 1 batches\n33 Start Epoch 0\n33: 1 batches\n18: 1 batches\n34: 1 batches\n28 Start Epoch 0\n28: 1 batches\n25 Start Epoch 0\n41 Start Epoch 0\n26 Start Epoch 0\n42 Start Epoch 0\n25: 1 batches\n26: 1 batches\n42: 1 batches\n41: 1 batches\n21 Start Epoch 0\n22 Start Epoch 0\n21: 1 batches\n22: 1 batches\n13 Start Epoch 0\n14 Start Epoch 0\n14: 1 batches\n13: 1 batches\n43 Start Epoch 0\n43: 1 batches\n27 Start Epoch 0\n27: 1 batches\n37 Start Epoch 0\n38 Start Epoch 0\n38: 1 batches\n37: 1 batches\n44 Start Epoch 0\n44: 1 batches\n29 Start Epoch 0\n30 Start Epoch 0\n29: 1 batches\n30: 1 batches\n45 Start Epoch 0\n46 Start Epoch 0\n46: 1 batches\n45: 1 batches\n3 Start Epoch 1\n3: 1 batches\n39 Start Epoch 1\n8 Start Epoch 1\n24 Start Epoch 1\n39: 1 batches\n8: 1 batches\n24: 1 batches\n19 Start Epoch 1\n6 Start Epoch 1\n12 Start Epoch 1\n29 Start Epoch 1\n4 Start Epoch 1\n15 Start Epoch 1\n38 Start Epoch 1\n47 Start Epoch 1\n19: 1 batches\n28 Start Epoch 1\n32 Start Epoch 1\n40 Start Epoch 1\n5 Start Epoch 1\n12: 1 batches\n38: 1 batches\n47: 1 batches\n21 Start Epoch 1\n25 Start Epoch 1\n18 Start Epoch 1\n4: 1 batches\n15: 1 batches\n46 Start Epoch 1\n11 Start Epoch 1\n22 Start Epoch 1\n22: 1 batches\n18: 1 batches\n30 Start Epoch 1\n32: 1 batches\n42 Start Epoch 1\n42: 1 batches\n6: 1 batches\n36 Start Epoch 1\n46: 1 batches\n10 Start Epoch 1\n20 Start Epoch 1\n27 Start Epoch 1\n30: 1 batches\n33 Start Epoch 1\n36: 1 batches\n10: 1 batches\n21: 1 batches\n25: 1 batches\n16 Start Epoch 1\n28: 1 batches\n33: 1 batches\n40: 1 batches\n7 Start Epoch 1\n14 Start Epoch 1\n7: 1 batches\n14: 1 batches\n23 Start Epoch 1\n27: 1 batches\n16: 1 batches\n31 Start Epoch 1\n45 Start Epoch 1\n9 Start Epoch 1\n23: 1 batches\n31: 1 batches\n35 Start Epoch 1\n43 Start Epoch 1\n5: 1 batches\n37 Start Epoch 1\n13 Start Epoch 1\n13: 1 batches\n37: 1 batches\n45: 1 batches\n9: 1 batches\n20: 1 batches\n26 Start Epoch 1\n17 Start Epoch 1\n29: 1 batches\n35: 1 batches\n43: 1 batches\n26: 1 batches\n17: 1 batches\n34 Start Epoch 1\n41 Start Epoch 1\n34: 1 batches\n41: 1 batches\n1 Start Epoch 1\n1: 1 batches\n2 Start Epoch 1\n2: 1 batches\n11: 1 batches\n44 Start Epoch 1\n44: 1 batches\n0 Start Epoch 1\n0: 1 batches\n34 Start Epoch 2\n39 Start Epoch 2\n38 Start Epoch 2\n35 Start Epoch 2\n35: 1 batches\n38: 1 batches\n1 Start Epoch 2\n1: 1 batches\n39: 1 batches\n30 Start Epoch 2\n29 Start Epoch 2\n34: 1 batches\n30: 1 batches\n41 Start Epoch 2\n31 Start Epoch 2\n40 Start Epoch 2\n40: 1 batches\n41: 1 batches\n27 Start Epoch 2\n31: 1 batches\n26 Start Epoch 2\n29: 1 batches\n27: 1 batches\n26: 1 batches\n28 Start Epoch 2\n28: 1 batches\n25 Start Epoch 2\n25: 1 batches\n24 Start Epoch 2\n24: 1 batches\n42 Start Epoch 2\n47 Start Epoch 2\n32 Start Epoch 2\n32: 1 batches\n42: 1 batches\n43 Start Epoch 2\n43: 1 batches\n37 Start Epoch 2\n36 Start Epoch 2\n45 Start Epoch 2\n33 Start Epoch 2\n37: 1 batches\n46 Start Epoch 2\n36: 1 batches\n2 Start Epoch 2\n2: 1 batches\n46: 1 batches\n33: 1 batches\n5 Start Epoch 2\n45: 1 batches\n19 Start Epoch 2\n6 Start Epoch 2\n6: 1 batches\n15 Start Epoch 2\n47: 1 batches\n4 Start Epoch 2\n4: 1 batches\n15: 1 batches\n9 Start Epoch 2\n19: 1 batches\n44 Start Epoch 2\n8 Start Epoch 2\n20 Start Epoch 2\n20: 1 batches\n7 Start Epoch 2\n9: 1 batches\n23 Start Epoch 2\n23: 1 batches\n18 Start Epoch 2\n7: 1 batches\n44: 1 batches\n8: 1 batches\n21 Start Epoch 2\n21: 1 batches\n5: 1 batches\n22 Start Epoch 2\n22: 1 batches\n11 Start Epoch 2\n10 Start Epoch 2\n11: 1 batches\n10: 1 batches\n3 Start Epoch 2\n3: 1 batches\n18: 1 batches\n17 Start Epoch 2\n17: 1 batches\n16 Start Epoch 2\n16: 1 batches\n14 Start Epoch 2\n12 Start Epoch 2\n14: 1 batches\n12: 1 batches\n13 Start Epoch 2\n13: 1 batches\n0 Start Epoch 2\n0: 1 batches\n14 Start Epoch 3\n15 Start Epoch 3\n5 Start Epoch 3\n6 Start Epoch 3\n6: 1 batches\n16 Start Epoch 3\n3 Start Epoch 3\n3: 1 batches\n4 Start Epoch 3\n12 Start Epoch 3\n12: 1 batches\n15: 1 batches\n38 Start Epoch 3\n47 Start Epoch 3\n31 Start Epoch 3\n31: 1 batches\n34 Start Epoch 3\n40 Start Epoch 3\n40: 1 batches\n7 Start Epoch 3\n32 Start Epoch 3\n41 Start Epoch 3\n7: 1 batches\n36 Start Epoch 3\n47: 1 batches\n9 Start Epoch 3\n35 Start Epoch 3\n41: 1 batches\n4: 1 batches\n13 Start Epoch 3\n13: 1 batches\n38: 1 batches\n46 Start Epoch 3\n10 Start Epoch 3\n34: 1 batches\n5: 1 batches\n36: 1 batches\n46: 1 batches\n10: 1 batches\n32: 1 batches\n14: 1 batches\n9: 1 batches\n39 Start Epoch 3\n11 Start Epoch 3\n24 Start Epoch 3\n19 Start Epoch 3\n33 Start Epoch 3\n42 Start Epoch 3\n39: 1 batches\n11: 1 batches\n25 Start Epoch 3\n17 Start Epoch 3\n29 Start Epoch 3\n33: 1 batches\n25: 1 batches\n19: 1 batches\n35: 1 batches\n42: 1 batches\n20 Start Epoch 3\n18 Start Epoch 3\n28 Start Epoch 3\n43 Start Epoch 3\n8 Start Epoch 3\n23 Start Epoch 3\n23: 1 batches\n18: 1 batches\n29: 1 batches\n43: 1 batches\n8: 1 batches\n21 Start Epoch 3\n21: 1 batches\n16: 1 batches\n28: 1 batches\n26 Start Epoch 3\n22 Start Epoch 3\n26: 1 batches\n30 Start Epoch 3\n22: 1 batches\n20: 1 batches\n30: 1 batches\n45 Start Epoch 3\n44 Start Epoch 3\n44: 1 batches\n27 Start Epoch 3\n27: 1 batches\n24: 1 batches\n2 Start Epoch 3\n2: 1 batches\n37 Start Epoch 3\n37: 1 batches\n45: 1 batches\n1 Start Epoch 3\n1: 1 batches\n17: 1 batches\n0 Start Epoch 3\n0: 1 batches\n7 Start Epoch 4\n12 Start Epoch 4\n47 Start Epoch 4\n7: 1 batches\n47: 1 batches\n14 Start Epoch 4\n14: 1 batches\n12: 1 batches\n2 Start Epoch 4\n2: 1 batches\n1 Start Epoch 4\n1: 1 batches\n11 Start Epoch 4\n21 Start Epoch 4\n25 Start Epoch 4\n29 Start Epoch 4\n35 Start Epoch 4\n5 Start Epoch 4\n38 Start Epoch 4\n11: 1 batches\n21: 1 batches\n25: 1 batches\n19 Start Epoch 4\n29: 1 batches\n5: 1 batches\n38: 1 batches\n45 Start Epoch 4\n23 Start Epoch 4\n19: 1 batches\n39 Start Epoch 4\n46 Start Epoch 4\n26 Start Epoch 4\n18 Start Epoch 4\n28 Start Epoch 4\n32 Start Epoch 4\n40 Start Epoch 4\n40: 1 batches\n46: 1 batches\n23: 1 batches\n26: 1 batches\n18: 1 batches\n33 Start Epoch 4\n43 Start Epoch 4\n39: 1 batches\n32: 1 batches\n42 Start Epoch 4\n42: 1 batches\n44 Start Epoch 4\n36 Start Epoch 4\n45: 1 batches\n20 Start Epoch 4\n24 Start Epoch 4\n28: 1 batches\n33: 1 batches\n41 Start Epoch 4\n24: 1 batches\n41: 1 batches\n36: 1 batches\n44: 1 batches\n10 Start Epoch 4\n22 Start Epoch 4\n34 Start Epoch 4\n43: 1 batches\n37 Start Epoch 4\n10: 1 batches\n22: 1 batches\n27 Start Epoch 4\n34: 1 batches\n20: 1 batches\n27: 1 batches\n35: 1 batches\n4 Start Epoch 4\n4: 1 batches\n37: 1 batches\n6 Start Epoch 4\n6: 1 batches\n8 Start Epoch 4\n9 Start Epoch 4\n9: 1 batches\n3 Start Epoch 4\n3: 1 batches\n8: 1 batches\n31 Start Epoch 4\n16 Start Epoch 4\n31: 1 batches\n17 Start Epoch 4\n16: 1 batches\n30 Start Epoch 4\n30: 1 batches\n17: 1 batches\n13 Start Epoch 4\n13: 1 batches\n15 Start Epoch 4\n15: 1 batches\n0 Start Epoch 4\n0: 1 batches\n45 Start Epoch 5\n37 Start Epoch 5\n37: 1 batches\n36 Start Epoch 5\n36: 1 batches\n45: 1 batches\n39 Start Epoch 5\n39: 1 batches\n1 Start Epoch 5\n1: 1 batches\n42 Start Epoch 5\n44 Start Epoch 5\n41 Start Epoch 5\n42: 1 batches\n46 Start Epoch 5\n33 Start Epoch 5\n40 Start Epoch 5\n46: 1 batches\n32 Start Epoch 5\n32: 1 batches\n40: 1 batches\n44: 1 batches\n35 Start Epoch 5\n35: 1 batches\n33: 1 batches\n34 Start Epoch 5\n34: 1 batches\n43 Start Epoch 5\n43: 1 batches\n41: 1 batches\n31 Start Epoch 5\n31: 1 batches\n47 Start Epoch 5\n47: 1 batches\n26 Start Epoch 5\n26: 1 batches\n18 Start Epoch 5\n22 Start Epoch 5\n18: 1 batches\n23 Start Epoch 5\n15 Start Epoch 5\n22: 1 batches\n19 Start Epoch 5\n23: 1 batches\n19: 1 batches\n14 Start Epoch 5\n21 Start Epoch 5\n21: 1 batches\n9 Start Epoch 5\n27 Start Epoch 5\n8 Start Epoch 5\n5 Start Epoch 5\n12 Start Epoch 5\n24 Start Epoch 5\n6 Start Epoch 5\n14: 1 batches\n9: 1 batches\n11 Start Epoch 5\n20 Start Epoch 5\n24: 1 batches\n6: 1 batches\n12: 1 batches\n11: 1 batches\n27: 1 batches\n5: 1 batches\n8: 1 batches\n7 Start Epoch 5\n15: 1 batches\n7: 1 batches\n3 Start Epoch 5\n3: 1 batches\n2 Start Epoch 5\n2: 1 batches\n20: 1 batches\n4 Start Epoch 5\n13 Start Epoch 5\n10 Start Epoch 5\n17 Start Epoch 5\n17: 1 batches\n4: 1 batches\n10: 1 batches\n38 Start Epoch 5\n38: 1 batches\n28 Start Epoch 5\n28: 1 batches\n29 Start Epoch 5\n29: 1 batches\n30 Start Epoch 5\n16 Start Epoch 5\n30: 1 batches\n25 Start Epoch 5\n25: 1 batches\n16: 1 batches\n13: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:5: Epoch 0 train loss: 4922.8583984375\nINFO:root:39: Epoch 0 train loss: 79506.2109375\nINFO:root:28: Epoch 0 train loss: 5301.16845703125\nINFO:root:3: Epoch 0 train loss: 18567.779296875\nINFO:root:6: Epoch 0 train loss: 12855.3349609375\nINFO:root:18: Epoch 0 train loss: 11944.427734375\nINFO:root:29: Epoch 0 train loss: 1994.8743896484375\nINFO:root:7: Epoch 0 train loss: 1340.751708984375\nINFO:root:15: Epoch 0 train loss: 10534.255859375\nINFO:root:8: Epoch 0 train loss: 5729.18505859375\nINFO:root:20: Epoch 0 train loss: 10900.9111328125\nINFO:root:24: Epoch 0 train loss: 2997.719970703125\nINFO:root:46: Epoch 0 train loss: 1782255.125\nINFO:root:0: Epoch 0 train loss: 355.2623291015625\nINFO:root:21: Epoch 0 train loss: 17884.513671875\nINFO:root:19: Epoch 0 train loss: 5978.65576171875\nINFO:root:30: Epoch 0 train loss: 974.921875\nINFO:root:4: Epoch 0 train loss: 4875.13427734375\nINFO:root:12: Epoch 0 train loss: 5756.7529296875\nINFO:root:22: Epoch 0 train loss: 17150.3046875\nINFO:root:31: Epoch 0 train loss: 25400.486328125\nINFO:root:1: Epoch 0 train loss: 17302.021484375\nINFO:root:32: Epoch 0 train loss: 978.5441284179688\nINFO:root:40: Epoch 0 train loss: 697.745361328125\nINFO:root:38: Epoch 0 train loss: 2487204.5\nINFO:root:47: Epoch 0 train loss: 8712.9150390625\nINFO:root:33: Epoch 0 train loss: 977.2520141601562\nINFO:root:42: Epoch 0 train loss: 2132899.25\nINFO:root:10: Epoch 0 train loss: 15946.61328125\nINFO:root:23: Epoch 0 train loss: 903.3662719726562\nINFO:root:25: Epoch 0 train loss: 6175.8994140625\nINFO:root:11: Epoch 0 train loss: 7786.75634765625\nINFO:root:36: Epoch 0 train loss: 6474.96630859375\nINFO:root:27: Epoch 0 train loss: 1788271.25\nINFO:root:14: Epoch 0 train loss: 10075.7041015625\nINFO:root:16: Epoch 0 train loss: 10491.091796875\nINFO:root:37: Epoch 0 train loss: 3432.6396484375\nINFO:root:45: Epoch 0 train loss: 709908.25\nINFO:root:9: Epoch 0 train loss: 6352.25927734375\nINFO:root:35: Epoch 0 train loss: 16236.2421875\nINFO:root:43: Epoch 0 train loss: 5889.4716796875\nINFO:root:26: Epoch 0 train loss: 910.0789184570312\nINFO:root:17: Epoch 0 train loss: 68275.859375\nINFO:root:13: Epoch 0 train loss: 9080.0751953125\nINFO:root:34: Epoch 0 train loss: 22808.0546875\nINFO:root:41: Epoch 0 train loss: 5909.4814453125\nINFO:root:2: Epoch 0 train loss: 4707719.5\nINFO:root:44: Epoch 0 train loss: 2008749.25\nINFO:root:0: Epoch 0 validation loss: 3981.2372843155254\nINFO:root:38: Epoch 1 train loss: 698964.875\nINFO:root:39: Epoch 1 train loss: 5635.57177734375\nINFO:root:34: Epoch 1 train loss: 8708.330078125\nINFO:root:35: Epoch 1 train loss: 2147297.25\nINFO:root:29: Epoch 1 train loss: 248163.21875\nINFO:root:30: Epoch 1 train loss: 456.5990295410156\nINFO:root:1: Epoch 1 train loss: 16134.1787109375\nINFO:root:31: Epoch 1 train loss: 25119.095703125\nINFO:root:41: Epoch 1 train loss: 13209.7392578125\nINFO:root:40: Epoch 1 train loss: 6008.505859375\nINFO:root:26: Epoch 1 train loss: 4181.50146484375\nINFO:root:27: Epoch 1 train loss: 20921.064453125\nINFO:root:28: Epoch 1 train loss: 365.275634765625\nINFO:root:25: Epoch 1 train loss: 4311.685546875\nINFO:root:24: Epoch 1 train loss: 2252141.75\nINFO:root:0: Epoch 1 train loss: 12125.2109375\nINFO:root:43: Epoch 1 train loss: 3143.8662109375\nINFO:root:42: Epoch 1 train loss: 2234981.75\nINFO:root:47: Epoch 1 train loss: 1404.1839599609375\nINFO:root:37: Epoch 1 train loss: 358.62908935546875\nINFO:root:32: Epoch 1 train loss: 10757.916015625\nINFO:root:36: Epoch 1 train loss: 472.2353515625\nINFO:root:45: Epoch 1 train loss: 700410.0\nINFO:root:33: Epoch 1 train loss: 14635.4931640625\nINFO:root:6: Epoch 1 train loss: 2194.7685546875\nINFO:root:46: Epoch 1 train loss: 10523.8271484375\nINFO:root:4: Epoch 1 train loss: 1573.2420654296875\nINFO:root:7: Epoch 1 train loss: 164.6582489013672\nINFO:root:5: Epoch 1 train loss: 3760.9697265625\nINFO:root:2: Epoch 1 train loss: 6129.39501953125\nINFO:root:9: Epoch 1 train loss: 5715.072265625\nINFO:root:20: Epoch 1 train loss: 2234874.25\nINFO:root:19: Epoch 1 train loss: 18608.81640625\nINFO:root:15: Epoch 1 train loss: 22578.111328125\nINFO:root:8: Epoch 1 train loss: 2283.2080078125\nINFO:root:23: Epoch 1 train loss: 11743.4072265625\nINFO:root:44: Epoch 1 train loss: 3611.64892578125\nINFO:root:21: Epoch 1 train loss: 27078.6875\nINFO:root:18: Epoch 1 train loss: 7926.07080078125\nINFO:root:10: Epoch 1 train loss: 3578.93603515625\nINFO:root:11: Epoch 1 train loss: 15129.173828125\nINFO:root:22: Epoch 1 train loss: 15610.1962890625\nINFO:root:3: Epoch 1 train loss: 20761.158203125\nINFO:root:14: Epoch 1 train loss: 8397.0673828125\nINFO:root:12: Epoch 1 train loss: 5564.39453125\nINFO:root:17: Epoch 1 train loss: 2886.541748046875\nINFO:root:16: Epoch 1 train loss: 435.7987976074219\nINFO:root:13: Epoch 1 train loss: 701.492919921875\nINFO:root:0: Epoch 1 validation loss: 3980.207450421182\nINFO:root:14: Epoch 2 train loss: 8138.85205078125\nINFO:root:15: Epoch 2 train loss: 1697161.125\nINFO:root:7: Epoch 2 train loss: 29404.1640625\nINFO:root:5: Epoch 2 train loss: 2477706.0\nINFO:root:6: Epoch 2 train loss: 6752.99462890625\nINFO:root:16: Epoch 2 train loss: 2048452.125\nINFO:root:34: Epoch 2 train loss: 1644.043701171875\nINFO:root:35: Epoch 2 train loss: 11968.3642578125\nINFO:root:41: Epoch 2 train loss: 38385.890625\nINFO:root:4: Epoch 2 train loss: 1678724.0\nINFO:root:3: Epoch 2 train loss: 13837.8212890625\nINFO:root:36: Epoch 2 train loss: 1893.0723876953125\nINFO:root:46: Epoch 2 train loss: 3912212.25\nINFO:root:9: Epoch 2 train loss: 2564.772216796875\nINFO:root:32: Epoch 2 train loss: 8067.73046875\nINFO:root:31: Epoch 2 train loss: 7981.5595703125\nINFO:root:33: Epoch 2 train loss: 530.136962890625\nINFO:root:40: Epoch 2 train loss: 3475.357666015625\nINFO:root:38: Epoch 2 train loss: 17257.880859375\nINFO:root:47: Epoch 2 train loss: 1777997.625\nINFO:root:10: Epoch 2 train loss: 10152.662109375\nINFO:root:11: Epoch 2 train loss: 768761.75\nINFO:root:13: Epoch 2 train loss: 42965.89453125\nINFO:root:18: Epoch 2 train loss: 1080.9271240234375\nINFO:root:12: Epoch 2 train loss: 133.7686309814453\nINFO:root:25: Epoch 2 train loss: 4168.57421875\nINFO:root:19: Epoch 2 train loss: 2239598.5\nINFO:root:17: Epoch 2 train loss: 9722.2529296875\nINFO:root:43: Epoch 2 train loss: 7949.73974609375\nINFO:root:39: Epoch 2 train loss: 700130.5625\nINFO:root:21: Epoch 2 train loss: 499.3179626464844\nINFO:root:24: Epoch 2 train loss: 2390.061279296875\nINFO:root:20: Epoch 2 train loss: 234743.4375\nINFO:root:29: Epoch 2 train loss: 8876.080078125\nINFO:root:42: Epoch 2 train loss: 5015.45556640625\nINFO:root:23: Epoch 2 train loss: 33322.76171875\nINFO:root:8: Epoch 2 train loss: 529.647705078125\nINFO:root:22: Epoch 2 train loss: 1649.3109130859375\nINFO:root:28: Epoch 2 train loss: 349.9013977050781\nINFO:root:26: Epoch 2 train loss: 4522.15576171875\nINFO:root:30: Epoch 2 train loss: 2202.130615234375\nINFO:root:44: Epoch 2 train loss: 2078.911376953125\nINFO:root:45: Epoch 2 train loss: 436.1138916015625\nINFO:root:27: Epoch 2 train loss: 5408.57568359375\nINFO:root:2: Epoch 2 train loss: 3204.321044921875\nINFO:root:0: Epoch 2 train loss: 12222.173828125\nINFO:root:37: Epoch 2 train loss: 50.891849517822266\nINFO:root:1: Epoch 2 train loss: 1678971.875\nINFO:root:0: Epoch 2 validation loss: 3979.202096877357\nINFO:root:7: Epoch 3 train loss: 3284.144287109375\nINFO:root:14: Epoch 3 train loss: 151.0367431640625\nINFO:root:12: Epoch 3 train loss: 5402.90478515625\nINFO:root:47: Epoch 3 train loss: 1708789.75\nINFO:root:2: Epoch 3 train loss: 7601.12548828125\nINFO:root:1: Epoch 3 train loss: 303.67913818359375\nINFO:root:41: Epoch 3 train loss: 11662.8564453125\nINFO:root:5: Epoch 3 train loss: 5580.373046875\nINFO:root:38: Epoch 3 train loss: 2069473.125\nINFO:root:45: Epoch 3 train loss: 384.7352600097656\nINFO:root:11: Epoch 3 train loss: 25298.173828125\nINFO:root:21: Epoch 3 train loss: 26833.396484375\nINFO:root:25: Epoch 3 train loss: 699609.25\nINFO:root:18: Epoch 3 train loss: 1348.462158203125\nINFO:root:29: Epoch 3 train loss: 38893.00390625\nINFO:root:35: Epoch 3 train loss: 1021.1290283203125\nINFO:root:19: Epoch 3 train loss: 13978.2841796875\nINFO:root:42: Epoch 3 train loss: 24971.1796875\nINFO:root:46: Epoch 3 train loss: 70662.2734375\nINFO:root:44: Epoch 3 train loss: 3512.2353515625\nINFO:root:33: Epoch 3 train loss: 13159.0927734375\nINFO:root:43: Epoch 3 train loss: 17851.50390625\nINFO:root:40: Epoch 3 train loss: 35428.8984375\nINFO:root:39: Epoch 3 train loss: 863.326904296875\nINFO:root:26: Epoch 3 train loss: 11576.8759765625\nINFO:root:28: Epoch 3 train loss: 629.4054565429688\nINFO:root:32: Epoch 3 train loss: 8844.0986328125\nINFO:root:23: Epoch 3 train loss: 2240266.25\nINFO:root:36: Epoch 3 train loss: 2123.0546875\nINFO:root:20: Epoch 3 train loss: 54804.015625\nINFO:root:24: Epoch 3 train loss: 68364.0390625\nINFO:root:10: Epoch 3 train loss: 42681.6796875\nINFO:root:22: Epoch 3 train loss: 10495.58203125\nINFO:root:34: Epoch 3 train loss: 5203.88720703125\nINFO:root:27: Epoch 3 train loss: 48478.171875\nINFO:root:37: Epoch 3 train loss: 60617.76953125\nINFO:root:8: Epoch 3 train loss: 51811.5859375\nINFO:root:9: Epoch 3 train loss: 26214.55078125\nINFO:root:4: Epoch 3 train loss: 7773.84326171875\nINFO:root:6: Epoch 3 train loss: 4687.85009765625\nINFO:root:3: Epoch 3 train loss: 3757.88818359375\nINFO:root:0: Epoch 3 train loss: 5265.8232421875\nINFO:root:16: Epoch 3 train loss: 7611.86279296875\nINFO:root:31: Epoch 3 train loss: 9271.3486328125\nINFO:root:17: Epoch 3 train loss: 710434.8125\nINFO:root:30: Epoch 3 train loss: 7649.6572265625\nINFO:root:13: Epoch 3 train loss: 7055.50537109375\nINFO:root:15: Epoch 3 train loss: 9576.427734375\nINFO:root:0: Epoch 3 validation loss: 3978.171856072437\nINFO:root:45: Epoch 4 train loss: 52029.6328125\nINFO:root:40: Epoch 4 train loss: 39968.5\nINFO:root:41: Epoch 4 train loss: 2047.5203857421875\nINFO:root:37: Epoch 4 train loss: 5134.28271484375\nINFO:root:36: Epoch 4 train loss: 10036.5693359375\nINFO:root:39: Epoch 4 train loss: 701.9140014648438\nINFO:root:1: Epoch 4 train loss: 1986365.5\nINFO:root:44: Epoch 4 train loss: 53151.44921875\nINFO:root:35: Epoch 4 train loss: 14718.4375\nINFO:root:42: Epoch 4 train loss: 1768.4644775390625\nINFO:root:33: Epoch 4 train loss: 2841370.0\nINFO:root:34: Epoch 4 train loss: 1312.5145263671875\nINFO:root:46: Epoch 4 train loss: 36736.38671875\nINFO:root:32: Epoch 4 train loss: 2417.700439453125\nINFO:root:0: Epoch 4 train loss: 29564.7265625\nINFO:root:43: Epoch 4 train loss: 1702262.875\nINFO:root:31: Epoch 4 train loss: 751023.125\nINFO:root:47: Epoch 4 train loss: 356.85589599609375\nINFO:root:26: Epoch 4 train loss: 2281.937744140625\nINFO:root:19: Epoch 4 train loss: 13662.912109375\nINFO:root:22: Epoch 4 train loss: 1793237.0\nINFO:root:23: Epoch 4 train loss: 816.9849243164062\nINFO:root:18: Epoch 4 train loss: 935.21142578125\nINFO:root:15: Epoch 4 train loss: 34791.66015625\nINFO:root:11: Epoch 4 train loss: 4196.00927734375\nINFO:root:8: Epoch 4 train loss: 8442.6220703125\nINFO:root:21: Epoch 4 train loss: 267.18963623046875\nINFO:root:5: Epoch 4 train loss: 4026.651123046875\nINFO:root:27: Epoch 4 train loss: 1777910.75\nINFO:root:7: Epoch 4 train loss: 2253113.5\nINFO:root:14: Epoch 4 train loss: 9005.486328125\nINFO:root:9: Epoch 4 train loss: 231594.796875\nINFO:root:6: Epoch 4 train loss: 5387.23974609375\nINFO:root:24: Epoch 4 train loss: 89.40253448486328\nINFO:root:20: Epoch 4 train loss: 26876.900390625\nINFO:root:12: Epoch 4 train loss: 7875.3017578125\nINFO:root:3: Epoch 4 train loss: 57337.24609375\nINFO:root:2: Epoch 4 train loss: 595.3650512695312\nINFO:root:10: Epoch 4 train loss: 4151.31005859375\nINFO:root:17: Epoch 4 train loss: 386.0994873046875\nINFO:root:4: Epoch 4 train loss: 7584.78515625\nINFO:root:13: Epoch 4 train loss: 260.57476806640625\nINFO:root:38: Epoch 4 train loss: 152.52621459960938\nINFO:root:28: Epoch 4 train loss: 13521.9404296875\nINFO:root:29: Epoch 4 train loss: 1137.8502197265625\nINFO:root:30: Epoch 4 train loss: 5929.97021484375\nINFO:root:16: Epoch 4 train loss: 4940.61083984375\nINFO:root:25: Epoch 4 train loss: 42026.453125\nINFO:root:0: Epoch 4 validation loss: 3977.141337327822\nINFO:root:5: Epoch 5 train loss: 1684787.5\nINFO:root:2: Epoch 5 train loss: 29419.833984375\nINFO:root:1: Epoch 5 train loss: 3965.798095703125\nINFO:root:0: Epoch 5 train loss: 2363860.25\nINFO:root:3: Epoch 5 train loss: 98.22416687011719\nINFO:root:46: Epoch 5 train loss: 3193.897705078125\nINFO:root:30: Epoch 5 train loss: 23467.12109375\nINFO:root:35: Epoch 5 train loss: 405.4534606933594\nINFO:root:43: Epoch 5 train loss: 10389.529296875\nINFO:root:7: Epoch 5 train loss: 2235643.75\nINFO:root:12: Epoch 5 train loss: 2235770.0\nINFO:root:31: Epoch 5 train loss: 10127.63671875\nINFO:root:33: Epoch 5 train loss: 775.0135498046875\nINFO:root:40: Epoch 5 train loss: 1605.6807861328125\nINFO:root:6: Epoch 5 train loss: 32657.060546875\nINFO:root:13: Epoch 5 train loss: 65481.03125\nINFO:root:47: Epoch 5 train loss: 3331.554931640625\nINFO:root:27: Epoch 5 train loss: 14532.3583984375\nINFO:root:44: Epoch 5 train loss: 13365.1044921875\nINFO:root:24: Epoch 5 train loss: 242779.265625\nINFO:root:34: Epoch 5 train loss: 28664.318359375\nINFO:root:41: Epoch 5 train loss: 993.9007568359375\nINFO:root:45: Epoch 5 train loss: 1811873.0\nINFO:root:32: Epoch 5 train loss: 1796.7227783203125\nINFO:root:25: Epoch 5 train loss: 1680954.5\nINFO:root:26: Epoch 5 train loss: 6055.89208984375\nINFO:root:8: Epoch 5 train loss: 779.2405395507812\nINFO:root:9: Epoch 5 train loss: 9926.68359375\nINFO:root:42: Epoch 5 train loss: 1464.25830078125\nINFO:root:10: Epoch 5 train loss: 1428.302978515625\nINFO:root:38: Epoch 5 train loss: 10156.5283203125\nINFO:root:37: Epoch 5 train loss: 2143900.5\nINFO:root:36: Epoch 5 train loss: 717609.3125\nINFO:root:39: Epoch 5 train loss: 38779.48828125\nINFO:root:23: Epoch 5 train loss: 2540.095703125\nINFO:root:19: Epoch 5 train loss: 3910.070068359375\nINFO:root:17: Epoch 5 train loss: 2010617.75\nINFO:root:20: Epoch 5 train loss: 483.0137939453125\nINFO:root:15: Epoch 5 train loss: 770.3939208984375\nINFO:root:22: Epoch 5 train loss: 1784460.5\nINFO:root:18: Epoch 5 train loss: 9018.30078125\nINFO:root:14: Epoch 5 train loss: 3200.906982421875\nINFO:root:21: Epoch 5 train loss: 9822.5166015625\nINFO:root:4: Epoch 5 train loss: 1779392.0\nINFO:root:29: Epoch 5 train loss: 53683.33203125\nINFO:root:28: Epoch 5 train loss: 51877.44921875\nINFO:root:11: Epoch 5 train loss: 305.4358825683594\nINFO:root:16: Epoch 5 train loss: 683.0631103515625\nINFO:root:0: Epoch 5 validation loss: 3976.1220286129974\n", "seconds": 11.912553310394287, "batch_size": 64, "nodes": 12, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 24 batches\n0 Start Epoch 1\n0: 24 batches\n0 Start Epoch 2\n0: 24 batches\n0 Start Epoch 3\n0: 24 batches\n0 Start Epoch 4\n0: 24 batches\n0 Start Epoch 5\n0: 24 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 159823.19437026978\nINFO:root:0: Epoch 0 validation loss: 36006.685428242294\nINFO:root:0: Epoch 1 train loss: 159932.43202463785\nINFO:root:0: Epoch 1 validation loss: 35892.558925669255\nINFO:root:0: Epoch 2 train loss: 159835.1039943695\nINFO:root:0: Epoch 2 validation loss: 35723.27428958822\nINFO:root:0: Epoch 3 train loss: 159816.56242879233\nINFO:root:0: Epoch 3 validation loss: 35563.16972117178\nINFO:root:0: Epoch 4 train loss: 159862.93702697754\nINFO:root:0: Epoch 4 validation loss: 35444.993626430114\nINFO:root:0: Epoch 5 train loss: 159772.69209774336\nINFO:root:0: Epoch 5 validation loss: 35348.11249776544\n", "seconds": 8.536552906036377, "batch_size": 128, "nodes": 1, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 12 batches\n1 Start Epoch 0\n1: 12 batches\n1 Start Epoch 1\n1: 12 batches\n0 Start Epoch 1\n0: 12 batches\n1 Start Epoch 2\n1: 12 batches\n0 Start Epoch 2\n0: 12 batches\n1 Start Epoch 3\n1: 12 batches\n0 Start Epoch 3\n0: 12 batches\n1 Start Epoch 4\n1: 12 batches\n0 Start Epoch 4\n0: 12 batches\n1 Start Epoch 5\n1: 12 batches\n0 Start Epoch 5\n0: 12 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 209333.05071004233\nINFO:root:1: Epoch 0 train loss: 103168.35725911458\nINFO:root:0: Epoch 0 validation loss: 17187.007043022277\nINFO:root:0: Epoch 1 train loss: 144480.07219441733\nINFO:root:1: Epoch 1 train loss: 185669.8769276937\nINFO:root:0: Epoch 1 validation loss: 17159.270829667304\nINFO:root:0: Epoch 2 train loss: 188963.71136983237\nINFO:root:1: Epoch 2 train loss: 165262.2611287435\nINFO:root:0: Epoch 2 validation loss: 17117.24447875459\nINFO:root:0: Epoch 3 train loss: 52857.17130533854\nINFO:root:1: Epoch 3 train loss: 170790.26436742148\nINFO:root:0: Epoch 3 validation loss: 17062.19336611238\nINFO:root:0: Epoch 4 train loss: 164776.79971313477\nINFO:root:1: Epoch 4 train loss: 217109.79450480142\nINFO:root:0: Epoch 4 validation loss: 17005.011916927222\nINFO:root:0: Epoch 5 train loss: 259160.80407714844\nINFO:root:1: Epoch 5 train loss: 118869.74338022868\nINFO:root:0: Epoch 5 validation loss: 16945.654351490324\n", "seconds": 5.709661960601807, "batch_size": 128, "nodes": 2, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 8 batches\n2 Start Epoch 0\n1 Start Epoch 0\n2: 8 batches\n1: 8 batches\n2 Start Epoch 1\n2: 8 batches\n1 Start Epoch 1\n1: 8 batches\n0 Start Epoch 1\n0: 8 batches\n2 Start Epoch 2\n2: 8 batches\n1 Start Epoch 2\n1: 8 batches\n0 Start Epoch 2\n0: 8 batches\n2 Start Epoch 3\n1 Start Epoch 3\n2: 8 batches\n1: 8 batches\n0 Start Epoch 3\n0: 8 batches\n1 Start Epoch 4\n2 Start Epoch 4\n1: 8 batches\n2: 8 batches\n0 Start Epoch 4\n0: 8 batches\n2 Start Epoch 5\n1 Start Epoch 5\n2: 8 batches\n1: 8 batches\n0 Start Epoch 5\n0: 8 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:2: Epoch 0 train loss: 211212.58782958984\nINFO:root:1: Epoch 0 train loss: 280848.2610168457\nINFO:root:0: Epoch 0 train loss: 260775.908203125\nINFO:root:0: Epoch 0 validation loss: 158585.52430516755\nINFO:root:2: Epoch 1 train loss: 200937.79864501953\nINFO:root:1: Epoch 1 train loss: 147968.33576965332\nINFO:root:0: Epoch 1 train loss: 317248.444770813\nINFO:root:0: Epoch 1 validation loss: 158552.38131951386\nINFO:root:0: Epoch 2 train loss: 292613.544380188\nINFO:root:2: Epoch 2 train loss: 205800.1527709961\nINFO:root:1: Epoch 2 train loss: 67951.02806091309\nINFO:root:0: Epoch 2 validation loss: 158506.92766866827\nINFO:root:0: Epoch 3 train loss: 151569.6979446411\nINFO:root:1: Epoch 3 train loss: 171205.80291748047\nINFO:root:2: Epoch 3 train loss: 180585.8869934082\nINFO:root:0: Epoch 3 validation loss: 158443.27822214417\nINFO:root:0: Epoch 4 train loss: 352171.5475769043\nINFO:root:1: Epoch 4 train loss: 81834.47937011719\nINFO:root:2: Epoch 4 train loss: 218641.87620544434\nINFO:root:0: Epoch 4 validation loss: 158349.9422261643\nINFO:root:0: Epoch 5 train loss: 81479.56884765625\nINFO:root:2: Epoch 5 train loss: 134149.48302459717\nINFO:root:1: Epoch 5 train loss: 130339.3012084961\nINFO:root:0: Epoch 5 validation loss: 158238.2359833512\n", "seconds": 12.274183988571167, "batch_size": 128, "nodes": 3, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 6 batches\n3 Start Epoch 0\n3: 6 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 6 batches\n2: 6 batches\n1 Start Epoch 1\n1: 6 batches\n3 Start Epoch 1\n2 Start Epoch 1\n2: 6 batches\n3: 6 batches\n0 Start Epoch 1\n0: 6 batches\n1 Start Epoch 2\n1: 6 batches\n3 Start Epoch 2\n3: 6 batches\n2 Start Epoch 2\n2: 6 batches\n0 Start Epoch 2\n0: 6 batches\n3 Start Epoch 3\n1 Start Epoch 3\n3: 6 batches\n1: 6 batches\n2 Start Epoch 3\n2: 6 batches\n0 Start Epoch 3\n0: 6 batches\n3 Start Epoch 4\n3: 6 batches\n1 Start Epoch 4\n1: 6 batches\n2 Start Epoch 4\n2: 6 batches\n0 Start Epoch 4\n0: 6 batches\n1 Start Epoch 5\n2 Start Epoch 5\n3 Start Epoch 5\n2: 6 batches\n3: 6 batches\n1: 6 batches\n0 Start Epoch 5\n0: 6 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:1: Epoch 0 train loss: 221859.72884114584\nINFO:root:2: Epoch 0 train loss: 346925.5616607666\nINFO:root:3: Epoch 0 train loss: 112900.00416056316\nINFO:root:0: Epoch 0 train loss: 98371.0721842448\nINFO:root:0: Epoch 0 validation loss: 12608.816089537444\nINFO:root:1: Epoch 1 train loss: 75246.302734375\nINFO:root:3: Epoch 1 train loss: 158521.4194539388\nINFO:root:2: Epoch 1 train loss: 118467.71097819011\nINFO:root:0: Epoch 1 train loss: 110315.14676920573\nINFO:root:0: Epoch 1 validation loss: 12598.829970466422\nINFO:root:1: Epoch 2 train loss: 31287.261688232422\nINFO:root:3: Epoch 2 train loss: 95564.45684814453\nINFO:root:0: Epoch 2 train loss: 114658.57338460286\nINFO:root:2: Epoch 2 train loss: 15147.180592854818\nINFO:root:0: Epoch 2 validation loss: 12586.6904330621\nINFO:root:0: Epoch 3 train loss: 89818.65946451823\nINFO:root:3: Epoch 3 train loss: 102582.13080851237\nINFO:root:1: Epoch 3 train loss: 174582.3536783854\nINFO:root:2: Epoch 3 train loss: 133967.3663736979\nINFO:root:0: Epoch 3 validation loss: 12570.602899313744\nINFO:root:0: Epoch 4 train loss: 199852.92293294272\nINFO:root:3: Epoch 4 train loss: 228325.2277018229\nINFO:root:1: Epoch 4 train loss: 195475.15193684897\nINFO:root:2: Epoch 4 train loss: 278573.4929707845\nINFO:root:0: Epoch 4 validation loss: 12548.755528305068\nINFO:root:2: Epoch 5 train loss: 89768.54276529948\nINFO:root:1: Epoch 5 train loss: 39869.671447753906\nINFO:root:0: Epoch 5 train loss: 115641.81526692708\nINFO:root:3: Epoch 5 train loss: 294830.7498982747\nINFO:root:0: Epoch 5 validation loss: 12521.37943251317\n", "seconds": 9.547313213348389, "batch_size": 128, "nodes": 4, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 5 batches\n1 Start Epoch 0\n2 Start Epoch 0\n2: 5 batches\n1: 5 batches\n4 Start Epoch 0\n4: 5 batches\n3 Start Epoch 0\n3: 5 batches\n3 Start Epoch 1\n3: 5 batches\n4 Start Epoch 1\n4: 5 batches\n1 Start Epoch 1\n1: 5 batches\n2 Start Epoch 1\n2: 5 batches\n0 Start Epoch 1\n0: 5 batches\n3 Start Epoch 2\n1 Start Epoch 2\n1: 5 batches\n3: 5 batches\n4 Start Epoch 2\n2 Start Epoch 2\n2: 5 batches\n4: 5 batches\n0 Start Epoch 2\n0: 5 batches\n2 Start Epoch 3\n3 Start Epoch 3\n1 Start Epoch 3\n2: 5 batches\n3: 5 batches\n1: 5 batches\n4 Start Epoch 3\n4: 5 batches\n0 Start Epoch 3\n0: 5 batches\n2 Start Epoch 4\n2: 5 batches\n4 Start Epoch 4\n4: 5 batches\n1 Start Epoch 4\n1: 5 batches\n3 Start Epoch 4\n3: 5 batches\n0 Start Epoch 4\n0: 5 batches\n2 Start Epoch 5\n2: 5 batches\n4 Start Epoch 5\n4: 5 batches\n3 Start Epoch 5\n3: 5 batches\n1 Start Epoch 5\n1: 5 batches\n0 Start Epoch 5\n0: 5 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:3: Epoch 0 train loss: 10537.1556640625\nINFO:root:0: Epoch 0 train loss: 39796.624194335935\nINFO:root:4: Epoch 0 train loss: 217939.98359375\nINFO:root:2: Epoch 0 train loss: 2724.3699462890627\nINFO:root:1: Epoch 0 train loss: 185256.9764465332\nINFO:root:0: Epoch 0 validation loss: 94153.66629246034\nINFO:root:3: Epoch 1 train loss: 235927.32133789064\nINFO:root:0: Epoch 1 train loss: 5771.46484375\nINFO:root:4: Epoch 1 train loss: 145190.83633422852\nINFO:root:2: Epoch 1 train loss: 245300.22087402345\nINFO:root:1: Epoch 1 train loss: 15121.416577148437\nINFO:root:0: Epoch 1 validation loss: 94135.5741091287\nINFO:root:0: Epoch 2 train loss: 50156.82314453125\nINFO:root:2: Epoch 2 train loss: 104245.00286865234\nINFO:root:3: Epoch 2 train loss: 93782.52978515625\nINFO:root:1: Epoch 2 train loss: 229629.34184570314\nINFO:root:4: Epoch 2 train loss: 110387.53479003906\nINFO:root:0: Epoch 2 validation loss: 94115.30130538422\nINFO:root:0: Epoch 3 train loss: 415567.8728027344\nINFO:root:2: Epoch 3 train loss: 124399.04918823243\nINFO:root:4: Epoch 3 train loss: 506888.934765625\nINFO:root:1: Epoch 3 train loss: 93387.59741210938\nINFO:root:3: Epoch 3 train loss: 145806.45357666016\nINFO:root:0: Epoch 3 validation loss: 94091.74142009507\nINFO:root:0: Epoch 4 train loss: 4329.529553222656\nINFO:root:2: Epoch 4 train loss: 222212.6642578125\nINFO:root:4: Epoch 4 train loss: 264275.72799072263\nINFO:root:3: Epoch 4 train loss: 137585.0479614258\nINFO:root:1: Epoch 4 train loss: 288290.1484680176\nINFO:root:0: Epoch 4 validation loss: 94062.92619251074\nINFO:root:2: Epoch 5 train loss: 102526.91856994628\nINFO:root:4: Epoch 5 train loss: 108779.59871826172\nINFO:root:3: Epoch 5 train loss: 3807.8685791015623\nINFO:root:1: Epoch 5 train loss: 429695.8062011719\nINFO:root:0: Epoch 5 train loss: 115460.75534667968\nINFO:root:0: Epoch 5 validation loss: 94026.48760305396\n", "seconds": 9.038747787475586, "batch_size": 128, "nodes": 5, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "4 Start Epoch 0\n4: 4 batches\n0 Start Epoch 0\n0: 4 batches\n5 Start Epoch 0\n1 Start Epoch 0\n3 Start Epoch 0\n2 Start Epoch 0\n1: 4 batches\n3: 4 batches\n5: 4 batches\n2: 4 batches\n2 Start Epoch 1\n2: 4 batches\n4 Start Epoch 1\n4: 4 batches\n3 Start Epoch 1\n3: 4 batches\n1 Start Epoch 1\n1: 4 batches\n5 Start Epoch 1\n5: 4 batches\n0 Start Epoch 1\n0: 4 batches\n1 Start Epoch 2\n1: 4 batches\n2 Start Epoch 2\n2: 4 batches\n5 Start Epoch 2\n5: 4 batches\n4 Start Epoch 2\n4: 4 batches\n3 Start Epoch 2\n3: 4 batches\n0 Start Epoch 2\n0: 4 batches\n2 Start Epoch 3\n2: 4 batches\n5 Start Epoch 3\n1 Start Epoch 3\n5: 4 batches\n1: 4 batches\n4 Start Epoch 3\n4: 4 batches\n3 Start Epoch 3\n3: 4 batches\n0 Start Epoch 3\n0: 4 batches\n1 Start Epoch 4\n1: 4 batches\n2 Start Epoch 4\n2: 4 batches\n4 Start Epoch 4\n4: 4 batches\n3 Start Epoch 4\n3: 4 batches\n5 Start Epoch 4\n5: 4 batches\n0 Start Epoch 4\n0: 4 batches\n1 Start Epoch 5\n2 Start Epoch 5\n5 Start Epoch 5\n1: 4 batches\n5: 4 batches\n2: 4 batches\n4 Start Epoch 5\n4: 4 batches\n3 Start Epoch 5\n3: 4 batches\n0 Start Epoch 5\n0: 4 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 524308.8613586426\nINFO:root:2: Epoch 0 train loss: 143229.49501800537\nINFO:root:4: Epoch 0 train loss: 417464.4362792969\nINFO:root:3: Epoch 0 train loss: 19386.638671875\nINFO:root:1: Epoch 0 train loss: 155018.8617553711\nINFO:root:5: Epoch 0 train loss: 47084.6178855896\nINFO:root:0: Epoch 0 validation loss: 38359.513476312415\nINFO:root:0: Epoch 1 train loss: 4453.432464599609\nINFO:root:1: Epoch 1 train loss: 4939.526794433594\nINFO:root:2: Epoch 1 train loss: 273824.8284301758\nINFO:root:5: Epoch 1 train loss: 5842.674133300781\nINFO:root:4: Epoch 1 train loss: 3210.8839569091797\nINFO:root:3: Epoch 1 train loss: 142567.84009552002\nINFO:root:0: Epoch 1 validation loss: 38347.76105472195\nINFO:root:2: Epoch 2 train loss: 127875.25073242188\nINFO:root:0: Epoch 2 train loss: 119096.01156616211\nINFO:root:5: Epoch 2 train loss: 104151.94708251953\nINFO:root:1: Epoch 2 train loss: 8810.952026367188\nINFO:root:4: Epoch 2 train loss: 267963.3486328125\nINFO:root:3: Epoch 2 train loss: 129345.23498535156\nINFO:root:0: Epoch 2 validation loss: 38333.93226785315\nINFO:root:1: Epoch 3 train loss: 237436.1328125\nINFO:root:2: Epoch 3 train loss: 48622.83393859863\nINFO:root:0: Epoch 3 train loss: 265991.3984069824\nINFO:root:4: Epoch 3 train loss: 9739.936737060547\nINFO:root:3: Epoch 3 train loss: 177928.48361206055\nINFO:root:5: Epoch 3 train loss: 303458.78369140625\nINFO:root:0: Epoch 3 validation loss: 38316.65355880661\nINFO:root:0: Epoch 4 train loss: 154639.10208129883\nINFO:root:5: Epoch 4 train loss: 129225.1396484375\nINFO:root:1: Epoch 4 train loss: 262814.8369140625\nINFO:root:2: Epoch 4 train loss: 400228.9460449219\nINFO:root:4: Epoch 4 train loss: 131094.4861755371\nINFO:root:3: Epoch 4 train loss: 416658.0595703125\nINFO:root:0: Epoch 4 validation loss: 38295.03320340504\nINFO:root:0: Epoch 5 train loss: 6735.930084228516\nINFO:root:4: Epoch 5 train loss: 11179.237915039062\nINFO:root:5: Epoch 5 train loss: 6787.321884155273\nINFO:root:1: Epoch 5 train loss: 3619.3443603515625\nINFO:root:3: Epoch 5 train loss: 7460.337951660156\nINFO:root:2: Epoch 5 train loss: 6128.45263671875\nINFO:root:0: Epoch 5 validation loss: 38267.5979002858\n", "seconds": 12.966764211654663, "batch_size": 128, "nodes": 6, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 4 batches\n5 Start Epoch 0\n5: 4 batches\n2 Start Epoch 0\n2: 4 batches\n1 Start Epoch 0\n3 Start Epoch 0\n4 Start Epoch 0\n6 Start Epoch 0\n4: 4 batches\n6: 4 batches\n1: 4 batches\n3: 4 batches\n3 Start Epoch 1\n3: 4 batches\n1 Start Epoch 1\n1: 4 batches\n2 Start Epoch 1\n4 Start Epoch 1\n6 Start Epoch 1\n4: 4 batches\n6: 4 batches\n2: 4 batches\n5 Start Epoch 1\n5: 4 batches\n0 Start Epoch 1\n0: 4 batches\n1 Start Epoch 2\n1: 4 batches\n3 Start Epoch 2\n3: 4 batches\n2 Start Epoch 2\n2: 4 batches\n4 Start Epoch 2\n4: 4 batches\n6 Start Epoch 2\n6: 4 batches\n5 Start Epoch 2\n5: 4 batches\n0 Start Epoch 2\n0: 4 batches\n1 Start Epoch 3\n3 Start Epoch 3\n1: 4 batches\n3: 4 batches\n4 Start Epoch 3\n4: 4 batches\n6 Start Epoch 3\n2 Start Epoch 3\n2: 4 batches\n6: 4 batches\n5 Start Epoch 3\n5: 4 batches\n0 Start Epoch 3\n0: 4 batches\n2 Start Epoch 4\n1 Start Epoch 4\n2: 4 batches\n1: 4 batches\n4 Start Epoch 4\n6 Start Epoch 4\n6: 4 batches\n4: 4 batches\n5 Start Epoch 4\n5: 4 batches\n3 Start Epoch 4\n3: 4 batches\n0 Start Epoch 4\n0: 4 batches\n4 Start Epoch 5\n6 Start Epoch 5\n2 Start Epoch 5\n1 Start Epoch 5\n2: 4 batches\n1: 4 batches\n4: 4 batches\n6: 4 batches\n3 Start Epoch 5\n3: 4 batches\n5 Start Epoch 5\n5: 4 batches\n0 Start Epoch 5\n0: 4 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:3: Epoch 0 train loss: 6550.912155151367\nINFO:root:1: Epoch 0 train loss: 451057.6892089844\nINFO:root:0: Epoch 0 train loss: 121858.62176513672\nINFO:root:2: Epoch 0 train loss: 326714.9633178711\nINFO:root:4: Epoch 0 train loss: 13463.230377197266\nINFO:root:6: Epoch 0 train loss: 131533.43822956085\nINFO:root:5: Epoch 0 train loss: 268823.36056518555\nINFO:root:0: Epoch 0 validation loss: 1379090.7887482666\nINFO:root:1: Epoch 1 train loss: 168144.0274963379\nINFO:root:0: Epoch 1 train loss: 127224.88348388672\nINFO:root:3: Epoch 1 train loss: 48076.71130371094\nINFO:root:2: Epoch 1 train loss: 285401.48527526855\nINFO:root:4: Epoch 1 train loss: 3991.9154357910156\nINFO:root:6: Epoch 1 train loss: 252880.23041057587\nINFO:root:5: Epoch 1 train loss: 400625.88751220703\nINFO:root:0: Epoch 1 validation loss: 1379055.0900691787\nINFO:root:1: Epoch 2 train loss: 47470.407653808594\nINFO:root:3: Epoch 2 train loss: 389226.16497802734\nINFO:root:4: Epoch 2 train loss: 52044.512939453125\nINFO:root:2: Epoch 2 train loss: 241077.52880859375\nINFO:root:6: Epoch 2 train loss: 140317.31127929688\nINFO:root:5: Epoch 2 train loss: 7576.412750244141\nINFO:root:0: Epoch 2 train loss: 52624.04717254639\nINFO:root:0: Epoch 2 validation loss: 1379014.842402814\nINFO:root:2: Epoch 3 train loss: 260919.2114868164\nINFO:root:1: Epoch 3 train loss: 250277.1675415039\nINFO:root:4: Epoch 3 train loss: 28885.370307922363\nINFO:root:6: Epoch 3 train loss: 124239.70534992218\nINFO:root:5: Epoch 3 train loss: 142551.57771492004\nINFO:root:3: Epoch 3 train loss: 254025.59447479248\nINFO:root:0: Epoch 3 train loss: 17832.22846221924\nINFO:root:0: Epoch 3 validation loss: 1378969.4997494277\nINFO:root:0: Epoch 4 train loss: 6750.330429077148\nINFO:root:2: Epoch 4 train loss: 519949.6828613281\nINFO:root:1: Epoch 4 train loss: 238349.85711669922\nINFO:root:4: Epoch 4 train loss: 1387.2082748413086\nINFO:root:6: Epoch 4 train loss: 147570.63146972656\nINFO:root:3: Epoch 4 train loss: 111608.41253471375\nINFO:root:5: Epoch 4 train loss: 236953.9535522461\nINFO:root:0: Epoch 4 validation loss: 1378915.6575405246\nINFO:root:1: Epoch 5 train loss: 130976.24603271484\nINFO:root:0: Epoch 5 train loss: 6213.8541259765625\nINFO:root:2: Epoch 5 train loss: 111851.16220855713\nINFO:root:6: Epoch 5 train loss: 23479.415252685547\nINFO:root:4: Epoch 5 train loss: 4410.789733886719\nINFO:root:5: Epoch 5 train loss: 1975.0104370117188\nINFO:root:3: Epoch 5 train loss: 153740.02389526367\nINFO:root:0: Epoch 5 validation loss: 1378849.8356232648\n", "seconds": 9.707365036010742, "batch_size": 128, "nodes": 7, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 3 batches\n4 Start Epoch 0\n7 Start Epoch 0\n4: 3 batches\n7: 3 batches\n2 Start Epoch 0\n1 Start Epoch 0\n2: 3 batches\n3 Start Epoch 0\n1: 3 batches\n3: 3 batches\n6 Start Epoch 0\n5 Start Epoch 0\n6: 3 batches\n5: 3 batches\n5 Start Epoch 1\n5: 3 batches\n1 Start Epoch 1\n3 Start Epoch 1\n2 Start Epoch 1\n7 Start Epoch 1\n1: 3 batches\n3: 3 batches\n2: 3 batches\n7: 3 batches\n6 Start Epoch 1\n4 Start Epoch 1\n6: 3 batches\n4: 3 batches\n0 Start Epoch 1\n0: 3 batches\n5 Start Epoch 2\n5: 3 batches\n7 Start Epoch 2\n1 Start Epoch 2\n3 Start Epoch 2\n2 Start Epoch 2\n1: 3 batches\n3: 3 batches\n2: 3 batches\n7: 3 batches\n6 Start Epoch 2\n6: 3 batches\n4 Start Epoch 2\n4: 3 batches\n0 Start Epoch 2\n0: 3 batches\n3 Start Epoch 3\n2 Start Epoch 3\n7 Start Epoch 3\n5 Start Epoch 3\n1 Start Epoch 3\n5: 3 batches\n1: 3 batches\n3: 3 batches\n2: 3 batches\n7: 3 batches\n6 Start Epoch 3\n4 Start Epoch 3\n6: 3 batches\n4: 3 batches\n0 Start Epoch 3\n0: 3 batches\n7 Start Epoch 4\n3 Start Epoch 4\n2 Start Epoch 4\n7: 3 batches\n1 Start Epoch 4\n5 Start Epoch 4\n1: 3 batches\n3: 3 batches\n2: 3 batches\n5: 3 batches\n4 Start Epoch 4\n6 Start Epoch 4\n6: 3 batches\n4: 3 batches\n0 Start Epoch 4\n0: 3 batches\n5 Start Epoch 5\n5: 3 batches\n3 Start Epoch 5\n1 Start Epoch 5\n7 Start Epoch 5\n7: 3 batches\n1: 3 batches\n3: 3 batches\n6 Start Epoch 5\n4 Start Epoch 5\n6: 3 batches\n4: 3 batches\n2 Start Epoch 5\n2: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:5: Epoch 0 train loss: 204376.04288736978\nINFO:root:1: Epoch 0 train loss: 3201.3616943359375\nINFO:root:3: Epoch 0 train loss: 190270.32096354166\nINFO:root:2: Epoch 0 train loss: 368003.1741536458\nINFO:root:7: Epoch 0 train loss: 187480.84318033853\nINFO:root:0: Epoch 0 train loss: 204162.22330729166\nINFO:root:6: Epoch 0 train loss: 224439.65096028647\nINFO:root:4: Epoch 0 train loss: 8401.812825520834\nINFO:root:0: Epoch 0 validation loss: 585450.7801756511\nINFO:root:5: Epoch 1 train loss: 184825.5499674479\nINFO:root:1: Epoch 1 train loss: 211962.265625\nINFO:root:3: Epoch 1 train loss: 163421.1053059896\nINFO:root:2: Epoch 1 train loss: 8754.2958984375\nINFO:root:7: Epoch 1 train loss: 60282.5263671875\nINFO:root:6: Epoch 1 train loss: 3054.06982421875\nINFO:root:4: Epoch 1 train loss: 372043.5975748698\nINFO:root:0: Epoch 1 train loss: 212565.60970052084\nINFO:root:0: Epoch 1 validation loss: 585443.7465793579\nINFO:root:2: Epoch 2 train loss: 5937.80073038737\nINFO:root:7: Epoch 2 train loss: 3297.4361979166665\nINFO:root:5: Epoch 2 train loss: 62355.87158203125\nINFO:root:1: Epoch 2 train loss: 60411.750325520836\nINFO:root:3: Epoch 2 train loss: 180372.94326782227\nINFO:root:0: Epoch 2 train loss: 520355.1354166667\nINFO:root:6: Epoch 2 train loss: 324081.1923014323\nINFO:root:4: Epoch 2 train loss: 312065.47639973956\nINFO:root:0: Epoch 2 validation loss: 585436.9197682044\nINFO:root:7: Epoch 3 train loss: 379149.60994466144\nINFO:root:1: Epoch 3 train loss: 9211.4365234375\nINFO:root:3: Epoch 3 train loss: 4564.9857177734375\nINFO:root:2: Epoch 3 train loss: 7903.126935323079\nINFO:root:5: Epoch 3 train loss: 417081.28515625\nINFO:root:0: Epoch 3 train loss: 79334.9769897461\nINFO:root:6: Epoch 3 train loss: 515373.05916341144\nINFO:root:4: Epoch 3 train loss: 180207.55521647134\nINFO:root:0: Epoch 3 validation loss: 585429.6015161764\nINFO:root:5: Epoch 4 train loss: 24716.782958984375\nINFO:root:1: Epoch 4 train loss: 155639.7919921875\nINFO:root:7: Epoch 4 train loss: 6652.104736328125\nINFO:root:3: Epoch 4 train loss: 6162.491373697917\nINFO:root:0: Epoch 4 train loss: 180716.7273763021\nINFO:root:6: Epoch 4 train loss: 4148.669270833333\nINFO:root:4: Epoch 4 train loss: 163256.62263997397\nINFO:root:2: Epoch 4 train loss: 182982.63680013022\nINFO:root:0: Epoch 4 validation loss: 585421.8219014854\nINFO:root:5: Epoch 5 train loss: 1945.6310017903645\nINFO:root:7: Epoch 5 train loss: 364764.1542561849\nINFO:root:1: Epoch 5 train loss: 9047.273681640625\nINFO:root:4: Epoch 5 train loss: 33676.11730957031\nINFO:root:0: Epoch 5 train loss: 203358.60245768228\nINFO:root:6: Epoch 5 train loss: 207089.78989664713\nINFO:root:3: Epoch 5 train loss: 201644.49157714844\nINFO:root:2: Epoch 5 train loss: 230329.36531575522\nINFO:root:0: Epoch 5 validation loss: 585412.459497641\n", "seconds": 11.86931586265564, "batch_size": 128, "nodes": 8, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 3 batches\n6 Start Epoch 0\n6: 3 batches\n3 Start Epoch 0\n3: 3 batches\n2 Start Epoch 0\n5 Start Epoch 0\n2: 3 batches\n1 Start Epoch 0\n1: 3 batches\n5: 3 batches\n4 Start Epoch 0\n8 Start Epoch 0\n4: 3 batches\n7 Start Epoch 0\n7: 3 batches\n8: 3 batches\n1 Start Epoch 1\n1: 3 batches\n4 Start Epoch 1\n4: 3 batches\n3 Start Epoch 1\n3: 3 batches\n5 Start Epoch 1\n6 Start Epoch 1\n2 Start Epoch 1\n5: 3 batches\n2: 3 batches\n6: 3 batches\n8 Start Epoch 1\n7 Start Epoch 1\n8: 3 batches\n7: 3 batches\n0 Start Epoch 1\n0: 3 batches\n1 Start Epoch 2\n1: 3 batches\n5 Start Epoch 2\n8 Start Epoch 2\n5: 3 batches\n6 Start Epoch 2\n4 Start Epoch 2\n3 Start Epoch 2\n3: 3 batches\n6: 3 batches\n8: 3 batches\n2 Start Epoch 2\n2: 3 batches\n4: 3 batches\n7 Start Epoch 2\n7: 3 batches\n0 Start Epoch 2\n0: 3 batches\n7 Start Epoch 3\n1 Start Epoch 3\n7: 3 batches\n1: 3 batches\n6 Start Epoch 3\n8 Start Epoch 3\n2 Start Epoch 3\n5 Start Epoch 3\n4 Start Epoch 3\n5: 3 batches\n4: 3 batches\n6: 3 batches\n8: 3 batches\n2: 3 batches\n3 Start Epoch 3\n3: 3 batches\n0 Start Epoch 3\n0: 3 batches\n3 Start Epoch 4\n1 Start Epoch 4\n7 Start Epoch 4\n7: 3 batches\n3: 3 batches\n1: 3 batches\n6 Start Epoch 4\n8 Start Epoch 4\n2 Start Epoch 4\n5 Start Epoch 4\n4 Start Epoch 4\n8: 3 batches\n2: 3 batches\n5: 3 batches\n4: 3 batches\n6: 3 batches\n0 Start Epoch 4\n0: 3 batches\n5 Start Epoch 5\n7 Start Epoch 5\n5: 3 batches\n7: 3 batches\n3 Start Epoch 5\n1 Start Epoch 5\n1: 3 batches\n3: 3 batches\n6 Start Epoch 5\n8 Start Epoch 5\n2 Start Epoch 5\n4 Start Epoch 5\n4: 3 batches\n6: 3 batches\n8: 3 batches\n2: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:1: Epoch 0 train loss: 6272.2998046875\nINFO:root:4: Epoch 0 train loss: 184004.29777018228\nINFO:root:3: Epoch 0 train loss: 10676.597895304361\nINFO:root:5: Epoch 0 train loss: 175611.3771158854\nINFO:root:6: Epoch 0 train loss: 2035.5197347005208\nINFO:root:2: Epoch 0 train loss: 2858.541951497396\nINFO:root:0: Epoch 0 train loss: 426934.4772135417\nINFO:root:8: Epoch 0 train loss: 304300.95393880206\nINFO:root:7: Epoch 0 train loss: 469773.15234375\nINFO:root:0: Epoch 0 validation loss: 155341.42153540667\nINFO:root:1: Epoch 1 train loss: 6917.892252604167\nINFO:root:5: Epoch 1 train loss: 349192.66015625\nINFO:root:6: Epoch 1 train loss: 422468.3551432292\nINFO:root:8: Epoch 1 train loss: 1484.5773162841797\nINFO:root:2: Epoch 1 train loss: 2203.1625773111978\nINFO:root:4: Epoch 1 train loss: 299540.908203125\nINFO:root:7: Epoch 1 train loss: 60284.36325073242\nINFO:root:3: Epoch 1 train loss: 7010.758626302083\nINFO:root:0: Epoch 1 train loss: 23732.010375976562\nINFO:root:0: Epoch 1 validation loss: 155325.602041346\nINFO:root:7: Epoch 2 train loss: 306926.92659505206\nINFO:root:1: Epoch 2 train loss: 14566.001220703125\nINFO:root:0: Epoch 2 train loss: 193884.54396565756\nINFO:root:6: Epoch 2 train loss: 229638.3585611979\nINFO:root:8: Epoch 2 train loss: 521885.0764973958\nINFO:root:2: Epoch 2 train loss: 204572.98317464194\nINFO:root:5: Epoch 2 train loss: 290796.46484375\nINFO:root:4: Epoch 2 train loss: 434721.5090332031\nINFO:root:3: Epoch 2 train loss: 8110.674479166667\nINFO:root:0: Epoch 2 validation loss: 155309.4757539762\nINFO:root:7: Epoch 3 train loss: 5105.138916015625\nINFO:root:1: Epoch 3 train loss: 8928.430582682291\nINFO:root:3: Epoch 3 train loss: 295154.31949869794\nINFO:root:0: Epoch 3 train loss: 360288.87581380206\nINFO:root:8: Epoch 3 train loss: 168956.65161132812\nINFO:root:2: Epoch 3 train loss: 3927.0890096028647\nINFO:root:5: Epoch 3 train loss: 2448.6573486328125\nINFO:root:4: Epoch 3 train loss: 5523.05224609375\nINFO:root:6: Epoch 3 train loss: 59970.185190836586\nINFO:root:0: Epoch 3 validation loss: 155292.20808399835\nINFO:root:5: Epoch 4 train loss: 8290.537923177084\nINFO:root:7: Epoch 4 train loss: 61535.61682128906\nINFO:root:3: Epoch 4 train loss: 186118.5470377604\nINFO:root:1: Epoch 4 train loss: 257706.87424723306\nINFO:root:0: Epoch 4 train loss: 300317.7276204427\nINFO:root:6: Epoch 4 train loss: 10436.540690104166\nINFO:root:8: Epoch 4 train loss: 451946.29606119794\nINFO:root:2: Epoch 4 train loss: 3830.3839518229165\nINFO:root:4: Epoch 4 train loss: 11772.535970052084\nINFO:root:0: Epoch 4 validation loss: 155273.08819471806\nINFO:root:3: Epoch 5 train loss: 150036.0968424479\nINFO:root:7: Epoch 5 train loss: 2667.7984415690103\nINFO:root:0: Epoch 5 train loss: 183999.90852864584\nINFO:root:8: Epoch 5 train loss: 10437.335327148438\nINFO:root:6: Epoch 5 train loss: 22898.407389322918\nINFO:root:4: Epoch 5 train loss: 347364.86385091144\nINFO:root:2: Epoch 5 train loss: 252037.08048502603\nINFO:root:1: Epoch 5 train loss: 522156.4935099284\nINFO:root:5: Epoch 5 train loss: 64496.698079427086\nINFO:root:0: Epoch 5 validation loss: 155251.62814316514\n", "seconds": 10.06418776512146, "batch_size": 128, "nodes": 9, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 3 batches\n9 Start Epoch 0\n8 Start Epoch 0\n9: 3 batches\n8: 3 batches\n1 Start Epoch 0\n2 Start Epoch 0\n5 Start Epoch 0\n7 Start Epoch 0\n6 Start Epoch 0\n3 Start Epoch 0\n1: 3 batches\n2: 3 batches\n4 Start Epoch 0\n5: 3 batches\n7: 3 batches\n6: 3 batches\n3: 3 batches\n4: 3 batches\n1 Start Epoch 1\n3 Start Epoch 1\n3: 3 batches\n1: 3 batches\n4 Start Epoch 1\n8 Start Epoch 1\n5 Start Epoch 1\n6 Start Epoch 1\n5: 3 batches\n7 Start Epoch 1\n6: 3 batches\n2 Start Epoch 1\n4: 3 batches\n8: 3 batches\n9 Start Epoch 1\n2: 3 batches\n7: 3 batches\n9: 3 batches\n0 Start Epoch 1\n0: 3 batches\n1 Start Epoch 2\n3 Start Epoch 2\n1: 3 batches\n3: 3 batches\n5 Start Epoch 2\n7 Start Epoch 2\n6 Start Epoch 2\n9 Start Epoch 2\n2 Start Epoch 2\n4 Start Epoch 2\n8 Start Epoch 2\n9: 3 batches\n2: 3 batches\n4: 3 batches\n8: 3 batches\n5: 3 batches\n7: 3 batches\n6: 3 batches\n0 Start Epoch 2\n0: 3 batches\n5 Start Epoch 3\n7 Start Epoch 3\n6 Start Epoch 3\n3 Start Epoch 3\n1 Start Epoch 3\n2 Start Epoch 3\n4 Start Epoch 3\n8 Start Epoch 3\n3: 3 batches\n1: 3 batches\n2: 3 batches\n4: 3 batches\n8: 3 batches\n5: 3 batches\n7: 3 batches\n6: 3 batches\n9 Start Epoch 3\n9: 3 batches\n0 Start Epoch 3\n0: 3 batches\n3 Start Epoch 4\n1 Start Epoch 4\n3: 3 batches\n1: 3 batches\n5 Start Epoch 4\n7 Start Epoch 4\n6 Start Epoch 4\n2 Start Epoch 4\n4 Start Epoch 4\n8 Start Epoch 4\n2: 3 batches\n4: 3 batches\n8: 3 batches\n5: 3 batches\n7: 3 batches\n6: 3 batches\n9 Start Epoch 4\n9: 3 batches\n0 Start Epoch 4\n0: 3 batches\n3 Start Epoch 5\n9 Start Epoch 5\n1 Start Epoch 5\n3: 3 batches\n9: 3 batches\n1: 3 batches\n2 Start Epoch 5\n4 Start Epoch 5\n8 Start Epoch 5\n5 Start Epoch 5\n7 Start Epoch 5\n6 Start Epoch 5\n8: 3 batches\n5: 3 batches\n7: 3 batches\n6: 3 batches\n2: 3 batches\n4: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:3: Epoch 0 train loss: 24726.797332763672\nINFO:root:1: Epoch 0 train loss: 174429.40164693198\nINFO:root:4: Epoch 0 train loss: 4307.569712320964\nINFO:root:8: Epoch 0 train loss: 20694.939646402996\nINFO:root:5: Epoch 0 train loss: 202150.38957722983\nINFO:root:6: Epoch 0 train loss: 350211.9612630208\nINFO:root:7: Epoch 0 train loss: 776457.6666666666\nINFO:root:2: Epoch 0 train loss: 206641.72176106772\nINFO:root:9: Epoch 0 train loss: 684969.0442708334\nINFO:root:0: Epoch 0 train loss: 61372.5634358724\nINFO:root:0: Epoch 0 validation loss: 2599229.024959749\nINFO:root:1: Epoch 1 train loss: 402379.3057149251\nINFO:root:3: Epoch 1 train loss: 169340.96004231772\nINFO:root:0: Epoch 1 train loss: 5096.157613118489\nINFO:root:6: Epoch 1 train loss: 8393.272623697916\nINFO:root:9: Epoch 1 train loss: 183085.1181640625\nINFO:root:2: Epoch 1 train loss: 3435.875691731771\nINFO:root:4: Epoch 1 train loss: 7768.505940755208\nINFO:root:8: Epoch 1 train loss: 600876.6928710938\nINFO:root:5: Epoch 1 train loss: 8403.151936848959\nINFO:root:7: Epoch 1 train loss: 66733.19775390625\nINFO:root:0: Epoch 1 validation loss: 2599179.4391246806\nINFO:root:0: Epoch 2 train loss: 14023.527994791666\nINFO:root:3: Epoch 2 train loss: 6523.486735026042\nINFO:root:1: Epoch 2 train loss: 172505.59619140625\nINFO:root:2: Epoch 2 train loss: 364813.6979980469\nINFO:root:4: Epoch 2 train loss: 5674.778762817383\nINFO:root:8: Epoch 2 train loss: 2078.332722981771\nINFO:root:5: Epoch 2 train loss: 9471.957763671875\nINFO:root:7: Epoch 2 train loss: 182996.1249593099\nINFO:root:6: Epoch 2 train loss: 326941.2317708333\nINFO:root:9: Epoch 2 train loss: 6190.5732421875\nINFO:root:0: Epoch 2 validation loss: 2599127.1125596217\nINFO:root:1: Epoch 3 train loss: 33678.500651041664\nINFO:root:3: Epoch 3 train loss: 137668.2881266276\nINFO:root:0: Epoch 3 train loss: 2048.9639485677085\nINFO:root:2: Epoch 3 train loss: 978.3264770507812\nINFO:root:4: Epoch 3 train loss: 168802.56216176352\nINFO:root:8: Epoch 3 train loss: 4567.202555338542\nINFO:root:5: Epoch 3 train loss: 184452.32080078125\nINFO:root:7: Epoch 3 train loss: 221245.2228190104\nINFO:root:6: Epoch 3 train loss: 174054.35041046143\nINFO:root:9: Epoch 3 train loss: 7850.349873860677\nINFO:root:0: Epoch 3 validation loss: 2599070.461625197\nINFO:root:3: Epoch 4 train loss: 10294.901204427084\nINFO:root:9: Epoch 4 train loss: 2796.9714152018228\nINFO:root:1: Epoch 4 train loss: 12951.449422200521\nINFO:root:0: Epoch 4 train loss: 183504.53440348306\nINFO:root:2: Epoch 4 train loss: 20026.298365275066\nINFO:root:4: Epoch 4 train loss: 507143.2633463542\nINFO:root:8: Epoch 4 train loss: 26364.753580729168\nINFO:root:5: Epoch 4 train loss: 57895.98887634277\nINFO:root:7: Epoch 4 train loss: 6245.485900878906\nINFO:root:6: Epoch 4 train loss: 65219.656087239586\nINFO:root:0: Epoch 4 validation loss: 2599008.5301751937\nINFO:root:0: Epoch 5 train loss: 2464.007095336914\nINFO:root:6: Epoch 5 train loss: 27082.667846679688\nINFO:root:9: Epoch 5 train loss: 68234.7928873698\nINFO:root:1: Epoch 5 train loss: 350479.7679036458\nINFO:root:2: Epoch 5 train loss: 9145.691162109375\nINFO:root:4: Epoch 5 train loss: 2015.1427675882976\nINFO:root:8: Epoch 5 train loss: 315381.51090494794\nINFO:root:5: Epoch 5 train loss: 71229.56217447917\nINFO:root:7: Epoch 5 train loss: 2041.2625732421875\nINFO:root:3: Epoch 5 train loss: 5516.703694661458\nINFO:root:0: Epoch 5 validation loss: 2598938.2118797684\n", "seconds": 8.442008256912231, "batch_size": 128, "nodes": 10, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 3 batches\n2 Start Epoch 0\n1 Start Epoch 0\n2: 3 batches\n4 Start Epoch 0\n8 Start Epoch 0\n4: 3 batches\n3 Start Epoch 0\n1: 3 batches\n7 Start Epoch 0\n8: 3 batches\n3: 3 batches\n10 Start Epoch 0\n9 Start Epoch 0\n7: 3 batches\n5 Start Epoch 0\n6 Start Epoch 0\n9: 3 batches\n5: 3 batches\n6: 3 batches\n10: 3 batches\n9 Start Epoch 1\n8 Start Epoch 1\n3 Start Epoch 1\n1 Start Epoch 1\n2 Start Epoch 1\n8: 3 batches\n3: 3 batches\n1: 3 batches\n2: 3 batches\n9: 3 batches\n4 Start Epoch 1\n10 Start Epoch 1\n7 Start Epoch 1\n5 Start Epoch 1\n6 Start Epoch 1\n7: 3 batches\n5: 3 batches\n6: 3 batches\n4: 3 batches\n10: 3 batches\n0 Start Epoch 1\n0: 3 batches\n1 Start Epoch 2\n3 Start Epoch 2\n1: 3 batches\n3: 3 batches\n9 Start Epoch 2\n9: 3 batches\n10 Start Epoch 2\n4 Start Epoch 2\n10: 3 batches\n2 Start Epoch 2\n5 Start Epoch 2\n6 Start Epoch 2\n2: 3 batches\n7 Start Epoch 2\n5: 3 batches\n6: 3 batches\n8 Start Epoch 2\n4: 3 batches\n7: 3 batches\n8: 3 batches\n0 Start Epoch 2\n0: 3 batches\n9 Start Epoch 3\n3 Start Epoch 3\n1 Start Epoch 3\n9: 3 batches\n3: 3 batches\n1: 3 batches\n6 Start Epoch 3\n8 Start Epoch 3\n7 Start Epoch 3\n10 Start Epoch 3\n2 Start Epoch 3\n7: 3 batches\n5 Start Epoch 3\n6: 3 batches\n8: 3 batches\n4 Start Epoch 3\n4: 3 batches\n10: 3 batches\n2: 3 batches\n5: 3 batches\n0 Start Epoch 3\n0: 3 batches\n9 Start Epoch 4\n7 Start Epoch 4\n3 Start Epoch 4\n1 Start Epoch 4\n1: 3 batches\n9: 3 batches\n7: 3 batches\n3: 3 batches\n8 Start Epoch 4\n4 Start Epoch 4\n10 Start Epoch 4\n2 Start Epoch 4\n5 Start Epoch 4\n6 Start Epoch 4\n8: 3 batches\n4: 3 batches\n10: 3 batches\n2: 3 batches\n5: 3 batches\n6: 3 batches\n0 Start Epoch 4\n0: 3 batches\n1 Start Epoch 5\n3 Start Epoch 5\n1: 3 batches\n9 Start Epoch 5\n3: 3 batches\n9: 3 batches\n5 Start Epoch 5\n10 Start Epoch 5\n7 Start Epoch 5\n5: 3 batches\n6 Start Epoch 5\n4 Start Epoch 5\n7: 3 batches\n6: 3 batches\n8 Start Epoch 5\n4: 3 batches\n10: 3 batches\n2 Start Epoch 5\n8: 3 batches\n2: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:8: Epoch 0 train loss: 201205.6557101806\nINFO:root:3: Epoch 0 train loss: 1823067.338704427\nINFO:root:1: Epoch 0 train loss: 7896.84240603447\nINFO:root:2: Epoch 0 train loss: 335081.8696376483\nINFO:root:9: Epoch 0 train loss: 319182.82806396484\nINFO:root:0: Epoch 0 train loss: 1658976.5123697917\nINFO:root:7: Epoch 0 train loss: 183238.49698893228\nINFO:root:5: Epoch 0 train loss: 163519.39388020834\nINFO:root:6: Epoch 0 train loss: 201943.00889078775\nINFO:root:4: Epoch 0 train loss: 201826.4237982432\nINFO:root:10: Epoch 0 train loss: 6151.0787474314375\nINFO:root:0: Epoch 0 validation loss: 887981.1646534505\nINFO:root:1: Epoch 1 train loss: 2344.815574645996\nINFO:root:3: Epoch 1 train loss: 6591.705647786458\nINFO:root:9: Epoch 1 train loss: 5373.016011555989\nINFO:root:10: Epoch 1 train loss: 173322.8224248886\nINFO:root:0: Epoch 1 train loss: 204975.21285502115\nINFO:root:2: Epoch 1 train loss: 136059.68617058298\nINFO:root:5: Epoch 1 train loss: 138579.15640703836\nINFO:root:6: Epoch 1 train loss: 4484.288492838542\nINFO:root:4: Epoch 1 train loss: 149757.56208292642\nINFO:root:8: Epoch 1 train loss: 183630.76692708334\nINFO:root:7: Epoch 1 train loss: 179567.33365885416\nINFO:root:0: Epoch 1 validation loss: 887957.4125443384\nINFO:root:9: Epoch 2 train loss: 23665.55857340495\nINFO:root:3: Epoch 2 train loss: 60854.456648508705\nINFO:root:1: Epoch 2 train loss: 4908.066080729167\nINFO:root:7: Epoch 2 train loss: 204213.4599609375\nINFO:root:6: Epoch 2 train loss: 149277.0355504354\nINFO:root:8: Epoch 2 train loss: 10338.372268676758\nINFO:root:4: Epoch 2 train loss: 11324.932291666666\nINFO:root:10: Epoch 2 train loss: 186522.74298350015\nINFO:root:2: Epoch 2 train loss: 530535.1761067709\nINFO:root:5: Epoch 2 train loss: 3660.5101928710938\nINFO:root:0: Epoch 2 train loss: 400349.3245465954\nINFO:root:0: Epoch 2 validation loss: 887931.7941304564\nINFO:root:3: Epoch 3 train loss: 176140.2543741862\nINFO:root:1: Epoch 3 train loss: 1678.8539326985676\nINFO:root:9: Epoch 3 train loss: 314839.67450968426\nINFO:root:7: Epoch 3 train loss: 172807.33919270834\nINFO:root:0: Epoch 3 train loss: 2115.3881047566733\nINFO:root:4: Epoch 3 train loss: 346933.31927490234\nINFO:root:10: Epoch 3 train loss: 6483.627527872722\nINFO:root:2: Epoch 3 train loss: 5275.578272501628\nINFO:root:5: Epoch 3 train loss: 185101.88705952963\nINFO:root:6: Epoch 3 train loss: 2541.0799458821616\nINFO:root:8: Epoch 3 train loss: 281786.7467651367\nINFO:root:0: Epoch 3 validation loss: 887904.9066399835\nINFO:root:1: Epoch 4 train loss: 2513.0390294392905\nINFO:root:3: Epoch 4 train loss: 6197.81554667155\nINFO:root:9: Epoch 4 train loss: 204754.8917643229\nINFO:root:5: Epoch 4 train loss: 1279.4092025756836\nINFO:root:0: Epoch 4 train loss: 1628.2412923177083\nINFO:root:7: Epoch 4 train loss: 57564.27635192871\nINFO:root:6: Epoch 4 train loss: 183084.90193684897\nINFO:root:4: Epoch 4 train loss: 209483.5594075521\nINFO:root:10: Epoch 4 train loss: 3745.4962412516275\nINFO:root:2: Epoch 4 train loss: 2565.9298807779946\nINFO:root:8: Epoch 4 train loss: 7293.30515229702\nINFO:root:0: Epoch 4 validation loss: 887876.9540710922\nINFO:root:9: Epoch 5 train loss: 363101.95703125\nINFO:root:1: Epoch 5 train loss: 334371.6632041931\nINFO:root:3: Epoch 5 train loss: 163168.09972556433\nINFO:root:0: Epoch 5 train loss: 341521.20025634766\nINFO:root:4: Epoch 5 train loss: 357433.70700581867\nINFO:root:10: Epoch 5 train loss: 2823.5855509440103\nINFO:root:2: Epoch 5 train loss: 137152.41697184244\nINFO:root:7: Epoch 5 train loss: 167403.0983988444\nINFO:root:5: Epoch 5 train loss: 148043.61297406504\nINFO:root:6: Epoch 5 train loss: 7241.765625\nINFO:root:8: Epoch 5 train loss: 172380.7276916504\nINFO:root:0: Epoch 5 validation loss: 887846.0995450588\n", "seconds": 9.095675945281982, "batch_size": 128, "nodes": 11, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n2 Start Epoch 0\n2: 2 batches\n5 Start Epoch 0\n6 Start Epoch 0\n5: 2 batches\n6: 2 batches\n10 Start Epoch 0\n10: 2 batches\n8 Start Epoch 0\n8: 2 batches\n1 Start Epoch 0\n1: 2 batches\n9 Start Epoch 0\n11 Start Epoch 0\n3 Start Epoch 0\n9: 2 batches\n4 Start Epoch 0\n4: 2 batches\n7 Start Epoch 0\n11: 2 batches\n7: 2 batches\n3: 2 batches\n1 Start Epoch 1\n3 Start Epoch 1\n9 Start Epoch 1\n9: 2 batches\n8 Start Epoch 1\n1: 2 batches\n3: 2 batches\n8: 2 batches\n2 Start Epoch 1\n6 Start Epoch 1\n5 Start Epoch 1\n2: 2 batches\n4 Start Epoch 1\n6: 2 batches\n7 Start Epoch 1\n5: 2 batches\n10 Start Epoch 1\n7: 2 batches\n10: 2 batches\n11 Start Epoch 1\n4: 2 batches\n11: 2 batches\n0 Start Epoch 1\n0: 2 batches\n1 Start Epoch 2\n3 Start Epoch 2\n7 Start Epoch 2\n1: 2 batches\n3: 2 batches\n8 Start Epoch 2\n8: 2 batches\n7: 2 batches\n9 Start Epoch 2\n9: 2 batches\n5 Start Epoch 2\n5: 2 batches\n4 Start Epoch 2\n6 Start Epoch 2\n10 Start Epoch 2\n2 Start Epoch 2\n6: 2 batches\n10: 2 batches\n11 Start Epoch 2\n11: 2 batches\n2: 2 batches\n4: 2 batches\n0 Start Epoch 2\n0: 2 batches\n3 Start Epoch 3\n1 Start Epoch 3\n3: 2 batches\n1: 2 batches\n8 Start Epoch 3\n9 Start Epoch 3\n8: 2 batches\n9: 2 batches\n2 Start Epoch 3\n4 Start Epoch 3\n4: 2 batches\n6 Start Epoch 3\n5 Start Epoch 3\n2: 2 batches\n7 Start Epoch 3\n5: 2 batches\n7: 2 batches\n10 Start Epoch 3\n6: 2 batches\n10: 2 batches\n11 Start Epoch 3\n11: 2 batches\n0 Start Epoch 3\n0: 2 batches\n3 Start Epoch 4\n3: 2 batches\n11 Start Epoch 4\n8 Start Epoch 4\n11: 2 batches\n9 Start Epoch 4\n8: 2 batches\n1 Start Epoch 4\n9: 2 batches\n1: 2 batches\n2 Start Epoch 4\n2: 2 batches\n4 Start Epoch 4\n5 Start Epoch 4\n4: 2 batches\n6 Start Epoch 4\n7 Start Epoch 4\n5: 2 batches\n10 Start Epoch 4\n6: 2 batches\n7: 2 batches\n10: 2 batches\n0 Start Epoch 4\n0: 2 batches\n1 Start Epoch 5\n3 Start Epoch 5\n5 Start Epoch 5\n1: 2 batches\n3: 2 batches\n5: 2 batches\n8 Start Epoch 5\n9 Start Epoch 5\n8: 2 batches\n9: 2 batches\n6 Start Epoch 5\n7 Start Epoch 5\n10 Start Epoch 5\n11 Start Epoch 5\n2 Start Epoch 5\n4 Start Epoch 5\n6: 2 batches\n7: 2 batches\n10: 2 batches\n11: 2 batches\n2: 2 batches\n4: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:9: Epoch 0 train loss: 2449.827880859375\nINFO:root:8: Epoch 0 train loss: 5227.4427490234375\nINFO:root:1: Epoch 0 train loss: 233028.15547180176\nINFO:root:3: Epoch 0 train loss: 38162.92687988281\nINFO:root:2: Epoch 0 train loss: 3380.318557739258\nINFO:root:5: Epoch 0 train loss: 4473.427490234375\nINFO:root:4: Epoch 0 train loss: 280001.802734375\nINFO:root:6: Epoch 0 train loss: 6890.7701416015625\nINFO:root:7: Epoch 0 train loss: 121793.73828125\nINFO:root:10: Epoch 0 train loss: 307735.03515625\nINFO:root:11: Epoch 0 train loss: 86357.60131835938\nINFO:root:0: Epoch 0 train loss: 285170.1193847656\nINFO:root:0: Epoch 0 validation loss: 30132.796284251588\nINFO:root:1: Epoch 1 train loss: 4403.151306152344\nINFO:root:3: Epoch 1 train loss: 2969.6728515625\nINFO:root:8: Epoch 1 train loss: 262428.84619140625\nINFO:root:7: Epoch 1 train loss: 275991.39376831055\nINFO:root:9: Epoch 1 train loss: 3583.3797607421875\nINFO:root:4: Epoch 1 train loss: 304293.34588623047\nINFO:root:5: Epoch 1 train loss: 220775.2421875\nINFO:root:10: Epoch 1 train loss: 259065.00927734375\nINFO:root:6: Epoch 1 train loss: 420461.2331542969\nINFO:root:2: Epoch 1 train loss: 5308.7474365234375\nINFO:root:11: Epoch 1 train loss: 7683.978942871094\nINFO:root:0: Epoch 1 train loss: 301939.1925048828\nINFO:root:0: Epoch 1 validation loss: 30129.10208541327\nINFO:root:3: Epoch 2 train loss: 255005.4754638672\nINFO:root:1: Epoch 2 train loss: 3643.748992919922\nINFO:root:8: Epoch 2 train loss: 5318.04638671875\nINFO:root:9: Epoch 2 train loss: 222943.03466796875\nINFO:root:2: Epoch 2 train loss: 275857.0714111328\nINFO:root:4: Epoch 2 train loss: 584838.90625\nINFO:root:6: Epoch 2 train loss: 3202.1861572265625\nINFO:root:5: Epoch 2 train loss: 596270.53125\nINFO:root:7: Epoch 2 train loss: 260393.99951171875\nINFO:root:10: Epoch 2 train loss: 4676.137542724609\nINFO:root:11: Epoch 2 train loss: 3743.5443115234375\nINFO:root:0: Epoch 2 train loss: 325252.484375\nINFO:root:0: Epoch 2 validation loss: 30125.357690721954\nINFO:root:3: Epoch 3 train loss: 327785.8254394531\nINFO:root:11: Epoch 3 train loss: 504032.4348144531\nINFO:root:9: Epoch 3 train loss: 220700.58911132812\nINFO:root:8: Epoch 3 train loss: 303736.78662109375\nINFO:root:1: Epoch 3 train loss: 36156.2802734375\nINFO:root:2: Epoch 3 train loss: 9153.158996582031\nINFO:root:6: Epoch 3 train loss: 223699.2724609375\nINFO:root:4: Epoch 3 train loss: 10491.10986328125\nINFO:root:5: Epoch 3 train loss: 6630.09130859375\nINFO:root:0: Epoch 3 train loss: 353314.5078125\nINFO:root:7: Epoch 3 train loss: 261816.890625\nINFO:root:10: Epoch 3 train loss: 245109.11401367188\nINFO:root:0: Epoch 3 validation loss: 30121.534920898037\nINFO:root:1: Epoch 4 train loss: 206421.25\nINFO:root:3: Epoch 4 train loss: 14847.0791015625\nINFO:root:5: Epoch 4 train loss: 264842.03271484375\nINFO:root:8: Epoch 4 train loss: 6686.786376953125\nINFO:root:9: Epoch 4 train loss: 6686.8946533203125\nINFO:root:0: Epoch 4 train loss: 6375.319885253906\nINFO:root:10: Epoch 4 train loss: 30140.751007080078\nINFO:root:11: Epoch 4 train loss: 10999.71337890625\nINFO:root:2: Epoch 4 train loss: 3593.928955078125\nINFO:root:4: Epoch 4 train loss: 230012.9666748047\nINFO:root:6: Epoch 4 train loss: 99979.5712890625\nINFO:root:7: Epoch 4 train loss: 89228.45251464844\nINFO:root:0: Epoch 4 validation loss: 30117.482116032093\nINFO:root:1: Epoch 5 train loss: 292583.7996826172\nINFO:root:0: Epoch 5 train loss: 577347.421875\nINFO:root:11: Epoch 5 train loss: 539943.7543945312\nINFO:root:9: Epoch 5 train loss: 204827.68487548828\nINFO:root:2: Epoch 5 train loss: 6449.275634765625\nINFO:root:4: Epoch 5 train loss: 1736.54150390625\nINFO:root:6: Epoch 5 train loss: 2658.8519287109375\nINFO:root:7: Epoch 5 train loss: 220955.86181640625\nINFO:root:5: Epoch 5 train loss: 242823.4849243164\nINFO:root:10: Epoch 5 train loss: 519053.90576171875\nINFO:root:3: Epoch 5 train loss: 275999.271484375\nINFO:root:8: Epoch 5 train loss: 533151.4609375\nINFO:root:0: Epoch 5 validation loss: 30113.31906126283\n", "seconds": 9.223121881484985, "batch_size": 128, "nodes": 12, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.15 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n1 Start Epoch 0\n1: 12 batches\n0: 12 batches\n1 Start Epoch 1\n1: 12 batches\n0 Start Epoch 1\n0: 12 batches\n1 Start Epoch 2\n1: 12 batches\n0 Start Epoch 2\n0: 12 batches\n1 Start Epoch 3\n1: 12 batches\n0 Start Epoch 3\n0: 12 batches\n1 Start Epoch 4\n1: 12 batches\n0 Start Epoch 4\n0: 12 batches\n1 Start Epoch 5\n1: 12 batches\n0 Start Epoch 5\n0: 12 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 126604.90347290039\nINFO:root:1: Epoch 0 train loss: 156855.64699808756\nINFO:root:0: Epoch 0 validation loss: 1739886.6233099787\nINFO:root:1: Epoch 1 train loss: 333167.1323445638\nINFO:root:0: Epoch 1 train loss: 185350.62019348145\nINFO:root:0: Epoch 1 validation loss: 1739737.9423133016\nINFO:root:0: Epoch 2 train loss: 164851.71793111166\nINFO:root:1: Epoch 2 train loss: 128422.96250406902\nINFO:root:0: Epoch 2 validation loss: 1739488.1937887464\nINFO:root:1: Epoch 3 train loss: 99155.43942260742\nINFO:root:0: Epoch 3 train loss: 197771.4673169454\nINFO:root:0: Epoch 3 validation loss: 1738985.0593668711\nINFO:root:0: Epoch 4 train loss: 180378.23229471841\nINFO:root:1: Epoch 4 train loss: 56305.239430745445\nINFO:root:0: Epoch 4 validation loss: 1738272.8907352746\nINFO:root:1: Epoch 5 train loss: 139072.53511301675\nINFO:root:0: Epoch 5 train loss: 246989.5203857422\nINFO:root:0: Epoch 5 validation loss: 1737545.5274202344\n", "seconds": 5.780070066452026, "batch_size": 128, "nodes": 1, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.15,192.168.2.2 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n1 Start Epoch 0\n3 Start Epoch 0\n2 Start Epoch 0\n0: 6 batches\n1: 6 batches\n2: 6 batches\n3: 6 batches\n1 Start Epoch 1\n1: 6 batches\n3 Start Epoch 1\n3: 6 batches\n2 Start Epoch 1\n2: 6 batches\n0 Start Epoch 1\n0: 6 batches\n1 Start Epoch 2\n1: 6 batches\n2 Start Epoch 2\n2: 6 batches\n3 Start Epoch 2\n3: 6 batches\n0 Start Epoch 2\n0: 6 batches\n1 Start Epoch 3\n2 Start Epoch 3\n3 Start Epoch 3\n3: 6 batches\n1: 6 batches\n2: 6 batches\n0 Start Epoch 3\n0: 6 batches\n1 Start Epoch 4\n1: 6 batches\n3 Start Epoch 4\n2 Start Epoch 4\n2: 6 batches\n3: 6 batches\n0 Start Epoch 4\n0: 6 batches\n1 Start Epoch 5\n1: 6 batches\n2 Start Epoch 5\n2: 6 batches\n3 Start Epoch 5\n3: 6 batches\n0 Start Epoch 5\n0: 6 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:1: Epoch 0 train loss: 102696.79503377278\nINFO:root:0: Epoch 0 train loss: 4185.309631347656\nINFO:root:3: Epoch 0 train loss: 3489.9236450195312\nINFO:root:2: Epoch 0 train loss: 82002.33659871419\nINFO:root:0: Epoch 0 validation loss: 229650799.803366\nINFO:root:0: Epoch 1 train loss: 435930.37864176434\nINFO:root:1: Epoch 1 train loss: 173854.6064860026\nINFO:root:2: Epoch 1 train loss: 340554.6037190755\nINFO:root:3: Epoch 1 train loss: 99208.56519063313\nINFO:root:0: Epoch 1 validation loss: 229650504.48878157\nINFO:root:1: Epoch 2 train loss: 298085.1725260417\nINFO:root:0: Epoch 2 train loss: 33477.563639322914\nINFO:root:2: Epoch 2 train loss: 70746.50061543782\nINFO:root:3: Epoch 2 train loss: 96869.6628519694\nINFO:root:0: Epoch 2 validation loss: 229650239.887594\nINFO:root:1: Epoch 3 train loss: 158040.9276936849\nINFO:root:0: Epoch 3 train loss: 203255.31786092123\nINFO:root:3: Epoch 3 train loss: 137352.2373046875\nINFO:root:2: Epoch 3 train loss: 4168.590016682942\nINFO:root:0: Epoch 3 validation loss: 229649929.13333943\nINFO:root:1: Epoch 4 train loss: 5587.4695231119795\nINFO:root:0: Epoch 4 train loss: 92071.36961873372\nINFO:root:3: Epoch 4 train loss: 166181.7159423828\nINFO:root:2: Epoch 4 train loss: 217901.85721842447\nINFO:root:0: Epoch 4 validation loss: 229649477.22087815\nINFO:root:3: Epoch 5 train loss: 159055.75410970053\nINFO:root:0: Epoch 5 train loss: 93676.17523956299\nINFO:root:1: Epoch 5 train loss: 4003.8682149251304\nINFO:root:2: Epoch 5 train loss: 148347.6264292399\nINFO:root:0: Epoch 5 validation loss: 229648859.58422762\n", "seconds": 56.525630950927734, "batch_size": 128, "nodes": 2, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.15,192.168.2.2,192.168.2.3 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 4 batches\n5 Start Epoch 0\n5: 4 batches\n1 Start Epoch 0\n1: 4 batches\n4 Start Epoch 0\n4: 4 batches\n2 Start Epoch 0\n2: 4 batches\n3 Start Epoch 0\n3: 4 batches\n3 Start Epoch 1\n3: 4 batches\n1 Start Epoch 1\n2 Start Epoch 1\n4 Start Epoch 1\n2: 4 batches\n5 Start Epoch 1\n4: 4 batches\n5: 4 batches\n1: 4 batches\n0 Start Epoch 1\n0: 4 batches\n1 Start Epoch 2\n1: 4 batches\n5 Start Epoch 2\n5: 4 batches\n4 Start Epoch 2\n4: 4 batches\n3 Start Epoch 2\n3: 4 batches\n2 Start Epoch 2\n2: 4 batches\n0 Start Epoch 2\n0: 4 batches\n5 Start Epoch 3\n5: 4 batches\n4 Start Epoch 3\n4: 4 batches\n3 Start Epoch 3\n3: 4 batches\n2 Start Epoch 3\n2: 4 batches\n1 Start Epoch 3\n1: 4 batches\n0 Start Epoch 3\n0: 4 batches\n1 Start Epoch 4\n3 Start Epoch 4\n3: 4 batches\n2 Start Epoch 4\n2: 4 batches\n1: 4 batches\n5 Start Epoch 4\n5: 4 batches\n4 Start Epoch 4\n4: 4 batches\n0 Start Epoch 4\n0: 4 batches\n5 Start Epoch 5\n5: 4 batches\n1 Start Epoch 5\n1: 4 batches\n4 Start Epoch 5\n4: 4 batches\n3 Start Epoch 5\n3: 4 batches\n2 Start Epoch 5\n2: 4 batches\n0 Start Epoch 5\n0: 4 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:3: Epoch 0 train loss: 255222.15264892578\nINFO:root:0: Epoch 0 train loss: 104007.16610717773\nINFO:root:1: Epoch 0 train loss: 19673.58087158203\nINFO:root:4: Epoch 0 train loss: 330966.17614746094\nINFO:root:5: Epoch 0 train loss: 5731.258117675781\nINFO:root:2: Epoch 0 train loss: 50278.98107910156\nINFO:root:0: Epoch 0 validation loss: 53433.008334079896\nINFO:root:1: Epoch 1 train loss: 10309.781433105469\nINFO:root:0: Epoch 1 train loss: 268450.7640991211\nINFO:root:5: Epoch 1 train loss: 12289.985961914062\nINFO:root:4: Epoch 1 train loss: 192308.21061706543\nINFO:root:3: Epoch 1 train loss: 255061.9458618164\nINFO:root:2: Epoch 1 train loss: 161029.65014648438\nINFO:root:0: Epoch 1 validation loss: 53422.05632480195\nINFO:root:5: Epoch 2 train loss: 157222.25134277344\nINFO:root:4: Epoch 2 train loss: 123768.60260009766\nINFO:root:3: Epoch 2 train loss: 4464.504295349121\nINFO:root:2: Epoch 2 train loss: 109250.9787902832\nINFO:root:0: Epoch 2 train loss: 9244.252410888672\nINFO:root:1: Epoch 2 train loss: 111637.91162109375\nINFO:root:0: Epoch 2 validation loss: 53411.42700394025\nINFO:root:0: Epoch 3 train loss: 153721.84872436523\nINFO:root:1: Epoch 3 train loss: 66547.00769042969\nINFO:root:3: Epoch 3 train loss: 145019.5938720703\nINFO:root:2: Epoch 3 train loss: 7189.023742675781\nINFO:root:4: Epoch 3 train loss: 247067.66676330566\nINFO:root:5: Epoch 3 train loss: 316667.35302734375\nINFO:root:0: Epoch 3 validation loss: 53400.358268341886\nINFO:root:5: Epoch 4 train loss: 6071.035068511963\nINFO:root:0: Epoch 4 train loss: 122574.41528320312\nINFO:root:1: Epoch 4 train loss: 310850.1357421875\nINFO:root:4: Epoch 4 train loss: 124742.45906066895\nINFO:root:2: Epoch 4 train loss: 252254.22595214844\nINFO:root:3: Epoch 4 train loss: 7803.518737792969\nINFO:root:0: Epoch 4 validation loss: 53387.906714899786\nINFO:root:0: Epoch 5 train loss: 318372.48126220703\nINFO:root:4: Epoch 5 train loss: 152769.48306274414\nINFO:root:2: Epoch 5 train loss: 153704.3087158203\nINFO:root:3: Epoch 5 train loss: 365509.9938964844\nINFO:root:5: Epoch 5 train loss: 293497.85276794434\nINFO:root:1: Epoch 5 train loss: 401614.84185791016\nINFO:root:0: Epoch 5 validation loss: 53373.66260105217\n", "seconds": 38.62609601020813, "batch_size": 128, "nodes": 3, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 3 batches\n7 Start Epoch 0\n7: 3 batches\n6 Start Epoch 0\n1 Start Epoch 0\n1: 3 batches\n6: 3 batches\n2 Start Epoch 0\n3 Start Epoch 0\n2: 3 batches\n5 Start Epoch 0\n3: 3 batches\n4 Start Epoch 0\n5: 3 batches\n4: 3 batches\n6 Start Epoch 1\n3 Start Epoch 1\n5 Start Epoch 1\n7 Start Epoch 1\n3: 3 batches\n4 Start Epoch 1\n7: 3 batches\n6: 3 batches\n5: 3 batches\n4: 3 batches\n1 Start Epoch 1\n1: 3 batches\n2 Start Epoch 1\n2: 3 batches\n0 Start Epoch 1\n0: 3 batches\n4 Start Epoch 2\n5 Start Epoch 2\n4: 3 batches\n1 Start Epoch 2\n5: 3 batches\n6 Start Epoch 2\n7 Start Epoch 2\n6: 3 batches\n7: 3 batches\n1: 3 batches\n3 Start Epoch 2\n3: 3 batches\n2 Start Epoch 2\n2: 3 batches\n0 Start Epoch 2\n0: 3 batches\n1 Start Epoch 3\n1: 3 batches\n4 Start Epoch 3\n7 Start Epoch 3\n6 Start Epoch 3\n5 Start Epoch 3\n5: 3 batches\n6: 3 batches\n4: 3 batches\n7: 3 batches\n2 Start Epoch 3\n2: 3 batches\n3 Start Epoch 3\n3: 3 batches\n0 Start Epoch 3\n0: 3 batches\n7 Start Epoch 4\n7: 3 batches\n2 Start Epoch 4\n5 Start Epoch 4\n3 Start Epoch 4\n4 Start Epoch 4\n4: 3 batches\n5: 3 batches\n1 Start Epoch 4\n1: 3 batches\n3: 3 batches\n2: 3 batches\n6 Start Epoch 4\n6: 3 batches\n0 Start Epoch 4\n0: 3 batches\n1 Start Epoch 5\n1: 3 batches\n3 Start Epoch 5\n4 Start Epoch 5\n6 Start Epoch 5\n2 Start Epoch 5\n2: 3 batches\n7 Start Epoch 5\n5 Start Epoch 5\n4: 3 batches\n7: 3 batches\n3: 3 batches\n5: 3 batches\n6: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:3: Epoch 0 train loss: 333968.9765625\nINFO:root:6: Epoch 0 train loss: 191804.34212239584\nINFO:root:4: Epoch 0 train loss: 188617.1036783854\nINFO:root:5: Epoch 0 train loss: 6462.07666015625\nINFO:root:7: Epoch 0 train loss: 180156.49845377603\nINFO:root:0: Epoch 0 train loss: 170252.17486572266\nINFO:root:1: Epoch 0 train loss: 149908.61865234375\nINFO:root:2: Epoch 0 train loss: 605980.21875\nINFO:root:0: Epoch 0 validation loss: 339503067.04487675\nINFO:root:5: Epoch 1 train loss: 60196.196533203125\nINFO:root:4: Epoch 1 train loss: 63926.12939453125\nINFO:root:0: Epoch 1 train loss: 362912.6451822917\nINFO:root:1: Epoch 1 train loss: 2514.8590087890625\nINFO:root:6: Epoch 1 train loss: 172423.53352864584\nINFO:root:7: Epoch 1 train loss: 165434.62239583334\nINFO:root:3: Epoch 1 train loss: 7243.453287760417\nINFO:root:2: Epoch 1 train loss: 9043.965169270834\nINFO:root:0: Epoch 1 validation loss: 339502813.8277631\nINFO:root:0: Epoch 2 train loss: 200924.27408854166\nINFO:root:1: Epoch 2 train loss: 181555.63444010416\nINFO:root:4: Epoch 2 train loss: 325753.751953125\nINFO:root:5: Epoch 2 train loss: 4408.498046875\nINFO:root:7: Epoch 2 train loss: 148740.27734375\nINFO:root:6: Epoch 2 train loss: 176571.6837565104\nINFO:root:3: Epoch 2 train loss: 346092.80921936035\nINFO:root:2: Epoch 2 train loss: 182745.00146484375\nINFO:root:0: Epoch 2 validation loss: 339502632.05515695\nINFO:root:7: Epoch 3 train loss: 5811.509195963542\nINFO:root:2: Epoch 3 train loss: 207332.2861328125\nINFO:root:5: Epoch 3 train loss: 218075.24869791666\nINFO:root:3: Epoch 3 train loss: 168479.83443196616\nINFO:root:4: Epoch 3 train loss: 227804.70149739584\nINFO:root:0: Epoch 3 train loss: 7499.3115234375\nINFO:root:1: Epoch 3 train loss: 23629.676432291668\nINFO:root:6: Epoch 3 train loss: 6490.243815104167\nINFO:root:0: Epoch 3 validation loss: 339502378.6263182\nINFO:root:1: Epoch 4 train loss: 199813.68098958334\nINFO:root:0: Epoch 4 train loss: 412747.72963460285\nINFO:root:7: Epoch 4 train loss: 9752.509114583334\nINFO:root:3: Epoch 4 train loss: 14068.702494303385\nINFO:root:5: Epoch 4 train loss: 3787.9456380208335\nINFO:root:6: Epoch 4 train loss: 6390.604329427083\nINFO:root:4: Epoch 4 train loss: 1391.1063842773438\nINFO:root:2: Epoch 4 train loss: 167228.83487955728\nINFO:root:0: Epoch 4 validation loss: 339502121.8983039\nINFO:root:5: Epoch 5 train loss: 184817.2980143229\nINFO:root:4: Epoch 5 train loss: 21866.523111979168\nINFO:root:3: Epoch 5 train loss: 437333.39592488605\nINFO:root:2: Epoch 5 train loss: 172062.212890625\nINFO:root:1: Epoch 5 train loss: 362136.1432291667\nINFO:root:6: Epoch 5 train loss: 6516.597737630208\nINFO:root:7: Epoch 5 train loss: 360225.4671223958\nINFO:root:0: Epoch 5 train loss: 8558.763326009115\nINFO:root:0: Epoch 5 validation loss: 339501860.39680517\n", "seconds": 29.73050093650818, "batch_size": 128, "nodes": 4, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 3 batches\n1 Start Epoch 0\n1: 3 batches\n2 Start Epoch 0\n2: 3 batches\n9 Start Epoch 0\n5 Start Epoch 0\n5: 3 batches\n6 Start Epoch 0\n6: 3 batches\n9: 3 batches\n3 Start Epoch 0\n3: 3 batches\n4 Start Epoch 0\n4: 3 batches\n7 Start Epoch 0\n8 Start Epoch 0\n8: 3 batches\n7: 3 batches\n9 Start Epoch 1\n9: 3 batches\n1 Start Epoch 1\n1: 3 batches\n2 Start Epoch 1\n3 Start Epoch 1\n2: 3 batches\n8 Start Epoch 1\n8: 3 batches\n3: 3 batches\n7 Start Epoch 1\n7: 3 batches\n6 Start Epoch 1\n6: 3 batches\n5 Start Epoch 1\n5: 3 batches\n4 Start Epoch 1\n4: 3 batches\n0 Start Epoch 1\n0: 3 batches\n3 Start Epoch 2\n3: 3 batches\n5 Start Epoch 2\n4 Start Epoch 2\n4: 3 batches\n7 Start Epoch 2\n7: 3 batches\n6 Start Epoch 2\n6: 3 batches\n5: 3 batches\n2 Start Epoch 2\n2: 3 batches\n1 Start Epoch 2\n1: 3 batches\n8 Start Epoch 2\n9 Start Epoch 2\n9: 3 batches\n8: 3 batches\n0 Start Epoch 2\n0: 3 batches\n5 Start Epoch 3\n4 Start Epoch 3\n5: 3 batches\n4: 3 batches\n6 Start Epoch 3\n7 Start Epoch 3\n9 Start Epoch 3\n6: 3 batches\n7: 3 batches\n8 Start Epoch 3\n9: 3 batches\n3 Start Epoch 3\n3: 3 batches\n1 Start Epoch 3\n1: 3 batches\n8: 3 batches\n2 Start Epoch 3\n2: 3 batches\n0 Start Epoch 3\n0: 3 batches\n9 Start Epoch 4\n9: 3 batches\n1 Start Epoch 4\n1: 3 batches\n3 Start Epoch 4\n2 Start Epoch 4\n3: 3 batches\n2: 3 batches\n8 Start Epoch 4\n8: 3 batches\n7 Start Epoch 4\n7: 3 batches\n5 Start Epoch 4\n6 Start Epoch 4\n6: 3 batches\n4 Start Epoch 4\n4: 3 batches\n5: 3 batches\n0 Start Epoch 4\n0: 3 batches\n6 Start Epoch 5\n7 Start Epoch 5\n6: 3 batches\n4 Start Epoch 5\n4: 3 batches\n5 Start Epoch 5\n5: 3 batches\n7: 3 batches\n3 Start Epoch 5\n3: 3 batches\n2 Start Epoch 5\n2: 3 batches\n1 Start Epoch 5\n1: 3 batches\n8 Start Epoch 5\n9 Start Epoch 5\n8: 3 batches\n9: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:9: Epoch 0 train loss: 205281.015625\nINFO:root:1: Epoch 0 train loss: 4362.391927083333\nINFO:root:0: Epoch 0 train loss: 175679.39717610678\nINFO:root:3: Epoch 0 train loss: 4817.739634195964\nINFO:root:2: Epoch 0 train loss: 4144.6930745442705\nINFO:root:8: Epoch 0 train loss: 989429.42578125\nINFO:root:7: Epoch 0 train loss: 505096.81819661456\nINFO:root:6: Epoch 0 train loss: 371520.9694010417\nINFO:root:5: Epoch 0 train loss: 232779.06795247397\nINFO:root:4: Epoch 0 train loss: 2549.2245966593423\nINFO:root:0: Epoch 0 validation loss: 75217.2342800228\nINFO:root:3: Epoch 1 train loss: 10508.519714355469\nINFO:root:5: Epoch 1 train loss: 6633.9990234375\nINFO:root:4: Epoch 1 train loss: 58105.64432779948\nINFO:root:7: Epoch 1 train loss: 7884.6287027994795\nINFO:root:6: Epoch 1 train loss: 8656.625244140625\nINFO:root:2: Epoch 1 train loss: 3118.543711344401\nINFO:root:1: Epoch 1 train loss: 5683.476501464844\nINFO:root:0: Epoch 1 train loss: 175099.27211507162\nINFO:root:9: Epoch 1 train loss: 3458.2499186197915\nINFO:root:8: Epoch 1 train loss: 1441.1136983235676\nINFO:root:0: Epoch 1 validation loss: 75208.6030571498\nINFO:root:4: Epoch 2 train loss: 142084.46482340494\nINFO:root:5: Epoch 2 train loss: 355916.63297526044\nINFO:root:7: Epoch 2 train loss: 165488.51595052084\nINFO:root:6: Epoch 2 train loss: 72018.79482014973\nINFO:root:8: Epoch 2 train loss: 528040.782796224\nINFO:root:9: Epoch 2 train loss: 239566.79166666666\nINFO:root:3: Epoch 2 train loss: 71813.24544270833\nINFO:root:1: Epoch 2 train loss: 158156.1788736979\nINFO:root:0: Epoch 2 train loss: 203742.26733398438\nINFO:root:2: Epoch 2 train loss: 168826.19610595703\nINFO:root:0: Epoch 2 validation loss: 75199.59319959703\nINFO:root:9: Epoch 3 train loss: 3936.7115071614585\nINFO:root:1: Epoch 3 train loss: 3824.410944620768\nINFO:root:0: Epoch 3 train loss: 238037.29659016928\nINFO:root:3: Epoch 3 train loss: 23700.09061686198\nINFO:root:2: Epoch 3 train loss: 177478.0013631185\nINFO:root:8: Epoch 3 train loss: 186501.47142537436\nINFO:root:7: Epoch 3 train loss: 4111.220703125\nINFO:root:4: Epoch 3 train loss: 164360.11553955078\nINFO:root:5: Epoch 3 train loss: 307203.3914794922\nINFO:root:6: Epoch 3 train loss: 233046.0079752604\nINFO:root:0: Epoch 3 validation loss: 75190.22954100242\nINFO:root:6: Epoch 4 train loss: 349521.2584635417\nINFO:root:7: Epoch 4 train loss: 308671.625\nINFO:root:5: Epoch 4 train loss: 175403.84783935547\nINFO:root:4: Epoch 4 train loss: 5757.109517415364\nINFO:root:2: Epoch 4 train loss: 1397.3836263020833\nINFO:root:3: Epoch 4 train loss: 6606.441487630208\nINFO:root:1: Epoch 4 train loss: 6887.094075520833\nINFO:root:0: Epoch 4 train loss: 6469.8179117838545\nINFO:root:8: Epoch 4 train loss: 330325.22599283856\nINFO:root:9: Epoch 4 train loss: 4991.1935628255205\nINFO:root:0: Epoch 4 validation loss: 75180.58576600048\nINFO:root:9: Epoch 5 train loss: 353787.7766927083\nINFO:root:0: Epoch 5 train loss: 924.5197245279948\nINFO:root:1: Epoch 5 train loss: 185575.8313369751\nINFO:root:2: Epoch 5 train loss: 228518.5978190104\nINFO:root:3: Epoch 5 train loss: 2706.7008463541665\nINFO:root:5: Epoch 5 train loss: 209140.0519205729\nINFO:root:7: Epoch 5 train loss: 183469.2648111979\nINFO:root:4: Epoch 5 train loss: 530466.2003580729\nINFO:root:6: Epoch 5 train loss: 342649.00293223065\nINFO:root:8: Epoch 5 train loss: 502464.676961263\nINFO:root:0: Epoch 5 validation loss: 75169.789671925\n", "seconds": 24.089163064956665, "batch_size": 128, "nodes": 5, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n11 Start Epoch 0\n11: 2 batches\n1 Start Epoch 0\n1: 2 batches\n4 Start Epoch 0\n8 Start Epoch 0\n4: 2 batches\n2 Start Epoch 0\n3 Start Epoch 0\n3: 2 batches\n8: 2 batches\n10 Start Epoch 0\n2: 2 batches\n7 Start Epoch 0\n9 Start Epoch 0\n5 Start Epoch 0\n10: 2 batches\n6 Start Epoch 0\n9: 2 batches\n5: 2 batches\n7: 2 batches\n6: 2 batches\n1 Start Epoch 1\n1: 2 batches\n2 Start Epoch 1\n4 Start Epoch 1\n5 Start Epoch 1\n3 Start Epoch 1\n4: 2 batches\n3: 2 batches\n5: 2 batches\n10 Start Epoch 1\n11 Start Epoch 1\n11: 2 batches\n10: 2 batches\n7 Start Epoch 1\n7: 2 batches\n8 Start Epoch 1\n9 Start Epoch 1\n9: 2 batches\n8: 2 batches\n2: 2 batches\n6 Start Epoch 1\n6: 2 batches\n0 Start Epoch 1\n0: 2 batches\n1 Start Epoch 2\n1: 2 batches\n11 Start Epoch 2\n9 Start Epoch 2\n5 Start Epoch 2\n7 Start Epoch 2\n9: 2 batches\n5: 2 batches\n11: 2 batches\n3 Start Epoch 2\n2 Start Epoch 2\n6 Start Epoch 2\n6: 2 batches\n4 Start Epoch 2\n10 Start Epoch 2\n2: 2 batches\n7: 2 batches\n4: 2 batches\n10: 2 batches\n8 Start Epoch 2\n8: 2 batches\n3: 2 batches\n0 Start Epoch 2\n0: 2 batches\n1 Start Epoch 3\n4 Start Epoch 3\n11 Start Epoch 3\n3 Start Epoch 3\n6 Start Epoch 3\n6: 2 batches\n2 Start Epoch 3\n7 Start Epoch 3\n7: 2 batches\n5 Start Epoch 3\n5: 2 batches\n10 Start Epoch 3\n3: 2 batches\n4: 2 batches\n10: 2 batches\n11: 2 batches\n1: 2 batches\n8 Start Epoch 3\n9 Start Epoch 3\n9: 2 batches\n2: 2 batches\n8: 2 batches\n0 Start Epoch 3\n0: 2 batches\n5 Start Epoch 4\n5: 2 batches\n7 Start Epoch 4\n6 Start Epoch 4\n6: 2 batches\n7: 2 batches\n9 Start Epoch 4\n9: 2 batches\n8 Start Epoch 4\n8: 2 batches\n1 Start Epoch 4\n1: 2 batches\n10 Start Epoch 4\n11 Start Epoch 4\n3 Start Epoch 4\n4 Start Epoch 4\n4: 2 batches\n10: 2 batches\n2 Start Epoch 4\n2: 2 batches\n11: 2 batches\n3: 2 batches\n0 Start Epoch 4\n0: 2 batches\n1 Start Epoch 5\n1: 2 batches\n5 Start Epoch 5\n3 Start Epoch 5\n2 Start Epoch 5\n2: 2 batches\n7 Start Epoch 5\n4 Start Epoch 5\n5: 2 batches\n3: 2 batches\n6 Start Epoch 5\n4: 2 batches\n8 Start Epoch 5\n10 Start Epoch 5\n9 Start Epoch 5\n11 Start Epoch 5\n8: 2 batches\n10: 2 batches\n11: 2 batches\n6: 2 batches\n7: 2 batches\n9: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 2471.071533203125\nINFO:root:1: Epoch 0 train loss: 10420.325439453125\nINFO:root:5: Epoch 0 train loss: 15907.857421875\nINFO:root:3: Epoch 0 train loss: 744572.84375\nINFO:root:4: Epoch 0 train loss: 540651.125\nINFO:root:2: Epoch 0 train loss: 4606.168212890625\nINFO:root:10: Epoch 0 train loss: 229362.3291015625\nINFO:root:11: Epoch 0 train loss: 2623.3194580078125\nINFO:root:7: Epoch 0 train loss: 209345.45013427734\nINFO:root:8: Epoch 0 train loss: 2271.447265625\nINFO:root:9: Epoch 0 train loss: 2732.6599731445312\nINFO:root:6: Epoch 0 train loss: 359502.578125\nINFO:root:0: Epoch 0 validation loss: 636659.2295298168\nINFO:root:0: Epoch 1 train loss: 10689.502990722656\nINFO:root:1: Epoch 1 train loss: 5622.2047119140625\nINFO:root:11: Epoch 1 train loss: 12210.83349609375\nINFO:root:3: Epoch 1 train loss: 270844.5419921875\nINFO:root:6: Epoch 1 train loss: 4476.0009765625\nINFO:root:9: Epoch 1 train loss: 6618.5975341796875\nINFO:root:5: Epoch 1 train loss: 3392.042510986328\nINFO:root:2: Epoch 1 train loss: 5190.5244140625\nINFO:root:7: Epoch 1 train loss: 1973.9070587158203\nINFO:root:4: Epoch 1 train loss: 270382.88204956055\nINFO:root:10: Epoch 1 train loss: 4037.6336059570312\nINFO:root:8: Epoch 1 train loss: 4026.59033203125\nINFO:root:0: Epoch 1 validation loss: 636640.656821011\nINFO:root:1: Epoch 2 train loss: 10125.050842285156\nINFO:root:0: Epoch 2 train loss: 2726.0963745117188\nINFO:root:3: Epoch 2 train loss: 356273.03515625\nINFO:root:5: Epoch 2 train loss: 294129.9765625\nINFO:root:10: Epoch 2 train loss: 6118.581787109375\nINFO:root:11: Epoch 2 train loss: 241978.68823242188\nINFO:root:2: Epoch 2 train loss: 93201.47216796875\nINFO:root:7: Epoch 2 train loss: 1026.87353515625\nINFO:root:4: Epoch 2 train loss: 276244.0807495117\nINFO:root:6: Epoch 2 train loss: 4680.8319091796875\nINFO:root:8: Epoch 2 train loss: 204300.70318603516\nINFO:root:9: Epoch 2 train loss: 1945.5890197753906\nINFO:root:0: Epoch 2 validation loss: 636621.2138611556\nINFO:root:5: Epoch 3 train loss: 10089.379455566406\nINFO:root:7: Epoch 3 train loss: 2361.169464111328\nINFO:root:6: Epoch 3 train loss: 34689.806884765625\nINFO:root:9: Epoch 3 train loss: 3950.914794921875\nINFO:root:8: Epoch 3 train loss: 5036.506896972656\nINFO:root:0: Epoch 3 train loss: 3465.095733642578\nINFO:root:1: Epoch 3 train loss: 8663.7685546875\nINFO:root:10: Epoch 3 train loss: 94496.79895019531\nINFO:root:11: Epoch 3 train loss: 2753.290771484375\nINFO:root:2: Epoch 3 train loss: 329724.48333740234\nINFO:root:3: Epoch 3 train loss: 240582.896484375\nINFO:root:4: Epoch 3 train loss: 254860.9873046875\nINFO:root:0: Epoch 3 validation loss: 636600.8988652265\nINFO:root:0: Epoch 4 train loss: 479263.40625\nINFO:root:1: Epoch 4 train loss: 4864.050231933594\nINFO:root:2: Epoch 4 train loss: 1731.6629028320312\nINFO:root:5: Epoch 4 train loss: 501951.84375\nINFO:root:6: Epoch 4 train loss: 265216.642578125\nINFO:root:4: Epoch 4 train loss: 1607.2370910644531\nINFO:root:3: Epoch 4 train loss: 337908.482421875\nINFO:root:7: Epoch 4 train loss: 261642.65600585938\nINFO:root:10: Epoch 4 train loss: 32443.054809570312\nINFO:root:9: Epoch 4 train loss: 5827.143859863281\nINFO:root:8: Epoch 4 train loss: 219997.97985839844\nINFO:root:11: Epoch 4 train loss: 7440.651611328125\nINFO:root:0: Epoch 4 validation loss: 636579.8962819042\nINFO:root:11: Epoch 5 train loss: 256881.3328857422\nINFO:root:10: Epoch 5 train loss: 494528.515625\nINFO:root:1: Epoch 5 train loss: 4646.2613525390625\nINFO:root:0: Epoch 5 train loss: 18020.767578125\nINFO:root:3: Epoch 5 train loss: 6748.7396240234375\nINFO:root:2: Epoch 5 train loss: 237745.25494384766\nINFO:root:7: Epoch 5 train loss: 222042.48510742188\nINFO:root:6: Epoch 5 train loss: 283334.4091796875\nINFO:root:5: Epoch 5 train loss: 35602.1689453125\nINFO:root:4: Epoch 5 train loss: 260795.60998535156\nINFO:root:9: Epoch 5 train loss: 308118.68896484375\nINFO:root:8: Epoch 5 train loss: 6398.185119628906\nINFO:root:0: Epoch 5 validation loss: 636557.5604908649\n", "seconds": 21.85505700111389, "batch_size": 128, "nodes": 6, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n1 Start Epoch 0\n2 Start Epoch 0\n2: 2 batches\n1: 2 batches\n5 Start Epoch 0\n11 Start Epoch 0\n5: 2 batches\n11: 2 batches\n6 Start Epoch 0\n12 Start Epoch 0\n12: 2 batches\n8 Start Epoch 0\n3 Start Epoch 0\n7 Start Epoch 0\n9 Start Epoch 0\n3: 2 batches\n7: 2 batches\n13 Start Epoch 0\n4 Start Epoch 0\n4: 2 batches\n8: 2 batches\n6: 2 batches\n13: 2 batches\n9: 2 batches\n10 Start Epoch 0\n10: 2 batches\n13 Start Epoch 1\n13: 2 batches\n3 Start Epoch 1\n3: 2 batches\n10 Start Epoch 1\n9 Start Epoch 1\n6 Start Epoch 1\n11 Start Epoch 1\n8 Start Epoch 1\n7 Start Epoch 1\n10: 2 batches\n9: 2 batches\n7: 2 batches\n12 Start Epoch 1\n11: 2 batches\n8: 2 batches\n12: 2 batches\n1 Start Epoch 1\n1: 2 batches\n5 Start Epoch 1\n6: 2 batches\n5: 2 batches\n4 Start Epoch 1\n4: 2 batches\n2 Start Epoch 1\n2: 2 batches\n0 Start Epoch 1\n0: 2 batches\n11 Start Epoch 2\n11: 2 batches\n10 Start Epoch 2\n10: 2 batches\n2 Start Epoch 2\n1 Start Epoch 2\n5 Start Epoch 2\n9 Start Epoch 2\n1: 2 batches\n5: 2 batches\n9: 2 batches\n2: 2 batches\n6 Start Epoch 2\n7 Start Epoch 2\n13 Start Epoch 2\n6: 2 batches\n13: 2 batches\n4 Start Epoch 2\n3 Start Epoch 2\n12 Start Epoch 2\n4: 2 batches\n3: 2 batches\n7: 2 batches\n12: 2 batches\n8 Start Epoch 2\n8: 2 batches\n0 Start Epoch 2\n0: 2 batches\n3 Start Epoch 3\n3: 2 batches\n6 Start Epoch 3\n4 Start Epoch 3\n7 Start Epoch 3\n5 Start Epoch 3\n7: 2 batches\n4: 2 batches\n6: 2 batches\n5: 2 batches\n2 Start Epoch 3\n13 Start Epoch 3\n11 Start Epoch 3\n11: 2 batches\n9 Start Epoch 3\n2: 2 batches\n13: 2 batches\n10 Start Epoch 3\n10: 2 batches\n8 Start Epoch 3\n9: 2 batches\n12 Start Epoch 3\n8: 2 batches\n12: 2 batches\n1 Start Epoch 3\n1: 2 batches\n0 Start Epoch 3\n0: 2 batches\n3 Start Epoch 4\n4 Start Epoch 4\n4: 2 batches\n3: 2 batches\n7 Start Epoch 4\n5 Start Epoch 4\n5: 2 batches\n6 Start Epoch 4\n7: 2 batches\n6: 2 batches\n2 Start Epoch 4\n11 Start Epoch 4\n11: 2 batches\n2: 2 batches\n10 Start Epoch 4\n10: 2 batches\n8 Start Epoch 4\n13 Start Epoch 4\n9 Start Epoch 4\n9: 2 batches\n12 Start Epoch 4\n8: 2 batches\n12: 2 batches\n13: 2 batches\n1 Start Epoch 4\n1: 2 batches\n0 Start Epoch 4\n0: 2 batches\n11 Start Epoch 5\n11: 2 batches\n12 Start Epoch 5\n13 Start Epoch 5\n13: 2 batches\n12: 2 batches\n5 Start Epoch 5\n4 Start Epoch 5\n4: 2 batches\n10 Start Epoch 5\n5: 2 batches\n10: 2 batches\n1 Start Epoch 5\n1: 2 batches\n9 Start Epoch 5\n9: 2 batches\n8 Start Epoch 5\n8: 2 batches\n6 Start Epoch 5\n6: 2 batches\n2 Start Epoch 5\n2: 2 batches\n3 Start Epoch 5\n3: 2 batches\n7 Start Epoch 5\n7: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:13: Epoch 0 train loss: 256204.3662109375\nINFO:root:3: Epoch 0 train loss: 2351.0965881347656\nINFO:root:6: Epoch 0 train loss: 278963.037109375\nINFO:root:10: Epoch 0 train loss: 10176.396728515625\nINFO:root:8: Epoch 0 train loss: 3849.4765625\nINFO:root:7: Epoch 0 train loss: 17473.4697265625\nINFO:root:11: Epoch 0 train loss: 7480.73193359375\nINFO:root:9: Epoch 0 train loss: 8584.322021484375\nINFO:root:12: Epoch 0 train loss: 769990.3995361328\nINFO:root:1: Epoch 0 train loss: 3501.597625732422\nINFO:root:5: Epoch 0 train loss: 2740.7666015625\nINFO:root:4: Epoch 0 train loss: 205590.94354248047\nINFO:root:2: Epoch 0 train loss: 6524.9044189453125\nINFO:root:0: Epoch 0 train loss: 238817.29907226562\nINFO:root:0: Epoch 0 validation loss: 1702712.3944215958\nINFO:root:11: Epoch 1 train loss: 992.3171691894531\nINFO:root:10: Epoch 1 train loss: 539.2183837890625\nINFO:root:0: Epoch 1 train loss: 730370.6704101562\nINFO:root:9: Epoch 1 train loss: 13841.111572265625\nINFO:root:2: Epoch 1 train loss: 9803.541259765625\nINFO:root:6: Epoch 1 train loss: 6730.3787841796875\nINFO:root:5: Epoch 1 train loss: 14577.49609375\nINFO:root:1: Epoch 1 train loss: 1160.711181640625\nINFO:root:7: Epoch 1 train loss: 368684.3564453125\nINFO:root:12: Epoch 1 train loss: 560116.1333618164\nINFO:root:13: Epoch 1 train loss: 9524.280517578125\nINFO:root:3: Epoch 1 train loss: 2595.5066528320312\nINFO:root:4: Epoch 1 train loss: 3692.4107666015625\nINFO:root:8: Epoch 1 train loss: 272432.58532714844\nINFO:root:0: Epoch 1 validation loss: 1702685.4125605656\nINFO:root:3: Epoch 2 train loss: 11277.1318359375\nINFO:root:7: Epoch 2 train loss: 2560.0244750976562\nINFO:root:5: Epoch 2 train loss: 3321.9515380859375\nINFO:root:4: Epoch 2 train loss: 377372.1181640625\nINFO:root:6: Epoch 2 train loss: 3983.77490234375\nINFO:root:0: Epoch 2 train loss: 1139.8346252441406\nINFO:root:11: Epoch 2 train loss: 333195.2551269531\nINFO:root:8: Epoch 2 train loss: 542034.6334228516\nINFO:root:2: Epoch 2 train loss: 332009.2736816406\nINFO:root:13: Epoch 2 train loss: 687346.6875\nINFO:root:12: Epoch 2 train loss: 272450.95153808594\nINFO:root:10: Epoch 2 train loss: 7837.860107421875\nINFO:root:9: Epoch 2 train loss: 1433.8612365722656\nINFO:root:1: Epoch 2 train loss: 3424.8167724609375\nINFO:root:0: Epoch 2 validation loss: 1702659.6440834396\nINFO:root:3: Epoch 3 train loss: 1749.9080810546875\nINFO:root:7: Epoch 3 train loss: 328844.72484588623\nINFO:root:4: Epoch 3 train loss: 333706.1640625\nINFO:root:6: Epoch 3 train loss: 2256.393165588379\nINFO:root:5: Epoch 3 train loss: 807.9773559570312\nINFO:root:2: Epoch 3 train loss: 6847.7020263671875\nINFO:root:11: Epoch 3 train loss: 12084.072265625\nINFO:root:10: Epoch 3 train loss: 274525.689453125\nINFO:root:8: Epoch 3 train loss: 313301.9169921875\nINFO:root:13: Epoch 3 train loss: 256801.77734375\nINFO:root:12: Epoch 3 train loss: 19953.3125\nINFO:root:9: Epoch 3 train loss: 1970.545150756836\nINFO:root:0: Epoch 3 train loss: 5248.3929443359375\nINFO:root:1: Epoch 3 train loss: 15729.790397644043\nINFO:root:0: Epoch 3 validation loss: 1702633.401105418\nINFO:root:11: Epoch 4 train loss: 223089.47607421875\nINFO:root:13: Epoch 4 train loss: 19522.588256835938\nINFO:root:12: Epoch 4 train loss: 12717.684875488281\nINFO:root:4: Epoch 4 train loss: 2379.4842529296875\nINFO:root:5: Epoch 4 train loss: 4317.385070800781\nINFO:root:10: Epoch 4 train loss: 4852.480239868164\nINFO:root:1: Epoch 4 train loss: 584956.390625\nINFO:root:8: Epoch 4 train loss: 300898.74617767334\nINFO:root:9: Epoch 4 train loss: 5499.597900390625\nINFO:root:0: Epoch 4 train loss: 6730.2884521484375\nINFO:root:2: Epoch 4 train loss: 459932.9753417969\nINFO:root:6: Epoch 4 train loss: 642346.09375\nINFO:root:3: Epoch 4 train loss: 306649.109375\nINFO:root:7: Epoch 4 train loss: 395519.62365722656\nINFO:root:0: Epoch 4 validation loss: 1702606.7616109673\nINFO:root:9: Epoch 5 train loss: 5260.502197265625\nINFO:root:8: Epoch 5 train loss: 4543.45361328125\nINFO:root:11: Epoch 5 train loss: 9811.692138671875\nINFO:root:10: Epoch 5 train loss: 974.6172637939453\nINFO:root:5: Epoch 5 train loss: 559615.7185058594\nINFO:root:3: Epoch 5 train loss: 1427.7713623046875\nINFO:root:4: Epoch 5 train loss: 9519.879028320312\nINFO:root:2: Epoch 5 train loss: 130045.56750488281\nINFO:root:6: Epoch 5 train loss: 5402.357971191406\nINFO:root:7: Epoch 5 train loss: 7576.283203125\nINFO:root:1: Epoch 5 train loss: 273049.1784439087\nINFO:root:12: Epoch 5 train loss: 1970.226318359375\nINFO:root:13: Epoch 5 train loss: 42616.3173828125\nINFO:root:0: Epoch 5 train loss: 304372.2282409668\nINFO:root:0: Epoch 5 validation loss: 1702579.764316231\n", "seconds": 23.1752610206604, "batch_size": 128, "nodes": 7, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 2 batches\n2: 2 batches\n15 Start Epoch 0\n15: 2 batches\n4 Start Epoch 0\n3 Start Epoch 0\n3: 2 batches\n4: 2 batches\n12 Start Epoch 0\n7 Start Epoch 0\n11 Start Epoch 0\n8 Start Epoch 0\n12: 2 batches\n7: 2 batches\n11: 2 batches\n8: 2 batches\n6 Start Epoch 0\n9 Start Epoch 0\n13 Start Epoch 0\n5 Start Epoch 0\n13: 2 batches\n9: 2 batches\n14 Start Epoch 0\n10 Start Epoch 0\n6: 2 batches\n14: 2 batches\n10: 2 batches\n5: 2 batches\n15 Start Epoch 1\n14 Start Epoch 1\n8 Start Epoch 1\n15: 2 batches\n9 Start Epoch 1\n14: 2 batches\n9: 2 batches\n8: 2 batches\n13 Start Epoch 1\n10 Start Epoch 1\n10: 2 batches\n13: 2 batches\n11 Start Epoch 1\n11: 2 batches\n12 Start Epoch 1\n12: 2 batches\n7 Start Epoch 1\n6 Start Epoch 1\n7: 2 batches\n6: 2 batches\n1 Start Epoch 1\n1: 2 batches\n3 Start Epoch 1\n3: 2 batches\n4 Start Epoch 1\n4: 2 batches\n5 Start Epoch 1\n5: 2 batches\n2 Start Epoch 1\n2: 2 batches\n0 Start Epoch 1\n0: 2 batches\n7 Start Epoch 2\n5 Start Epoch 2\n14 Start Epoch 2\n14: 2 batches\n2 Start Epoch 2\n6 Start Epoch 2\n2: 2 batches\n4 Start Epoch 2\n15 Start Epoch 2\n15: 2 batches\n4: 2 batches\n7: 2 batches\n6: 2 batches\n1 Start Epoch 2\n1: 2 batches\n13 Start Epoch 2\n12 Start Epoch 2\n12: 2 batches\n13: 2 batches\n11 Start Epoch 2\n10 Start Epoch 2\n11: 2 batches\n10: 2 batches\n3 Start Epoch 2\n5: 2 batches\n3: 2 batches\n8 Start Epoch 2\n9 Start Epoch 2\n9: 2 batches\n8: 2 batches\n0 Start Epoch 2\n0: 2 batches\n7 Start Epoch 3\n7: 2 batches\n10 Start Epoch 3\n12 Start Epoch 3\n6 Start Epoch 3\n11 Start Epoch 3\n5 Start Epoch 3\n14 Start Epoch 3\n6: 2 batches\n4 Start Epoch 3\n13 Start Epoch 3\n13: 2 batches\n15 Start Epoch 3\n15: 2 batches\n5: 2 batches\n12: 2 batches\n4: 2 batches\n8 Start Epoch 3\n9 Start Epoch 3\n8: 2 batches\n10: 2 batches\n9: 2 batches\n11: 2 batches\n3 Start Epoch 3\n3: 2 batches\n2 Start Epoch 3\n2: 2 batches\n14: 2 batches\n1 Start Epoch 3\n1: 2 batches\n0 Start Epoch 3\n0: 2 batches\n4 Start Epoch 4\n5 Start Epoch 4\n3 Start Epoch 4\n4: 2 batches\n2 Start Epoch 4\n3: 2 batches\n5: 2 batches\n2: 2 batches\n11 Start Epoch 4\n10 Start Epoch 4\n14 Start Epoch 4\n11: 2 batches\n15 Start Epoch 4\n15: 2 batches\n8 Start Epoch 4\n13 Start Epoch 4\n9 Start Epoch 4\n13: 2 batches\n8: 2 batches\n12 Start Epoch 4\n12: 2 batches\n9: 2 batches\n7 Start Epoch 4\n7: 2 batches\n6 Start Epoch 4\n6: 2 batches\n14: 2 batches\n10: 2 batches\n1 Start Epoch 4\n1: 2 batches\n0 Start Epoch 4\n0: 2 batches\n11 Start Epoch 5\n11: 2 batches\n10 Start Epoch 5\n10: 2 batches\n9 Start Epoch 5\n8 Start Epoch 5\n8: 2 batches\n9: 2 batches\n13 Start Epoch 5\n12 Start Epoch 5\n13: 2 batches\n7 Start Epoch 5\n7: 2 batches\n12: 2 batches\n15 Start Epoch 5\n15: 2 batches\n2 Start Epoch 5\n6 Start Epoch 5\n6: 2 batches\n14 Start Epoch 5\n3 Start Epoch 5\n2: 2 batches\n14: 2 batches\n3: 2 batches\n5 Start Epoch 5\n5: 2 batches\n4 Start Epoch 5\n4: 2 batches\n1 Start Epoch 5\n1: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:14: Epoch 0 train loss: 3748.9700927734375\nINFO:root:15: Epoch 0 train loss: 7360.8525390625\nINFO:root:8: Epoch 0 train loss: 4854.857116699219\nINFO:root:9: Epoch 0 train loss: 3382.3422241210938\nINFO:root:13: Epoch 0 train loss: 244026.4543914795\nINFO:root:11: Epoch 0 train loss: 13788.923095703125\nINFO:root:10: Epoch 0 train loss: 3816.3612060546875\nINFO:root:12: Epoch 0 train loss: 1184.3364715576172\nINFO:root:7: Epoch 0 train loss: 91928.1328125\nINFO:root:6: Epoch 0 train loss: 252116.85095214844\nINFO:root:0: Epoch 0 train loss: 63648.99768066406\nINFO:root:1: Epoch 0 train loss: 1198.5218353271484\nINFO:root:3: Epoch 0 train loss: 11502.45654296875\nINFO:root:4: Epoch 0 train loss: 571560.2431640625\nINFO:root:5: Epoch 0 train loss: 87839.31823730469\nINFO:root:2: Epoch 0 train loss: 2718.1841430664062\nINFO:root:0: Epoch 0 validation loss: 11928.287842964617\nINFO:root:2: Epoch 1 train loss: 477432.5627441406\nINFO:root:6: Epoch 1 train loss: 944.7270812988281\nINFO:root:5: Epoch 1 train loss: 7492.5740966796875\nINFO:root:15: Epoch 1 train loss: 8344.178352355957\nINFO:root:14: Epoch 1 train loss: 219526.74017333984\nINFO:root:3: Epoch 1 train loss: 7730.038330078125\nINFO:root:4: Epoch 1 train loss: 8578.578857421875\nINFO:root:7: Epoch 1 train loss: 811347.15625\nINFO:root:12: Epoch 1 train loss: 1220.964111328125\nINFO:root:1: Epoch 1 train loss: 254579.34326171875\nINFO:root:13: Epoch 1 train loss: 86545.97827148438\nINFO:root:10: Epoch 1 train loss: 664939.3781738281\nINFO:root:11: Epoch 1 train loss: 735394.8212890625\nINFO:root:8: Epoch 1 train loss: 12113.200927734375\nINFO:root:9: Epoch 1 train loss: 2110.9722290039062\nINFO:root:0: Epoch 1 train loss: 5454.85693359375\nINFO:root:0: Epoch 1 validation loss: 11923.103103957605\nINFO:root:7: Epoch 2 train loss: 18343.869018554688\nINFO:root:4: Epoch 2 train loss: 300193.4137573242\nINFO:root:13: Epoch 2 train loss: 301026.9825439453\nINFO:root:14: Epoch 2 train loss: 901278.375\nINFO:root:6: Epoch 2 train loss: 252762.8051147461\nINFO:root:5: Epoch 2 train loss: 7845.4686279296875\nINFO:root:15: Epoch 2 train loss: 8626.07666015625\nINFO:root:11: Epoch 2 train loss: 14726.5517578125\nINFO:root:12: Epoch 2 train loss: 478323.20739746094\nINFO:root:10: Epoch 2 train loss: 321000.494140625\nINFO:root:9: Epoch 2 train loss: 4011.6319580078125\nINFO:root:8: Epoch 2 train loss: 3932.1469116210938\nINFO:root:2: Epoch 2 train loss: 11337.062194824219\nINFO:root:3: Epoch 2 train loss: 267334.67919921875\nINFO:root:0: Epoch 2 train loss: 1050095.53125\nINFO:root:1: Epoch 2 train loss: 30778.90087890625\nINFO:root:0: Epoch 2 validation loss: 11917.895356654912\nINFO:root:4: Epoch 3 train loss: 472780.84703826904\nINFO:root:2: Epoch 3 train loss: 5079.41650390625\nINFO:root:5: Epoch 3 train loss: 430532.96875\nINFO:root:3: Epoch 3 train loss: 437.64881896972656\nINFO:root:10: Epoch 3 train loss: 1085326.7973632812\nINFO:root:11: Epoch 3 train loss: 271993.84729003906\nINFO:root:15: Epoch 3 train loss: 4264.502166748047\nINFO:root:14: Epoch 3 train loss: 299836.6505279541\nINFO:root:12: Epoch 3 train loss: 254583.68713378906\nINFO:root:9: Epoch 3 train loss: 7228.998443603516\nINFO:root:13: Epoch 3 train loss: 320788.140625\nINFO:root:8: Epoch 3 train loss: 21958.5244140625\nINFO:root:0: Epoch 3 train loss: 253211.34594726562\nINFO:root:7: Epoch 3 train loss: 255057.47480773926\nINFO:root:6: Epoch 3 train loss: 2072.375732421875\nINFO:root:1: Epoch 3 train loss: 12754.864501953125\nINFO:root:0: Epoch 3 validation loss: 11912.46154579957\nINFO:root:11: Epoch 4 train loss: 7683.280029296875\nINFO:root:10: Epoch 4 train loss: 749131.875\nINFO:root:8: Epoch 4 train loss: 373978.96129989624\nINFO:root:9: Epoch 4 train loss: 4166.818603515625\nINFO:root:12: Epoch 4 train loss: 261220.91975402832\nINFO:root:13: Epoch 4 train loss: 7239.408935546875\nINFO:root:7: Epoch 4 train loss: 62788.3271484375\nINFO:root:2: Epoch 4 train loss: 266747.3955078125\nINFO:root:6: Epoch 4 train loss: 1301.7566223144531\nINFO:root:15: Epoch 4 train loss: 1685.8744812011719\nINFO:root:14: Epoch 4 train loss: 6127.0859375\nINFO:root:3: Epoch 4 train loss: 2134.0991821289062\nINFO:root:0: Epoch 4 train loss: 533743.3898925781\nINFO:root:1: Epoch 4 train loss: 6606.07568359375\nINFO:root:4: Epoch 4 train loss: 257998.32861328125\nINFO:root:5: Epoch 4 train loss: 916424.328125\nINFO:root:0: Epoch 4 validation loss: 11906.706790008293\nINFO:root:11: Epoch 5 train loss: 2392.255584716797\nINFO:root:3: Epoch 5 train loss: 2867.4739990234375\nINFO:root:6: Epoch 5 train loss: 452220.919921875\nINFO:root:7: Epoch 5 train loss: 247973.59110069275\nINFO:root:0: Epoch 5 train loss: 16140.25439453125\nINFO:root:8: Epoch 5 train loss: 264795.431640625\nINFO:root:13: Epoch 5 train loss: 3649.53662109375\nINFO:root:9: Epoch 5 train loss: 3257.97900390625\nINFO:root:10: Epoch 5 train loss: 9330.243286132812\nINFO:root:15: Epoch 5 train loss: 87984.28918457031\nINFO:root:2: Epoch 5 train loss: 87571.0302734375\nINFO:root:14: Epoch 5 train loss: 666105.7727050781\nINFO:root:12: Epoch 5 train loss: 2212.19189453125\nINFO:root:1: Epoch 5 train loss: 7730.5911865234375\nINFO:root:4: Epoch 5 train loss: 483123.958984375\nINFO:root:5: Epoch 5 train loss: 8047.72607421875\nINFO:root:0: Epoch 5 validation loss: 11900.532947221449\n", "seconds": 18.393326997756958, "batch_size": 128, "nodes": 8, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 2 batches\n2: 2 batches\n17 Start Epoch 0\n4 Start Epoch 0\n8 Start Epoch 0\n4: 2 batches\n11 Start Epoch 0\n7 Start Epoch 0\n12 Start Epoch 0\n7: 2 batches\n12: 2 batches\n15 Start Epoch 0\n17: 2 batches\n11: 2 batches\n3 Start Epoch 0\n8: 2 batches\n3: 2 batches\n15: 2 batches\n16 Start Epoch 0\n16: 2 batches\n6 Start Epoch 0\n10 Start Epoch 0\n14 Start Epoch 0\n9 Start Epoch 0\n6: 2 batches\n5 Start Epoch 0\n13 Start Epoch 0\n14: 2 batches\n10: 2 batches\n9: 2 batches\n5: 2 batches\n13: 2 batches\n17 Start Epoch 1\n17: 2 batches\n7 Start Epoch 1\n6 Start Epoch 1\n6: 2 batches\n16 Start Epoch 1\n16: 2 batches\n9 Start Epoch 1\n5 Start Epoch 1\n8 Start Epoch 1\n4 Start Epoch 1\n9: 2 batches\n4: 2 batches\n8: 2 batches\n5: 2 batches\n11 Start Epoch 1\n11: 2 batches\n3 Start Epoch 1\n3: 2 batches\n1 Start Epoch 1\n7: 2 batches\n1: 2 batches\n2 Start Epoch 1\n2: 2 batches\n14 Start Epoch 1\n14: 2 batches\n15 Start Epoch 1\n15: 2 batches\n12 Start Epoch 1\n12: 2 batches\n13 Start Epoch 1\n13: 2 batches\n10 Start Epoch 1\n10: 2 batches\n0 Start Epoch 1\n0: 2 batches\n1 Start Epoch 2\n7 Start Epoch 2\n3 Start Epoch 2\n6 Start Epoch 2\n6: 2 batches\n11 Start Epoch 2\n16 Start Epoch 2\n11: 2 batches\n3: 2 batches\n5 Start Epoch 2\n8 Start Epoch 2\n4 Start Epoch 2\n13 Start Epoch 2\n17 Start Epoch 2\n2 Start Epoch 2\n9 Start Epoch 2\n7: 2 batches\n4: 2 batches\n13: 2 batches\n14 Start Epoch 2\n16: 2 batches\n2: 2 batches\n9: 2 batches\n5: 2 batches\n12 Start Epoch 2\n15 Start Epoch 2\n17: 2 batches\n14: 2 batches\n8: 2 batches\n12: 2 batches\n15: 2 batches\n1: 2 batches\n10 Start Epoch 2\n10: 2 batches\n0 Start Epoch 2\n0: 2 batches\n17 Start Epoch 3\n17: 2 batches\n15 Start Epoch 3\n16 Start Epoch 3\n16: 2 batches\n5 Start Epoch 3\n7 Start Epoch 3\n5: 2 batches\n14 Start Epoch 3\n15: 2 batches\n2 Start Epoch 3\n6 Start Epoch 3\n1 Start Epoch 3\n3 Start Epoch 3\n1: 2 batches\n7: 2 batches\n4 Start Epoch 3\n13 Start Epoch 3\n14: 2 batches\n3: 2 batches\n6: 2 batches\n4: 2 batches\n13: 2 batches\n11 Start Epoch 3\n2: 2 batches\n8 Start Epoch 3\n10 Start Epoch 3\n9 Start Epoch 3\n11: 2 batches\n9: 2 batches\n10: 2 batches\n8: 2 batches\n12 Start Epoch 3\n12: 2 batches\n0 Start Epoch 3\n0: 2 batches\n13 Start Epoch 4\n13: 2 batches\n15 Start Epoch 4\n16 Start Epoch 4\n14 Start Epoch 4\n17 Start Epoch 4\n14: 2 batches\n17: 2 batches\n15: 2 batches\n16: 2 batches\n7 Start Epoch 4\n2 Start Epoch 4\n6 Start Epoch 4\n5 Start Epoch 4\n3 Start Epoch 4\n4 Start Epoch 4\n2: 2 batches\n7: 2 batches\n4: 2 batches\n3: 2 batches\n6: 2 batches\n5: 2 batches\n12 Start Epoch 4\n1 Start Epoch 4\n1: 2 batches\n9 Start Epoch 4\n11 Start Epoch 4\n8 Start Epoch 4\n11: 2 batches\n10 Start Epoch 4\n8: 2 batches\n10: 2 batches\n9: 2 batches\n12: 2 batches\n0 Start Epoch 4\n0: 2 batches\n16 Start Epoch 5\n15 Start Epoch 5\n17 Start Epoch 5\n14 Start Epoch 5\n15: 2 batches\n17: 2 batches\n14: 2 batches\n1 Start Epoch 5\n1: 2 batches\n11 Start Epoch 5\n16: 2 batches\n11: 2 batches\n13 Start Epoch 5\n13: 2 batches\n12 Start Epoch 5\n12: 2 batches\n2 Start Epoch 5\n2: 2 batches\n3 Start Epoch 5\n3: 2 batches\n5 Start Epoch 5\n4 Start Epoch 5\n4: 2 batches\n5: 2 batches\n7 Start Epoch 5\n6 Start Epoch 5\n6: 2 batches\n10 Start Epoch 5\n10: 2 batches\n7: 2 batches\n8 Start Epoch 5\n9 Start Epoch 5\n9: 2 batches\n8: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:17: Epoch 0 train loss: 4093.0396728515625\nINFO:root:6: Epoch 0 train loss: 10264.53271484375\nINFO:root:7: Epoch 0 train loss: 4091.3792724609375\nINFO:root:16: Epoch 0 train loss: 2041.4917678833008\nINFO:root:9: Epoch 0 train loss: 2763.3812408447266\nINFO:root:5: Epoch 0 train loss: 345.08299255371094\nINFO:root:8: Epoch 0 train loss: 2839.05712890625\nINFO:root:4: Epoch 0 train loss: 85899.22039318085\nINFO:root:11: Epoch 0 train loss: 859.5289916992188\nINFO:root:3: Epoch 0 train loss: 271448.0552253723\nINFO:root:1: Epoch 0 train loss: 1031759.21875\nINFO:root:2: Epoch 0 train loss: 243235.8560180664\nINFO:root:15: Epoch 0 train loss: 309418.0087890625\nINFO:root:0: Epoch 0 train loss: 7287.925354003906\nINFO:root:14: Epoch 0 train loss: 7498.738525390625\nINFO:root:12: Epoch 0 train loss: 2726.1198120117188\nINFO:root:13: Epoch 0 train loss: 7233.119140625\nINFO:root:10: Epoch 0 train loss: 8043.52783203125\nINFO:root:0: Epoch 0 validation loss: 709771.1188218382\nINFO:root:1: Epoch 1 train loss: 1648.7317810058594\nINFO:root:0: Epoch 1 train loss: 100261.13105773926\nINFO:root:17: Epoch 1 train loss: 243398.4609222412\nINFO:root:11: Epoch 1 train loss: 261227.99365234375\nINFO:root:3: Epoch 1 train loss: 306277.79249191284\nINFO:root:5: Epoch 1 train loss: 252229.580078125\nINFO:root:8: Epoch 1 train loss: 31404.0673828125\nINFO:root:4: Epoch 1 train loss: 9867.250305175781\nINFO:root:12: Epoch 1 train loss: 746220.6748046875\nINFO:root:16: Epoch 1 train loss: 251729.505859375\nINFO:root:13: Epoch 1 train loss: 5539.791748046875\nINFO:root:14: Epoch 1 train loss: 2676.0721435546875\nINFO:root:9: Epoch 1 train loss: 3131.5656814575195\nINFO:root:7: Epoch 1 train loss: 2583.6909790039062\nINFO:root:2: Epoch 1 train loss: 6230.640859603882\nINFO:root:6: Epoch 1 train loss: 1747.7601318359375\nINFO:root:15: Epoch 1 train loss: 295114.15576171875\nINFO:root:10: Epoch 1 train loss: 912.8126602172852\nINFO:root:0: Epoch 1 validation loss: 709741.8062684854\nINFO:root:17: Epoch 2 train loss: 3287.5916748046875\nINFO:root:15: Epoch 2 train loss: 12405.87451171875\nINFO:root:6: Epoch 2 train loss: 2754.2280807495117\nINFO:root:5: Epoch 2 train loss: 271600.3218383789\nINFO:root:14: Epoch 2 train loss: 275146.6202392578\nINFO:root:16: Epoch 2 train loss: 2859.113048553467\nINFO:root:3: Epoch 2 train loss: 43396.74609375\nINFO:root:7: Epoch 2 train loss: 301917.11083984375\nINFO:root:2: Epoch 2 train loss: 208201.83447265625\nINFO:root:4: Epoch 2 train loss: 531077.1077880859\nINFO:root:13: Epoch 2 train loss: 6823.956848144531\nINFO:root:1: Epoch 2 train loss: 7209.3994140625\nINFO:root:8: Epoch 2 train loss: 2350.9970092773438\nINFO:root:11: Epoch 2 train loss: 3275.6712646484375\nINFO:root:9: Epoch 2 train loss: 217018.3977355957\nINFO:root:10: Epoch 2 train loss: 247019.19343566895\nINFO:root:0: Epoch 2 train loss: 17198.05517578125\nINFO:root:12: Epoch 2 train loss: 8094.733795166016\nINFO:root:0: Epoch 2 validation loss: 709712.7480691868\nINFO:root:13: Epoch 3 train loss: 12496.33984375\nINFO:root:14: Epoch 3 train loss: 5228.37353515625\nINFO:root:17: Epoch 3 train loss: 103854.626953125\nINFO:root:15: Epoch 3 train loss: 86898.00434684753\nINFO:root:16: Epoch 3 train loss: 5123.9521484375\nINFO:root:2: Epoch 3 train loss: 7249.598146438599\nINFO:root:4: Epoch 3 train loss: 222354.62438964844\nINFO:root:3: Epoch 3 train loss: 635442.3305664062\nINFO:root:6: Epoch 3 train loss: 2576.116455078125\nINFO:root:5: Epoch 3 train loss: 896165.4013671875\nINFO:root:7: Epoch 3 train loss: 8909.516723632812\nINFO:root:12: Epoch 3 train loss: 1108199.171875\nINFO:root:1: Epoch 3 train loss: 706472.1328125\nINFO:root:11: Epoch 3 train loss: 247833.94775390625\nINFO:root:8: Epoch 3 train loss: 13397.895080566406\nINFO:root:10: Epoch 3 train loss: 218552.51599121094\nINFO:root:9: Epoch 3 train loss: 272102.1229248047\nINFO:root:0: Epoch 3 train loss: 895181.5675048828\nINFO:root:0: Epoch 3 validation loss: 709682.9721530576\nINFO:root:15: Epoch 4 train loss: 519300.8540391922\nINFO:root:17: Epoch 4 train loss: 7050.275787353516\nINFO:root:14: Epoch 4 train loss: 2529.3704681396484\nINFO:root:16: Epoch 4 train loss: 1257074.1875\nINFO:root:0: Epoch 4 train loss: 245913.2022705078\nINFO:root:11: Epoch 4 train loss: 4848.2735595703125\nINFO:root:1: Epoch 4 train loss: 1759955.6093444824\nINFO:root:12: Epoch 4 train loss: 570172.2341308594\nINFO:root:13: Epoch 4 train loss: 6060.3095703125\nINFO:root:3: Epoch 4 train loss: 2103.691360473633\nINFO:root:2: Epoch 4 train loss: 354.4810562133789\nINFO:root:5: Epoch 4 train loss: 205522.4158935547\nINFO:root:4: Epoch 4 train loss: 942096.9858398438\nINFO:root:6: Epoch 4 train loss: 250265.36241149902\nINFO:root:7: Epoch 4 train loss: 4704.922180175781\nINFO:root:10: Epoch 4 train loss: 10647.4423828125\nINFO:root:9: Epoch 4 train loss: 6049.72146987915\nINFO:root:8: Epoch 4 train loss: 89240.23376464844\nINFO:root:0: Epoch 4 validation loss: 709652.5511091662\nINFO:root:7: Epoch 5 train loss: 206123.3051147461\nINFO:root:15: Epoch 5 train loss: 406966.2265625\nINFO:root:0: Epoch 5 train loss: 5877.26953125\nINFO:root:1: Epoch 5 train loss: 252487.8995361328\nINFO:root:9: Epoch 5 train loss: 5103.5908203125\nINFO:root:4: Epoch 5 train loss: 11363.51654624939\nINFO:root:12: Epoch 5 train loss: 2557.4769287109375\nINFO:root:14: Epoch 5 train loss: 2223.7199096679688\nINFO:root:17: Epoch 5 train loss: 6914.1990966796875\nINFO:root:11: Epoch 5 train loss: 5357.722473144531\nINFO:root:13: Epoch 5 train loss: 247324.48376464844\nINFO:root:16: Epoch 5 train loss: 16200.33984375\nINFO:root:10: Epoch 5 train loss: 246080.58926391602\nINFO:root:8: Epoch 5 train loss: 248062.3660583496\nINFO:root:6: Epoch 5 train loss: 5884.464744567871\nINFO:root:5: Epoch 5 train loss: 834249.3358154297\nINFO:root:2: Epoch 5 train loss: 2711.768524169922\nINFO:root:3: Epoch 5 train loss: 117321.03955078125\nINFO:root:0: Epoch 5 validation loss: 709620.8487735887\n", "seconds": 17.762314081192017, "batch_size": 128, "nodes": 9, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 2 batches\n2: 2 batches\n19 Start Epoch 0\n19: 2 batches\n4 Start Epoch 0\n12 Start Epoch 0\n4: 2 batches\n12: 2 batches\n3 Start Epoch 0\n3: 2 batches\n15 Start Epoch 0\n11 Start Epoch 0\n15: 2 batches\n11: 2 batches\n7 Start Epoch 0\n8 Start Epoch 0\n7: 2 batches\n8: 2 batches\n16 Start Epoch 0\n16: 2 batches\n14 Start Epoch 0\n14: 2 batches\n5 Start Epoch 0\n6 Start Epoch 0\n5: 2 batches\n13 Start Epoch 0\n6: 2 batches\n13: 2 batches\n9 Start Epoch 0\n17 Start Epoch 0\n9: 2 batches\n10 Start Epoch 0\n17: 2 batches\n10: 2 batches\n18 Start Epoch 0\n18: 2 batches\n19 Start Epoch 1\n19: 2 batches\n18 Start Epoch 1\n18: 2 batches\n2 Start Epoch 1\n7 Start Epoch 1\n3 Start Epoch 1\n6 Start Epoch 1\n2: 2 batches\n7: 2 batches\n3: 2 batches\n6: 2 batches\n14 Start Epoch 1\n15 Start Epoch 1\n14: 2 batches\n15: 2 batches\n5 Start Epoch 1\n16 Start Epoch 1\n17 Start Epoch 1\n5: 2 batches\n4 Start Epoch 1\n10 Start Epoch 1\n13 Start Epoch 1\n17: 2 batches\n16: 2 batches\n8 Start Epoch 1\n4: 2 batches\n10: 2 batches\n11 Start Epoch 1\n13: 2 batches\n9 Start Epoch 1\n8: 2 batches\n11: 2 batches\n12 Start Epoch 1\n12: 2 batches\n9: 2 batches\n1 Start Epoch 1\n1: 2 batches\n0 Start Epoch 1\n0: 2 batches\n7 Start Epoch 2\n7: 2 batches\n2 Start Epoch 2\n3 Start Epoch 2\n3: 2 batches\n19 Start Epoch 2\n2: 2 batches\n18 Start Epoch 2\n19: 2 batches\n18: 2 batches\n1 Start Epoch 2\n1: 2 batches\n5 Start Epoch 2\n5: 2 batches\n8 Start Epoch 2\n4 Start Epoch 2\n10 Start Epoch 2\n17 Start Epoch 2\n15 Start Epoch 2\n8: 2 batches\n4: 2 batches\n11 Start Epoch 2\n13 Start Epoch 2\n17: 2 batches\n14 Start Epoch 2\n14: 2 batches\n9 Start Epoch 2\n11: 2 batches\n12 Start Epoch 2\n16 Start Epoch 2\n15: 2 batches\n9: 2 batches\n10: 2 batches\n13: 2 batches\n16: 2 batches\n12: 2 batches\n6 Start Epoch 2\n6: 2 batches\n0 Start Epoch 2\n0: 2 batches\n15 Start Epoch 3\n6 Start Epoch 3\n14 Start Epoch 3\n3 Start Epoch 3\n14: 2 batches\n6: 2 batches\n19 Start Epoch 3\n7 Start Epoch 3\n2 Start Epoch 3\n7: 2 batches\n3: 2 batches\n19: 2 batches\n2: 2 batches\n18 Start Epoch 3\n18: 2 batches\n10 Start Epoch 3\n13 Start Epoch 3\n11 Start Epoch 3\n4 Start Epoch 3\n11: 2 batches\n12 Start Epoch 3\n8 Start Epoch 3\n1 Start Epoch 3\n1: 2 batches\n17 Start Epoch 3\n9 Start Epoch 3\n5 Start Epoch 3\n12: 2 batches\n16 Start Epoch 3\n8: 2 batches\n4: 2 batches\n10: 2 batches\n17: 2 batches\n9: 2 batches\n5: 2 batches\n13: 2 batches\n16: 2 batches\n15: 2 batches\n0 Start Epoch 3\n0: 2 batches\n3 Start Epoch 4\n15 Start Epoch 4\n2 Start Epoch 4\n14 Start Epoch 4\n19 Start Epoch 4\n2: 2 batches\n14: 2 batches\n19: 2 batches\n15: 2 batches\n18 Start Epoch 4\n3: 2 batches\n18: 2 batches\n7 Start Epoch 4\n7: 2 batches\n1 Start Epoch 4\n1: 2 batches\n6 Start Epoch 4\n6: 2 batches\n17 Start Epoch 4\n12 Start Epoch 4\n17: 2 batches\n8 Start Epoch 4\n4 Start Epoch 4\n10 Start Epoch 4\n5 Start Epoch 4\n11 Start Epoch 4\n13 Start Epoch 4\n9 Start Epoch 4\n16 Start Epoch 4\n9: 2 batches\n4: 2 batches\n10: 2 batches\n12: 2 batches\n13: 2 batches\n16: 2 batches\n8: 2 batches\n5: 2 batches\n11: 2 batches\n0 Start Epoch 4\n0: 2 batches\n19 Start Epoch 5\n19: 2 batches\n7 Start Epoch 5\n14 Start Epoch 5\n7: 2 batches\n2 Start Epoch 5\n17 Start Epoch 5\n18 Start Epoch 5\n2: 2 batches\n17: 2 batches\n14: 2 batches\n16 Start Epoch 5\n15 Start Epoch 5\n18: 2 batches\n3 Start Epoch 5\n3: 2 batches\n16: 2 batches\n15: 2 batches\n1 Start Epoch 5\n1: 2 batches\n6 Start Epoch 5\n6: 2 batches\n5 Start Epoch 5\n10 Start Epoch 5\n13 Start Epoch 5\n9 Start Epoch 5\n9: 2 batches\n4 Start Epoch 5\n11 Start Epoch 5\n12 Start Epoch 5\n8 Start Epoch 5\n8: 2 batches\n5: 2 batches\n11: 2 batches\n13: 2 batches\n12: 2 batches\n4: 2 batches\n10: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:19: Epoch 0 train loss: 173692.89721679688\nINFO:root:18: Epoch 0 train loss: 1834.7730054855347\nINFO:root:3: Epoch 0 train loss: 94246.74153137207\nINFO:root:7: Epoch 0 train loss: 241375.94966125488\nINFO:root:2: Epoch 0 train loss: 5824.8128662109375\nINFO:root:6: Epoch 0 train loss: 999.4005651473999\nINFO:root:14: Epoch 0 train loss: 271611.552734375\nINFO:root:15: Epoch 0 train loss: 11587.005493164062\nINFO:root:0: Epoch 0 train loss: 25441.984985351562\nINFO:root:4: Epoch 0 train loss: 1060.4876098632812\nINFO:root:17: Epoch 0 train loss: 301792.05882287025\nINFO:root:5: Epoch 0 train loss: 205178.52026367188\nINFO:root:16: Epoch 0 train loss: 1980.8184967041016\nINFO:root:10: Epoch 0 train loss: 1831044.80078125\nINFO:root:9: Epoch 0 train loss: 86075.70992934704\nINFO:root:11: Epoch 0 train loss: 87763.51795959473\nINFO:root:13: Epoch 0 train loss: 1746.07666015625\nINFO:root:8: Epoch 0 train loss: 85418.40171813965\nINFO:root:12: Epoch 0 train loss: 7890.39306640625\nINFO:root:1: Epoch 0 train loss: 5350.2252197265625\nINFO:root:0: Epoch 0 validation loss: 229904586.23726356\nINFO:root:7: Epoch 1 train loss: 1056.1908512115479\nINFO:root:3: Epoch 1 train loss: 945.4294738769531\nINFO:root:2: Epoch 1 train loss: 998.8533477783203\nINFO:root:19: Epoch 1 train loss: 10144.062744140625\nINFO:root:18: Epoch 1 train loss: 710.0346755981445\nINFO:root:1: Epoch 1 train loss: 222560.0146484375\nINFO:root:5: Epoch 1 train loss: 616.9157485961914\nINFO:root:9: Epoch 1 train loss: 38511.3681640625\nINFO:root:4: Epoch 1 train loss: 260449.62754821777\nINFO:root:8: Epoch 1 train loss: 175288.33154296875\nINFO:root:17: Epoch 1 train loss: 259835.65280151367\nINFO:root:15: Epoch 1 train loss: 2128.1593627929688\nINFO:root:11: Epoch 1 train loss: 5394.002868652344\nINFO:root:13: Epoch 1 train loss: 15413.135070800781\nINFO:root:10: Epoch 1 train loss: 1650578.324584961\nINFO:root:16: Epoch 1 train loss: 2048.8087310791016\nINFO:root:14: Epoch 1 train loss: 255802.4769897461\nINFO:root:12: Epoch 1 train loss: 30034.035888671875\nINFO:root:6: Epoch 1 train loss: 2464.5156650543213\nINFO:root:0: Epoch 1 train loss: 2454.247314453125\nINFO:root:0: Epoch 1 validation loss: 229904441.45203772\nINFO:root:14: Epoch 2 train loss: 4336.29150390625\nINFO:root:15: Epoch 2 train loss: 1700.7813415527344\nINFO:root:6: Epoch 2 train loss: 271261.9555358887\nINFO:root:7: Epoch 2 train loss: 3700.3029174804688\nINFO:root:3: Epoch 2 train loss: 6129.15966796875\nINFO:root:2: Epoch 2 train loss: 2013.004698753357\nINFO:root:19: Epoch 2 train loss: 426.7979335784912\nINFO:root:18: Epoch 2 train loss: 1313.4634094238281\nINFO:root:13: Epoch 2 train loss: 32452.103759765625\nINFO:root:11: Epoch 2 train loss: 3729.26904296875\nINFO:root:9: Epoch 2 train loss: 8846.90673828125\nINFO:root:4: Epoch 2 train loss: 299940.5447616577\nINFO:root:10: Epoch 2 train loss: 9458.011840820312\nINFO:root:12: Epoch 2 train loss: 3885.948989868164\nINFO:root:16: Epoch 2 train loss: 273886.48919677734\nINFO:root:8: Epoch 2 train loss: 512.5349273681641\nINFO:root:5: Epoch 2 train loss: 268158.9380493164\nINFO:root:17: Epoch 2 train loss: 2564.2455291748047\nINFO:root:1: Epoch 2 train loss: 453533.48020648956\nINFO:root:0: Epoch 2 train loss: 476526.2331542969\nINFO:root:0: Epoch 2 validation loss: 229904332.77284682\nINFO:root:2: Epoch 3 train loss: 259447.7271118164\nINFO:root:15: Epoch 3 train loss: 261944.13690185547\nINFO:root:3: Epoch 3 train loss: 573244.6455078125\nINFO:root:14: Epoch 3 train loss: 1606.041244506836\nINFO:root:19: Epoch 3 train loss: 6765.114013671875\nINFO:root:18: Epoch 3 train loss: 15801.72802734375\nINFO:root:7: Epoch 3 train loss: 3259.0638122558594\nINFO:root:6: Epoch 3 train loss: 4692.971717834473\nINFO:root:17: Epoch 3 train loss: 2635.623950958252\nINFO:root:9: Epoch 3 train loss: 9377.619567871094\nINFO:root:4: Epoch 3 train loss: 1820.0973663330078\nINFO:root:11: Epoch 3 train loss: 346106.7219238281\nINFO:root:13: Epoch 3 train loss: 329042.6117858887\nINFO:root:0: Epoch 3 train loss: 116661.9389038086\nINFO:root:1: Epoch 3 train loss: 12259.34912109375\nINFO:root:8: Epoch 3 train loss: 4550.452237606049\nINFO:root:5: Epoch 3 train loss: 248927.18720912933\nINFO:root:10: Epoch 3 train loss: 1466640.8888549805\nINFO:root:12: Epoch 3 train loss: 251676.4221343994\nINFO:root:16: Epoch 3 train loss: 1598.2782669067383\nINFO:root:0: Epoch 3 validation loss: 229904224.33244106\nINFO:root:7: Epoch 4 train loss: 272651.1905822754\nINFO:root:3: Epoch 4 train loss: 244323.828125\nINFO:root:16: Epoch 4 train loss: 25055.9306640625\nINFO:root:14: Epoch 4 train loss: 2043.4410400390625\nINFO:root:19: Epoch 4 train loss: 16470.033935546875\nINFO:root:17: Epoch 4 train loss: 5132.038896560669\nINFO:root:15: Epoch 4 train loss: 515887.03883361816\nINFO:root:2: Epoch 4 train loss: 1112.5227355957031\nINFO:root:18: Epoch 4 train loss: 5132.2198486328125\nINFO:root:1: Epoch 4 train loss: 6334.882549285889\nINFO:root:0: Epoch 4 train loss: 8610.75048828125\nINFO:root:9: Epoch 4 train loss: 1709.857904434204\nINFO:root:4: Epoch 4 train loss: 273375.939453125\nINFO:root:10: Epoch 4 train loss: 3367186.15625\nINFO:root:13: Epoch 4 train loss: 31845.140625\nINFO:root:6: Epoch 4 train loss: 215924.73959350586\nINFO:root:5: Epoch 4 train loss: 11395.2138671875\nINFO:root:11: Epoch 4 train loss: 1544.4667358398438\nINFO:root:12: Epoch 4 train loss: 28434.747817993164\nINFO:root:8: Epoch 4 train loss: 8490.1494140625\nINFO:root:0: Epoch 4 validation loss: 229904115.82001138\nINFO:root:15: Epoch 5 train loss: 1677.8084716796875\nINFO:root:19: Epoch 5 train loss: 5384.33740234375\nINFO:root:6: Epoch 5 train loss: 580017.6105117798\nINFO:root:2: Epoch 5 train loss: 2155.311092376709\nINFO:root:7: Epoch 5 train loss: 299836.67164611816\nINFO:root:3: Epoch 5 train loss: 224926.296875\nINFO:root:14: Epoch 5 train loss: 619.6272430419922\nINFO:root:18: Epoch 5 train loss: 1830977.0537109375\nINFO:root:1: Epoch 5 train loss: 6307.0255126953125\nINFO:root:9: Epoch 5 train loss: 7387.480037689209\nINFO:root:4: Epoch 5 train loss: 216542.73850393295\nINFO:root:11: Epoch 5 train loss: 268704.37741851807\nINFO:root:13: Epoch 5 train loss: 275231.81842803955\nINFO:root:10: Epoch 5 train loss: 252414.80883789062\nINFO:root:12: Epoch 5 train loss: 3329.0145263671875\nINFO:root:8: Epoch 5 train loss: 3590.7290649414062\nINFO:root:5: Epoch 5 train loss: 8700.59375\nINFO:root:17: Epoch 5 train loss: 273033.02265930176\nINFO:root:16: Epoch 5 train loss: 8652.11865234375\nINFO:root:0: Epoch 5 train loss: 260229.97491455078\nINFO:root:0: Epoch 5 validation loss: 229903971.53106168\n", "seconds": 14.878450155258179, "batch_size": 128, "nodes": 10, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n1 Start Epoch 0\n1: 2 batches\n2 Start Epoch 0\n2: 2 batches\n3 Start Epoch 0\n3: 2 batches\n21 Start Epoch 0\n21: 2 batches\n5 Start Epoch 0\n6 Start Epoch 0\n13 Start Epoch 0\n6: 2 batches\n5: 2 batches\n13: 2 batches\n14 Start Epoch 0\n14: 2 batches\n16 Start Epoch 0\n8 Start Epoch 0\n7 Start Epoch 0\n4 Start Epoch 0\n16: 2 batches\n8: 2 batches\n7: 2 batches\n4: 2 batches\n12 Start Epoch 0\n20 Start Epoch 0\n15 Start Epoch 0\n18 Start Epoch 0\n18: 2 batches\n15: 2 batches\n17 Start Epoch 0\n9 Start Epoch 0\n12: 2 batches\n10 Start Epoch 0\n20: 2 batches\n19 Start Epoch 0\n17: 2 batches\n9: 2 batches\n11 Start Epoch 0\n19: 2 batches\n10: 2 batches\n11: 2 batches\n19 Start Epoch 1\n19: 2 batches\n6 Start Epoch 1\n15 Start Epoch 1\n3 Start Epoch 1\n17 Start Epoch 1\n7 Start Epoch 1\n5 Start Epoch 1\n2 Start Epoch 1\n14 Start Epoch 1\n16 Start Epoch 1\n3: 2 batches\n15: 2 batches\n17: 2 batches\n6: 2 batches\n14: 2 batches\n16: 2 batches\n7: 2 batches\n4 Start Epoch 1\n4: 2 batches\n21 Start Epoch 1\n5: 2 batches\n21: 2 batches\n9 Start Epoch 1\n12 Start Epoch 1\n1 Start Epoch 1\n1: 2 batches\n8 Start Epoch 1\n12: 2 batches\n10 Start Epoch 1\n20 Start Epoch 1\n13 Start Epoch 1\n11 Start Epoch 1\n20: 2 batches\n9: 2 batches\n8: 2 batches\n13: 2 batches\n10: 2 batches\n11: 2 batches\n2: 2 batches\n18 Start Epoch 1\n18: 2 batches\n0 Start Epoch 1\n0: 2 batches\n5 Start Epoch 2\n7 Start Epoch 2\n5: 2 batches\n7: 2 batches\n6 Start Epoch 2\n6: 2 batches\n2 Start Epoch 2\n4 Start Epoch 2\n3 Start Epoch 2\n4: 2 batches\n2: 2 batches\n17 Start Epoch 2\n17: 2 batches\n3: 2 batches\n18 Start Epoch 2\n15 Start Epoch 2\n18: 2 batches\n19 Start Epoch 2\n14 Start Epoch 2\n15: 2 batches\n19: 2 batches\n14: 2 batches\n11 Start Epoch 2\n21 Start Epoch 2\n16 Start Epoch 2\n21: 2 batches\n16: 2 batches\n9 Start Epoch 2\n12 Start Epoch 2\n11: 2 batches\n8 Start Epoch 2\n13 Start Epoch 2\n9: 2 batches\n13: 2 batches\n8: 2 batches\n12: 2 batches\n20 Start Epoch 2\n1 Start Epoch 2\n1: 2 batches\n20: 2 batches\n10 Start Epoch 2\n10: 2 batches\n0 Start Epoch 2\n0: 2 batches\n6 Start Epoch 3\n7 Start Epoch 3\n6: 2 batches\n7: 2 batches\n2 Start Epoch 3\n3 Start Epoch 3\n2: 2 batches\n18 Start Epoch 3\n17 Start Epoch 3\n3: 2 batches\n19 Start Epoch 3\n18: 2 batches\n16 Start Epoch 3\n11 Start Epoch 3\n15 Start Epoch 3\n11: 2 batches\n15: 2 batches\n19: 2 batches\n16: 2 batches\n17: 2 batches\n10 Start Epoch 3\n14 Start Epoch 3\n14: 2 batches\n10: 2 batches\n1 Start Epoch 3\n1: 2 batches\n13 Start Epoch 3\n8 Start Epoch 3\n13: 2 batches\n4 Start Epoch 3\n20 Start Epoch 3\n5 Start Epoch 3\n21 Start Epoch 3\n9 Start Epoch 3\n9: 2 batches\n12 Start Epoch 3\n5: 2 batches\n20: 2 batches\n8: 2 batches\n4: 2 batches\n21: 2 batches\n12: 2 batches\n0 Start Epoch 3\n0: 2 batches\n2 Start Epoch 4\n3 Start Epoch 4\n2: 2 batches\n17 Start Epoch 4\n3: 2 batches\n17: 2 batches\n14 Start Epoch 4\n16 Start Epoch 4\n11 Start Epoch 4\n7 Start Epoch 4\n11: 2 batches\n14: 2 batches\n16: 2 batches\n6 Start Epoch 4\n10 Start Epoch 4\n15 Start Epoch 4\n6: 2 batches\n10: 2 batches\n15: 2 batches\n7: 2 batches\n4 Start Epoch 4\n21 Start Epoch 4\n19 Start Epoch 4\n19: 2 batches\n8 Start Epoch 4\n12 Start Epoch 4\n20 Start Epoch 4\n13 Start Epoch 4\n5 Start Epoch 4\n21: 2 batches\n9 Start Epoch 4\n5: 2 batches\n20: 2 batches\n8: 2 batches\n13: 2 batches\n4: 2 batches\n9: 2 batches\n12: 2 batches\n18 Start Epoch 4\n18: 2 batches\n1 Start Epoch 4\n1: 2 batches\n0 Start Epoch 4\n0: 2 batches\n3 Start Epoch 5\n14 Start Epoch 5\n18 Start Epoch 5\n17 Start Epoch 5\n6 Start Epoch 5\n15 Start Epoch 5\n18: 2 batches\n16 Start Epoch 5\n6: 2 batches\n3: 2 batches\n14: 2 batches\n19 Start Epoch 5\n17: 2 batches\n7 Start Epoch 5\n2 Start Epoch 5\n16: 2 batches\n7: 2 batches\n2: 2 batches\n15: 2 batches\n19: 2 batches\n1 Start Epoch 5\n1: 2 batches\n9 Start Epoch 5\n12 Start Epoch 5\n11 Start Epoch 5\n4 Start Epoch 5\n20 Start Epoch 5\n12: 2 batches\n10 Start Epoch 5\n10: 2 batches\n4: 2 batches\n21 Start Epoch 5\n8 Start Epoch 5\n11: 2 batches\n5 Start Epoch 5\n20: 2 batches\n8: 2 batches\n13 Start Epoch 5\n9: 2 batches\n13: 2 batches\n5: 2 batches\n21: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:19: Epoch 0 train loss: 247251.07678222656\nINFO:root:2: Epoch 0 train loss: 7451.156799316406\nINFO:root:15: Epoch 0 train loss: 12998.299083709717\nINFO:root:16: Epoch 0 train loss: 303686.2556359493\nINFO:root:6: Epoch 0 train loss: 457.4193580150604\nINFO:root:3: Epoch 0 train loss: 28832.85156528352\nINFO:root:17: Epoch 0 train loss: 250329.94677734375\nINFO:root:5: Epoch 0 train loss: 247824.45849609375\nINFO:root:14: Epoch 0 train loss: 1172.6346967220306\nINFO:root:7: Epoch 0 train loss: 450.8433303833008\nINFO:root:4: Epoch 0 train loss: 1987.7617232559937\nINFO:root:20: Epoch 0 train loss: 203487.20485687256\nINFO:root:8: Epoch 0 train loss: 6723.505615234375\nINFO:root:12: Epoch 0 train loss: 1807.4341707229614\nINFO:root:21: Epoch 0 train loss: 39216.489013671875\nINFO:root:9: Epoch 0 train loss: 1171.5630187988281\nINFO:root:13: Epoch 0 train loss: 1831.9247360229492\nINFO:root:10: Epoch 0 train loss: 4551.556133270264\nINFO:root:11: Epoch 0 train loss: 8345.26297467947\nINFO:root:1: Epoch 0 train loss: 1780.507348537445\nINFO:root:0: Epoch 0 train loss: 2567.5108032226562\nINFO:root:18: Epoch 0 train loss: 1657.824312634766\nINFO:root:0: Epoch 0 validation loss: 578746.6260432077\nINFO:root:7: Epoch 1 train loss: 11675.008095599711\nINFO:root:5: Epoch 1 train loss: 507541.7171870172\nINFO:root:6: Epoch 1 train loss: 12813.559051513672\nINFO:root:2: Epoch 1 train loss: 478246.7609863281\nINFO:root:3: Epoch 1 train loss: 6937.283280611038\nINFO:root:4: Epoch 1 train loss: 10315.15412902832\nINFO:root:17: Epoch 1 train loss: 250149.06813049316\nINFO:root:19: Epoch 1 train loss: 10759.004638671875\nINFO:root:14: Epoch 1 train loss: 30428.463592529297\nINFO:root:18: Epoch 1 train loss: 287481.5185546875\nINFO:root:15: Epoch 1 train loss: 29067.091564178467\nINFO:root:16: Epoch 1 train loss: 4912.47474861145\nINFO:root:8: Epoch 1 train loss: 10547.543579101562\nINFO:root:12: Epoch 1 train loss: 313028.2451171875\nINFO:root:11: Epoch 1 train loss: 1721.8668911457062\nINFO:root:21: Epoch 1 train loss: 4032.933967590332\nINFO:root:9: Epoch 1 train loss: 86534.0785484314\nINFO:root:13: Epoch 1 train loss: 1705.9915161132812\nINFO:root:20: Epoch 1 train loss: 4223.470687866211\nINFO:root:1: Epoch 1 train loss: 2449.6710205078125\nINFO:root:0: Epoch 1 train loss: 267.19383430480957\nINFO:root:10: Epoch 1 train loss: 2291.2433853149414\nINFO:root:0: Epoch 1 validation loss: 578725.9112937329\nINFO:root:7: Epoch 2 train loss: 798.5142669677734\nINFO:root:6: Epoch 2 train loss: 262134.65039253235\nINFO:root:2: Epoch 2 train loss: 453596.05817598104\nINFO:root:3: Epoch 2 train loss: 299916.2788333893\nINFO:root:19: Epoch 2 train loss: 215217.3567428589\nINFO:root:18: Epoch 2 train loss: 50.45263147354126\nINFO:root:16: Epoch 2 train loss: 249282.78155326843\nINFO:root:10: Epoch 2 train loss: 8681.492919921875\nINFO:root:15: Epoch 2 train loss: 32846.758405685425\nINFO:root:17: Epoch 2 train loss: 30151.6552734375\nINFO:root:11: Epoch 2 train loss: 75290.51806640625\nINFO:root:14: Epoch 2 train loss: 6958.672096252441\nINFO:root:1: Epoch 2 train loss: 1235.7916412353516\nINFO:root:9: Epoch 2 train loss: 216285.37217578292\nINFO:root:13: Epoch 2 train loss: 1843.7609901428223\nINFO:root:4: Epoch 2 train loss: 4519.600254058838\nINFO:root:20: Epoch 2 train loss: 497880.87646484375\nINFO:root:8: Epoch 2 train loss: 674.7324123382568\nINFO:root:5: Epoch 2 train loss: 300698.6296272278\nINFO:root:21: Epoch 2 train loss: 9623.755126953125\nINFO:root:12: Epoch 2 train loss: 6119.9599609375\nINFO:root:0: Epoch 2 train loss: 242936.8807734251\nINFO:root:0: Epoch 2 validation loss: 578705.6042554603\nINFO:root:3: Epoch 3 train loss: 301604.5203409195\nINFO:root:2: Epoch 3 train loss: 3896.910888671875\nINFO:root:16: Epoch 3 train loss: 1811.3586883544922\nINFO:root:17: Epoch 3 train loss: 88724.33715820312\nINFO:root:14: Epoch 3 train loss: 29254.97156906128\nINFO:root:11: Epoch 3 train loss: 130466.55078125\nINFO:root:15: Epoch 3 train loss: 276347.486328125\nINFO:root:7: Epoch 3 train loss: 3118.82133436203\nINFO:root:10: Epoch 3 train loss: 5763.030241012573\nINFO:root:6: Epoch 3 train loss: 300446.7305584848\nINFO:root:20: Epoch 3 train loss: 249484.49977207184\nINFO:root:21: Epoch 3 train loss: 4465.420826911926\nINFO:root:19: Epoch 3 train loss: 763.0957279205322\nINFO:root:8: Epoch 3 train loss: 10260.089477539062\nINFO:root:12: Epoch 3 train loss: 2312.1357192993164\nINFO:root:4: Epoch 3 train loss: 3413.7028336524963\nINFO:root:9: Epoch 3 train loss: 2620.03648352623\nINFO:root:13: Epoch 3 train loss: 205222.84051513672\nINFO:root:5: Epoch 3 train loss: 205361.84536258504\nINFO:root:0: Epoch 3 train loss: 300979.83556461334\nINFO:root:18: Epoch 3 train loss: 711.1479291915894\nINFO:root:1: Epoch 3 train loss: 1208.8772621154785\nINFO:root:0: Epoch 3 validation loss: 578685.095678769\nINFO:root:2: Epoch 4 train loss: 963.3725924491882\nINFO:root:15: Epoch 4 train loss: 402.19903766014613\nINFO:root:18: Epoch 4 train loss: 837.0564422607422\nINFO:root:17: Epoch 4 train loss: 1223.8656082749367\nINFO:root:6: Epoch 4 train loss: 203926.76197433472\nINFO:root:3: Epoch 4 train loss: 241392.05518388748\nINFO:root:14: Epoch 4 train loss: 274325.9546017647\nINFO:root:19: Epoch 4 train loss: 241066.583984375\nINFO:root:16: Epoch 4 train loss: 812441.46875\nINFO:root:7: Epoch 4 train loss: 10627.548706054688\nINFO:root:1: Epoch 4 train loss: 280.1782341003418\nINFO:root:0: Epoch 4 train loss: 312386.9892578125\nINFO:root:9: Epoch 4 train loss: 1754.7196807861328\nINFO:root:13: Epoch 4 train loss: 223451.2481842041\nINFO:root:10: Epoch 4 train loss: 217224.71479034424\nINFO:root:4: Epoch 4 train loss: 948.2657928466797\nINFO:root:21: Epoch 4 train loss: 152.84609520435333\nINFO:root:11: Epoch 4 train loss: 2341.926067352295\nINFO:root:5: Epoch 4 train loss: 1263.5047636032104\nINFO:root:20: Epoch 4 train loss: 2071.736114025116\nINFO:root:12: Epoch 4 train loss: 307250.29626464844\nINFO:root:8: Epoch 4 train loss: 3895.2830810546875\nINFO:root:0: Epoch 4 validation loss: 578664.8352590718\nINFO:root:1: Epoch 5 train loss: 3334.688127040863\nINFO:root:0: Epoch 5 train loss: 304859.5942169311\nINFO:root:19: Epoch 5 train loss: 9707.348388671875\nINFO:root:6: Epoch 5 train loss: 5138.669727033004\nINFO:root:20: Epoch 5 train loss: 7470.952707290649\nINFO:root:7: Epoch 5 train loss: 8780.631165025756\nINFO:root:21: Epoch 5 train loss: 1824.9374923706055\nINFO:root:18: Epoch 5 train loss: 85633.43106842041\nINFO:root:14: Epoch 5 train loss: 2757.3207330703735\nINFO:root:15: Epoch 5 train loss: 84900.18648275733\nINFO:root:16: Epoch 5 train loss: 1084.4380459785461\nINFO:root:17: Epoch 5 train loss: 3554.4543495178223\nINFO:root:5: Epoch 5 train loss: 2581.3981323242188\nINFO:root:11: Epoch 5 train loss: 2127.2916870117188\nINFO:root:10: Epoch 5 train loss: 244570.15350341797\nINFO:root:4: Epoch 5 train loss: 272799.9916381836\nINFO:root:9: Epoch 5 train loss: 28775.14730297122\nINFO:root:8: Epoch 5 train loss: 34363.71240234375\nINFO:root:3: Epoch 5 train loss: 22328.701171875\nINFO:root:2: Epoch 5 train loss: 1994.5173950195312\nINFO:root:12: Epoch 5 train loss: 302653.5054912567\nINFO:root:13: Epoch 5 train loss: 2993.8538736999035\nINFO:root:0: Epoch 5 validation loss: 578644.1772814937\n", "seconds": 15.424922943115234, "batch_size": 128, "nodes": 11, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n23 Start Epoch 0\n1 Start Epoch 0\n1: 1 batches\n23: 1 batches\n2 Start Epoch 0\n2: 1 batches\n4 Start Epoch 0\n4: 1 batches\n3 Start Epoch 0\n3: 1 batches\n8 Start Epoch 0\n16 Start Epoch 0\n16: 1 batches\n7 Start Epoch 0\n8: 1 batches\n15 Start Epoch 0\n7: 1 batches\n15: 1 batches\n19 Start Epoch 0\n20 Start Epoch 0\n19: 1 batches\n11 Start Epoch 0\n12 Start Epoch 0\n20: 1 batches\n12: 1 batches\n11: 1 batches\n22 Start Epoch 0\n22: 1 batches\n6 Start Epoch 0\n10 Start Epoch 0\n10: 1 batches\n5 Start Epoch 0\n5: 1 batches\n18 Start Epoch 0\n9 Start Epoch 0\n6: 1 batches\n17 Start Epoch 0\n9: 1 batches\n18: 1 batches\n14 Start Epoch 0\n13 Start Epoch 0\n17: 1 batches\n21 Start Epoch 0\n21: 1 batches\n14: 1 batches\n13: 1 batches\n22 Start Epoch 1\n23 Start Epoch 1\n22: 1 batches\n7 Start Epoch 1\n23: 1 batches\n3 Start Epoch 1\n6 Start Epoch 1\n7: 1 batches\n2 Start Epoch 1\n2: 1 batches\n6: 1 batches\n3: 1 batches\n21 Start Epoch 1\n15 Start Epoch 1\n17 Start Epoch 1\n18 Start Epoch 1\n20 Start Epoch 1\n9 Start Epoch 1\n14 Start Epoch 1\n10 Start Epoch 1\n13 Start Epoch 1\n16 Start Epoch 1\n19 Start Epoch 1\n21: 1 batches\n12 Start Epoch 1\n5 Start Epoch 1\n16: 1 batches\n19: 1 batches\n20: 1 batches\n8 Start Epoch 1\n15: 1 batches\n11 Start Epoch 1\n17: 1 batches\n18: 1 batches\n9: 1 batches\n14: 1 batches\n10: 1 batches\n12: 1 batches\n5: 1 batches\n8: 1 batches\n11: 1 batches\n13: 1 batches\n4 Start Epoch 1\n4: 1 batches\n1 Start Epoch 1\n1: 1 batches\n0 Start Epoch 1\n0: 1 batches\n13 Start Epoch 2\n13: 1 batches\n12 Start Epoch 2\n12: 1 batches\n15 Start Epoch 2\n9 Start Epoch 2\n15: 1 batches\n14 Start Epoch 2\n14: 1 batches\n9: 1 batches\n10 Start Epoch 2\n11 Start Epoch 2\n10: 1 batches\n11: 1 batches\n1 Start Epoch 2\n1: 1 batches\n21 Start Epoch 2\n21: 1 batches\n2 Start Epoch 2\n22 Start Epoch 2\n23 Start Epoch 2\n22: 1 batches\n3 Start Epoch 2\n3: 1 batches\n2: 1 batches\n7 Start Epoch 2\n7: 1 batches\n20 Start Epoch 2\n20: 1 batches\n6 Start Epoch 2\n6: 1 batches\n17 Start Epoch 2\n16 Start Epoch 2\n23: 1 batches\n16: 1 batches\n5 Start Epoch 2\n18 Start Epoch 2\n4 Start Epoch 2\n19 Start Epoch 2\n8 Start Epoch 2\n5: 1 batches\n4: 1 batches\n17: 1 batches\n19: 1 batches\n18: 1 batches\n8: 1 batches\n0 Start Epoch 2\n0: 1 batches\n7 Start Epoch 3\n17 Start Epoch 3\n7: 1 batches\n17: 1 batches\n18 Start Epoch 3\n15 Start Epoch 3\n15: 1 batches\n3 Start Epoch 3\n3: 1 batches\n2 Start Epoch 3\n2: 1 batches\n6 Start Epoch 3\n6: 1 batches\n16 Start Epoch 3\n1 Start Epoch 3\n1: 1 batches\n16: 1 batches\n19 Start Epoch 3\n19: 1 batches\n4 Start Epoch 3\n18: 1 batches\n21 Start Epoch 3\n22 Start Epoch 3\n8 Start Epoch 3\n14 Start Epoch 3\n10 Start Epoch 3\n13 Start Epoch 3\n21: 1 batches\n23 Start Epoch 3\n9 Start Epoch 3\n14: 1 batches\n11 Start Epoch 3\n12 Start Epoch 3\n5 Start Epoch 3\n23: 1 batches\n8: 1 batches\n10: 1 batches\n12: 1 batches\n4: 1 batches\n20 Start Epoch 3\n5: 1 batches\n20: 1 batches\n22: 1 batches\n9: 1 batches\n11: 1 batches\n13: 1 batches\n0 Start Epoch 3\n0: 1 batches\n14 Start Epoch 4\n15 Start Epoch 4\n17 Start Epoch 4\n15: 1 batches\n16 Start Epoch 4\n14: 1 batches\n17: 1 batches\n16: 1 batches\n21 Start Epoch 4\n20 Start Epoch 4\n22 Start Epoch 4\n20: 1 batches\n23 Start Epoch 4\n19 Start Epoch 4\n19: 1 batches\n21: 1 batches\n23: 1 batches\n7 Start Epoch 4\n22: 1 batches\n18 Start Epoch 4\n18: 1 batches\n7: 1 batches\n6 Start Epoch 4\n6: 1 batches\n3 Start Epoch 4\n3: 1 batches\n4 Start Epoch 4\n4: 1 batches\n2 Start Epoch 4\n2: 1 batches\n5 Start Epoch 4\n5: 1 batches\n1 Start Epoch 4\n1: 1 batches\n9 Start Epoch 4\n13 Start Epoch 4\n13: 1 batches\n8 Start Epoch 4\n9: 1 batches\n12 Start Epoch 4\n8: 1 batches\n12: 1 batches\n10 Start Epoch 4\n11 Start Epoch 4\n10: 1 batches\n11: 1 batches\n0 Start Epoch 4\n0: 1 batches\n3 Start Epoch 5\n3: 1 batches\n4 Start Epoch 5\n5 Start Epoch 5\n4: 1 batches\n5: 1 batches\n6 Start Epoch 5\n6: 1 batches\n7 Start Epoch 5\n7: 1 batches\n9 Start Epoch 5\n8 Start Epoch 5\n8: 1 batches\n9: 1 batches\n2 Start Epoch 5\n2: 1 batches\n15 Start Epoch 5\n16 Start Epoch 5\n15: 1 batches\n17 Start Epoch 5\n17: 1 batches\n16: 1 batches\n14 Start Epoch 5\n14: 1 batches\n11 Start Epoch 5\n19 Start Epoch 5\n19: 1 batches\n20 Start Epoch 5\n22 Start Epoch 5\n10 Start Epoch 5\n13 Start Epoch 5\n10: 1 batches\n12 Start Epoch 5\n18 Start Epoch 5\n18: 1 batches\n21 Start Epoch 5\n23 Start Epoch 5\n20: 1 batches\n23: 1 batches\n11: 1 batches\n12: 1 batches\n13: 1 batches\n21: 1 batches\n22: 1 batches\n1 Start Epoch 5\n1: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:22: Epoch 0 train loss: 7041.8369140625\nINFO:root:23: Epoch 0 train loss: 60227.23046875\nINFO:root:7: Epoch 0 train loss: 2806.068603515625\nINFO:root:2: Epoch 0 train loss: 30064.49609375\nINFO:root:6: Epoch 0 train loss: 7282.30810546875\nINFO:root:3: Epoch 0 train loss: 2221.089599609375\nINFO:root:18: Epoch 0 train loss: 194181.5\nINFO:root:20: Epoch 0 train loss: 18324.28515625\nINFO:root:10: Epoch 0 train loss: 2070.630859375\nINFO:root:16: Epoch 0 train loss: 524698.5\nINFO:root:21: Epoch 0 train loss: 2598.331787109375\nINFO:root:14: Epoch 0 train loss: 63349.16015625\nINFO:root:17: Epoch 0 train loss: 63012.07421875\nINFO:root:19: Epoch 0 train loss: 631954.0\nINFO:root:8: Epoch 0 train loss: 445287.90625\nINFO:root:15: Epoch 0 train loss: 497136.71875\nINFO:root:12: Epoch 0 train loss: 6179.14892578125\nINFO:root:11: Epoch 0 train loss: 1764.927978515625\nINFO:root:13: Epoch 0 train loss: 515917.4375\nINFO:root:5: Epoch 0 train loss: 5823.220703125\nINFO:root:9: Epoch 0 train loss: 11799.349609375\nINFO:root:4: Epoch 0 train loss: 19371.41796875\nINFO:root:0: Epoch 0 train loss: 5356.15185546875\nINFO:root:1: Epoch 0 train loss: 444831.03125\nINFO:root:0: Epoch 0 validation loss: 2910952.5784912435\nINFO:root:13: Epoch 1 train loss: 13783.126953125\nINFO:root:12: Epoch 1 train loss: 13213.0537109375\nINFO:root:14: Epoch 1 train loss: 179623.546875\nINFO:root:15: Epoch 1 train loss: 1038037.25\nINFO:root:9: Epoch 1 train loss: 561365.4375\nINFO:root:10: Epoch 1 train loss: 5679.42724609375\nINFO:root:11: Epoch 1 train loss: 451989.53125\nINFO:root:1: Epoch 1 train loss: 2990.95166015625\nINFO:root:0: Epoch 1 train loss: 5064.8115234375\nINFO:root:21: Epoch 1 train loss: 181187.15625\nINFO:root:23: Epoch 1 train loss: 527934.4375\nINFO:root:3: Epoch 1 train loss: 58859.390625\nINFO:root:22: Epoch 1 train loss: 2801.073486328125\nINFO:root:2: Epoch 1 train loss: 8430.58203125\nINFO:root:7: Epoch 1 train loss: 4103.29443359375\nINFO:root:20: Epoch 1 train loss: 576435.3125\nINFO:root:6: Epoch 1 train loss: 4002.2587890625\nINFO:root:17: Epoch 1 train loss: 621814.875\nINFO:root:16: Epoch 1 train loss: 3962.43017578125\nINFO:root:19: Epoch 1 train loss: 528106.6875\nINFO:root:5: Epoch 1 train loss: 624.5134887695312\nINFO:root:18: Epoch 1 train loss: 7311.3232421875\nINFO:root:4: Epoch 1 train loss: 10348.177734375\nINFO:root:8: Epoch 1 train loss: 11352.443359375\nINFO:root:0: Epoch 1 validation loss: 2910939.4758732957\nINFO:root:7: Epoch 2 train loss: 1086773.125\nINFO:root:17: Epoch 2 train loss: 4552.4873046875\nINFO:root:19: Epoch 2 train loss: 1671.9390869140625\nINFO:root:18: Epoch 2 train loss: 5372.00439453125\nINFO:root:15: Epoch 2 train loss: 2967.26416015625\nINFO:root:2: Epoch 2 train loss: 13533.51953125\nINFO:root:3: Epoch 2 train loss: 4047.711181640625\nINFO:root:6: Epoch 2 train loss: 625.1156616210938\nINFO:root:16: Epoch 2 train loss: 564365.5\nINFO:root:1: Epoch 2 train loss: 1917.26904296875\nINFO:root:20: Epoch 2 train loss: 23549.51953125\nINFO:root:22: Epoch 2 train loss: 176276.953125\nINFO:root:8: Epoch 2 train loss: 59735.16796875\nINFO:root:10: Epoch 2 train loss: 2702.36279296875\nINFO:root:12: Epoch 2 train loss: 4561.09375\nINFO:root:5: Epoch 2 train loss: 9916.056640625\nINFO:root:21: Epoch 2 train loss: 1831.75244140625\nINFO:root:23: Epoch 2 train loss: 561144.5625\nINFO:root:9: Epoch 2 train loss: 560628.0\nINFO:root:14: Epoch 2 train loss: 6643.4091796875\nINFO:root:11: Epoch 2 train loss: 420348.90625\nINFO:root:13: Epoch 2 train loss: 1163.8623046875\nINFO:root:4: Epoch 2 train loss: 1090.131103515625\nINFO:root:0: Epoch 2 train loss: 509781.125\nINFO:root:0: Epoch 2 validation loss: 2910926.662832847\nINFO:root:14: Epoch 3 train loss: 1239.9656982421875\nINFO:root:15: Epoch 3 train loss: 6704.6025390625\nINFO:root:16: Epoch 3 train loss: 913.5521240234375\nINFO:root:17: Epoch 3 train loss: 6076.1630859375\nINFO:root:20: Epoch 3 train loss: 2570.3369140625\nINFO:root:21: Epoch 3 train loss: 535334.8125\nINFO:root:22: Epoch 3 train loss: 4870.705078125\nINFO:root:23: Epoch 3 train loss: 421000.03125\nINFO:root:19: Epoch 3 train loss: 8111.541015625\nINFO:root:18: Epoch 3 train loss: 1280.3321533203125\nINFO:root:7: Epoch 3 train loss: 1351.1771240234375\nINFO:root:6: Epoch 3 train loss: 505022.375\nINFO:root:3: Epoch 3 train loss: 20090.2734375\nINFO:root:0: Epoch 3 train loss: 7476.697265625\nINFO:root:4: Epoch 3 train loss: 500796.5625\nINFO:root:2: Epoch 3 train loss: 7022.60498046875\nINFO:root:5: Epoch 3 train loss: 12054.451171875\nINFO:root:1: Epoch 3 train loss: 944.8607177734375\nINFO:root:9: Epoch 3 train loss: 9985.9873046875\nINFO:root:13: Epoch 3 train loss: 568998.0\nINFO:root:8: Epoch 3 train loss: 455907.9375\nINFO:root:12: Epoch 3 train loss: 420565.8125\nINFO:root:11: Epoch 3 train loss: 855.3251342773438\nINFO:root:10: Epoch 3 train loss: 7406.287109375\nINFO:root:0: Epoch 3 validation loss: 2910913.6096057873\nINFO:root:3: Epoch 4 train loss: 5039.2666015625\nINFO:root:4: Epoch 4 train loss: 8966.7138671875\nINFO:root:5: Epoch 4 train loss: 5871.8837890625\nINFO:root:6: Epoch 4 train loss: 5668.0107421875\nINFO:root:7: Epoch 4 train loss: 1810.2763671875\nINFO:root:8: Epoch 4 train loss: 936504.8125\nINFO:root:9: Epoch 4 train loss: 428299.15625\nINFO:root:2: Epoch 4 train loss: 10260.884765625\nINFO:root:17: Epoch 4 train loss: 6950.5126953125\nINFO:root:15: Epoch 4 train loss: 7723.91943359375\nINFO:root:16: Epoch 4 train loss: 2336.634033203125\nINFO:root:14: Epoch 4 train loss: 618898.0625\nINFO:root:11: Epoch 4 train loss: 59734.84765625\nINFO:root:18: Epoch 4 train loss: 2282.37158203125\nINFO:root:21: Epoch 4 train loss: 826.1534423828125\nINFO:root:22: Epoch 4 train loss: 2705.31884765625\nINFO:root:10: Epoch 4 train loss: 500083.53125\nINFO:root:12: Epoch 4 train loss: 6408.01806640625\nINFO:root:23: Epoch 4 train loss: 1339.6827392578125\nINFO:root:13: Epoch 4 train loss: 1624.08154296875\nINFO:root:19: Epoch 4 train loss: 2006.48779296875\nINFO:root:20: Epoch 4 train loss: 199993.625\nINFO:root:0: Epoch 4 train loss: 61957.1953125\nINFO:root:1: Epoch 4 train loss: 409.0948486328125\nINFO:root:0: Epoch 4 validation loss: 2910900.238736094\nINFO:root:5: Epoch 5 train loss: 509.99884033203125\nINFO:root:4: Epoch 5 train loss: 2152.211669921875\nINFO:root:18: Epoch 5 train loss: 498561.40625\nINFO:root:19: Epoch 5 train loss: 1123.4478759765625\nINFO:root:8: Epoch 5 train loss: 707934.0625\nINFO:root:20: Epoch 5 train loss: 64539.859375\nINFO:root:23: Epoch 5 train loss: 174671.640625\nINFO:root:9: Epoch 5 train loss: 11593.8955078125\nINFO:root:15: Epoch 5 train loss: 64995.68359375\nINFO:root:14: Epoch 5 train loss: 2904.7724609375\nINFO:root:21: Epoch 5 train loss: 199.29478454589844\nINFO:root:22: Epoch 5 train loss: 626138.5625\nINFO:root:3: Epoch 5 train loss: 178901.8125\nINFO:root:2: Epoch 5 train loss: 1299.478759765625\nINFO:root:0: Epoch 5 train loss: 449403.78125\nINFO:root:1: Epoch 5 train loss: 1982.816162109375\nINFO:root:7: Epoch 5 train loss: 2877.583740234375\nINFO:root:6: Epoch 5 train loss: 539803.4375\nINFO:root:11: Epoch 5 train loss: 186186.3125\nINFO:root:10: Epoch 5 train loss: 3855.48974609375\nINFO:root:16: Epoch 5 train loss: 12779.001953125\nINFO:root:17: Epoch 5 train loss: 12422.4755859375\nINFO:root:13: Epoch 5 train loss: 2720.144775390625\nINFO:root:12: Epoch 5 train loss: 23958.345703125\nINFO:root:0: Epoch 5 validation loss: 2910887.087756677\n", "seconds": 15.361142873764038, "batch_size": 128, "nodes": 12, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.15,192.168.2.15 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n2 Start Epoch 0\n0: 8 batches\n1 Start Epoch 0\n2: 8 batches\n1: 8 batches\n1 Start Epoch 1\n2 Start Epoch 1\n1: 8 batches\n2: 8 batches\n0 Start Epoch 1\n0: 8 batches\n1 Start Epoch 2\n1: 8 batches\n2 Start Epoch 2\n2: 8 batches\n0 Start Epoch 2\n0: 8 batches\n2 Start Epoch 3\n2: 8 batches\n1 Start Epoch 3\n1: 8 batches\n0 Start Epoch 3\n0: 8 batches\n2 Start Epoch 4\n2: 8 batches\n1 Start Epoch 4\n1: 8 batches\n0 Start Epoch 4\n0: 8 batches\n1 Start Epoch 5\n1: 8 batches\n2 Start Epoch 5\n2: 8 batches\n0 Start Epoch 5\n0: 8 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 12754.284980773926\nINFO:root:1: Epoch 0 train loss: 162622.37856292725\nINFO:root:2: Epoch 0 train loss: 280035.8984222412\nINFO:root:0: Epoch 0 validation loss: 109004.68818301524\nINFO:root:0: Epoch 1 train loss: 4626.015293121338\nINFO:root:1: Epoch 1 train loss: 58355.02869415283\nINFO:root:2: Epoch 1 train loss: 86753.69653129578\nINFO:root:0: Epoch 1 validation loss: 108967.76001331367\nINFO:root:0: Epoch 2 train loss: 194449.6902923584\nINFO:root:2: Epoch 2 train loss: 101352.56581115723\nINFO:root:1: Epoch 2 train loss: 77012.29263305664\nINFO:root:0: Epoch 2 validation loss: 108915.70225064906\nINFO:root:2: Epoch 3 train loss: 223041.75965118408\nINFO:root:0: Epoch 3 train loss: 258598.17358398438\nINFO:root:1: Epoch 3 train loss: 269208.23963165283\nINFO:root:0: Epoch 3 validation loss: 108831.10849312128\nINFO:root:1: Epoch 4 train loss: 235646.1608581543\nINFO:root:0: Epoch 4 train loss: 269278.5055541992\nINFO:root:2: Epoch 4 train loss: 87612.72407531738\nINFO:root:0: Epoch 4 validation loss: 108711.62533585701\nINFO:root:1: Epoch 5 train loss: 143445.4612121582\nINFO:root:0: Epoch 5 train loss: 166644.41264343262\nINFO:root:2: Epoch 5 train loss: 136639.5430908203\nINFO:root:0: Epoch 5 validation loss: 108574.77906846636\n", "seconds": 105.0900149345398, "batch_size": 128, "nodes": 1, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.15,192.168.2.2,192.168.2.15,192.168.2.2 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "2 Start Epoch 0\n2: 4 batches\n3 Start Epoch 0\n3: 4 batches\n4 Start Epoch 0\n4: 4 batches\n0 Start Epoch 0\n0: 4 batches\n1 Start Epoch 0\n1: 4 batches\n5 Start Epoch 0\n5: 4 batches\n3 Start Epoch 1\n3: 4 batches\n2 Start Epoch 1\n2: 4 batches\n1 Start Epoch 1\n1: 4 batches\n5 Start Epoch 1\n5: 4 batches\n4 Start Epoch 1\n4: 4 batches\n0 Start Epoch 1\n0: 4 batches\n3 Start Epoch 2\n4 Start Epoch 2\n4: 4 batches\n5 Start Epoch 2\n5: 4 batches\n3: 4 batches\n2 Start Epoch 2\n2: 4 batches\n1 Start Epoch 2\n1: 4 batches\n0 Start Epoch 2\n0: 4 batches\n1 Start Epoch 3\n1: 4 batches\n5 Start Epoch 3\n3 Start Epoch 3\n4 Start Epoch 3\n4: 4 batches\n5: 4 batches\n3: 4 batches\n2 Start Epoch 3\n2: 4 batches\n0 Start Epoch 3\n0: 4 batches\n1 Start Epoch 4\n2 Start Epoch 4\n1: 4 batches\n2: 4 batches\n4 Start Epoch 4\n4: 4 batches\n3 Start Epoch 4\n3: 4 batches\n5 Start Epoch 4\n5: 4 batches\n0 Start Epoch 4\n0: 4 batches\n2 Start Epoch 5\n2: 4 batches\n1 Start Epoch 5\n1: 4 batches\n5 Start Epoch 5\n5: 4 batches\n3 Start Epoch 5\n3: 4 batches\n4 Start Epoch 5\n4: 4 batches\n0 Start Epoch 5\n0: 4 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:3: Epoch 0 train loss: 45422.77424621582\nINFO:root:2: Epoch 0 train loss: 5310.038513183594\nINFO:root:1: Epoch 0 train loss: 6871.113662719727\nINFO:root:0: Epoch 0 train loss: 154549.86589431763\nINFO:root:5: Epoch 0 train loss: 300041.01623535156\nINFO:root:4: Epoch 0 train loss: 200986.06732177734\nINFO:root:0: Epoch 0 validation loss: 60615.96826608164\nINFO:root:5: Epoch 1 train loss: 22184.672302246094\nINFO:root:4: Epoch 1 train loss: 235853.4891052246\nINFO:root:3: Epoch 1 train loss: 4526.529051780701\nINFO:root:0: Epoch 1 train loss: 146669.71647644043\nINFO:root:2: Epoch 1 train loss: 18219.33974456787\nINFO:root:1: Epoch 1 train loss: 162381.27087402344\nINFO:root:0: Epoch 1 validation loss: 60602.428453063665\nINFO:root:1: Epoch 2 train loss: 130387.16467285156\nINFO:root:0: Epoch 2 train loss: 260970.81982421875\nINFO:root:5: Epoch 2 train loss: 130707.98989868164\nINFO:root:4: Epoch 2 train loss: 7996.7646484375\nINFO:root:3: Epoch 2 train loss: 240954.4193725586\nINFO:root:2: Epoch 2 train loss: 286974.1650390625\nINFO:root:0: Epoch 2 validation loss: 60587.84889730926\nINFO:root:1: Epoch 3 train loss: 188752.89208984375\nINFO:root:2: Epoch 3 train loss: 285348.76261138916\nINFO:root:0: Epoch 3 train loss: 107016.10751342773\nINFO:root:3: Epoch 3 train loss: 150202.79919433594\nINFO:root:4: Epoch 3 train loss: 374556.3960571289\nINFO:root:5: Epoch 3 train loss: 3619.114013671875\nINFO:root:0: Epoch 3 validation loss: 60571.33858914958\nINFO:root:2: Epoch 4 train loss: 6608.910385131836\nINFO:root:1: Epoch 4 train loss: 150294.5565185547\nINFO:root:0: Epoch 4 train loss: 252867.27117919922\nINFO:root:5: Epoch 4 train loss: 299772.4557495117\nINFO:root:3: Epoch 4 train loss: 146666.2963256836\nINFO:root:4: Epoch 4 train loss: 370009.27600097656\nINFO:root:0: Epoch 4 validation loss: 60551.80278186596\nINFO:root:3: Epoch 5 train loss: 4447.95068359375\nINFO:root:2: Epoch 5 train loss: 206118.73950195312\nINFO:root:1: Epoch 5 train loss: 520549.8034057617\nINFO:root:0: Epoch 5 train loss: 133142.93886566162\nINFO:root:4: Epoch 5 train loss: 260198.45791625977\nINFO:root:5: Epoch 5 train loss: 128581.208984375\nINFO:root:0: Epoch 5 validation loss: 60528.11995970728\n", "seconds": 56.76447796821594, "batch_size": 128, "nodes": 2, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.15,192.168.2.2,192.168.2.3 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 3 batches\n2 Start Epoch 0\n2: 3 batches\n5 Start Epoch 0\n1 Start Epoch 0\n1: 3 batches\n5: 3 batches\n6 Start Epoch 0\n4 Start Epoch 0\n7 Start Epoch 0\n4: 3 batches\n3 Start Epoch 0\n8 Start Epoch 0\n3: 3 batches\n7: 3 batches\n6: 3 batches\n8: 3 batches\n8 Start Epoch 1\n8: 3 batches\n7 Start Epoch 1\n7: 3 batches\n1 Start Epoch 1\n2 Start Epoch 1\n2: 3 batches\n1: 3 batches\n4 Start Epoch 1\n4: 3 batches\n5 Start Epoch 1\n5: 3 batches\n3 Start Epoch 1\n6 Start Epoch 1\n6: 3 batches\n3: 3 batches\n0 Start Epoch 1\n0: 3 batches\n1 Start Epoch 2\n2 Start Epoch 2\n1: 3 batches\n2: 3 batches\n3 Start Epoch 2\n5 Start Epoch 2\n4 Start Epoch 2\n4: 3 batches\n5: 3 batches\n3: 3 batches\n7 Start Epoch 2\n7: 3 batches\n6 Start Epoch 2\n8 Start Epoch 2\n6: 3 batches\n8: 3 batches\n0 Start Epoch 2\n0: 3 batches\n8 Start Epoch 3\n8: 3 batches\n7 Start Epoch 3\n7: 3 batches\n6 Start Epoch 3\n6: 3 batches\n5 Start Epoch 3\n5: 3 batches\n4 Start Epoch 3\n4: 3 batches\n3 Start Epoch 3\n3: 3 batches\n2 Start Epoch 3\n2: 3 batches\n1 Start Epoch 3\n1: 3 batches\n0 Start Epoch 3\n0: 3 batches\n2 Start Epoch 4\n1 Start Epoch 4\n6 Start Epoch 4\n6: 3 batches\n1: 3 batches\n4 Start Epoch 4\n5 Start Epoch 4\n5: 3 batches\n4: 3 batches\n3 Start Epoch 4\n3: 3 batches\n2: 3 batches\n7 Start Epoch 4\n8 Start Epoch 4\n7: 3 batches\n8: 3 batches\n0 Start Epoch 4\n0: 3 batches\n5 Start Epoch 5\n5: 3 batches\n4 Start Epoch 5\n4: 3 batches\n6 Start Epoch 5\n6: 3 batches\n7 Start Epoch 5\n8 Start Epoch 5\n7: 3 batches\n8: 3 batches\n2 Start Epoch 5\n2: 3 batches\n1 Start Epoch 5\n1: 3 batches\n3 Start Epoch 5\n3: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:8: Epoch 0 train loss: 10634.047648111979\nINFO:root:7: Epoch 0 train loss: 262522.3619791667\nINFO:root:0: Epoch 0 train loss: 3720.26513671875\nINFO:root:2: Epoch 0 train loss: 136741.11779785156\nINFO:root:1: Epoch 0 train loss: 6256.856669108073\nINFO:root:4: Epoch 0 train loss: 660376.4860026041\nINFO:root:5: Epoch 0 train loss: 9885.95068359375\nINFO:root:3: Epoch 0 train loss: 397708.6946614583\nINFO:root:6: Epoch 0 train loss: 28317.23046875\nINFO:root:0: Epoch 0 validation loss: 6275.436360199643\nINFO:root:0: Epoch 1 train loss: 8860.672200520834\nINFO:root:1: Epoch 1 train loss: 34521.467041015625\nINFO:root:2: Epoch 1 train loss: 8319.776326497396\nINFO:root:5: Epoch 1 train loss: 319411.806640625\nINFO:root:3: Epoch 1 train loss: 4742.934000651042\nINFO:root:4: Epoch 1 train loss: 6749.26416015625\nINFO:root:7: Epoch 1 train loss: 5240.522786458333\nINFO:root:6: Epoch 1 train loss: 176687.05541992188\nINFO:root:8: Epoch 1 train loss: 30195.072916666668\nINFO:root:0: Epoch 1 validation loss: 6271.008930251513\nINFO:root:8: Epoch 2 train loss: 173328.5623372396\nINFO:root:7: Epoch 2 train loss: 364013.34423828125\nINFO:root:6: Epoch 2 train loss: 328406.23311360675\nINFO:root:5: Epoch 2 train loss: 201107.16623942056\nINFO:root:4: Epoch 2 train loss: 301533.58357747394\nINFO:root:3: Epoch 2 train loss: 397210.2761230469\nINFO:root:2: Epoch 2 train loss: 4078.8779805501304\nINFO:root:0: Epoch 2 train loss: 1170.2503662109375\nINFO:root:1: Epoch 2 train loss: 3278.6878865559897\nINFO:root:0: Epoch 2 validation loss: 6266.438120541163\nINFO:root:1: Epoch 3 train loss: 26473.56005859375\nINFO:root:0: Epoch 3 train loss: 4921.296142578125\nINFO:root:2: Epoch 3 train loss: 25537.06913248698\nINFO:root:6: Epoch 3 train loss: 202729.30126953125\nINFO:root:5: Epoch 3 train loss: 60580.619873046875\nINFO:root:3: Epoch 3 train loss: 170207.5517578125\nINFO:root:4: Epoch 3 train loss: 494237.9635416667\nINFO:root:7: Epoch 3 train loss: 13590.281005859375\nINFO:root:8: Epoch 3 train loss: 5052.140218098958\nINFO:root:0: Epoch 3 validation loss: 6261.517936216828\nINFO:root:4: Epoch 4 train loss: 4988.770192464192\nINFO:root:5: Epoch 4 train loss: 226590.97721354166\nINFO:root:6: Epoch 4 train loss: 164786.40388997397\nINFO:root:8: Epoch 4 train loss: 24007.732014973957\nINFO:root:7: Epoch 4 train loss: 140466.39933268228\nINFO:root:2: Epoch 4 train loss: 201650.11889648438\nINFO:root:1: Epoch 4 train loss: 314847.8759765625\nINFO:root:0: Epoch 4 train loss: 206247.42277018228\nINFO:root:3: Epoch 4 train loss: 177523.89225260416\nINFO:root:0: Epoch 4 validation loss: 6256.125021612978\nINFO:root:8: Epoch 5 train loss: 5446.8572998046875\nINFO:root:7: Epoch 5 train loss: 368493.619140625\nINFO:root:6: Epoch 5 train loss: 205087.29150390625\nINFO:root:4: Epoch 5 train loss: 220866.66286214194\nINFO:root:3: Epoch 5 train loss: 6132.741455078125\nINFO:root:5: Epoch 5 train loss: 1043.6386311848958\nINFO:root:2: Epoch 5 train loss: 2989.021240234375\nINFO:root:1: Epoch 5 train loss: 4880.569091796875\nINFO:root:0: Epoch 5 train loss: 21522.489339192707\nINFO:root:0: Epoch 5 validation loss: 6250.064309703379\n", "seconds": 42.612468957901, "batch_size": 128, "nodes": 3, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 2 batches\n2: 2 batches\n4 Start Epoch 0\n8 Start Epoch 0\n4: 2 batches\n7 Start Epoch 0\n8: 2 batches\n7: 2 batches\n3 Start Epoch 0\n3: 2 batches\n5 Start Epoch 0\n5: 2 batches\n10 Start Epoch 0\n11 Start Epoch 0\n11: 2 batches\n9 Start Epoch 0\n9: 2 batches\n10: 2 batches\n6 Start Epoch 0\n6: 2 batches\n2 Start Epoch 1\n2: 2 batches\n1 Start Epoch 1\n1: 2 batches\n11 Start Epoch 1\n11: 2 batches\n10 Start Epoch 1\n10: 2 batches\n9 Start Epoch 1\n9: 2 batches\n8 Start Epoch 1\n8: 2 batches\n4 Start Epoch 1\n3 Start Epoch 1\n4: 2 batches\n5 Start Epoch 1\n5: 2 batches\n3: 2 batches\n6 Start Epoch 1\n6: 2 batches\n7 Start Epoch 1\n7: 2 batches\n0 Start Epoch 1\n0: 2 batches\n11 Start Epoch 2\n6 Start Epoch 2\n1 Start Epoch 2\n4 Start Epoch 2\n6: 2 batches\n1: 2 batches\n11: 2 batches\n5 Start Epoch 2\n4: 2 batches\n2 Start Epoch 2\n2: 2 batches\n5: 2 batches\n8 Start Epoch 2\n8: 2 batches\n10 Start Epoch 2\n10: 2 batches\n3 Start Epoch 2\n3: 2 batches\n9 Start Epoch 2\n9: 2 batches\n7 Start Epoch 2\n7: 2 batches\n0 Start Epoch 2\n0: 2 batches\n2 Start Epoch 3\n2: 2 batches\n4 Start Epoch 3\n5 Start Epoch 3\n4: 2 batches\n3 Start Epoch 3\n3: 2 batches\n5: 2 batches\n6 Start Epoch 3\n6: 2 batches\n1 Start Epoch 3\n1: 2 batches\n9 Start Epoch 3\n10 Start Epoch 3\n11 Start Epoch 3\n10: 2 batches\n11: 2 batches\n9: 2 batches\n7 Start Epoch 3\n8 Start Epoch 3\n7: 2 batches\n8: 2 batches\n0 Start Epoch 3\n0: 2 batches\n5 Start Epoch 4\n4 Start Epoch 4\n4: 2 batches\n5: 2 batches\n6 Start Epoch 4\n6: 2 batches\n1 Start Epoch 4\n1: 2 batches\n3 Start Epoch 4\n3: 2 batches\n7 Start Epoch 4\n11 Start Epoch 4\n7: 2 batches\n8 Start Epoch 4\n9 Start Epoch 4\n8: 2 batches\n10 Start Epoch 4\n10: 2 batches\n11: 2 batches\n9: 2 batches\n2 Start Epoch 4\n2: 2 batches\n0 Start Epoch 4\n0: 2 batches\n1 Start Epoch 5\n9 Start Epoch 5\n9: 2 batches\n7 Start Epoch 5\n7: 2 batches\n8 Start Epoch 5\n8: 2 batches\n1: 2 batches\n2 Start Epoch 5\n2: 2 batches\n10 Start Epoch 5\n11 Start Epoch 5\n10: 2 batches\n11: 2 batches\n6 Start Epoch 5\n3 Start Epoch 5\n6: 2 batches\n4 Start Epoch 5\n4: 2 batches\n3: 2 batches\n5 Start Epoch 5\n5: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:2: Epoch 0 train loss: 300587.82275390625\nINFO:root:0: Epoch 0 train loss: 6690.180618286133\nINFO:root:1: Epoch 0 train loss: 37764.453125\nINFO:root:11: Epoch 0 train loss: 36352.01434326172\nINFO:root:10: Epoch 0 train loss: 5280.767639160156\nINFO:root:9: Epoch 0 train loss: 6539.9775390625\nINFO:root:8: Epoch 0 train loss: 8639.875244140625\nINFO:root:3: Epoch 0 train loss: 14108.62939453125\nINFO:root:4: Epoch 0 train loss: 3926.2164306640625\nINFO:root:5: Epoch 0 train loss: 355092.2734375\nINFO:root:6: Epoch 0 train loss: 10050.496337890625\nINFO:root:7: Epoch 0 train loss: 509937.8359375\nINFO:root:0: Epoch 0 validation loss: 31696106.54065332\nINFO:root:5: Epoch 1 train loss: 36067.4609375\nINFO:root:6: Epoch 1 train loss: 4176.064697265625\nINFO:root:11: Epoch 1 train loss: 3453.735107421875\nINFO:root:4: Epoch 1 train loss: 244704.99438476562\nINFO:root:1: Epoch 1 train loss: 11040.76416015625\nINFO:root:0: Epoch 1 train loss: 220332.95065307617\nINFO:root:2: Epoch 1 train loss: 95840.1162109375\nINFO:root:3: Epoch 1 train loss: 1877.1640625\nINFO:root:8: Epoch 1 train loss: 5941.5579833984375\nINFO:root:10: Epoch 1 train loss: 2181.4389038085938\nINFO:root:9: Epoch 1 train loss: 2408.9708251953125\nINFO:root:7: Epoch 1 train loss: 244628.994140625\nINFO:root:0: Epoch 1 validation loss: 31696038.053381227\nINFO:root:2: Epoch 2 train loss: 7740.088562011719\nINFO:root:4: Epoch 2 train loss: 3898.3515625\nINFO:root:3: Epoch 2 train loss: 8585.484375\nINFO:root:5: Epoch 2 train loss: 270290.029296875\nINFO:root:0: Epoch 2 train loss: 14882.1083984375\nINFO:root:1: Epoch 2 train loss: 12515.093505859375\nINFO:root:6: Epoch 2 train loss: 7295.866943359375\nINFO:root:11: Epoch 2 train loss: 573649.4096679688\nINFO:root:9: Epoch 2 train loss: 508050.82092285156\nINFO:root:10: Epoch 2 train loss: 494515.4445800781\nINFO:root:7: Epoch 2 train loss: 545716.0915527344\nINFO:root:8: Epoch 2 train loss: 513656.859375\nINFO:root:0: Epoch 2 validation loss: 31695967.486226756\nINFO:root:5: Epoch 3 train loss: 3236.5892333984375\nINFO:root:4: Epoch 3 train loss: 12122.077453613281\nINFO:root:6: Epoch 3 train loss: 7012.1568603515625\nINFO:root:1: Epoch 3 train loss: 259539.45727539062\nINFO:root:0: Epoch 3 train loss: 87446.03515625\nINFO:root:2: Epoch 3 train loss: 264819.08642578125\nINFO:root:11: Epoch 3 train loss: 220116.0223388672\nINFO:root:8: Epoch 3 train loss: 31364.697021484375\nINFO:root:7: Epoch 3 train loss: 7191.9246826171875\nINFO:root:9: Epoch 3 train loss: 242837.732421875\nINFO:root:3: Epoch 3 train loss: 6746.844482421875\nINFO:root:10: Epoch 3 train loss: 6842.403991699219\nINFO:root:0: Epoch 3 validation loss: 31695901.36357117\nINFO:root:1: Epoch 4 train loss: 3119.4725341796875\nINFO:root:2: Epoch 4 train loss: 7534.1044921875\nINFO:root:8: Epoch 4 train loss: 1564.9918823242188\nINFO:root:9: Epoch 4 train loss: 2170.1557006835938\nINFO:root:7: Epoch 4 train loss: 368559.078125\nINFO:root:10: Epoch 4 train loss: 97973.54333496094\nINFO:root:11: Epoch 4 train loss: 498052.635345459\nINFO:root:0: Epoch 4 train loss: 1671.8309631347656\nINFO:root:5: Epoch 4 train loss: 507262.09375\nINFO:root:6: Epoch 4 train loss: 268958.1591796875\nINFO:root:3: Epoch 4 train loss: 234602.2197265625\nINFO:root:4: Epoch 4 train loss: 262461.33557128906\nINFO:root:0: Epoch 4 validation loss: 31695830.583454475\nINFO:root:8: Epoch 5 train loss: 37257.4208984375\nINFO:root:2: Epoch 5 train loss: 34329.16455078125\nINFO:root:1: Epoch 5 train loss: 10831.51904296875\nINFO:root:0: Epoch 5 train loss: 224550.94329833984\nINFO:root:9: Epoch 5 train loss: 5862.0877685546875\nINFO:root:6: Epoch 5 train loss: 6847.600296020508\nINFO:root:7: Epoch 5 train loss: 33188.5283203125\nINFO:root:10: Epoch 5 train loss: 259406.80920410156\nINFO:root:3: Epoch 5 train loss: 209573.1561279297\nINFO:root:5: Epoch 5 train loss: 12456.82421875\nINFO:root:11: Epoch 5 train loss: 4567.476257324219\nINFO:root:4: Epoch 5 train loss: 15759.94189453125\nINFO:root:0: Epoch 5 validation loss: 31695763.89320774\n", "seconds": 29.556827068328857, "batch_size": 128, "nodes": 4, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n1 Start Epoch 0\n1: 2 batches\n2 Start Epoch 0\n2: 2 batches\n12 Start Epoch 0\n11 Start Epoch 0\n11: 2 batches\n7 Start Epoch 0\n3 Start Epoch 0\n12: 2 batches\n8 Start Epoch 0\n3: 2 batches\n7: 2 batches\n4 Start Epoch 0\n8: 2 batches\n4: 2 batches\n6 Start Epoch 0\n5 Start Epoch 0\n14 Start Epoch 0\n6: 2 batches\n5: 2 batches\n13 Start Epoch 0\n14: 2 batches\n13: 2 batches\n9 Start Epoch 0\n9: 2 batches\n10 Start Epoch 0\n10: 2 batches\n2 Start Epoch 1\n2: 2 batches\n3 Start Epoch 1\n3: 2 batches\n5 Start Epoch 1\n5: 2 batches\n4 Start Epoch 1\n4: 2 batches\n6 Start Epoch 1\n6: 2 batches\n8 Start Epoch 1\n7 Start Epoch 1\n7: 2 batches\n8: 2 batches\n12 Start Epoch 1\n14 Start Epoch 1\n14: 2 batches\n1 Start Epoch 1\n1: 2 batches\n12: 2 batches\n11 Start Epoch 1\n11: 2 batches\n9 Start Epoch 1\n9: 2 batches\n10 Start Epoch 1\n10: 2 batches\n13 Start Epoch 1\n13: 2 batches\n0 Start Epoch 1\n0: 2 batches\n6 Start Epoch 2\n6: 2 batches\n5 Start Epoch 2\n5: 2 batches\n7 Start Epoch 2\n7: 2 batches\n12 Start Epoch 2\n14 Start Epoch 2\n14: 2 batches\n11 Start Epoch 2\n8 Start Epoch 2\n12: 2 batches\n9 Start Epoch 2\n10 Start Epoch 2\n8: 2 batches\n9: 2 batches\n11: 2 batches\n10: 2 batches\n1 Start Epoch 2\n1: 2 batches\n2 Start Epoch 2\n2: 2 batches\n3 Start Epoch 2\n3: 2 batches\n4 Start Epoch 2\n4: 2 batches\n13 Start Epoch 2\n13: 2 batches\n0 Start Epoch 2\n0: 2 batches\n4 Start Epoch 3\n5 Start Epoch 3\n4: 2 batches\n5: 2 batches\n1 Start Epoch 3\n1: 2 batches\n13 Start Epoch 3\n14 Start Epoch 3\n14: 2 batches\n13: 2 batches\n2 Start Epoch 3\n2: 2 batches\n6 Start Epoch 3\n6: 2 batches\n8 Start Epoch 3\n8: 2 batches\n7 Start Epoch 3\n7: 2 batches\n9 Start Epoch 3\n10 Start Epoch 3\n11 Start Epoch 3\n11: 2 batches\n9: 2 batches\n10: 2 batches\n3 Start Epoch 3\n3: 2 batches\n12 Start Epoch 3\n12: 2 batches\n0 Start Epoch 3\n0: 2 batches\n1 Start Epoch 4\n13 Start Epoch 4\n13: 2 batches\n14 Start Epoch 4\n14: 2 batches\n3 Start Epoch 4\n12 Start Epoch 4\n9 Start Epoch 4\n6 Start Epoch 4\n5 Start Epoch 4\n12: 2 batches\n7 Start Epoch 4\n5: 2 batches\n10 Start Epoch 4\n11 Start Epoch 4\n7: 2 batches\n3: 2 batches\n9: 2 batches\n6: 2 batches\n4 Start Epoch 4\n10: 2 batches\n8 Start Epoch 4\n4: 2 batches\n11: 2 batches\n8: 2 batches\n1: 2 batches\n2 Start Epoch 4\n2: 2 batches\n0 Start Epoch 4\n0: 2 batches\n9 Start Epoch 5\n7 Start Epoch 5\n6 Start Epoch 5\n10 Start Epoch 5\n10: 2 batches\n7: 2 batches\n11 Start Epoch 5\n6: 2 batches\n11: 2 batches\n9: 2 batches\n12 Start Epoch 5\n12: 2 batches\n8 Start Epoch 5\n8: 2 batches\n5 Start Epoch 5\n5: 2 batches\n14 Start Epoch 5\n13 Start Epoch 5\n13: 2 batches\n14: 2 batches\n2 Start Epoch 5\n2: 2 batches\n1 Start Epoch 5\n1: 2 batches\n4 Start Epoch 5\n3 Start Epoch 5\n4: 2 batches\n3: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:2: Epoch 0 train loss: 915528.3481445312\nINFO:root:3: Epoch 0 train loss: 224158.5909423828\nINFO:root:4: Epoch 0 train loss: 4808.928955078125\nINFO:root:5: Epoch 0 train loss: 2345.299560546875\nINFO:root:6: Epoch 0 train loss: 156304.63720703125\nINFO:root:8: Epoch 0 train loss: 157489.38647460938\nINFO:root:7: Epoch 0 train loss: 5360.3856201171875\nINFO:root:12: Epoch 0 train loss: 1040609.25\nINFO:root:14: Epoch 0 train loss: 4792.784423828125\nINFO:root:0: Epoch 0 train loss: 2573.82666015625\nINFO:root:1: Epoch 0 train loss: 217006.09790039062\nINFO:root:10: Epoch 0 train loss: 1025089.4868164062\nINFO:root:11: Epoch 0 train loss: 218959.8077392578\nINFO:root:9: Epoch 0 train loss: 4072.766571044922\nINFO:root:13: Epoch 0 train loss: 94125.685546875\nINFO:root:0: Epoch 0 validation loss: 232514694.8348545\nINFO:root:6: Epoch 1 train loss: 453602.4267578125\nINFO:root:5: Epoch 1 train loss: 279439.74743652344\nINFO:root:0: Epoch 1 train loss: 3305.960693359375\nINFO:root:11: Epoch 1 train loss: 275992.83752441406\nINFO:root:7: Epoch 1 train loss: 5191.252685546875\nINFO:root:12: Epoch 1 train loss: 8590.844482421875\nINFO:root:14: Epoch 1 train loss: 31305.733642578125\nINFO:root:10: Epoch 1 train loss: 1878.7371215820312\nINFO:root:9: Epoch 1 train loss: 7913.80570602417\nINFO:root:8: Epoch 1 train loss: 4170.631408691406\nINFO:root:1: Epoch 1 train loss: 1732.2077026367188\nINFO:root:2: Epoch 1 train loss: 290049.45698928833\nINFO:root:3: Epoch 1 train loss: 3464.4578857421875\nINFO:root:4: Epoch 1 train loss: 2070.7557983398438\nINFO:root:13: Epoch 1 train loss: 457556.47833251953\nINFO:root:0: Epoch 1 validation loss: 232514568.64318696\nINFO:root:5: Epoch 2 train loss: 242138.52828979492\nINFO:root:4: Epoch 2 train loss: 7368.194396972656\nINFO:root:2: Epoch 2 train loss: 397776.853515625\nINFO:root:1: Epoch 2 train loss: 2459.4066162109375\nINFO:root:0: Epoch 2 train loss: 11415.495483398438\nINFO:root:14: Epoch 2 train loss: 646584.96875\nINFO:root:13: Epoch 2 train loss: 4743.110809326172\nINFO:root:6: Epoch 2 train loss: 2992.67919921875\nINFO:root:8: Epoch 2 train loss: 5093.1727294921875\nINFO:root:7: Epoch 2 train loss: 9284.485717773438\nINFO:root:11: Epoch 2 train loss: 248256.04821777344\nINFO:root:10: Epoch 2 train loss: 12834.874755859375\nINFO:root:9: Epoch 2 train loss: 13920.134033203125\nINFO:root:3: Epoch 2 train loss: 4811.270751953125\nINFO:root:12: Epoch 2 train loss: 1696.8460083007812\nINFO:root:0: Epoch 2 validation loss: 232514440.51176763\nINFO:root:1: Epoch 3 train loss: 7779.74267578125\nINFO:root:0: Epoch 3 train loss: 4415.965400695801\nINFO:root:2: Epoch 3 train loss: 301210.5153198242\nINFO:root:14: Epoch 3 train loss: 812739.9978942871\nINFO:root:5: Epoch 3 train loss: 208930.12622070312\nINFO:root:13: Epoch 3 train loss: 14601.0390625\nINFO:root:11: Epoch 3 train loss: 1110584.09375\nINFO:root:6: Epoch 3 train loss: 1648.5108337402344\nINFO:root:4: Epoch 3 train loss: 9722.984008789062\nINFO:root:7: Epoch 3 train loss: 97718.78515625\nINFO:root:3: Epoch 3 train loss: 9642.617553710938\nINFO:root:12: Epoch 3 train loss: 4162.8990478515625\nINFO:root:10: Epoch 3 train loss: 809924.671875\nINFO:root:8: Epoch 3 train loss: 4905.2021484375\nINFO:root:9: Epoch 3 train loss: 505887.67041015625\nINFO:root:0: Epoch 3 validation loss: 232514255.91023764\nINFO:root:11: Epoch 4 train loss: 4613.9451904296875\nINFO:root:6: Epoch 4 train loss: 477061.314491272\nINFO:root:7: Epoch 4 train loss: 4192.837005615234\nINFO:root:10: Epoch 4 train loss: 253768.44161224365\nINFO:root:9: Epoch 4 train loss: 3643.9638671875\nINFO:root:8: Epoch 4 train loss: 501517.2126464844\nINFO:root:12: Epoch 4 train loss: 834703.8309326172\nINFO:root:5: Epoch 4 train loss: 4262.0391845703125\nINFO:root:14: Epoch 4 train loss: 217259.36515808105\nINFO:root:13: Epoch 4 train loss: 5539.3739013671875\nINFO:root:2: Epoch 4 train loss: 243901.28442382812\nINFO:root:1: Epoch 4 train loss: 247316.9504852295\nINFO:root:0: Epoch 4 train loss: 29967.469848632812\nINFO:root:4: Epoch 4 train loss: 242743.11743164062\nINFO:root:3: Epoch 4 train loss: 455.2581787109375\nINFO:root:0: Epoch 4 validation loss: 232514086.87849703\nINFO:root:8: Epoch 5 train loss: 450970.9724121094\nINFO:root:11: Epoch 5 train loss: 381003.5017089844\nINFO:root:5: Epoch 5 train loss: 257174.96170806885\nINFO:root:13: Epoch 5 train loss: 206071.40225219727\nINFO:root:12: Epoch 5 train loss: 18208.7138671875\nINFO:root:14: Epoch 5 train loss: 191.9711456298828\nINFO:root:10: Epoch 5 train loss: 8679.4150390625\nINFO:root:9: Epoch 5 train loss: 8778.755615234375\nINFO:root:0: Epoch 5 train loss: 261066.09088134766\nINFO:root:6: Epoch 5 train loss: 2080.056915283203\nINFO:root:7: Epoch 5 train loss: 17802.30352783203\nINFO:root:3: Epoch 5 train loss: 274436.16522216797\nINFO:root:4: Epoch 5 train loss: 3904.5944213867188\nINFO:root:1: Epoch 5 train loss: 740.685302734375\nINFO:root:2: Epoch 5 train loss: 3593.908004760742\nINFO:root:0: Epoch 5 validation loss: 232513895.09005165\n", "seconds": 30.418558835983276, "batch_size": 128, "nodes": 5, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n1 Start Epoch 0\n2 Start Epoch 0\n2: 2 batches\n1: 2 batches\n15 Start Epoch 0\n7 Start Epoch 0\n16 Start Epoch 0\n8 Start Epoch 0\n8: 2 batches\n15: 2 batches\n16: 2 batches\n7: 2 batches\n3 Start Epoch 0\n4 Start Epoch 0\n4: 2 batches\n3: 2 batches\n5 Start Epoch 0\n17 Start Epoch 0\n6 Start Epoch 0\n5: 2 batches\n17: 2 batches\n9 Start Epoch 0\n6: 2 batches\n10 Start Epoch 0\n13 Start Epoch 0\n14 Start Epoch 0\n9: 2 batches\n13: 2 batches\n10: 2 batches\n14: 2 batches\n11 Start Epoch 0\n12 Start Epoch 0\n12: 2 batches\n11: 2 batches\n11 Start Epoch 1\n11: 2 batches\n17 Start Epoch 1\n17: 2 batches\n2 Start Epoch 1\n2: 2 batches\n4 Start Epoch 1\n4: 2 batches\n5 Start Epoch 1\n5: 2 batches\n9 Start Epoch 1\n12 Start Epoch 1\n12: 2 batches\n15 Start Epoch 1\n9: 2 batches\n8 Start Epoch 1\n16 Start Epoch 1\n6 Start Epoch 1\n15: 2 batches\n6: 2 batches\n8: 2 batches\n16: 2 batches\n14 Start Epoch 1\n1 Start Epoch 1\n14: 2 batches\n1: 2 batches\n10 Start Epoch 1\n10: 2 batches\n7 Start Epoch 1\n7: 2 batches\n13 Start Epoch 1\n13: 2 batches\n3 Start Epoch 1\n3: 2 batches\n0 Start Epoch 1\n0: 2 batches\n15 Start Epoch 2\n15: 2 batches\n14 Start Epoch 2\n14: 2 batches\n3 Start Epoch 2\n3: 2 batches\n17 Start Epoch 2\n16 Start Epoch 2\n11 Start Epoch 2\n11: 2 batches\n4 Start Epoch 2\n5 Start Epoch 2\n5: 2 batches\n4: 2 batches\n1 Start Epoch 2\n1: 2 batches\n2 Start Epoch 2\n2: 2 batches\n17: 2 batches\n16: 2 batches\n9 Start Epoch 2\n9: 2 batches\n10 Start Epoch 2\n10: 2 batches\n8 Start Epoch 2\n8: 2 batches\n7 Start Epoch 2\n7: 2 batches\n6 Start Epoch 2\n6: 2 batches\n12 Start Epoch 2\n12: 2 batches\n13 Start Epoch 2\n13: 2 batches\n0 Start Epoch 2\n0: 2 batches\n2 Start Epoch 3\n2: 2 batches\n17 Start Epoch 3\n17: 2 batches\n16 Start Epoch 3\n15 Start Epoch 3\n16: 2 batches\n15: 2 batches\n12 Start Epoch 3\n12: 2 batches\n1 Start Epoch 3\n1: 2 batches\n5 Start Epoch 3\n5: 2 batches\n11 Start Epoch 3\n11: 2 batches\n8 Start Epoch 3\n8: 2 batches\n7 Start Epoch 3\n7: 2 batches\n13 Start Epoch 3\n4 Start Epoch 3\n3 Start Epoch 3\n4: 2 batches\n3: 2 batches\n13: 2 batches\n14 Start Epoch 3\n14: 2 batches\n10 Start Epoch 3\n10: 2 batches\n9 Start Epoch 3\n9: 2 batches\n6 Start Epoch 3\n6: 2 batches\n0 Start Epoch 3\n0: 2 batches\n12 Start Epoch 4\n17 Start Epoch 4\n7 Start Epoch 4\n12: 2 batches\n17: 2 batches\n7: 2 batches\n8 Start Epoch 4\n10 Start Epoch 4\n5 Start Epoch 4\n11 Start Epoch 4\n6 Start Epoch 4\n11: 2 batches\n6: 2 batches\n3 Start Epoch 4\n3: 2 batches\n10: 2 batches\n5: 2 batches\n9 Start Epoch 4\n9: 2 batches\n4 Start Epoch 4\n4: 2 batches\n15 Start Epoch 4\n16 Start Epoch 4\n16: 2 batches\n14 Start Epoch 4\n13 Start Epoch 4\n14: 2 batches\n13: 2 batches\n8: 2 batches\n1 Start Epoch 4\n1: 2 batches\n2 Start Epoch 4\n2: 2 batches\n15: 2 batches\n0 Start Epoch 4\n0: 2 batches\n9 Start Epoch 5\n1 Start Epoch 5\n2 Start Epoch 5\n17 Start Epoch 5\n17: 2 batches\n5 Start Epoch 5\n3 Start Epoch 5\n7 Start Epoch 5\n8 Start Epoch 5\n7: 2 batches\n6 Start Epoch 5\n6: 2 batches\n1: 2 batches\n2: 2 batches\n16 Start Epoch 5\n12 Start Epoch 5\n12: 2 batches\n16: 2 batches\n9: 2 batches\n10 Start Epoch 5\n10: 2 batches\n5: 2 batches\n4 Start Epoch 5\n4: 2 batches\n3: 2 batches\n8: 2 batches\n11 Start Epoch 5\n15 Start Epoch 5\n15: 2 batches\n11: 2 batches\n14 Start Epoch 5\n14: 2 batches\n13 Start Epoch 5\n13: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:11: Epoch 0 train loss: 218.2286720275879\nINFO:root:17: Epoch 0 train loss: 203992.69305419922\nINFO:root:2: Epoch 0 train loss: 749912.3579101562\nINFO:root:4: Epoch 0 train loss: 220551.25268554688\nINFO:root:5: Epoch 0 train loss: 216944.34155273438\nINFO:root:0: Epoch 0 train loss: 260754.97285079956\nINFO:root:12: Epoch 0 train loss: 292938.48403930664\nINFO:root:15: Epoch 0 train loss: 752.9591674804688\nINFO:root:9: Epoch 0 train loss: 1219.8131103515625\nINFO:root:8: Epoch 0 train loss: 5698.061319351196\nINFO:root:16: Epoch 0 train loss: 30234.327026367188\nINFO:root:6: Epoch 0 train loss: 837.569580078125\nINFO:root:1: Epoch 0 train loss: 207471.71020507812\nINFO:root:14: Epoch 0 train loss: 629.3061218261719\nINFO:root:10: Epoch 0 train loss: 3778.748046875\nINFO:root:7: Epoch 0 train loss: 282249.3250384331\nINFO:root:13: Epoch 0 train loss: 266724.892578125\nINFO:root:3: Epoch 0 train loss: 5485.7755126953125\nINFO:root:0: Epoch 0 validation loss: 1762.1191190553122\nINFO:root:15: Epoch 1 train loss: 563722.7316894531\nINFO:root:14: Epoch 1 train loss: 34873.197509765625\nINFO:root:3: Epoch 1 train loss: 1121.2702522277832\nINFO:root:16: Epoch 1 train loss: 640.9803771972656\nINFO:root:17: Epoch 1 train loss: 4302.452930450439\nINFO:root:9: Epoch 1 train loss: 295448.431640625\nINFO:root:11: Epoch 1 train loss: 10838.8779296875\nINFO:root:4: Epoch 1 train loss: 250818.07843017578\nINFO:root:5: Epoch 1 train loss: 1945549.59375\nINFO:root:0: Epoch 1 train loss: 1028308.65625\nINFO:root:2: Epoch 1 train loss: 708135.2622070312\nINFO:root:1: Epoch 1 train loss: 5184.063232421875\nINFO:root:10: Epoch 1 train loss: 5346.75634765625\nINFO:root:7: Epoch 1 train loss: 241810.82525634766\nINFO:root:6: Epoch 1 train loss: 217386.7657775879\nINFO:root:8: Epoch 1 train loss: 3594.8972778320312\nINFO:root:12: Epoch 1 train loss: 1106608.515625\nINFO:root:13: Epoch 1 train loss: 258705.21670532227\nINFO:root:0: Epoch 1 validation loss: 1760.4672101709093\nINFO:root:2: Epoch 2 train loss: 218295.86950683594\nINFO:root:17: Epoch 2 train loss: 6860.927490234375\nINFO:root:0: Epoch 2 train loss: 15049.217163085938\nINFO:root:15: Epoch 2 train loss: 6173.36408996582\nINFO:root:16: Epoch 2 train loss: 271881.67124557495\nINFO:root:12: Epoch 2 train loss: 265381.97265625\nINFO:root:1: Epoch 2 train loss: 11165.400390625\nINFO:root:5: Epoch 2 train loss: 1021.2165222167969\nINFO:root:8: Epoch 2 train loss: 301573.696723938\nINFO:root:11: Epoch 2 train loss: 2489.3285522460938\nINFO:root:7: Epoch 2 train loss: 3674.010498046875\nINFO:root:13: Epoch 2 train loss: 4111.626220703125\nINFO:root:3: Epoch 2 train loss: 937371.5169677734\nINFO:root:4: Epoch 2 train loss: 4644.3175048828125\nINFO:root:14: Epoch 2 train loss: 299805.9801826477\nINFO:root:9: Epoch 2 train loss: 1434.3544616699219\nINFO:root:10: Epoch 2 train loss: 10040.374267578125\nINFO:root:6: Epoch 2 train loss: 1102271.265625\nINFO:root:0: Epoch 2 validation loss: 1758.8361085529984\nINFO:root:17: Epoch 3 train loss: 28061.31805419922\nINFO:root:7: Epoch 3 train loss: 300267.91204833984\nINFO:root:12: Epoch 3 train loss: 2351.2515869140625\nINFO:root:8: Epoch 3 train loss: 2247.6506958007812\nINFO:root:11: Epoch 3 train loss: 3147.4171752929688\nINFO:root:4: Epoch 3 train loss: 227003.111328125\nINFO:root:10: Epoch 3 train loss: 2427.3438720703125\nINFO:root:5: Epoch 3 train loss: 9182.304443359375\nINFO:root:9: Epoch 3 train loss: 2076.5772094726562\nINFO:root:6: Epoch 3 train loss: 32911.648193359375\nINFO:root:3: Epoch 3 train loss: 4088.86865234375\nINFO:root:15: Epoch 3 train loss: 4869.084136962891\nINFO:root:16: Epoch 3 train loss: 206043.29296875\nINFO:root:14: Epoch 3 train loss: 90513.54931640625\nINFO:root:13: Epoch 3 train loss: 2375.6500396728516\nINFO:root:2: Epoch 3 train loss: 16207.99365234375\nINFO:root:1: Epoch 3 train loss: 263132.6237792969\nINFO:root:0: Epoch 3 train loss: 8650.760246276855\nINFO:root:0: Epoch 3 validation loss: 1757.1126972662992\nINFO:root:9: Epoch 4 train loss: 259838.0202331543\nINFO:root:2: Epoch 4 train loss: 204919.32299804688\nINFO:root:1: Epoch 4 train loss: 21946.823974609375\nINFO:root:0: Epoch 4 train loss: 6885.3255615234375\nINFO:root:4: Epoch 4 train loss: 4004.3388671875\nINFO:root:17: Epoch 4 train loss: 2149.62744140625\nINFO:root:5: Epoch 4 train loss: 208631.56626033783\nINFO:root:8: Epoch 4 train loss: 1998.6770629882812\nINFO:root:6: Epoch 4 train loss: 1996.4319458007812\nINFO:root:3: Epoch 4 train loss: 252503.0453491211\nINFO:root:7: Epoch 4 train loss: 261309.9229736328\nINFO:root:16: Epoch 4 train loss: 4014.082530260086\nINFO:root:12: Epoch 4 train loss: 17125.457763671875\nINFO:root:10: Epoch 4 train loss: 271766.71575164795\nINFO:root:11: Epoch 4 train loss: 43795.56396484375\nINFO:root:15: Epoch 4 train loss: 3726.733409881592\nINFO:root:14: Epoch 4 train loss: 9720.4326171875\nINFO:root:13: Epoch 4 train loss: 15441.5810546875\nINFO:root:0: Epoch 4 validation loss: 1755.306690066796\nINFO:root:9: Epoch 5 train loss: 6355.999946594238\nINFO:root:11: Epoch 5 train loss: 3843.7909393310547\nINFO:root:8: Epoch 5 train loss: 1154.8397521972656\nINFO:root:6: Epoch 5 train loss: 4036.5623779296875\nINFO:root:7: Epoch 5 train loss: 7378.207550048828\nINFO:root:5: Epoch 5 train loss: 5811.539306640625\nINFO:root:10: Epoch 5 train loss: 543948.359375\nINFO:root:12: Epoch 5 train loss: 9724.664459228516\nINFO:root:2: Epoch 5 train loss: 523024.681640625\nINFO:root:17: Epoch 5 train loss: 884676.40625\nINFO:root:3: Epoch 5 train loss: 31215.51708984375\nINFO:root:4: Epoch 5 train loss: 27261.3955078125\nINFO:root:15: Epoch 5 train loss: 717.6803588867188\nINFO:root:16: Epoch 5 train loss: 32538.05078125\nINFO:root:14: Epoch 5 train loss: 6396.166959762573\nINFO:root:13: Epoch 5 train loss: 260407.58476257324\nINFO:root:0: Epoch 5 train loss: 6787.0560302734375\nINFO:root:1: Epoch 5 train loss: 7160.681396484375\nINFO:root:0: Epoch 5 validation loss: 1753.3609730490837\n", "seconds": 20.33577299118042, "batch_size": 128, "nodes": 6, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 2 batches\n2: 2 batches\n4 Start Epoch 0\n3 Start Epoch 0\n4: 2 batches\n8 Start Epoch 0\n3: 2 batches\n7 Start Epoch 0\n8: 2 batches\n7: 2 batches\n15 Start Epoch 0\n15: 2 batches\n16 Start Epoch 0\n16: 2 batches\n6 Start Epoch 0\n6: 2 batches\n5 Start Epoch 0\n5: 2 batches\n13 Start Epoch 0\n19 Start Epoch 0\n14 Start Epoch 0\n20 Start Epoch 0\n14: 2 batches\n20: 2 batches\n9 Start Epoch 0\n13: 2 batches\n10 Start Epoch 0\n9: 2 batches\n19: 2 batches\n10: 2 batches\n17 Start Epoch 0\n17: 2 batches\n18 Start Epoch 0\n18: 2 batches\n12 Start Epoch 0\n11 Start Epoch 0\n11: 2 batches\n12: 2 batches\n17 Start Epoch 1\n17: 2 batches\n16 Start Epoch 1\n11 Start Epoch 1\n9 Start Epoch 1\n16: 2 batches\n4 Start Epoch 1\n5 Start Epoch 1\n1 Start Epoch 1\n11: 2 batches\n5: 2 batches\n15 Start Epoch 1\n3 Start Epoch 1\n3: 2 batches\n19 Start Epoch 1\n14 Start Epoch 1\n9: 2 batches\n10 Start Epoch 1\n10: 2 batches\n15: 2 batches\n4: 2 batches\n19: 2 batches\n13 Start Epoch 1\n13: 2 batches\n14: 2 batches\n18 Start Epoch 1\n18: 2 batches\n1: 2 batches\n20 Start Epoch 1\n12 Start Epoch 1\n20: 2 batches\n8 Start Epoch 1\n8: 2 batches\n6 Start Epoch 1\n12: 2 batches\n7 Start Epoch 1\n7: 2 batches\n6: 2 batches\n2 Start Epoch 1\n2: 2 batches\n0 Start Epoch 1\n0: 2 batches\n17 Start Epoch 2\n19 Start Epoch 2\n20 Start Epoch 2\n17: 2 batches\n18 Start Epoch 2\n20: 2 batches\n16 Start Epoch 2\n15 Start Epoch 2\n15: 2 batches\n1 Start Epoch 2\n1: 2 batches\n2 Start Epoch 2\n2: 2 batches\n11 Start Epoch 2\n16: 2 batches\n18: 2 batches\n5 Start Epoch 2\n5: 2 batches\n19: 2 batches\n12 Start Epoch 2\n10 Start Epoch 2\n10: 2 batches\n13 Start Epoch 2\n6 Start Epoch 2\n3 Start Epoch 2\n13: 2 batches\n7 Start Epoch 2\n3: 2 batches\n12: 2 batches\n11: 2 batches\n7: 2 batches\n14 Start Epoch 2\n9 Start Epoch 2\n6: 2 batches\n9: 2 batches\n8 Start Epoch 2\n14: 2 batches\n8: 2 batches\n4 Start Epoch 2\n4: 2 batches\n0 Start Epoch 2\n0: 2 batches\n11 Start Epoch 3\n17 Start Epoch 3\n11: 2 batches\n17: 2 batches\n20 Start Epoch 3\n20: 2 batches\n18 Start Epoch 3\n15 Start Epoch 3\n19 Start Epoch 3\n19: 2 batches\n15: 2 batches\n14 Start Epoch 3\n12 Start Epoch 3\n14: 2 batches\n12: 2 batches\n13 Start Epoch 3\n13: 2 batches\n18: 2 batches\n16 Start Epoch 3\n16: 2 batches\n10 Start Epoch 3\n10: 2 batches\n8 Start Epoch 3\n8: 2 batches\n5 Start Epoch 3\n6 Start Epoch 3\n6: 2 batches\n3 Start Epoch 3\n3: 2 batches\n5: 2 batches\n4 Start Epoch 3\n4: 2 batches\n1 Start Epoch 3\n1: 2 batches\n7 Start Epoch 3\n7: 2 batches\n9 Start Epoch 3\n9: 2 batches\n2 Start Epoch 3\n2: 2 batches\n0 Start Epoch 3\n0: 2 batches\n19 Start Epoch 4\n19: 2 batches\n16 Start Epoch 4\n16: 2 batches\n18 Start Epoch 4\n18: 2 batches\n14 Start Epoch 4\n15 Start Epoch 4\n14: 2 batches\n17 Start Epoch 4\n15: 2 batches\n17: 2 batches\n20 Start Epoch 4\n20: 2 batches\n13 Start Epoch 4\n13: 2 batches\n1 Start Epoch 4\n1: 2 batches\n7 Start Epoch 4\n5 Start Epoch 4\n11 Start Epoch 4\n5: 2 batches\n10 Start Epoch 4\n7: 2 batches\n11: 2 batches\n6 Start Epoch 4\n10: 2 batches\n6: 2 batches\n8 Start Epoch 4\n8: 2 batches\n2 Start Epoch 4\n2: 2 batches\n4 Start Epoch 4\n4: 2 batches\n3 Start Epoch 4\n3: 2 batches\n12 Start Epoch 4\n12: 2 batches\n9 Start Epoch 4\n9: 2 batches\n0 Start Epoch 4\n0: 2 batches\n11 Start Epoch 5\n11: 2 batches\n17 Start Epoch 5\n19 Start Epoch 5\n19: 2 batches\n8 Start Epoch 5\n17: 2 batches\n7 Start Epoch 5\n7: 2 batches\n4 Start Epoch 5\n4: 2 batches\n3 Start Epoch 5\n3: 2 batches\n1 Start Epoch 5\n2 Start Epoch 5\n1: 2 batches\n2: 2 batches\n16 Start Epoch 5\n16: 2 batches\n18 Start Epoch 5\n18: 2 batches\n14 Start Epoch 5\n14: 2 batches\n20 Start Epoch 5\n13 Start Epoch 5\n8: 2 batches\n15 Start Epoch 5\n5 Start Epoch 5\n20: 2 batches\n13: 2 batches\n6 Start Epoch 5\n15: 2 batches\n5: 2 batches\n6: 2 batches\n9 Start Epoch 5\n9: 2 batches\n10 Start Epoch 5\n10: 2 batches\n12 Start Epoch 5\n12: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:16: Epoch 0 train loss: 13716.208862304688\nINFO:root:17: Epoch 0 train loss: 10376.280101776123\nINFO:root:10: Epoch 0 train loss: 1974.2620239257812\nINFO:root:11: Epoch 0 train loss: 6663.74560546875\nINFO:root:9: Epoch 0 train loss: 782.251220703125\nINFO:root:3: Epoch 0 train loss: 557.3019127845764\nINFO:root:4: Epoch 0 train loss: 3701.820432662964\nINFO:root:5: Epoch 0 train loss: 1588.843542098999\nINFO:root:1: Epoch 0 train loss: 223259.740234375\nINFO:root:15: Epoch 0 train loss: 1453.5611996650696\nINFO:root:19: Epoch 0 train loss: 228501.486328125\nINFO:root:14: Epoch 0 train loss: 7635.810615539551\nINFO:root:13: Epoch 0 train loss: 3155.1776027679443\nINFO:root:18: Epoch 0 train loss: 2626.8395385742188\nINFO:root:20: Epoch 0 train loss: 2085.2175827026367\nINFO:root:12: Epoch 0 train loss: 260932.71380615234\nINFO:root:8: Epoch 0 train loss: 4583.534606933594\nINFO:root:6: Epoch 0 train loss: 29207.294921875\nINFO:root:7: Epoch 0 train loss: 1379.047695159912\nINFO:root:0: Epoch 0 train loss: 6680.450000762939\nINFO:root:2: Epoch 0 train loss: 588.5528297424316\nINFO:root:0: Epoch 0 validation loss: 1069254.9660763599\nINFO:root:17: Epoch 1 train loss: 253152.02252197266\nINFO:root:19: Epoch 1 train loss: 731.5499912500381\nINFO:root:20: Epoch 1 train loss: 2586.927028656006\nINFO:root:18: Epoch 1 train loss: 4326.372314453125\nINFO:root:16: Epoch 1 train loss: 19449.138549804688\nINFO:root:15: Epoch 1 train loss: 1757.1337146759033\nINFO:root:12: Epoch 1 train loss: 5538.048263192177\nINFO:root:0: Epoch 1 train loss: 5870.3260498046875\nINFO:root:1: Epoch 1 train loss: 5479.635986328125\nINFO:root:2: Epoch 1 train loss: 91639.66064453125\nINFO:root:6: Epoch 1 train loss: 1661.4188842773438\nINFO:root:5: Epoch 1 train loss: 86351.45825195312\nINFO:root:13: Epoch 1 train loss: 90632.39331054688\nINFO:root:10: Epoch 1 train loss: 7245.6011962890625\nINFO:root:7: Epoch 1 train loss: 2296.2125282287598\nINFO:root:8: Epoch 1 train loss: 284510.36669921875\nINFO:root:3: Epoch 1 train loss: 1154.7730742692947\nINFO:root:11: Epoch 1 train loss: 30900.26806640625\nINFO:root:14: Epoch 1 train loss: 235703.72314453125\nINFO:root:9: Epoch 1 train loss: 271998.4441680908\nINFO:root:4: Epoch 1 train loss: 599.8745880126953\nINFO:root:0: Epoch 1 validation loss: 1069231.1077666676\nINFO:root:17: Epoch 2 train loss: 260867.97667598724\nINFO:root:20: Epoch 2 train loss: 713.0757904052734\nINFO:root:11: Epoch 2 train loss: 11794.607124328613\nINFO:root:18: Epoch 2 train loss: 1842.648959159851\nINFO:root:0: Epoch 2 train loss: 29984.096572875977\nINFO:root:15: Epoch 2 train loss: 1049435.3125\nINFO:root:19: Epoch 2 train loss: 3847.7825927734375\nINFO:root:13: Epoch 2 train loss: 2189.700881958008\nINFO:root:12: Epoch 2 train loss: 274757.4873085022\nINFO:root:14: Epoch 2 train loss: 218214.01229858398\nINFO:root:16: Epoch 2 train loss: 250876.06546020508\nINFO:root:10: Epoch 2 train loss: 247536.57983398438\nINFO:root:8: Epoch 2 train loss: 822.8543701171875\nINFO:root:4: Epoch 2 train loss: 2212.5825657844543\nINFO:root:5: Epoch 2 train loss: 4365.266227722168\nINFO:root:3: Epoch 2 train loss: 546276.8046875\nINFO:root:6: Epoch 2 train loss: 8939.220115661621\nINFO:root:1: Epoch 2 train loss: 349445.0625\nINFO:root:7: Epoch 2 train loss: 1478.3375940322876\nINFO:root:9: Epoch 2 train loss: 2665.197998046875\nINFO:root:2: Epoch 2 train loss: 260130.06103515625\nINFO:root:0: Epoch 2 validation loss: 1069207.1811902758\nINFO:root:19: Epoch 3 train loss: 489361.3203125\nINFO:root:16: Epoch 3 train loss: 244544.51443958282\nINFO:root:18: Epoch 3 train loss: 260904.38846111298\nINFO:root:17: Epoch 3 train loss: 303914.9833984375\nINFO:root:15: Epoch 3 train loss: 1639.7880762517452\nINFO:root:14: Epoch 3 train loss: 279762.388671875\nINFO:root:20: Epoch 3 train loss: 13027.39501953125\nINFO:root:0: Epoch 3 train loss: 86638.21899414062\nINFO:root:13: Epoch 3 train loss: 2477558.2045898438\nINFO:root:1: Epoch 3 train loss: 4251.3291015625\nINFO:root:5: Epoch 3 train loss: 784144.62890625\nINFO:root:10: Epoch 3 train loss: 6081.98934173584\nINFO:root:7: Epoch 3 train loss: 204871.95653438568\nINFO:root:11: Epoch 3 train loss: 7849.564453125\nINFO:root:6: Epoch 3 train loss: 1044.0472153797746\nINFO:root:8: Epoch 3 train loss: 3545.8715534210205\nINFO:root:2: Epoch 3 train loss: 987.7573318481445\nINFO:root:4: Epoch 3 train loss: 6454.819061279297\nINFO:root:3: Epoch 3 train loss: 31737.293731689453\nINFO:root:12: Epoch 3 train loss: 3544.5685653686523\nINFO:root:9: Epoch 3 train loss: 5147.724273681641\nINFO:root:0: Epoch 3 validation loss: 1069182.6147606326\nINFO:root:11: Epoch 4 train loss: 1641.7493104934692\nINFO:root:7: Epoch 4 train loss: 259886.8720703125\nINFO:root:17: Epoch 4 train loss: 696.6993637084961\nINFO:root:19: Epoch 4 train loss: 270950.039188385\nINFO:root:8: Epoch 4 train loss: 2361561.3110351562\nINFO:root:18: Epoch 4 train loss: 312.6996383666992\nINFO:root:4: Epoch 4 train loss: 779.3178176879883\nINFO:root:3: Epoch 4 train loss: 305799.4507121146\nINFO:root:16: Epoch 4 train loss: 299315.4811935425\nINFO:root:2: Epoch 4 train loss: 210666.88427734375\nINFO:root:1: Epoch 4 train loss: 2444.804885864258\nINFO:root:20: Epoch 4 train loss: 489.90796279907227\nINFO:root:13: Epoch 4 train loss: 1972449.3642578125\nINFO:root:14: Epoch 4 train loss: 8695.927001953125\nINFO:root:0: Epoch 4 train loss: 3024.1319580078125\nINFO:root:15: Epoch 4 train loss: 1662.0937194824219\nINFO:root:5: Epoch 4 train loss: 4113.639638900757\nINFO:root:6: Epoch 4 train loss: 5485.706809997559\nINFO:root:9: Epoch 4 train loss: 205535.47857666016\nINFO:root:12: Epoch 4 train loss: 5180.010559082031\nINFO:root:10: Epoch 4 train loss: 8845.55615234375\nINFO:root:0: Epoch 4 validation loss: 1069158.3218797501\nINFO:root:2: Epoch 5 train loss: 302839.2191769779\nINFO:root:1: Epoch 5 train loss: 2355.0226440429688\nINFO:root:9: Epoch 5 train loss: 271812.5866394043\nINFO:root:3: Epoch 5 train loss: 11466.885375976562\nINFO:root:20: Epoch 5 train loss: 2361127.611022949\nINFO:root:8: Epoch 5 train loss: 15335.474853515625\nINFO:root:15: Epoch 5 train loss: 2364748.514892578\nINFO:root:5: Epoch 5 train loss: 3234.414764404297\nINFO:root:10: Epoch 5 train loss: 3447.9179153442383\nINFO:root:7: Epoch 5 train loss: 203467.3246231079\nINFO:root:17: Epoch 5 train loss: 254717.7107849121\nINFO:root:16: Epoch 5 train loss: 5300.88623046875\nINFO:root:18: Epoch 5 train loss: 272630.46405029297\nINFO:root:12: Epoch 5 train loss: 2285566.5318603516\nINFO:root:14: Epoch 5 train loss: 220006.89611816406\nINFO:root:4: Epoch 5 train loss: 4203.551086425781\nINFO:root:13: Epoch 5 train loss: 1198.6146379113197\nINFO:root:0: Epoch 5 train loss: 2208393.88671875\nINFO:root:19: Epoch 5 train loss: 2319.4931640625\nINFO:root:6: Epoch 5 train loss: 266074.57275390625\nINFO:root:11: Epoch 5 train loss: 2648.9545097351074\nINFO:root:0: Epoch 5 validation loss: 1069134.3490086421\n", "seconds": 18.378056049346924, "batch_size": 128, "nodes": 7, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n2 Start Epoch 0\n2: 1 batches\n1 Start Epoch 0\n1: 1 batches\n4 Start Epoch 0\n3 Start Epoch 0\n4: 1 batches\n3: 1 batches\n19 Start Epoch 0\n20 Start Epoch 0\n19: 1 batches\n20: 1 batches\n11 Start Epoch 0\n12 Start Epoch 0\n11: 1 batches\n12: 1 batches\n18 Start Epoch 0\n18: 1 batches\n23 Start Epoch 0\n5 Start Epoch 0\n5: 1 batches\n10 Start Epoch 0\n23: 1 batches\n8 Start Epoch 0\n6 Start Epoch 0\n15 Start Epoch 0\n10: 1 batches\n16 Start Epoch 0\n17 Start Epoch 0\n9 Start Epoch 0\n7 Start Epoch 0\n8: 1 batches\n17: 1 batches\n9: 1 batches\n6: 1 batches\n15: 1 batches\n7: 1 batches\n16: 1 batches\n13 Start Epoch 0\n21 Start Epoch 0\n13: 1 batches\n22 Start Epoch 0\n14 Start Epoch 0\n21: 1 batches\n14: 1 batches\n22: 1 batches\n12 Start Epoch 1\n12: 1 batches\n11 Start Epoch 1\n11: 1 batches\n8 Start Epoch 1\n8: 1 batches\n16 Start Epoch 1\n17 Start Epoch 1\n17: 1 batches\n16: 1 batches\n15 Start Epoch 1\n15: 1 batches\n10 Start Epoch 1\n9 Start Epoch 1\n10: 1 batches\n18 Start Epoch 1\n9: 1 batches\n18: 1 batches\n14 Start Epoch 1\n14: 1 batches\n13 Start Epoch 1\n2 Start Epoch 1\n2: 1 batches\n13: 1 batches\n6 Start Epoch 1\n5 Start Epoch 1\n7 Start Epoch 1\n5: 1 batches\n21 Start Epoch 1\n3 Start Epoch 1\n23 Start Epoch 1\n6: 1 batches\n3: 1 batches\n22 Start Epoch 1\n23: 1 batches\n21: 1 batches\n22: 1 batches\n4 Start Epoch 1\n19 Start Epoch 1\n4: 1 batches\n20 Start Epoch 1\n19: 1 batches\n20: 1 batches\n1 Start Epoch 1\n1: 1 batches\n7: 1 batches\n0 Start Epoch 1\n0: 1 batches\n15 Start Epoch 2\n15: 1 batches\n11 Start Epoch 2\n11: 1 batches\n16 Start Epoch 2\n10 Start Epoch 2\n10: 1 batches\n16: 1 batches\n9 Start Epoch 2\n9: 1 batches\n18 Start Epoch 2\n18: 1 batches\n12 Start Epoch 2\n13 Start Epoch 2\n12: 1 batches\n14 Start Epoch 2\n14: 1 batches\n13: 1 batches\n23 Start Epoch 2\n23: 1 batches\n5 Start Epoch 2\n5: 1 batches\n8 Start Epoch 2\n17 Start Epoch 2\n17: 1 batches\n8: 1 batches\n7 Start Epoch 2\n7: 1 batches\n6 Start Epoch 2\n6: 1 batches\n20 Start Epoch 2\n19 Start Epoch 2\n20: 1 batches\n19: 1 batches\n4 Start Epoch 2\n4: 1 batches\n3 Start Epoch 2\n3: 1 batches\n21 Start Epoch 2\n22 Start Epoch 2\n21: 1 batches\n22: 1 batches\n2 Start Epoch 2\n1 Start Epoch 2\n2: 1 batches\n1: 1 batches\n0 Start Epoch 2\n0: 1 batches\n11 Start Epoch 3\n9 Start Epoch 3\n9: 1 batches\n11: 1 batches\n10 Start Epoch 3\n10: 1 batches\n12 Start Epoch 3\n16 Start Epoch 3\n15 Start Epoch 3\n16: 1 batches\n15: 1 batches\n17 Start Epoch 3\n17: 1 batches\n7 Start Epoch 3\n4 Start Epoch 3\n5 Start Epoch 3\n8 Start Epoch 3\n5: 1 batches\n4: 1 batches\n8: 1 batches\n7: 1 batches\n6 Start Epoch 3\n6: 1 batches\n13 Start Epoch 3\n18 Start Epoch 3\n14 Start Epoch 3\n18: 1 batches\n14: 1 batches\n13: 1 batches\n12: 1 batches\n23 Start Epoch 3\n21 Start Epoch 3\n21: 1 batches\n22 Start Epoch 3\n22: 1 batches\n19 Start Epoch 3\n19: 1 batches\n20 Start Epoch 3\n20: 1 batches\n23: 1 batches\n1 Start Epoch 3\n1: 1 batches\n2 Start Epoch 3\n2: 1 batches\n3 Start Epoch 3\n3: 1 batches\n0 Start Epoch 3\n0: 1 batches\n11 Start Epoch 4\n11: 1 batches\n17 Start Epoch 4\n16 Start Epoch 4\n15 Start Epoch 4\n22 Start Epoch 4\n17: 1 batches\n21 Start Epoch 4\n23 Start Epoch 4\n16: 1 batches\n15: 1 batches\n22: 1 batches\n21: 1 batches\n23: 1 batches\n13 Start Epoch 4\n13: 1 batches\n18 Start Epoch 4\n18: 1 batches\n19 Start Epoch 4\n19: 1 batches\n20 Start Epoch 4\n20: 1 batches\n8 Start Epoch 4\n8: 1 batches\n14 Start Epoch 4\n5 Start Epoch 4\n4 Start Epoch 4\n12 Start Epoch 4\n7 Start Epoch 4\n5: 1 batches\n14: 1 batches\n7: 1 batches\n4: 1 batches\n12: 1 batches\n6 Start Epoch 4\n6: 1 batches\n1 Start Epoch 4\n1: 1 batches\n2 Start Epoch 4\n2: 1 batches\n3 Start Epoch 4\n3: 1 batches\n9 Start Epoch 4\n9: 1 batches\n10 Start Epoch 4\n10: 1 batches\n0 Start Epoch 4\n0: 1 batches\n20 Start Epoch 5\n23 Start Epoch 5\n8 Start Epoch 5\n20: 1 batches\n23: 1 batches\n8: 1 batches\n10 Start Epoch 5\n16 Start Epoch 5\n17 Start Epoch 5\n9 Start Epoch 5\n17: 1 batches\n5 Start Epoch 5\n10: 1 batches\n16: 1 batches\n5: 1 batches\n9: 1 batches\n15 Start Epoch 5\n11 Start Epoch 5\n15: 1 batches\n11: 1 batches\n3 Start Epoch 5\n4 Start Epoch 5\n4: 1 batches\n2 Start Epoch 5\n2: 1 batches\n3: 1 batches\n12 Start Epoch 5\n22 Start Epoch 5\n12: 1 batches\n22: 1 batches\n21 Start Epoch 5\n21: 1 batches\n6 Start Epoch 5\n6: 1 batches\n7 Start Epoch 5\n7: 1 batches\n13 Start Epoch 5\n14 Start Epoch 5\n13: 1 batches\n1 Start Epoch 5\n1: 1 batches\n19 Start Epoch 5\n19: 1 batches\n18 Start Epoch 5\n18: 1 batches\n14: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:12: Epoch 0 train loss: 1876.423583984375\nINFO:root:11: Epoch 0 train loss: 1744.91357421875\nINFO:root:8: Epoch 0 train loss: 10654.1259765625\nINFO:root:16: Epoch 0 train loss: 3388.14892578125\nINFO:root:17: Epoch 0 train loss: 446366.65625\nINFO:root:15: Epoch 0 train loss: 58950.91015625\nINFO:root:10: Epoch 0 train loss: 427206.78125\nINFO:root:9: Epoch 0 train loss: 263.5308532714844\nINFO:root:18: Epoch 0 train loss: 6334.65380859375\nINFO:root:14: Epoch 0 train loss: 560532.9375\nINFO:root:13: Epoch 0 train loss: 419485.6875\nINFO:root:2: Epoch 0 train loss: 794.525146484375\nINFO:root:5: Epoch 0 train loss: 8654.8525390625\nINFO:root:22: Epoch 0 train loss: 6122.33935546875\nINFO:root:21: Epoch 0 train loss: 1022.89404296875\nINFO:root:23: Epoch 0 train loss: 10402.09765625\nINFO:root:7: Epoch 0 train loss: 547663.75\nINFO:root:3: Epoch 0 train loss: 5920.8818359375\nINFO:root:6: Epoch 0 train loss: 2796.805419921875\nINFO:root:0: Epoch 0 train loss: 6218.65380859375\nINFO:root:1: Epoch 0 train loss: 18305.46484375\nINFO:root:4: Epoch 0 train loss: 17407.25\nINFO:root:20: Epoch 0 train loss: 505492.4375\nINFO:root:19: Epoch 0 train loss: 4564.37158203125\nINFO:root:0: Epoch 0 validation loss: 1026.3634123398183\nINFO:root:15: Epoch 1 train loss: 535115.6875\nINFO:root:10: Epoch 1 train loss: 4055.354736328125\nINFO:root:11: Epoch 1 train loss: 3974.57666015625\nINFO:root:16: Epoch 1 train loss: 3349.743408203125\nINFO:root:9: Epoch 1 train loss: 562627.5625\nINFO:root:18: Epoch 1 train loss: 7292.62548828125\nINFO:root:13: Epoch 1 train loss: 618363.6875\nINFO:root:14: Epoch 1 train loss: 566130.8125\nINFO:root:12: Epoch 1 train loss: 1303.758544921875\nINFO:root:23: Epoch 1 train loss: 59515.27734375\nINFO:root:5: Epoch 1 train loss: 21559.646484375\nINFO:root:17: Epoch 1 train loss: 2495.586669921875\nINFO:root:8: Epoch 1 train loss: 2445.989990234375\nINFO:root:7: Epoch 1 train loss: 563001.6875\nINFO:root:6: Epoch 1 train loss: 20699.439453125\nINFO:root:20: Epoch 1 train loss: 7772.04296875\nINFO:root:19: Epoch 1 train loss: 363.6129455566406\nINFO:root:3: Epoch 1 train loss: 5246.7490234375\nINFO:root:4: Epoch 1 train loss: 3496.55419921875\nINFO:root:0: Epoch 1 train loss: 565676.375\nINFO:root:22: Epoch 1 train loss: 10160.4580078125\nINFO:root:21: Epoch 1 train loss: 3271.8681640625\nINFO:root:1: Epoch 1 train loss: 559304.6875\nINFO:root:2: Epoch 1 train loss: 538184.75\nINFO:root:0: Epoch 1 validation loss: 1025.7774481596105\nINFO:root:9: Epoch 2 train loss: 444847.8125\nINFO:root:10: Epoch 2 train loss: 518294.0625\nINFO:root:11: Epoch 2 train loss: 510.5224609375\nINFO:root:12: Epoch 2 train loss: 5932.84033203125\nINFO:root:17: Epoch 2 train loss: 520.929931640625\nINFO:root:16: Epoch 2 train loss: 455.6844787597656\nINFO:root:15: Epoch 2 train loss: 569940.0625\nINFO:root:5: Epoch 2 train loss: 6544.845703125\nINFO:root:8: Epoch 2 train loss: 2761.06005859375\nINFO:root:4: Epoch 2 train loss: 5592.953125\nINFO:root:6: Epoch 2 train loss: 2769.22900390625\nINFO:root:7: Epoch 2 train loss: 5194.71044921875\nINFO:root:13: Epoch 2 train loss: 11127.0751953125\nINFO:root:14: Epoch 2 train loss: 5615.052734375\nINFO:root:18: Epoch 2 train loss: 8274.4013671875\nINFO:root:21: Epoch 2 train loss: 1561.1812744140625\nINFO:root:23: Epoch 2 train loss: 185586.984375\nINFO:root:22: Epoch 2 train loss: 1655.48486328125\nINFO:root:19: Epoch 2 train loss: 1386.3359375\nINFO:root:20: Epoch 2 train loss: 547.2527465820312\nINFO:root:2: Epoch 2 train loss: 2810.27685546875\nINFO:root:0: Epoch 2 train loss: 453666.34375\nINFO:root:1: Epoch 2 train loss: 564409.3125\nINFO:root:3: Epoch 2 train loss: 3877.86279296875\nINFO:root:0: Epoch 2 validation loss: 1025.170958434649\nINFO:root:11: Epoch 3 train loss: 59034.29296875\nINFO:root:15: Epoch 3 train loss: 3168.47607421875\nINFO:root:17: Epoch 3 train loss: 6329.60205078125\nINFO:root:22: Epoch 3 train loss: 6442.3251953125\nINFO:root:16: Epoch 3 train loss: 5780.43994140625\nINFO:root:21: Epoch 3 train loss: 1420.4951171875\nINFO:root:23: Epoch 3 train loss: 1574.2861328125\nINFO:root:13: Epoch 3 train loss: 3595.863037109375\nINFO:root:18: Epoch 3 train loss: 620288.5\nINFO:root:19: Epoch 3 train loss: 517824.78125\nINFO:root:20: Epoch 3 train loss: 2062.37158203125\nINFO:root:8: Epoch 3 train loss: 621275.625\nINFO:root:4: Epoch 3 train loss: 1304.4481201171875\nINFO:root:14: Epoch 3 train loss: 9721.9814453125\nINFO:root:7: Epoch 3 train loss: 519205.3125\nINFO:root:5: Epoch 3 train loss: 621876.375\nINFO:root:12: Epoch 3 train loss: 943299.6875\nINFO:root:6: Epoch 3 train loss: 1046051.75\nINFO:root:1: Epoch 3 train loss: 1836.3653564453125\nINFO:root:2: Epoch 3 train loss: 447158.15625\nINFO:root:3: Epoch 3 train loss: 6172.67919921875\nINFO:root:0: Epoch 3 train loss: 4980.5048828125\nINFO:root:9: Epoch 3 train loss: 3342.31298828125\nINFO:root:10: Epoch 3 train loss: 523828.34375\nINFO:root:0: Epoch 3 validation loss: 1024.5605345793583\nINFO:root:20: Epoch 4 train loss: 2773.568603515625\nINFO:root:23: Epoch 4 train loss: 527548.125\nINFO:root:8: Epoch 4 train loss: 14906.3134765625\nINFO:root:10: Epoch 4 train loss: 4104.77490234375\nINFO:root:15: Epoch 4 train loss: 11923.302734375\nINFO:root:9: Epoch 4 train loss: 5117.59716796875\nINFO:root:17: Epoch 4 train loss: 507614.125\nINFO:root:16: Epoch 4 train loss: 2016.80615234375\nINFO:root:11: Epoch 4 train loss: 5857.26708984375\nINFO:root:5: Epoch 4 train loss: 3802.17724609375\nINFO:root:4: Epoch 4 train loss: 6081.16748046875\nINFO:root:3: Epoch 4 train loss: 2689.23388671875\nINFO:root:22: Epoch 4 train loss: 3839.835693359375\nINFO:root:0: Epoch 4 train loss: 323.00152587890625\nINFO:root:2: Epoch 4 train loss: 12547.1162109375\nINFO:root:6: Epoch 4 train loss: 536287.9375\nINFO:root:12: Epoch 4 train loss: 21956.5078125\nINFO:root:21: Epoch 4 train loss: 11744.8505859375\nINFO:root:7: Epoch 4 train loss: 2756.067626953125\nINFO:root:13: Epoch 4 train loss: 3920.92822265625\nINFO:root:14: Epoch 4 train loss: 822.2733764648438\nINFO:root:1: Epoch 4 train loss: 2899.17041015625\nINFO:root:18: Epoch 4 train loss: 176398.9375\nINFO:root:19: Epoch 4 train loss: 182956.3125\nINFO:root:0: Epoch 4 validation loss: 1023.9279025852167\nINFO:root:8: Epoch 5 train loss: 6076.24951171875\nINFO:root:5: Epoch 5 train loss: 2089.449462890625\nINFO:root:4: Epoch 5 train loss: 1836.6932373046875\nINFO:root:11: Epoch 5 train loss: 876.8717651367188\nINFO:root:7: Epoch 5 train loss: 2943.5068359375\nINFO:root:10: Epoch 5 train loss: 19287.158203125\nINFO:root:6: Epoch 5 train loss: 2190.44580078125\nINFO:root:9: Epoch 5 train loss: 59997.2734375\nINFO:root:12: Epoch 5 train loss: 966.3765869140625\nINFO:root:3: Epoch 5 train loss: 994.2276611328125\nINFO:root:23: Epoch 5 train loss: 1450.405029296875\nINFO:root:17: Epoch 5 train loss: 630.3230590820312\nINFO:root:16: Epoch 5 train loss: 4948.6669921875\nINFO:root:15: Epoch 5 train loss: 500746.5625\nINFO:root:18: Epoch 5 train loss: 7139.044921875\nINFO:root:13: Epoch 5 train loss: 186196.625\nINFO:root:19: Epoch 5 train loss: 178171.359375\nINFO:root:14: Epoch 5 train loss: 14186.572265625\nINFO:root:1: Epoch 5 train loss: 3828.001220703125\nINFO:root:0: Epoch 5 train loss: 299.3211669921875\nINFO:root:2: Epoch 5 train loss: 174891.265625\nINFO:root:21: Epoch 5 train loss: 2954.1669921875\nINFO:root:22: Epoch 5 train loss: 88.28882598876953\nINFO:root:20: Epoch 5 train loss: 497652.84375\nINFO:root:0: Epoch 5 validation loss: 1023.278892450677\n", "seconds": 19.266512870788574, "batch_size": 128, "nodes": 8, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 1 batches\n2: 1 batches\n3 Start Epoch 0\n4 Start Epoch 0\n4: 1 batches\n3: 1 batches\n11 Start Epoch 0\n11: 1 batches\n19 Start Epoch 0\n12 Start Epoch 0\n12: 1 batches\n20 Start Epoch 0\n24 Start Epoch 0\n23 Start Epoch 0\n5 Start Epoch 0\n24: 1 batches\n23: 1 batches\n15 Start Epoch 0\n5: 1 batches\n7 Start Epoch 0\n16 Start Epoch 0\n7: 1 batches\n16: 1 batches\n15: 1 batches\n8 Start Epoch 0\n8: 1 batches\n19: 1 batches\n20: 1 batches\n6 Start Epoch 0\n6: 1 batches\n25 Start Epoch 0\n26 Start Epoch 0\n26: 1 batches\n25: 1 batches\n13 Start Epoch 0\n14 Start Epoch 0\n18 Start Epoch 0\n13: 1 batches\n18: 1 batches\n14: 1 batches\n21 Start Epoch 0\n17 Start Epoch 0\n22 Start Epoch 0\n22: 1 batches\n17: 1 batches\n21: 1 batches\n9 Start Epoch 0\n9: 1 batches\n10 Start Epoch 0\n10: 1 batches\n8 Start Epoch 1\n8: 1 batches\n7 Start Epoch 1\n7: 1 batches\n10 Start Epoch 1\n10: 1 batches\n11 Start Epoch 1\n11: 1 batches\n9 Start Epoch 1\n9: 1 batches\n12 Start Epoch 1\n12: 1 batches\n6 Start Epoch 1\n6: 1 batches\n26 Start Epoch 1\n26: 1 batches\n23 Start Epoch 1\n22 Start Epoch 1\n19 Start Epoch 1\n22: 1 batches\n18 Start Epoch 1\n21 Start Epoch 1\n19: 1 batches\n21: 1 batches\n20 Start Epoch 1\n23: 1 batches\n20: 1 batches\n18: 1 batches\n14 Start Epoch 1\n13 Start Epoch 1\n14: 1 batches\n1 Start Epoch 1\n1: 1 batches\n16 Start Epoch 1\n17 Start Epoch 1\n13: 1 batches\n16: 1 batches\n15 Start Epoch 1\n15: 1 batches\n17: 1 batches\n3 Start Epoch 1\n3: 1 batches\n5 Start Epoch 1\n5: 1 batches\n2 Start Epoch 1\n2: 1 batches\n24 Start Epoch 1\n25 Start Epoch 1\n24: 1 batches\n25: 1 batches\n4 Start Epoch 1\n4: 1 batches\n0 Start Epoch 1\n0: 1 batches\n11 Start Epoch 2\n26 Start Epoch 2\n11: 1 batches\n8 Start Epoch 2\n8: 1 batches\n22 Start Epoch 2\n23 Start Epoch 2\n3 Start Epoch 2\n26: 1 batches\n23: 1 batches\n4 Start Epoch 2\n21 Start Epoch 2\n3: 1 batches\n21: 1 batches\n22: 1 batches\n4: 1 batches\n5 Start Epoch 2\n5: 1 batches\n9 Start Epoch 2\n6 Start Epoch 2\n9: 1 batches\n24 Start Epoch 2\n6: 1 batches\n25 Start Epoch 2\n7 Start Epoch 2\n24: 1 batches\n16 Start Epoch 2\n18 Start Epoch 2\n12 Start Epoch 2\n25: 1 batches\n17 Start Epoch 2\n19 Start Epoch 2\n14 Start Epoch 2\n7: 1 batches\n16: 1 batches\n18: 1 batches\n12: 1 batches\n15 Start Epoch 2\n19: 1 batches\n14: 1 batches\n20 Start Epoch 2\n13 Start Epoch 2\n15: 1 batches\n13: 1 batches\n17: 1 batches\n20: 1 batches\n1 Start Epoch 2\n1: 1 batches\n2 Start Epoch 2\n2: 1 batches\n10 Start Epoch 2\n10: 1 batches\n0 Start Epoch 2\n0: 1 batches\n23 Start Epoch 3\n23: 1 batches\n15 Start Epoch 3\n15: 1 batches\n17 Start Epoch 3\n21 Start Epoch 3\n21: 1 batches\n16 Start Epoch 3\n19 Start Epoch 3\n16: 1 batches\n20 Start Epoch 3\n17: 1 batches\n19: 1 batches\n20: 1 batches\n22 Start Epoch 3\n22: 1 batches\n7 Start Epoch 3\n7: 1 batches\n5 Start Epoch 3\n26 Start Epoch 3\n9 Start Epoch 3\n25 Start Epoch 3\n10 Start Epoch 3\n25: 1 batches\n9: 1 batches\n10: 1 batches\n4 Start Epoch 3\n11 Start Epoch 3\n3 Start Epoch 3\n8 Start Epoch 3\n11: 1 batches\n4: 1 batches\n3: 1 batches\n5: 1 batches\n6 Start Epoch 3\n12 Start Epoch 3\n6: 1 batches\n12: 1 batches\n24 Start Epoch 3\n18 Start Epoch 3\n26: 1 batches\n18: 1 batches\n24: 1 batches\n8: 1 batches\n14 Start Epoch 3\n1 Start Epoch 3\n1: 1 batches\n13 Start Epoch 3\n13: 1 batches\n14: 1 batches\n2 Start Epoch 3\n2: 1 batches\n0 Start Epoch 3\n0: 1 batches\n11 Start Epoch 4\n11: 1 batches\n17 Start Epoch 4\n9 Start Epoch 4\n10 Start Epoch 4\n10: 1 batches\n9: 1 batches\n12 Start Epoch 4\n13 Start Epoch 4\n13: 1 batches\n14 Start Epoch 4\n14: 1 batches\n12: 1 batches\n6 Start Epoch 4\n3 Start Epoch 4\n22 Start Epoch 4\n8 Start Epoch 4\n4 Start Epoch 4\n23 Start Epoch 4\n3: 1 batches\n22: 1 batches\n4: 1 batches\n23: 1 batches\n5 Start Epoch 4\n15 Start Epoch 4\n21 Start Epoch 4\n1 Start Epoch 4\n1: 1 batches\n18 Start Epoch 4\n5: 1 batches\n16 Start Epoch 4\n16: 1 batches\n21: 1 batches\n25 Start Epoch 4\n18: 1 batches\n25: 1 batches\n15: 1 batches\n17: 1 batches\n20 Start Epoch 4\n20: 1 batches\n6: 1 batches\n8: 1 batches\n7 Start Epoch 4\n7: 1 batches\n26 Start Epoch 4\n2 Start Epoch 4\n2: 1 batches\n26: 1 batches\n24 Start Epoch 4\n24: 1 batches\n19 Start Epoch 4\n19: 1 batches\n0 Start Epoch 4\n0: 1 batches\n15 Start Epoch 5\n15: 1 batches\n11 Start Epoch 5\n11: 1 batches\n4 Start Epoch 5\n13 Start Epoch 5\n3 Start Epoch 5\n13: 1 batches\n4: 1 batches\n8 Start Epoch 5\n10 Start Epoch 5\n10: 1 batches\n3: 1 batches\n6 Start Epoch 5\n9 Start Epoch 5\n9: 1 batches\n5 Start Epoch 5\n6: 1 batches\n5: 1 batches\n7 Start Epoch 5\n7: 1 batches\n8: 1 batches\n1 Start Epoch 5\n1: 1 batches\n14 Start Epoch 5\n2 Start Epoch 5\n2: 1 batches\n12 Start Epoch 5\n12: 1 batches\n14: 1 batches\n25 Start Epoch 5\n25: 1 batches\n26 Start Epoch 5\n26: 1 batches\n23 Start Epoch 5\n19 Start Epoch 5\n16 Start Epoch 5\n19: 1 batches\n16: 1 batches\n17 Start Epoch 5\n17: 1 batches\n24 Start Epoch 5\n24: 1 batches\n21 Start Epoch 5\n21: 1 batches\n23: 1 batches\n22 Start Epoch 5\n22: 1 batches\n20 Start Epoch 5\n18 Start Epoch 5\n20: 1 batches\n18: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:8: Epoch 0 train loss: 1379.15283203125\nINFO:root:7: Epoch 0 train loss: 1203238.0\nINFO:root:9: Epoch 0 train loss: 600.1771850585938\nINFO:root:11: Epoch 0 train loss: 1108852.375\nINFO:root:10: Epoch 0 train loss: 1302.3116455078125\nINFO:root:12: Epoch 0 train loss: 587303.5\nINFO:root:6: Epoch 0 train loss: 6634.08203125\nINFO:root:26: Epoch 0 train loss: 1265.301025390625\nINFO:root:21: Epoch 0 train loss: 5097.18310546875\nINFO:root:22: Epoch 0 train loss: 6285.69091796875\nINFO:root:20: Epoch 0 train loss: 602668.5\nINFO:root:23: Epoch 0 train loss: 2535.363525390625\nINFO:root:19: Epoch 0 train loss: 833.7130737304688\nINFO:root:18: Epoch 0 train loss: 13754.9443359375\nINFO:root:13: Epoch 0 train loss: 10414.5986328125\nINFO:root:14: Epoch 0 train loss: 67455.484375\nINFO:root:16: Epoch 0 train loss: 15915.2783203125\nINFO:root:17: Epoch 0 train loss: 4626.90673828125\nINFO:root:1: Epoch 0 train loss: 2638.224609375\nINFO:root:15: Epoch 0 train loss: 781.9735107421875\nINFO:root:3: Epoch 0 train loss: 2011.8399658203125\nINFO:root:5: Epoch 0 train loss: 25617.666015625\nINFO:root:2: Epoch 0 train loss: 504776.75\nINFO:root:24: Epoch 0 train loss: 1267.1405029296875\nINFO:root:25: Epoch 0 train loss: 6909.087890625\nINFO:root:0: Epoch 0 train loss: 7965.32568359375\nINFO:root:4: Epoch 0 train loss: 631185.6875\nINFO:root:0: Epoch 0 validation loss: 2316873.3455752097\nINFO:root:11: Epoch 1 train loss: 520.7945556640625\nINFO:root:26: Epoch 1 train loss: 1928510.125\nINFO:root:8: Epoch 1 train loss: 472919.78125\nINFO:root:23: Epoch 1 train loss: 8562.9912109375\nINFO:root:21: Epoch 1 train loss: 5959.12939453125\nINFO:root:3: Epoch 1 train loss: 6217.3740234375\nINFO:root:22: Epoch 1 train loss: 608892.5\nINFO:root:5: Epoch 1 train loss: 587618.8125\nINFO:root:4: Epoch 1 train loss: 504660.65625\nINFO:root:6: Epoch 1 train loss: 9475.453125\nINFO:root:25: Epoch 1 train loss: 10778.3427734375\nINFO:root:9: Epoch 1 train loss: 1581.508544921875\nINFO:root:24: Epoch 1 train loss: 582908.8125\nINFO:root:15: Epoch 1 train loss: 120.34600830078125\nINFO:root:18: Epoch 1 train loss: 7550.42041015625\nINFO:root:13: Epoch 1 train loss: 679.166748046875\nINFO:root:12: Epoch 1 train loss: 3450.513427734375\nINFO:root:7: Epoch 1 train loss: 561329.375\nINFO:root:16: Epoch 1 train loss: 3758.92529296875\nINFO:root:20: Epoch 1 train loss: 504047.46875\nINFO:root:17: Epoch 1 train loss: 4036.6474609375\nINFO:root:19: Epoch 1 train loss: 6538.978515625\nINFO:root:14: Epoch 1 train loss: 702165.75\nINFO:root:1: Epoch 1 train loss: 1176010.125\nINFO:root:0: Epoch 1 train loss: 20305.966796875\nINFO:root:2: Epoch 1 train loss: 7048.92431640625\nINFO:root:10: Epoch 1 train loss: 503360.90625\nINFO:root:0: Epoch 1 validation loss: 2316857.4250031495\nINFO:root:23: Epoch 2 train loss: 1625.979736328125\nINFO:root:15: Epoch 2 train loss: 702216.5\nINFO:root:0: Epoch 2 train loss: 908.1679077148438\nINFO:root:17: Epoch 2 train loss: 4308.21484375\nINFO:root:21: Epoch 2 train loss: 3024.892578125\nINFO:root:20: Epoch 2 train loss: 2876.31103515625\nINFO:root:16: Epoch 2 train loss: 1898.235107421875\nINFO:root:19: Epoch 2 train loss: 229.54122924804688\nINFO:root:22: Epoch 2 train loss: 2042.5284423828125\nINFO:root:7: Epoch 2 train loss: 1706.9210205078125\nINFO:root:11: Epoch 2 train loss: 635155.0\nINFO:root:26: Epoch 2 train loss: 611746.75\nINFO:root:9: Epoch 2 train loss: 1061.30322265625\nINFO:root:5: Epoch 2 train loss: 4042.747802734375\nINFO:root:25: Epoch 2 train loss: 1681.171630859375\nINFO:root:10: Epoch 2 train loss: 4597.44677734375\nINFO:root:4: Epoch 2 train loss: 701.971435546875\nINFO:root:3: Epoch 2 train loss: 1645.39599609375\nINFO:root:8: Epoch 2 train loss: 920.6736450195312\nINFO:root:6: Epoch 2 train loss: 7533.17236328125\nINFO:root:12: Epoch 2 train loss: 1641.6995849609375\nINFO:root:24: Epoch 2 train loss: 29725.00390625\nINFO:root:18: Epoch 2 train loss: 572883.0625\nINFO:root:14: Epoch 2 train loss: 3960.482177734375\nINFO:root:1: Epoch 2 train loss: 3134.359619140625\nINFO:root:13: Epoch 2 train loss: 4246.79248046875\nINFO:root:2: Epoch 2 train loss: 524571.8125\nINFO:root:0: Epoch 2 validation loss: 2316841.265454123\nINFO:root:11: Epoch 3 train loss: 15602.9521484375\nINFO:root:17: Epoch 3 train loss: 8598.896484375\nINFO:root:9: Epoch 3 train loss: 1217.6048583984375\nINFO:root:12: Epoch 3 train loss: 584653.4375\nINFO:root:10: Epoch 3 train loss: 6508.17919921875\nINFO:root:13: Epoch 3 train loss: 9676.26171875\nINFO:root:14: Epoch 3 train loss: 14050.916015625\nINFO:root:7: Epoch 3 train loss: 3445.046875\nINFO:root:4: Epoch 3 train loss: 3368.77734375\nINFO:root:21: Epoch 3 train loss: 1591.98876953125\nINFO:root:6: Epoch 3 train loss: 582623.0\nINFO:root:3: Epoch 3 train loss: 10082.3818359375\nINFO:root:23: Epoch 3 train loss: 3646.02392578125\nINFO:root:22: Epoch 3 train loss: 2209.3154296875\nINFO:root:8: Epoch 3 train loss: 453.53704833984375\nINFO:root:5: Epoch 3 train loss: 4645.52685546875\nINFO:root:16: Epoch 3 train loss: 3426.773681640625\nINFO:root:1: Epoch 3 train loss: 2177.513427734375\nINFO:root:18: Epoch 3 train loss: 474143.71875\nINFO:root:25: Epoch 3 train loss: 4334.68115234375\nINFO:root:15: Epoch 3 train loss: 5328.48681640625\nINFO:root:20: Epoch 3 train loss: 342.81793212890625\nINFO:root:26: Epoch 3 train loss: 21355.6484375\nINFO:root:2: Epoch 3 train loss: 6356.44189453125\nINFO:root:0: Epoch 3 train loss: 5867.30908203125\nINFO:root:24: Epoch 3 train loss: 1607.483154296875\nINFO:root:19: Epoch 3 train loss: 23468.89453125\nINFO:root:0: Epoch 3 validation loss: 2316824.143011467\nINFO:root:15: Epoch 4 train loss: 11711.1796875\nINFO:root:1: Epoch 4 train loss: 10349.2490234375\nINFO:root:11: Epoch 4 train loss: 566638.75\nINFO:root:3: Epoch 4 train loss: 6334.97900390625\nINFO:root:5: Epoch 4 train loss: 505447.375\nINFO:root:13: Epoch 4 train loss: 2033.17333984375\nINFO:root:4: Epoch 4 train loss: 7230.68408203125\nINFO:root:7: Epoch 4 train loss: 238.73802185058594\nINFO:root:6: Epoch 4 train loss: 1938.3302001953125\nINFO:root:8: Epoch 4 train loss: 705317.0625\nINFO:root:9: Epoch 4 train loss: 18997.296875\nINFO:root:10: Epoch 4 train loss: 7091.0595703125\nINFO:root:2: Epoch 4 train loss: 7888.5556640625\nINFO:root:14: Epoch 4 train loss: 3054.333984375\nINFO:root:12: Epoch 4 train loss: 2503.508056640625\nINFO:root:26: Epoch 4 train loss: 441.3127136230469\nINFO:root:25: Epoch 4 train loss: 472912.875\nINFO:root:23: Epoch 4 train loss: 608227.875\nINFO:root:0: Epoch 4 train loss: 80820.6875\nINFO:root:16: Epoch 4 train loss: 479728.0\nINFO:root:19: Epoch 4 train loss: 587035.5\nINFO:root:17: Epoch 4 train loss: 1735.053466796875\nINFO:root:24: Epoch 4 train loss: 15976.9365234375\nINFO:root:18: Epoch 4 train loss: 1640.4747314453125\nINFO:root:22: Epoch 4 train loss: 10059.2216796875\nINFO:root:21: Epoch 4 train loss: 562030.875\nINFO:root:20: Epoch 4 train loss: 4565.20703125\nINFO:root:0: Epoch 4 validation loss: 2316806.563505881\nINFO:root:26: Epoch 5 train loss: 1990.6414794921875\nINFO:root:0: Epoch 5 train loss: 3997.401611328125\nINFO:root:11: Epoch 5 train loss: 706269.75\nINFO:root:3: Epoch 5 train loss: 2109.072509765625\nINFO:root:10: Epoch 5 train loss: 1667.0780029296875\nINFO:root:4: Epoch 5 train loss: 707300.625\nINFO:root:5: Epoch 5 train loss: 697248.8125\nINFO:root:25: Epoch 5 train loss: 12805.3798828125\nINFO:root:9: Epoch 5 train loss: 3084.105712890625\nINFO:root:12: Epoch 5 train loss: 502938.1875\nINFO:root:7: Epoch 5 train loss: 14175.1025390625\nINFO:root:8: Epoch 5 train loss: 12208.505859375\nINFO:root:1: Epoch 5 train loss: 4115.841796875\nINFO:root:15: Epoch 5 train loss: 2060.866455078125\nINFO:root:17: Epoch 5 train loss: 2622.545654296875\nINFO:root:16: Epoch 5 train loss: 863.6847534179688\nINFO:root:6: Epoch 5 train loss: 3847.244384765625\nINFO:root:2: Epoch 5 train loss: 6555.0791015625\nINFO:root:14: Epoch 5 train loss: 3643.265625\nINFO:root:13: Epoch 5 train loss: 7543.88916015625\nINFO:root:18: Epoch 5 train loss: 748.0077514648438\nINFO:root:23: Epoch 5 train loss: 6433.54638671875\nINFO:root:24: Epoch 5 train loss: 9806.2861328125\nINFO:root:19: Epoch 5 train loss: 1971.6640625\nINFO:root:20: Epoch 5 train loss: 18508.4453125\nINFO:root:22: Epoch 5 train loss: 585674.875\nINFO:root:21: Epoch 5 train loss: 586347.25\nINFO:root:0: Epoch 5 validation loss: 2316788.2308001937\n", "seconds": 18.68853497505188, "batch_size": 128, "nodes": 9, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n2 Start Epoch 0\n2: 1 batches\n1: 1 batches\n3 Start Epoch 0\n4 Start Epoch 0\n3: 1 batches\n4: 1 batches\n24 Start Epoch 0\n24: 1 batches\n6 Start Epoch 0\n29 Start Epoch 0\n29: 1 batches\n6: 1 batches\n5 Start Epoch 0\n5: 1 batches\n23 Start Epoch 0\n23: 1 batches\n15 Start Epoch 0\n16 Start Epoch 0\n16: 1 batches\n8 Start Epoch 0\n8: 1 batches\n15: 1 batches\n7 Start Epoch 0\n7: 1 batches\n18 Start Epoch 0\n18: 1 batches\n25 Start Epoch 0\n26 Start Epoch 0\n25: 1 batches\n26: 1 batches\n10 Start Epoch 0\n17 Start Epoch 0\n9 Start Epoch 0\n9: 1 batches\n10: 1 batches\n17: 1 batches\n13 Start Epoch 0\n13: 1 batches\n14 Start Epoch 0\n14: 1 batches\n21 Start Epoch 0\n22 Start Epoch 0\n22: 1 batches\n21: 1 batches\n12 Start Epoch 0\n11 Start Epoch 0\n12: 1 batches\n11: 1 batches\n27 Start Epoch 0\n28 Start Epoch 0\n27: 1 batches\n28: 1 batches\n19 Start Epoch 0\n19: 1 batches\n20 Start Epoch 0\n20: 1 batches\n5 Start Epoch 1\n5: 1 batches\n29 Start Epoch 1\n29: 1 batches\n25 Start Epoch 1\n26 Start Epoch 1\n22 Start Epoch 1\n25: 1 batches\n23 Start Epoch 1\n9 Start Epoch 1\n26: 1 batches\n23: 1 batches\n10 Start Epoch 1\n22: 1 batches\n10: 1 batches\n9: 1 batches\n21 Start Epoch 1\n11 Start Epoch 1\n28 Start Epoch 1\n21: 1 batches\n11: 1 batches\n28: 1 batches\n3 Start Epoch 1\n6 Start Epoch 1\n24 Start Epoch 1\n24: 1 batches\n4 Start Epoch 1\n2 Start Epoch 1\n2: 1 batches\n3: 1 batches\n8 Start Epoch 1\n4: 1 batches\n8: 1 batches\n27 Start Epoch 1\n12 Start Epoch 1\n18 Start Epoch 1\n17 Start Epoch 1\n6: 1 batches\n27: 1 batches\n13 Start Epoch 1\n19 Start Epoch 1\n17: 1 batches\n13: 1 batches\n18: 1 batches\n7 Start Epoch 1\n12: 1 batches\n19: 1 batches\n7: 1 batches\n14 Start Epoch 1\n20 Start Epoch 1\n16 Start Epoch 1\n1 Start Epoch 1\n14: 1 batches\n20: 1 batches\n16: 1 batches\n15 Start Epoch 1\n15: 1 batches\n1: 1 batches\n0 Start Epoch 1\n0: 1 batches\n10 Start Epoch 2\n9 Start Epoch 2\n9: 1 batches\n4 Start Epoch 2\n11 Start Epoch 2\n3 Start Epoch 2\n4: 1 batches\n5 Start Epoch 2\n25 Start Epoch 2\n25: 1 batches\n23 Start Epoch 2\n23: 1 batches\n19 Start Epoch 2\n18 Start Epoch 2\n19: 1 batches\n20 Start Epoch 2\n20: 1 batches\n5: 1 batches\n24 Start Epoch 2\n3: 1 batches\n24: 1 batches\n22 Start Epoch 2\n27 Start Epoch 2\n27: 1 batches\n29 Start Epoch 2\n29: 1 batches\n26 Start Epoch 2\n21 Start Epoch 2\n26: 1 batches\n21: 1 batches\n7 Start Epoch 2\n28 Start Epoch 2\n28: 1 batches\n6 Start Epoch 2\n15 Start Epoch 2\n22: 1 batches\n8 Start Epoch 2\n12 Start Epoch 2\n15: 1 batches\n6: 1 batches\n13 Start Epoch 2\n16 Start Epoch 2\n11: 1 batches\n8: 1 batches\n12: 1 batches\n10: 1 batches\n7: 1 batches\n13: 1 batches\n18: 1 batches\n14 Start Epoch 2\n17 Start Epoch 2\n16: 1 batches\n14: 1 batches\n17: 1 batches\n2 Start Epoch 2\n2: 1 batches\n1 Start Epoch 2\n1: 1 batches\n0 Start Epoch 2\n0: 1 batches\n29 Start Epoch 3\n29: 1 batches\n20 Start Epoch 3\n20: 1 batches\n28 Start Epoch 3\n28: 1 batches\n27 Start Epoch 3\n12 Start Epoch 3\n12: 1 batches\n19 Start Epoch 3\n18 Start Epoch 3\n18: 1 batches\n19: 1 batches\n27: 1 batches\n16 Start Epoch 3\n15 Start Epoch 3\n16: 1 batches\n17 Start Epoch 3\n17: 1 batches\n15: 1 batches\n25 Start Epoch 3\n25: 1 batches\n26 Start Epoch 3\n26: 1 batches\n13 Start Epoch 3\n14 Start Epoch 3\n14: 1 batches\n21 Start Epoch 3\n21: 1 batches\n23 Start Epoch 3\n23: 1 batches\n13: 1 batches\n22 Start Epoch 3\n22: 1 batches\n5 Start Epoch 3\n6 Start Epoch 3\n5: 1 batches\n6: 1 batches\n2 Start Epoch 3\n2: 1 batches\n1 Start Epoch 3\n11 Start Epoch 3\n11: 1 batches\n1: 1 batches\n24 Start Epoch 3\n4 Start Epoch 3\n24: 1 batches\n3 Start Epoch 3\n7 Start Epoch 3\n8 Start Epoch 3\n8: 1 batches\n7: 1 batches\n10 Start Epoch 3\n10: 1 batches\n3: 1 batches\n4: 1 batches\n9 Start Epoch 3\n9: 1 batches\n0 Start Epoch 3\n0: 1 batches\n29 Start Epoch 4\n29: 1 batches\n28 Start Epoch 4\n28: 1 batches\n27 Start Epoch 4\n27: 1 batches\n10 Start Epoch 4\n11 Start Epoch 4\n3 Start Epoch 4\n11: 1 batches\n26 Start Epoch 4\n24 Start Epoch 4\n17 Start Epoch 4\n4 Start Epoch 4\n10: 1 batches\n4: 1 batches\n25 Start Epoch 4\n25: 1 batches\n16 Start Epoch 4\n3: 1 batches\n2 Start Epoch 4\n2: 1 batches\n16: 1 batches\n26: 1 batches\n17: 1 batches\n5 Start Epoch 4\n5: 1 batches\n8 Start Epoch 4\n19 Start Epoch 4\n12 Start Epoch 4\n12: 1 batches\n19: 1 batches\n24: 1 batches\n8: 1 batches\n15 Start Epoch 4\n22 Start Epoch 4\n1 Start Epoch 4\n9 Start Epoch 4\n15: 1 batches\n22: 1 batches\n9: 1 batches\n20 Start Epoch 4\n7 Start Epoch 4\n14 Start Epoch 4\n20: 1 batches\n14: 1 batches\n21 Start Epoch 4\n6 Start Epoch 4\n18 Start Epoch 4\n21: 1 batches\n7: 1 batches\n13 Start Epoch 4\n18: 1 batches\n13: 1 batches\n23 Start Epoch 4\n23: 1 batches\n1: 1 batches\n6: 1 batches\n0 Start Epoch 4\n0: 1 batches\n26 Start Epoch 5\n4 Start Epoch 5\n26: 1 batches\n23 Start Epoch 5\n23: 1 batches\n4: 1 batches\n3 Start Epoch 5\n3: 1 batches\n10 Start Epoch 5\n28 Start Epoch 5\n11 Start Epoch 5\n27 Start Epoch 5\n16 Start Epoch 5\n5 Start Epoch 5\n15 Start Epoch 5\n5: 1 batches\n27: 1 batches\n15: 1 batches\n6 Start Epoch 5\n6: 1 batches\n28: 1 batches\n16: 1 batches\n10: 1 batches\n29 Start Epoch 5\n17 Start Epoch 5\n22 Start Epoch 5\n11: 1 batches\n29: 1 batches\n7 Start Epoch 5\n14 Start Epoch 5\n2 Start Epoch 5\n2: 1 batches\n18 Start Epoch 5\n17: 1 batches\n21 Start Epoch 5\n22: 1 batches\n7: 1 batches\n13 Start Epoch 5\n19 Start Epoch 5\n21: 1 batches\n8 Start Epoch 5\n14: 1 batches\n20 Start Epoch 5\n8: 1 batches\n1 Start Epoch 5\n13: 1 batches\n18: 1 batches\n12 Start Epoch 5\n19: 1 batches\n12: 1 batches\n20: 1 batches\n1: 1 batches\n9 Start Epoch 5\n9: 1 batches\n24 Start Epoch 5\n24: 1 batches\n25 Start Epoch 5\n25: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:5: Epoch 0 train loss: 1870.862548828125\nINFO:root:29: Epoch 0 train loss: 648001.3125\nINFO:root:26: Epoch 0 train loss: 7943.6728515625\nINFO:root:9: Epoch 0 train loss: 2102.203369140625\nINFO:root:25: Epoch 0 train loss: 585.85791015625\nINFO:root:23: Epoch 0 train loss: 6590.16552734375\nINFO:root:22: Epoch 0 train loss: 1112.564453125\nINFO:root:10: Epoch 0 train loss: 1710.572021484375\nINFO:root:11: Epoch 0 train loss: 10627.6328125\nINFO:root:21: Epoch 0 train loss: 2589.908203125\nINFO:root:28: Epoch 0 train loss: 12457.158203125\nINFO:root:4: Epoch 0 train loss: 525261.0\nINFO:root:24: Epoch 0 train loss: 886.9305419921875\nINFO:root:3: Epoch 0 train loss: 3407.302734375\nINFO:root:6: Epoch 0 train loss: 625.5518188476562\nINFO:root:14: Epoch 0 train loss: 1922.4215087890625\nINFO:root:19: Epoch 0 train loss: 3945.16015625\nINFO:root:13: Epoch 0 train loss: 2150.6552734375\nINFO:root:20: Epoch 0 train loss: 3502.57470703125\nINFO:root:0: Epoch 0 train loss: 759.779541015625\nINFO:root:2: Epoch 0 train loss: 289.53619384765625\nINFO:root:8: Epoch 0 train loss: 3731.389404296875\nINFO:root:27: Epoch 0 train loss: 14576.490234375\nINFO:root:12: Epoch 0 train loss: 4814.85498046875\nINFO:root:18: Epoch 0 train loss: 35478.28125\nINFO:root:17: Epoch 0 train loss: 647529.4375\nINFO:root:16: Epoch 0 train loss: 1796.1724853515625\nINFO:root:7: Epoch 0 train loss: 12802.0986328125\nINFO:root:15: Epoch 0 train loss: 13715.078125\nINFO:root:1: Epoch 0 train loss: 526770.6875\nINFO:root:0: Epoch 0 validation loss: 19023.84247105883\nINFO:root:11: Epoch 1 train loss: 76720.4140625\nINFO:root:9: Epoch 1 train loss: 75216.4296875\nINFO:root:10: Epoch 1 train loss: 17114.37109375\nINFO:root:4: Epoch 1 train loss: 3152.461181640625\nINFO:root:3: Epoch 1 train loss: 2590.573974609375\nINFO:root:5: Epoch 1 train loss: 10861.51171875\nINFO:root:25: Epoch 1 train loss: 635.7052001953125\nINFO:root:23: Epoch 1 train loss: 8554.4921875\nINFO:root:20: Epoch 1 train loss: 4391.60693359375\nINFO:root:18: Epoch 1 train loss: 6734.943359375\nINFO:root:19: Epoch 1 train loss: 21287.876953125\nINFO:root:24: Epoch 1 train loss: 4006.739990234375\nINFO:root:27: Epoch 1 train loss: 1478.4891357421875\nINFO:root:29: Epoch 1 train loss: 776356.4375\nINFO:root:22: Epoch 1 train loss: 1186.8641357421875\nINFO:root:7: Epoch 1 train loss: 189.79820251464844\nINFO:root:28: Epoch 1 train loss: 18951.255859375\nINFO:root:21: Epoch 1 train loss: 1320.876708984375\nINFO:root:8: Epoch 1 train loss: 3176.54736328125\nINFO:root:26: Epoch 1 train loss: 622.5992431640625\nINFO:root:13: Epoch 1 train loss: 681.8801879882812\nINFO:root:6: Epoch 1 train loss: 705308.4375\nINFO:root:15: Epoch 1 train loss: 2188.4052734375\nINFO:root:12: Epoch 1 train loss: 8793.7255859375\nINFO:root:14: Epoch 1 train loss: 3486.33544921875\nINFO:root:16: Epoch 1 train loss: 670119.875\nINFO:root:17: Epoch 1 train loss: 73086.78125\nINFO:root:2: Epoch 1 train loss: 14971.9169921875\nINFO:root:0: Epoch 1 train loss: 392.952880859375\nINFO:root:1: Epoch 1 train loss: 4551.318359375\nINFO:root:0: Epoch 1 validation loss: 19021.91054787691\nINFO:root:29: Epoch 2 train loss: 149.57537841796875\nINFO:root:20: Epoch 2 train loss: 1658.877685546875\nINFO:root:28: Epoch 2 train loss: 1416.1876220703125\nINFO:root:27: Epoch 2 train loss: 14533.6865234375\nINFO:root:12: Epoch 2 train loss: 4100.8642578125\nINFO:root:19: Epoch 2 train loss: 787306.125\nINFO:root:18: Epoch 2 train loss: 167.1671142578125\nINFO:root:16: Epoch 2 train loss: 1889.4732666015625\nINFO:root:15: Epoch 2 train loss: 2762.41845703125\nINFO:root:17: Epoch 2 train loss: 84875.3671875\nINFO:root:26: Epoch 2 train loss: 318.10400390625\nINFO:root:25: Epoch 2 train loss: 4155.1015625\nINFO:root:0: Epoch 2 train loss: 81113.96875\nINFO:root:14: Epoch 2 train loss: 5158.12109375\nINFO:root:13: Epoch 2 train loss: 13316.96484375\nINFO:root:21: Epoch 2 train loss: 669381.5625\nINFO:root:23: Epoch 2 train loss: 777518.5625\nINFO:root:22: Epoch 2 train loss: 2475.885009765625\nINFO:root:5: Epoch 2 train loss: 222547.953125\nINFO:root:6: Epoch 2 train loss: 233301.171875\nINFO:root:2: Epoch 2 train loss: 77438.34375\nINFO:root:1: Epoch 2 train loss: 5872.72216796875\nINFO:root:11: Epoch 2 train loss: 5092.9609375\nINFO:root:24: Epoch 2 train loss: 3088.103271484375\nINFO:root:8: Epoch 2 train loss: 626430.25\nINFO:root:7: Epoch 2 train loss: 35775.484375\nINFO:root:4: Epoch 2 train loss: 946.9674682617188\nINFO:root:3: Epoch 2 train loss: 12904.732421875\nINFO:root:10: Epoch 2 train loss: 709220.0625\nINFO:root:9: Epoch 2 train loss: 557580.625\nINFO:root:0: Epoch 2 validation loss: 19019.959334032235\nINFO:root:29: Epoch 3 train loss: 5366.06689453125\nINFO:root:28: Epoch 3 train loss: 2673.15234375\nINFO:root:27: Epoch 3 train loss: 5414.39208984375\nINFO:root:0: Epoch 3 train loss: 7697.91455078125\nINFO:root:10: Epoch 3 train loss: 3365.83056640625\nINFO:root:3: Epoch 3 train loss: 202.09481811523438\nINFO:root:11: Epoch 3 train loss: 2937.395751953125\nINFO:root:5: Epoch 3 train loss: 705.6875\nINFO:root:16: Epoch 3 train loss: 676363.9375\nINFO:root:4: Epoch 3 train loss: 8384.419921875\nINFO:root:26: Epoch 3 train loss: 720791.0\nINFO:root:17: Epoch 3 train loss: 6759.4677734375\nINFO:root:2: Epoch 3 train loss: 22592.27734375\nINFO:root:24: Epoch 3 train loss: 2051.291748046875\nINFO:root:8: Epoch 3 train loss: 3281.098876953125\nINFO:root:19: Epoch 3 train loss: 629386.5\nINFO:root:25: Epoch 3 train loss: 557477.9375\nINFO:root:12: Epoch 3 train loss: 25737.14453125\nINFO:root:15: Epoch 3 train loss: 11316.2763671875\nINFO:root:22: Epoch 3 train loss: 15855.2978515625\nINFO:root:9: Epoch 3 train loss: 2329.1982421875\nINFO:root:1: Epoch 3 train loss: 701596.875\nINFO:root:20: Epoch 3 train loss: 10512.1904296875\nINFO:root:7: Epoch 3 train loss: 13143.30078125\nINFO:root:14: Epoch 3 train loss: 8080.763671875\nINFO:root:21: Epoch 3 train loss: 669089.6875\nINFO:root:6: Epoch 3 train loss: 559806.4375\nINFO:root:18: Epoch 3 train loss: 4057.222900390625\nINFO:root:13: Epoch 3 train loss: 986.4901123046875\nINFO:root:23: Epoch 3 train loss: 22997.388671875\nINFO:root:0: Epoch 3 validation loss: 19017.998265485676\nINFO:root:4: Epoch 4 train loss: 13124.6904296875\nINFO:root:26: Epoch 4 train loss: 23607.552734375\nINFO:root:5: Epoch 4 train loss: 1362.4139404296875\nINFO:root:23: Epoch 4 train loss: 703360.8125\nINFO:root:10: Epoch 4 train loss: 83.38410186767578\nINFO:root:28: Epoch 4 train loss: 393.138427734375\nINFO:root:27: Epoch 4 train loss: 5670.58447265625\nINFO:root:15: Epoch 4 train loss: 1900.2132568359375\nINFO:root:11: Epoch 4 train loss: 6897.10400390625\nINFO:root:16: Epoch 4 train loss: 5634.94677734375\nINFO:root:3: Epoch 4 train loss: 2777.61865234375\nINFO:root:6: Epoch 4 train loss: 4981.7099609375\nINFO:root:29: Epoch 4 train loss: 6153.0986328125\nINFO:root:12: Epoch 4 train loss: 3554.19580078125\nINFO:root:18: Epoch 4 train loss: 627.6929931640625\nINFO:root:17: Epoch 4 train loss: 225.19175720214844\nINFO:root:22: Epoch 4 train loss: 4227.7548828125\nINFO:root:21: Epoch 4 train loss: 79968.9609375\nINFO:root:0: Epoch 4 train loss: 11648.953125\nINFO:root:7: Epoch 4 train loss: 7757.7119140625\nINFO:root:14: Epoch 4 train loss: 3337.184326171875\nINFO:root:20: Epoch 4 train loss: 1754.084228515625\nINFO:root:19: Epoch 4 train loss: 782.7705078125\nINFO:root:8: Epoch 4 train loss: 671259.25\nINFO:root:13: Epoch 4 train loss: 1184462.75\nINFO:root:2: Epoch 4 train loss: 1823.693359375\nINFO:root:1: Epoch 4 train loss: 18661.880859375\nINFO:root:9: Epoch 4 train loss: 27971.65625\nINFO:root:24: Epoch 4 train loss: 529885.5625\nINFO:root:25: Epoch 4 train loss: 1708.6751708984375\nINFO:root:0: Epoch 4 validation loss: 19016.025474897586\nINFO:root:2: Epoch 5 train loss: 5789.15380859375\nINFO:root:5: Epoch 5 train loss: 821.0512084960938\nINFO:root:4: Epoch 5 train loss: 6269.53369140625\nINFO:root:11: Epoch 5 train loss: 16823.76171875\nINFO:root:20: Epoch 5 train loss: 634556.0625\nINFO:root:25: Epoch 5 train loss: 1474.7294921875\nINFO:root:22: Epoch 5 train loss: 3581.255615234375\nINFO:root:15: Epoch 5 train loss: 1190.689453125\nINFO:root:16: Epoch 5 train loss: 14694.298828125\nINFO:root:17: Epoch 5 train loss: 7849.77294921875\nINFO:root:21: Epoch 5 train loss: 1632.236328125\nINFO:root:24: Epoch 5 train loss: 1302.82958984375\nINFO:root:6: Epoch 5 train loss: 669438.5625\nINFO:root:29: Epoch 5 train loss: 2437.495361328125\nINFO:root:28: Epoch 5 train loss: 8188.94384765625\nINFO:root:7: Epoch 5 train loss: 654102.8125\nINFO:root:8: Epoch 5 train loss: 838.135498046875\nINFO:root:26: Epoch 5 train loss: 3244.771484375\nINFO:root:14: Epoch 5 train loss: 646471.3125\nINFO:root:13: Epoch 5 train loss: 648019.625\nINFO:root:12: Epoch 5 train loss: 626459.8125\nINFO:root:9: Epoch 5 train loss: 184.37741088867188\nINFO:root:10: Epoch 5 train loss: 2325.70703125\nINFO:root:19: Epoch 5 train loss: 559869.3125\nINFO:root:18: Epoch 5 train loss: 9233.49609375\nINFO:root:3: Epoch 5 train loss: 4428.888671875\nINFO:root:23: Epoch 5 train loss: 972.5152587890625\nINFO:root:27: Epoch 5 train loss: 73063.03125\nINFO:root:0: Epoch 5 train loss: 773978.0\nINFO:root:1: Epoch 5 train loss: 2816.35693359375\nINFO:root:0: Epoch 5 validation loss: 19014.010415448003\n", "seconds": 18.632051944732666, "batch_size": 128, "nodes": 10, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 1 batches\n2: 1 batches\n3 Start Epoch 0\n4 Start Epoch 0\n4: 1 batches\n3: 1 batches\n24 Start Epoch 0\n25 Start Epoch 0\n25: 1 batches\n26 Start Epoch 0\n24: 1 batches\n26: 1 batches\n23 Start Epoch 0\n23: 1 batches\n18 Start Epoch 0\n5 Start Epoch 0\n7 Start Epoch 0\n18: 1 batches\n32 Start Epoch 0\n17 Start Epoch 0\n5: 1 batches\n7: 1 batches\n9 Start Epoch 0\n6 Start Epoch 0\n10 Start Epoch 0\n32: 1 batches\n17: 1 batches\n6: 1 batches\n10: 1 batches\n16 Start Epoch 0\n9: 1 batches\n31 Start Epoch 0\n31: 1 batches\n16: 1 batches\n15 Start Epoch 0\n15: 1 batches\n8 Start Epoch 0\n8: 1 batches\n27 Start Epoch 0\n27: 1 batches\n12 Start Epoch 0\n19 Start Epoch 0\n28 Start Epoch 0\n12: 1 batches\n20 Start Epoch 0\n28: 1 batches\n11 Start Epoch 0\n19: 1 batches\n20: 1 batches\n11: 1 batches\n21 Start Epoch 0\n22 Start Epoch 0\n30 Start Epoch 0\n22: 1 batches\n13 Start Epoch 0\n21: 1 batches\n14 Start Epoch 0\n29 Start Epoch 0\n13: 1 batches\n30: 1 batches\n14: 1 batches\n29: 1 batches\n29 Start Epoch 1\n29: 1 batches\n23 Start Epoch 1\n23: 1 batches\n25 Start Epoch 1\n24 Start Epoch 1\n25: 1 batches\n22 Start Epoch 1\n5 Start Epoch 1\n26 Start Epoch 1\n22: 1 batches\n3 Start Epoch 1\n10 Start Epoch 1\n26: 1 batches\n21 Start Epoch 1\n4 Start Epoch 1\n9 Start Epoch 1\n24: 1 batches\n21: 1 batches\n4: 1 batches\n9: 1 batches\n5: 1 batches\n11 Start Epoch 1\n3: 1 batches\n11: 1 batches\n10: 1 batches\n27 Start Epoch 1\n28 Start Epoch 1\n28: 1 batches\n27: 1 batches\n32 Start Epoch 1\n20 Start Epoch 1\n31 Start Epoch 1\n32: 1 batches\n17 Start Epoch 1\n30 Start Epoch 1\n17: 1 batches\n20: 1 batches\n30: 1 batches\n13 Start Epoch 1\n16 Start Epoch 1\n18 Start Epoch 1\n31: 1 batches\n13: 1 batches\n16: 1 batches\n18: 1 batches\n8 Start Epoch 1\n14 Start Epoch 1\n7 Start Epoch 1\n8: 1 batches\n7: 1 batches\n6 Start Epoch 1\n6: 1 batches\n14: 1 batches\n12 Start Epoch 1\n12: 1 batches\n19 Start Epoch 1\n19: 1 batches\n15 Start Epoch 1\n15: 1 batches\n1 Start Epoch 1\n1: 1 batches\n2 Start Epoch 1\n2: 1 batches\n0 Start Epoch 1\n0: 1 batches\n32 Start Epoch 2\n32: 1 batches\n5 Start Epoch 2\n3 Start Epoch 2\n11 Start Epoch 2\n23 Start Epoch 2\n4 Start Epoch 2\n11: 1 batches\n23: 1 batches\n29 Start Epoch 2\n5: 1 batches\n4: 1 batches\n25 Start Epoch 2\n31 Start Epoch 2\n24 Start Epoch 2\n25: 1 batches\n30 Start Epoch 2\n26 Start Epoch 2\n26: 1 batches\n30: 1 batches\n24: 1 batches\n31: 1 batches\n2 Start Epoch 2\n2: 1 batches\n1 Start Epoch 2\n1: 1 batches\n3: 1 batches\n10 Start Epoch 2\n10: 1 batches\n28 Start Epoch 2\n28: 1 batches\n17 Start Epoch 2\n17: 1 batches\n21 Start Epoch 2\n27 Start Epoch 2\n27: 1 batches\n13 Start Epoch 2\n13: 1 batches\n20 Start Epoch 2\n22 Start Epoch 2\n8 Start Epoch 2\n9 Start Epoch 2\n9: 1 batches\n21: 1 batches\n29: 1 batches\n7 Start Epoch 2\n15 Start Epoch 2\n19 Start Epoch 2\n22: 1 batches\n7: 1 batches\n14 Start Epoch 2\n15: 1 batches\n20: 1 batches\n8: 1 batches\n12 Start Epoch 2\n19: 1 batches\n12: 1 batches\n16 Start Epoch 2\n18 Start Epoch 2\n6 Start Epoch 2\n6: 1 batches\n14: 1 batches\n16: 1 batches\n18: 1 batches\n0 Start Epoch 2\n0: 1 batches\n29 Start Epoch 3\n29: 1 batches\n20 Start Epoch 3\n23 Start Epoch 3\n20: 1 batches\n23: 1 batches\n11 Start Epoch 3\n17 Start Epoch 3\n4 Start Epoch 3\n16 Start Epoch 3\n24 Start Epoch 3\n5 Start Epoch 3\n25 Start Epoch 3\n5: 1 batches\n25: 1 batches\n4: 1 batches\n26 Start Epoch 3\n27 Start Epoch 3\n28 Start Epoch 3\n27: 1 batches\n28: 1 batches\n19 Start Epoch 3\n19: 1 batches\n22 Start Epoch 3\n21 Start Epoch 3\n22: 1 batches\n21: 1 batches\n12 Start Epoch 3\n3 Start Epoch 3\n1 Start Epoch 3\n1: 1 batches\n14 Start Epoch 3\n3: 1 batches\n12: 1 batches\n10 Start Epoch 3\n10: 1 batches\n9 Start Epoch 3\n9: 1 batches\n14: 1 batches\n6 Start Epoch 3\n6: 1 batches\n11: 1 batches\n7 Start Epoch 3\n7: 1 batches\n17: 1 batches\n2 Start Epoch 3\n16: 1 batches\n2: 1 batches\n13 Start Epoch 3\n13: 1 batches\n30 Start Epoch 3\n8 Start Epoch 3\n32 Start Epoch 3\n8: 1 batches\n32: 1 batches\n18 Start Epoch 3\n18: 1 batches\n31 Start Epoch 3\n15 Start Epoch 3\n30: 1 batches\n15: 1 batches\n31: 1 batches\n26: 1 batches\n24: 1 batches\n0 Start Epoch 3\n0: 1 batches\n8 Start Epoch 4\n11 Start Epoch 4\n8: 1 batches\n29 Start Epoch 4\n5 Start Epoch 4\n29: 1 batches\n4 Start Epoch 4\n5: 1 batches\n23 Start Epoch 4\n23: 1 batches\n25 Start Epoch 4\n24 Start Epoch 4\n25: 1 batches\n26 Start Epoch 4\n6 Start Epoch 4\n12 Start Epoch 4\n1 Start Epoch 4\n1: 1 batches\n12: 1 batches\n4: 1 batches\n7 Start Epoch 4\n28 Start Epoch 4\n6: 1 batches\n30 Start Epoch 4\n7: 1 batches\n14 Start Epoch 4\n27 Start Epoch 4\n3 Start Epoch 4\n32 Start Epoch 4\n13 Start Epoch 4\n28: 1 batches\n3: 1 batches\n27: 1 batches\n32: 1 batches\n13: 1 batches\n31 Start Epoch 4\n14: 1 batches\n31: 1 batches\n10 Start Epoch 4\n10: 1 batches\n9 Start Epoch 4\n9: 1 batches\n30: 1 batches\n11: 1 batches\n2 Start Epoch 4\n2: 1 batches\n17 Start Epoch 4\n19 Start Epoch 4\n16 Start Epoch 4\n20 Start Epoch 4\n16: 1 batches\n20: 1 batches\n19: 1 batches\n17: 1 batches\n15 Start Epoch 4\n15: 1 batches\n18 Start Epoch 4\n18: 1 batches\n26: 1 batches\n24: 1 batches\n22 Start Epoch 4\n22: 1 batches\n21 Start Epoch 4\n21: 1 batches\n0 Start Epoch 4\n0: 1 batches\n27 Start Epoch 5\n25 Start Epoch 5\n26 Start Epoch 5\n29 Start Epoch 5\n27: 1 batches\n25: 1 batches\n26: 1 batches\n29: 1 batches\n24 Start Epoch 5\n24: 1 batches\n28 Start Epoch 5\n28: 1 batches\n23 Start Epoch 5\n23: 1 batches\n31 Start Epoch 5\n30 Start Epoch 5\n30: 1 batches\n32 Start Epoch 5\n32: 1 batches\n31: 1 batches\n3 Start Epoch 5\n3: 1 batches\n21 Start Epoch 5\n21: 1 batches\n22 Start Epoch 5\n22: 1 batches\n2 Start Epoch 5\n2: 1 batches\n1 Start Epoch 5\n1: 1 batches\n5 Start Epoch 5\n5: 1 batches\n11 Start Epoch 5\n11: 1 batches\n16 Start Epoch 5\n17 Start Epoch 5\n17: 1 batches\n16: 1 batches\n4 Start Epoch 5\n4: 1 batches\n8 Start Epoch 5\n7 Start Epoch 5\n7: 1 batches\n20 Start Epoch 5\n10 Start Epoch 5\n19 Start Epoch 5\n19: 1 batches\n9 Start Epoch 5\n14 Start Epoch 5\n20: 1 batches\n8: 1 batches\n9: 1 batches\n12 Start Epoch 5\n12: 1 batches\n18 Start Epoch 5\n14: 1 batches\n13 Start Epoch 5\n18: 1 batches\n13: 1 batches\n6 Start Epoch 5\n6: 1 batches\n10: 1 batches\n15 Start Epoch 5\n15: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:29: Epoch 0 train loss: 1643.1932373046875\nINFO:root:25: Epoch 0 train loss: 1216.860107421875\nINFO:root:23: Epoch 0 train loss: 486.8316345214844\nINFO:root:24: Epoch 0 train loss: 9457.8828125\nINFO:root:26: Epoch 0 train loss: 1926.9678955078125\nINFO:root:3: Epoch 0 train loss: 2762.125732421875\nINFO:root:22: Epoch 0 train loss: 712283.875\nINFO:root:4: Epoch 0 train loss: 539.348876953125\nINFO:root:11: Epoch 0 train loss: 356.72027587890625\nINFO:root:21: Epoch 0 train loss: 10773.2958984375\nINFO:root:5: Epoch 0 train loss: 1207.6236572265625\nINFO:root:10: Epoch 0 train loss: 6447.08349609375\nINFO:root:9: Epoch 0 train loss: 20862.767578125\nINFO:root:27: Epoch 0 train loss: 6714.810546875\nINFO:root:28: Epoch 0 train loss: 3778.41845703125\nINFO:root:30: Epoch 0 train loss: 4563.76416015625\nINFO:root:32: Epoch 0 train loss: 14735.875\nINFO:root:16: Epoch 0 train loss: 6167.314453125\nINFO:root:18: Epoch 0 train loss: 1513.6282958984375\nINFO:root:31: Epoch 0 train loss: 620294.875\nINFO:root:17: Epoch 0 train loss: 1497.6253662109375\nINFO:root:13: Epoch 0 train loss: 712590.6875\nINFO:root:20: Epoch 0 train loss: 6031.8837890625\nINFO:root:8: Epoch 0 train loss: 372.2457580566406\nINFO:root:14: Epoch 0 train loss: 17486.84375\nINFO:root:6: Epoch 0 train loss: 94388.9296875\nINFO:root:7: Epoch 0 train loss: 241943.59375\nINFO:root:12: Epoch 0 train loss: 2696.213134765625\nINFO:root:19: Epoch 0 train loss: 304.3977966308594\nINFO:root:0: Epoch 0 train loss: 3954.372802734375\nINFO:root:15: Epoch 0 train loss: 806142.0625\nINFO:root:1: Epoch 0 train loss: 882.3917236328125\nINFO:root:2: Epoch 0 train loss: 1705.05224609375\nINFO:root:0: Epoch 0 validation loss: 76134.11942702842\nINFO:root:32: Epoch 1 train loss: 721294.375\nINFO:root:3: Epoch 1 train loss: 915.200439453125\nINFO:root:4: Epoch 1 train loss: 6191.08251953125\nINFO:root:5: Epoch 1 train loss: 7855.83203125\nINFO:root:11: Epoch 1 train loss: 541.829345703125\nINFO:root:23: Epoch 1 train loss: 66.12440490722656\nINFO:root:29: Epoch 1 train loss: 5456.50927734375\nINFO:root:25: Epoch 1 train loss: 1922.6324462890625\nINFO:root:24: Epoch 1 train loss: 1887.6953125\nINFO:root:26: Epoch 1 train loss: 1150.801513671875\nINFO:root:31: Epoch 1 train loss: 612627.375\nINFO:root:30: Epoch 1 train loss: 1697.367919921875\nINFO:root:0: Epoch 1 train loss: 740614.5625\nINFO:root:2: Epoch 1 train loss: 13014.9990234375\nINFO:root:1: Epoch 1 train loss: 86739.578125\nINFO:root:17: Epoch 1 train loss: 5631.23779296875\nINFO:root:19: Epoch 1 train loss: 244481.59375\nINFO:root:22: Epoch 1 train loss: 305.9811706542969\nINFO:root:27: Epoch 1 train loss: 739367.4375\nINFO:root:8: Epoch 1 train loss: 12412.2958984375\nINFO:root:13: Epoch 1 train loss: 80009.5390625\nINFO:root:6: Epoch 1 train loss: 5249.96728515625\nINFO:root:10: Epoch 1 train loss: 244.28445434570312\nINFO:root:14: Epoch 1 train loss: 5922.87548828125\nINFO:root:18: Epoch 1 train loss: 1995.0946044921875\nINFO:root:21: Epoch 1 train loss: 3685.9443359375\nINFO:root:20: Epoch 1 train loss: 2091.28857421875\nINFO:root:7: Epoch 1 train loss: 737676.0\nINFO:root:9: Epoch 1 train loss: 335.76416015625\nINFO:root:15: Epoch 1 train loss: 2810.799560546875\nINFO:root:28: Epoch 1 train loss: 853237.0625\nINFO:root:12: Epoch 1 train loss: 601264.75\nINFO:root:16: Epoch 1 train loss: 7199.9970703125\nINFO:root:0: Epoch 1 validation loss: 76130.43174194467\nINFO:root:29: Epoch 2 train loss: 88501.484375\nINFO:root:20: Epoch 2 train loss: 4481.38525390625\nINFO:root:23: Epoch 2 train loss: 582177.9375\nINFO:root:11: Epoch 2 train loss: 434.3240051269531\nINFO:root:10: Epoch 2 train loss: 4278.12060546875\nINFO:root:4: Epoch 2 train loss: 3278.45703125\nINFO:root:16: Epoch 2 train loss: 2872.339599609375\nINFO:root:26: Epoch 2 train loss: 10935.236328125\nINFO:root:24: Epoch 2 train loss: 2994.449951171875\nINFO:root:5: Epoch 2 train loss: 9124.359375\nINFO:root:25: Epoch 2 train loss: 1178.0145263671875\nINFO:root:17: Epoch 2 train loss: 617272.6875\nINFO:root:28: Epoch 2 train loss: 3289.08154296875\nINFO:root:27: Epoch 2 train loss: 711680.3125\nINFO:root:19: Epoch 2 train loss: 2553.60546875\nINFO:root:21: Epoch 2 train loss: 82084.109375\nINFO:root:22: Epoch 2 train loss: 3101.015380859375\nINFO:root:12: Epoch 2 train loss: 11134.400390625\nINFO:root:14: Epoch 2 train loss: 1111.0819091796875\nINFO:root:3: Epoch 2 train loss: 2979.72802734375\nINFO:root:1: Epoch 2 train loss: 25812.7109375\nINFO:root:0: Epoch 2 train loss: 784.5814819335938\nINFO:root:9: Epoch 2 train loss: 778632.5625\nINFO:root:7: Epoch 2 train loss: 866957.3125\nINFO:root:6: Epoch 2 train loss: 6613.5400390625\nINFO:root:2: Epoch 2 train loss: 7715.68310546875\nINFO:root:13: Epoch 2 train loss: 6888.271484375\nINFO:root:30: Epoch 2 train loss: 580608.4375\nINFO:root:32: Epoch 2 train loss: 586.5338134765625\nINFO:root:8: Epoch 2 train loss: 528.5027465820312\nINFO:root:18: Epoch 2 train loss: 616234.8125\nINFO:root:15: Epoch 2 train loss: 2037.1260986328125\nINFO:root:31: Epoch 2 train loss: 10969.5302734375\nINFO:root:0: Epoch 2 validation loss: 76126.7536373453\nINFO:root:8: Epoch 3 train loss: 258.2840576171875\nINFO:root:11: Epoch 3 train loss: 14795.345703125\nINFO:root:5: Epoch 3 train loss: 9707.75390625\nINFO:root:4: Epoch 3 train loss: 2318.4638671875\nINFO:root:29: Epoch 3 train loss: 2204558.25\nINFO:root:23: Epoch 3 train loss: 618502.25\nINFO:root:25: Epoch 3 train loss: 617300.5\nINFO:root:26: Epoch 3 train loss: 734850.1875\nINFO:root:24: Epoch 3 train loss: 2820.641357421875\nINFO:root:12: Epoch 3 train loss: 5604.4892578125\nINFO:root:7: Epoch 3 train loss: 876915.75\nINFO:root:27: Epoch 3 train loss: 6590.96337890625\nINFO:root:6: Epoch 3 train loss: 1851.536865234375\nINFO:root:31: Epoch 3 train loss: 3275.48193359375\nINFO:root:1: Epoch 3 train loss: 1140.1807861328125\nINFO:root:13: Epoch 3 train loss: 10215.8232421875\nINFO:root:28: Epoch 3 train loss: 14510.69140625\nINFO:root:32: Epoch 3 train loss: 741967.0\nINFO:root:3: Epoch 3 train loss: 1687.8138427734375\nINFO:root:14: Epoch 3 train loss: 10471.22265625\nINFO:root:30: Epoch 3 train loss: 15120.1640625\nINFO:root:10: Epoch 3 train loss: 794.0135498046875\nINFO:root:9: Epoch 3 train loss: 866272.0\nINFO:root:0: Epoch 3 train loss: 10207.5908203125\nINFO:root:2: Epoch 3 train loss: 273.98065185546875\nINFO:root:16: Epoch 3 train loss: 8136.68798828125\nINFO:root:20: Epoch 3 train loss: 31595.796875\nINFO:root:17: Epoch 3 train loss: 3605.08935546875\nINFO:root:19: Epoch 3 train loss: 176.10939025878906\nINFO:root:15: Epoch 3 train loss: 6096.02685546875\nINFO:root:18: Epoch 3 train loss: 12729.5888671875\nINFO:root:22: Epoch 3 train loss: 770281.9375\nINFO:root:21: Epoch 3 train loss: 149.85748291015625\nINFO:root:0: Epoch 3 validation loss: 76123.13336151285\nINFO:root:24: Epoch 4 train loss: 470.1930847167969\nINFO:root:27: Epoch 4 train loss: 15023.8544921875\nINFO:root:25: Epoch 4 train loss: 858414.5\nINFO:root:26: Epoch 4 train loss: 2245.31103515625\nINFO:root:29: Epoch 4 train loss: 9716.013671875\nINFO:root:28: Epoch 4 train loss: 248716.265625\nINFO:root:23: Epoch 4 train loss: 19538.478515625\nINFO:root:31: Epoch 4 train loss: 3061.524658203125\nINFO:root:30: Epoch 4 train loss: 743584.4375\nINFO:root:32: Epoch 4 train loss: 7045.5595703125\nINFO:root:0: Epoch 4 train loss: 9905.484375\nINFO:root:3: Epoch 4 train loss: 16254.7294921875\nINFO:root:21: Epoch 4 train loss: 7940.82568359375\nINFO:root:22: Epoch 4 train loss: 13193.9287109375\nINFO:root:2: Epoch 4 train loss: 1028.796142578125\nINFO:root:1: Epoch 4 train loss: 257723.359375\nINFO:root:4: Epoch 4 train loss: 411.2248840332031\nINFO:root:5: Epoch 4 train loss: 2715.23583984375\nINFO:root:11: Epoch 4 train loss: 5937.4814453125\nINFO:root:17: Epoch 4 train loss: 2184.627197265625\nINFO:root:16: Epoch 4 train loss: 619.6435546875\nINFO:root:8: Epoch 4 train loss: 1015545.5\nINFO:root:7: Epoch 4 train loss: 6453.05078125\nINFO:root:18: Epoch 4 train loss: 24789.841796875\nINFO:root:12: Epoch 4 train loss: 7750.15576171875\nINFO:root:13: Epoch 4 train loss: 5249.6640625\nINFO:root:19: Epoch 4 train loss: 13973.048828125\nINFO:root:20: Epoch 4 train loss: 2596.914306640625\nINFO:root:10: Epoch 4 train loss: 13053.275390625\nINFO:root:14: Epoch 4 train loss: 250087.375\nINFO:root:9: Epoch 4 train loss: 580.3424682617188\nINFO:root:6: Epoch 4 train loss: 1291.743896484375\nINFO:root:15: Epoch 4 train loss: 3122.76220703125\nINFO:root:0: Epoch 4 validation loss: 76119.34054764277\nINFO:root:28: Epoch 5 train loss: 3478.976806640625\nINFO:root:29: Epoch 5 train loss: 199.7646942138672\nINFO:root:21: Epoch 5 train loss: 1965.449951171875\nINFO:root:11: Epoch 5 train loss: 772.7052001953125\nINFO:root:17: Epoch 5 train loss: 2006.037109375\nINFO:root:22: Epoch 5 train loss: 4169.39111328125\nINFO:root:23: Epoch 5 train loss: 5058.29638671875\nINFO:root:16: Epoch 5 train loss: 1284.724365234375\nINFO:root:15: Epoch 5 train loss: 242335.28125\nINFO:root:3: Epoch 5 train loss: 240645.515625\nINFO:root:4: Epoch 5 train loss: 84139.6640625\nINFO:root:5: Epoch 5 train loss: 578647.9375\nINFO:root:20: Epoch 5 train loss: 241118.4375\nINFO:root:26: Epoch 5 train loss: 2156.296142578125\nINFO:root:7: Epoch 5 train loss: 955.8034057617188\nINFO:root:30: Epoch 5 train loss: 9675.6455078125\nINFO:root:14: Epoch 5 train loss: 4209.541015625\nINFO:root:12: Epoch 5 train loss: 92.54777526855469\nINFO:root:18: Epoch 5 train loss: 7944.70703125\nINFO:root:25: Epoch 5 train loss: 588136.5\nINFO:root:27: Epoch 5 train loss: 477.6259460449219\nINFO:root:6: Epoch 5 train loss: 852791.0\nINFO:root:10: Epoch 5 train loss: 4342.80615234375\nINFO:root:32: Epoch 5 train loss: 2475.445556640625\nINFO:root:19: Epoch 5 train loss: 23619.771484375\nINFO:root:8: Epoch 5 train loss: 24898.546875\nINFO:root:9: Epoch 5 train loss: 227.62010192871094\nINFO:root:31: Epoch 5 train loss: 770.783447265625\nINFO:root:13: Epoch 5 train loss: 1520.272216796875\nINFO:root:1: Epoch 5 train loss: 4616.1005859375\nINFO:root:24: Epoch 5 train loss: 9072.2724609375\nINFO:root:2: Epoch 5 train loss: 1573.6419677734375\nINFO:root:0: Epoch 5 train loss: 2559.54443359375\nINFO:root:0: Epoch 5 validation loss: 76115.47570760468\n", "seconds": 19.629390001296997, "batch_size": 128, "nodes": 11, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n1: 1 batches\n2 Start Epoch 0\n2: 1 batches\n3 Start Epoch 0\n4 Start Epoch 0\n4: 1 batches\n3: 1 batches\n23 Start Epoch 0\n23: 1 batches\n5 Start Epoch 0\n24 Start Epoch 0\n24: 1 batches\n5: 1 batches\n25 Start Epoch 0\n25: 1 batches\n26 Start Epoch 0\n26: 1 batches\n7 Start Epoch 0\n8 Start Epoch 0\n8: 1 batches\n7: 1 batches\n18 Start Epoch 0\n18: 1 batches\n9 Start Epoch 0\n17 Start Epoch 0\n33 Start Epoch 0\n6 Start Epoch 0\n10 Start Epoch 0\n33: 1 batches\n6: 1 batches\n34 Start Epoch 0\n9: 1 batches\n34: 1 batches\n10: 1 batches\n17: 1 batches\n32 Start Epoch 0\n15 Start Epoch 0\n31 Start Epoch 0\n16 Start Epoch 0\n32: 1 batches\n31: 1 batches\n15: 1 batches\n16: 1 batches\n29 Start Epoch 0\n29: 1 batches\n28 Start Epoch 0\n27 Start Epoch 0\n27: 1 batches\n28: 1 batches\n13 Start Epoch 0\n30 Start Epoch 0\n14 Start Epoch 0\n14: 1 batches\n30: 1 batches\n13: 1 batches\n11 Start Epoch 0\n11: 1 batches\n21 Start Epoch 0\n21: 1 batches\n22 Start Epoch 0\n22: 1 batches\n20 Start Epoch 0\n19 Start Epoch 0\n20: 1 batches\n35 Start Epoch 0\n35: 1 batches\n19: 1 batches\n12 Start Epoch 0\n12: 1 batches\n29 Start Epoch 1\n29: 1 batches\n10 Start Epoch 1\n26 Start Epoch 1\n11 Start Epoch 1\n26: 1 batches\n11: 1 batches\n5 Start Epoch 1\n9 Start Epoch 1\n9: 1 batches\n10: 1 batches\n5: 1 batches\n4 Start Epoch 1\n3 Start Epoch 1\n24 Start Epoch 1\n25 Start Epoch 1\n3: 1 batches\n25: 1 batches\n4: 1 batches\n24: 1 batches\n30 Start Epoch 1\n8 Start Epoch 1\n35 Start Epoch 1\n8: 1 batches\n33 Start Epoch 1\n13 Start Epoch 1\n32 Start Epoch 1\n33: 1 batches\n14 Start Epoch 1\n32: 1 batches\n35: 1 batches\n14: 1 batches\n30: 1 batches\n12 Start Epoch 1\n12: 1 batches\n13: 1 batches\n1 Start Epoch 1\n6 Start Epoch 1\n31 Start Epoch 1\n15 Start Epoch 1\n6: 1 batches\n31: 1 batches\n15: 1 batches\n7 Start Epoch 1\n1: 1 batches\n7: 1 batches\n34 Start Epoch 1\n34: 1 batches\n2 Start Epoch 1\n2: 1 batches\n23 Start Epoch 1\n23: 1 batches\n21 Start Epoch 1\n22 Start Epoch 1\n22: 1 batches\n21: 1 batches\n16 Start Epoch 1\n16: 1 batches\n17 Start Epoch 1\n18 Start Epoch 1\n17: 1 batches\n20 Start Epoch 1\n20: 1 batches\n19 Start Epoch 1\n18: 1 batches\n19: 1 batches\n28 Start Epoch 1\n28: 1 batches\n27 Start Epoch 1\n27: 1 batches\n0 Start Epoch 1\n0: 1 batches\n15 Start Epoch 2\n15: 1 batches\n12 Start Epoch 2\n12: 1 batches\n14 Start Epoch 2\n13 Start Epoch 2\n14: 1 batches\n13: 1 batches\n11 Start Epoch 2\n11: 1 batches\n10 Start Epoch 2\n10: 1 batches\n9 Start Epoch 2\n9: 1 batches\n8 Start Epoch 2\n8: 1 batches\n17 Start Epoch 2\n16 Start Epoch 2\n16: 1 batches\n17: 1 batches\n23 Start Epoch 2\n23: 1 batches\n24 Start Epoch 2\n26 Start Epoch 2\n4 Start Epoch 2\n24: 1 batches\n26: 1 batches\n4: 1 batches\n25 Start Epoch 2\n3 Start Epoch 2\n25: 1 batches\n5 Start Epoch 2\n3: 1 batches\n5: 1 batches\n6 Start Epoch 2\n29 Start Epoch 2\n29: 1 batches\n7 Start Epoch 2\n6: 1 batches\n18 Start Epoch 2\n20 Start Epoch 2\n34 Start Epoch 2\n7: 1 batches\n19 Start Epoch 2\n31 Start Epoch 2\n35 Start Epoch 2\n18: 1 batches\n32 Start Epoch 2\n34: 1 batches\n20: 1 batches\n31: 1 batches\n35: 1 batches\n19: 1 batches\n30 Start Epoch 2\n30: 1 batches\n2 Start Epoch 2\n33 Start Epoch 2\n32: 1 batches\n33: 1 batches\n2: 1 batches\n1 Start Epoch 2\n1: 1 batches\n28 Start Epoch 2\n28: 1 batches\n27 Start Epoch 2\n27: 1 batches\n22 Start Epoch 2\n22: 1 batches\n21 Start Epoch 2\n21: 1 batches\n0 Start Epoch 2\n0: 1 batches\n11 Start Epoch 3\n16 Start Epoch 3\n16: 1 batches\n23 Start Epoch 3\n26 Start Epoch 3\n5 Start Epoch 3\n4 Start Epoch 3\n26: 1 batches\n11: 1 batches\n23: 1 batches\n4: 1 batches\n28 Start Epoch 3\n27 Start Epoch 3\n27: 1 batches\n29 Start Epoch 3\n17 Start Epoch 3\n1 Start Epoch 3\n29: 1 batches\n15 Start Epoch 3\n28: 1 batches\n25 Start Epoch 3\n15: 1 batches\n34 Start Epoch 3\n17: 1 batches\n35 Start Epoch 3\n12 Start Epoch 3\n24 Start Epoch 3\n30 Start Epoch 3\n24: 1 batches\n10 Start Epoch 3\n35: 1 batches\n8 Start Epoch 3\n14 Start Epoch 3\n25: 1 batches\n3 Start Epoch 3\n3: 1 batches\n34: 1 batches\n8: 1 batches\n20 Start Epoch 3\n13 Start Epoch 3\n32 Start Epoch 3\n9 Start Epoch 3\n19 Start Epoch 3\n12: 1 batches\n32: 1 batches\n5: 1 batches\n20: 1 batches\n14: 1 batches\n30: 1 batches\n9: 1 batches\n18 Start Epoch 3\n13: 1 batches\n31 Start Epoch 3\n10: 1 batches\n18: 1 batches\n31: 1 batches\n19: 1 batches\n22 Start Epoch 3\n21 Start Epoch 3\n1: 1 batches\n21: 1 batches\n7 Start Epoch 3\n7: 1 batches\n6 Start Epoch 3\n33 Start Epoch 3\n6: 1 batches\n33: 1 batches\n2 Start Epoch 3\n2: 1 batches\n22: 1 batches\n0 Start Epoch 3\n0: 1 batches\n14 Start Epoch 4\n14: 1 batches\n15 Start Epoch 4\n15: 1 batches\n16 Start Epoch 4\n17 Start Epoch 4\n16: 1 batches\n17: 1 batches\n26 Start Epoch 4\n26: 1 batches\n29 Start Epoch 4\n28 Start Epoch 4\n28: 1 batches\n29: 1 batches\n27 Start Epoch 4\n27: 1 batches\n33 Start Epoch 4\n32 Start Epoch 4\n24 Start Epoch 4\n25 Start Epoch 4\n33: 1 batches\n20 Start Epoch 4\n18 Start Epoch 4\n31 Start Epoch 4\n24: 1 batches\n23 Start Epoch 4\n20: 1 batches\n31: 1 batches\n25: 1 batches\n21 Start Epoch 4\n32: 1 batches\n21: 1 batches\n18: 1 batches\n23: 1 batches\n19 Start Epoch 4\n19: 1 batches\n30 Start Epoch 4\n22 Start Epoch 4\n22: 1 batches\n34 Start Epoch 4\n30: 1 batches\n35 Start Epoch 4\n34: 1 batches\n35: 1 batches\n10 Start Epoch 4\n10: 1 batches\n9 Start Epoch 4\n9: 1 batches\n11 Start Epoch 4\n11: 1 batches\n12 Start Epoch 4\n13 Start Epoch 4\n12: 1 batches\n13: 1 batches\n2 Start Epoch 4\n2: 1 batches\n1 Start Epoch 4\n1: 1 batches\n6 Start Epoch 4\n6: 1 batches\n5 Start Epoch 4\n3 Start Epoch 4\n7 Start Epoch 4\n3: 1 batches\n8 Start Epoch 4\n5: 1 batches\n8: 1 batches\n4 Start Epoch 4\n4: 1 batches\n7: 1 batches\n0 Start Epoch 4\n0: 1 batches\n11 Start Epoch 5\n11: 1 batches\n12 Start Epoch 5\n10 Start Epoch 5\n10: 1 batches\n12: 1 batches\n4 Start Epoch 5\n5 Start Epoch 5\n9 Start Epoch 5\n14 Start Epoch 5\n4: 1 batches\n15 Start Epoch 5\n6 Start Epoch 5\n14: 1 batches\n5: 1 batches\n15: 1 batches\n6: 1 batches\n3 Start Epoch 5\n3: 1 batches\n1 Start Epoch 5\n1: 1 batches\n7 Start Epoch 5\n13 Start Epoch 5\n13: 1 batches\n22 Start Epoch 5\n35 Start Epoch 5\n8 Start Epoch 5\n23 Start Epoch 5\n33 Start Epoch 5\n7: 1 batches\n23: 1 batches\n34 Start Epoch 5\n8: 1 batches\n21 Start Epoch 5\n34: 1 batches\n35: 1 batches\n2 Start Epoch 5\n2: 1 batches\n21: 1 batches\n33: 1 batches\n32 Start Epoch 5\n9: 1 batches\n22: 1 batches\n32: 1 batches\n25 Start Epoch 5\n17 Start Epoch 5\n20 Start Epoch 5\n25: 1 batches\n29 Start Epoch 5\n17: 1 batches\n18 Start Epoch 5\n30 Start Epoch 5\n28 Start Epoch 5\n28: 1 batches\n16 Start Epoch 5\n29: 1 batches\n16: 1 batches\n20: 1 batches\n31 Start Epoch 5\n31: 1 batches\n24 Start Epoch 5\n26 Start Epoch 5\n27 Start Epoch 5\n18: 1 batches\n30: 1 batches\n27: 1 batches\n19 Start Epoch 5\n19: 1 batches\n24: 1 batches\n26: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:29: Epoch 0 train loss: 2737.546630859375\nINFO:root:10: Epoch 0 train loss: 797370.375\nINFO:root:11: Epoch 0 train loss: 8295.5244140625\nINFO:root:26: Epoch 0 train loss: 1631283.25\nINFO:root:9: Epoch 0 train loss: 9606.1884765625\nINFO:root:5: Epoch 0 train loss: 13060.48046875\nINFO:root:3: Epoch 0 train loss: 796464.75\nINFO:root:24: Epoch 0 train loss: 1303.3994140625\nINFO:root:4: Epoch 0 train loss: 7750.1904296875\nINFO:root:25: Epoch 0 train loss: 1104.7506103515625\nINFO:root:33: Epoch 0 train loss: 9256.6357421875\nINFO:root:8: Epoch 0 train loss: 890404.0625\nINFO:root:12: Epoch 0 train loss: 664828.25\nINFO:root:30: Epoch 0 train loss: 86488.4375\nINFO:root:14: Epoch 0 train loss: 6325.73583984375\nINFO:root:35: Epoch 0 train loss: 2758.936279296875\nINFO:root:13: Epoch 0 train loss: 1193.3580322265625\nINFO:root:32: Epoch 0 train loss: 2726.990478515625\nINFO:root:1: Epoch 0 train loss: 664412.0625\nINFO:root:15: Epoch 0 train loss: 1460465.375\nINFO:root:6: Epoch 0 train loss: 840569.5625\nINFO:root:31: Epoch 0 train loss: 933401.625\nINFO:root:7: Epoch 0 train loss: 925404.125\nINFO:root:34: Epoch 0 train loss: 2817.0498046875\nINFO:root:2: Epoch 0 train loss: 11441.734375\nINFO:root:0: Epoch 0 train loss: 18686.32421875\nINFO:root:23: Epoch 0 train loss: 10018.2978515625\nINFO:root:21: Epoch 0 train loss: 1111.874755859375\nINFO:root:22: Epoch 0 train loss: 729.343994140625\nINFO:root:17: Epoch 0 train loss: 2372.907470703125\nINFO:root:16: Epoch 0 train loss: 5435.041015625\nINFO:root:20: Epoch 0 train loss: 2226.008544921875\nINFO:root:19: Epoch 0 train loss: 251.661376953125\nINFO:root:18: Epoch 0 train loss: 22248.544921875\nINFO:root:28: Epoch 0 train loss: 88367.90625\nINFO:root:27: Epoch 0 train loss: 6069.21484375\nINFO:root:0: Epoch 0 validation loss: 3621.8248994383835\nINFO:root:15: Epoch 1 train loss: 1215.8172607421875\nINFO:root:13: Epoch 1 train loss: 2934.975341796875\nINFO:root:12: Epoch 1 train loss: 1542.959716796875\nINFO:root:14: Epoch 1 train loss: 1553.298095703125\nINFO:root:11: Epoch 1 train loss: 1460965.375\nINFO:root:10: Epoch 1 train loss: 4999.80810546875\nINFO:root:9: Epoch 1 train loss: 1671251.5\nINFO:root:8: Epoch 1 train loss: 3989.3779296875\nINFO:root:16: Epoch 1 train loss: 1224.80126953125\nINFO:root:17: Epoch 1 train loss: 3107.13525390625\nINFO:root:23: Epoch 1 train loss: 1134.2088623046875\nINFO:root:26: Epoch 1 train loss: 27258.8515625\nINFO:root:25: Epoch 1 train loss: 926423.5\nINFO:root:24: Epoch 1 train loss: 779398.875\nINFO:root:4: Epoch 1 train loss: 7259.24072265625\nINFO:root:5: Epoch 1 train loss: 2606.916015625\nINFO:root:3: Epoch 1 train loss: 135.80213928222656\nINFO:root:7: Epoch 1 train loss: 3009.406005859375\nINFO:root:6: Epoch 1 train loss: 4671.77197265625\nINFO:root:20: Epoch 1 train loss: 14244.349609375\nINFO:root:29: Epoch 1 train loss: 30317.037109375\nINFO:root:19: Epoch 1 train loss: 1492.2950439453125\nINFO:root:30: Epoch 1 train loss: 17081.005859375\nINFO:root:18: Epoch 1 train loss: 265262.15625\nINFO:root:34: Epoch 1 train loss: 743381.5625\nINFO:root:31: Epoch 1 train loss: 4484.2021484375\nINFO:root:35: Epoch 1 train loss: 5430.25830078125\nINFO:root:32: Epoch 1 train loss: 17245.98828125\nINFO:root:0: Epoch 1 train loss: 5421.68310546875\nINFO:root:2: Epoch 1 train loss: 6767.97900390625\nINFO:root:33: Epoch 1 train loss: 133.5703582763672\nINFO:root:1: Epoch 1 train loss: 4554.76220703125\nINFO:root:28: Epoch 1 train loss: 775374.875\nINFO:root:27: Epoch 1 train loss: 664981.1875\nINFO:root:22: Epoch 1 train loss: 17188.234375\nINFO:root:21: Epoch 1 train loss: 2441.443359375\nINFO:root:0: Epoch 1 validation loss: 3621.1806714110367\nINFO:root:11: Epoch 2 train loss: 267736.875\nINFO:root:16: Epoch 2 train loss: 136.219970703125\nINFO:root:26: Epoch 2 train loss: 478.8605651855469\nINFO:root:4: Epoch 2 train loss: 2295.0185546875\nINFO:root:5: Epoch 2 train loss: 2747.681640625\nINFO:root:27: Epoch 2 train loss: 7335.20556640625\nINFO:root:23: Epoch 2 train loss: 1550439.0\nINFO:root:29: Epoch 2 train loss: 1493.2303466796875\nINFO:root:28: Epoch 2 train loss: 4181.94189453125\nINFO:root:17: Epoch 2 train loss: 27536.220703125\nINFO:root:1: Epoch 2 train loss: 743459.0625\nINFO:root:25: Epoch 2 train loss: 346.8799743652344\nINFO:root:34: Epoch 2 train loss: 4919.28857421875\nINFO:root:13: Epoch 2 train loss: 1889.5816650390625\nINFO:root:35: Epoch 2 train loss: 8430.0927734375\nINFO:root:14: Epoch 2 train loss: 1572962.625\nINFO:root:32: Epoch 2 train loss: 972.974609375\nINFO:root:24: Epoch 2 train loss: 6710.87744140625\nINFO:root:15: Epoch 2 train loss: 21108.75\nINFO:root:30: Epoch 2 train loss: 3919.1640625\nINFO:root:20: Epoch 2 train loss: 10390.8740234375\nINFO:root:12: Epoch 2 train loss: 2329.757080078125\nINFO:root:8: Epoch 2 train loss: 317.5366516113281\nINFO:root:19: Epoch 2 train loss: 456.5364685058594\nINFO:root:31: Epoch 2 train loss: 1098.1258544921875\nINFO:root:9: Epoch 2 train loss: 4525.1630859375\nINFO:root:18: Epoch 2 train loss: 2399.4404296875\nINFO:root:10: Epoch 2 train loss: 261296.625\nINFO:root:3: Epoch 2 train loss: 925394.3125\nINFO:root:21: Epoch 2 train loss: 3185.134033203125\nINFO:root:22: Epoch 2 train loss: 1803.9344482421875\nINFO:root:0: Epoch 2 train loss: 1474.29296875\nINFO:root:7: Epoch 2 train loss: 16628.654296875\nINFO:root:6: Epoch 2 train loss: 98.82725524902344\nINFO:root:33: Epoch 2 train loss: 16223.15625\nINFO:root:2: Epoch 2 train loss: 8477.3486328125\nINFO:root:0: Epoch 2 validation loss: 3620.5242433187245\nINFO:root:14: Epoch 3 train loss: 8409.7841796875\nINFO:root:15: Epoch 3 train loss: 114684.015625\nINFO:root:16: Epoch 3 train loss: 404.83062744140625\nINFO:root:17: Epoch 3 train loss: 257.48822021484375\nINFO:root:26: Epoch 3 train loss: 5696.12744140625\nINFO:root:27: Epoch 3 train loss: 18757.0078125\nINFO:root:29: Epoch 3 train loss: 696.805908203125\nINFO:root:28: Epoch 3 train loss: 2995.24267578125\nINFO:root:20: Epoch 3 train loss: 4352.47216796875\nINFO:root:24: Epoch 3 train loss: 667231.25\nINFO:root:22: Epoch 3 train loss: 107.62648010253906\nINFO:root:33: Epoch 3 train loss: 1722.1937255859375\nINFO:root:19: Epoch 3 train loss: 264237.03125\nINFO:root:32: Epoch 3 train loss: 924836.9375\nINFO:root:25: Epoch 3 train loss: 1167.61181640625\nINFO:root:21: Epoch 3 train loss: 3145.006103515625\nINFO:root:18: Epoch 3 train loss: 3309.4140625\nINFO:root:23: Epoch 3 train loss: 6271.52490234375\nINFO:root:31: Epoch 3 train loss: 4453.36572265625\nINFO:root:34: Epoch 3 train loss: 732.477294921875\nINFO:root:30: Epoch 3 train loss: 102917.578125\nINFO:root:35: Epoch 3 train loss: 926.280517578125\nINFO:root:0: Epoch 3 train loss: 86673.0625\nINFO:root:9: Epoch 3 train loss: 6963.90283203125\nINFO:root:10: Epoch 3 train loss: 1031819.0625\nINFO:root:11: Epoch 3 train loss: 4308.54541015625\nINFO:root:13: Epoch 3 train loss: 222.18809509277344\nINFO:root:12: Epoch 3 train loss: 3864.602783203125\nINFO:root:2: Epoch 3 train loss: 102383.3984375\nINFO:root:6: Epoch 3 train loss: 13429.8779296875\nINFO:root:5: Epoch 3 train loss: 774532.125\nINFO:root:1: Epoch 3 train loss: 16141.775390625\nINFO:root:4: Epoch 3 train loss: 3162.4521484375\nINFO:root:3: Epoch 3 train loss: 2348.757080078125\nINFO:root:7: Epoch 3 train loss: 12237.861328125\nINFO:root:8: Epoch 3 train loss: 2491.55322265625\nINFO:root:0: Epoch 3 validation loss: 3619.8476462183953\nINFO:root:11: Epoch 4 train loss: 417.2583312988281\nINFO:root:0: Epoch 4 train loss: 26522.74609375\nINFO:root:3: Epoch 4 train loss: 2766.30126953125\nINFO:root:10: Epoch 4 train loss: 7726.60986328125\nINFO:root:12: Epoch 4 train loss: 565.5443115234375\nINFO:root:5: Epoch 4 train loss: 7435.19482421875\nINFO:root:4: Epoch 4 train loss: 2762.932373046875\nINFO:root:9: Epoch 4 train loss: 4736.75927734375\nINFO:root:14: Epoch 4 train loss: 198.78953552246094\nINFO:root:15: Epoch 4 train loss: 4340.31298828125\nINFO:root:6: Epoch 4 train loss: 32577.48828125\nINFO:root:1: Epoch 4 train loss: 19061.421875\nINFO:root:23: Epoch 4 train loss: 6441.203125\nINFO:root:33: Epoch 4 train loss: 1243.0174560546875\nINFO:root:7: Epoch 4 train loss: 28103.083984375\nINFO:root:13: Epoch 4 train loss: 790099.375\nINFO:root:22: Epoch 4 train loss: 968.0924072265625\nINFO:root:35: Epoch 4 train loss: 5614.67138671875\nINFO:root:21: Epoch 4 train loss: 5950.70166015625\nINFO:root:34: Epoch 4 train loss: 87264.609375\nINFO:root:8: Epoch 4 train loss: 787956.4375\nINFO:root:32: Epoch 4 train loss: 190.03392028808594\nINFO:root:2: Epoch 4 train loss: 1539.8099365234375\nINFO:root:17: Epoch 4 train loss: 445.4304504394531\nINFO:root:20: Epoch 4 train loss: 1665657.25\nINFO:root:25: Epoch 4 train loss: 6276.11083984375\nINFO:root:27: Epoch 4 train loss: 1006.3843994140625\nINFO:root:19: Epoch 4 train loss: 3161.016845703125\nINFO:root:26: Epoch 4 train loss: 6478.375\nINFO:root:28: Epoch 4 train loss: 775328.625\nINFO:root:16: Epoch 4 train loss: 2505.8515625\nINFO:root:30: Epoch 4 train loss: 20309.873046875\nINFO:root:29: Epoch 4 train loss: 4782.82861328125\nINFO:root:18: Epoch 4 train loss: 6974.8515625\nINFO:root:31: Epoch 4 train loss: 1966.096435546875\nINFO:root:24: Epoch 4 train loss: 8178.8740234375\nINFO:root:0: Epoch 4 validation loss: 3619.16138228287\nINFO:root:35: Epoch 5 train loss: 8625.103515625\nINFO:root:32: Epoch 5 train loss: 1148.6600341796875\nINFO:root:33: Epoch 5 train loss: 3855.4091796875\nINFO:root:34: Epoch 5 train loss: 6813.96142578125\nINFO:root:0: Epoch 5 train loss: 4469.56591796875\nINFO:root:31: Epoch 5 train loss: 13630.619140625\nINFO:root:5: Epoch 5 train loss: 2567.927001953125\nINFO:root:29: Epoch 5 train loss: 4935.67431640625\nINFO:root:11: Epoch 5 train loss: 1445.58447265625\nINFO:root:4: Epoch 5 train loss: 669.8665161132812\nINFO:root:28: Epoch 5 train loss: 3001.822265625\nINFO:root:27: Epoch 5 train loss: 3062.83984375\nINFO:root:10: Epoch 5 train loss: 6765.66845703125\nINFO:root:23: Epoch 5 train loss: 12194.1796875\nINFO:root:1: Epoch 5 train loss: 337.86505126953125\nINFO:root:21: Epoch 5 train loss: 695.6694946289062\nINFO:root:22: Epoch 5 train loss: 1992.7125244140625\nINFO:root:6: Epoch 5 train loss: 748628.625\nINFO:root:14: Epoch 5 train loss: 8284.4052734375\nINFO:root:26: Epoch 5 train loss: 90939.1796875\nINFO:root:9: Epoch 5 train loss: 2607.650146484375\nINFO:root:15: Epoch 5 train loss: 1039119.25\nINFO:root:12: Epoch 5 train loss: 1565.5574951171875\nINFO:root:20: Epoch 5 train loss: 931937.0625\nINFO:root:30: Epoch 5 train loss: 15186.498046875\nINFO:root:24: Epoch 5 train loss: 662.9573974609375\nINFO:root:16: Epoch 5 train loss: 9437.9677734375\nINFO:root:8: Epoch 5 train loss: 4825.71337890625\nINFO:root:18: Epoch 5 train loss: 6316.615234375\nINFO:root:17: Epoch 5 train loss: 490.37567138671875\nINFO:root:7: Epoch 5 train loss: 94380.8984375\nINFO:root:19: Epoch 5 train loss: 876.8038330078125\nINFO:root:25: Epoch 5 train loss: 4794.59619140625\nINFO:root:2: Epoch 5 train loss: 724.9932861328125\nINFO:root:13: Epoch 5 train loss: 260966.890625\nINFO:root:3: Epoch 5 train loss: 69.17422485351562\nINFO:root:0: Epoch 5 validation loss: 3618.4630000766065\n", "seconds": 19.304476022720337, "batch_size": 128, "nodes": 12, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.15,192.168.2.15,192.168.2.15 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n1 Start Epoch 0\n2 Start Epoch 0\n0: 6 batches\n2: 6 batches\n3 Start Epoch 0\n1: 6 batches\n3: 6 batches\n1 Start Epoch 1\n1: 6 batches\n3 Start Epoch 1\n3: 6 batches\n2 Start Epoch 1\n2: 6 batches\n0 Start Epoch 1\n0: 6 batches\n3 Start Epoch 2\n2 Start Epoch 2\n3: 6 batches\n2: 6 batches\n1 Start Epoch 2\n1: 6 batches\n0 Start Epoch 2\n0: 6 batches\n3 Start Epoch 3\n3: 6 batches\n1 Start Epoch 3\n1: 6 batches\n2 Start Epoch 3\n2: 6 batches\n0 Start Epoch 3\n0: 6 batches\n3 Start Epoch 4\n3: 6 batches\n1 Start Epoch 4\n2 Start Epoch 4\n1: 6 batches\n2: 6 batches\n0 Start Epoch 4\n0: 6 batches\n1 Start Epoch 5\n1: 6 batches\n2 Start Epoch 5\n2: 6 batches\n3 Start Epoch 5\n3: 6 batches\n0 Start Epoch 5\n0: 6 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 102637.16196695964\nINFO:root:1: Epoch 0 train loss: 166288.6266377767\nINFO:root:3: Epoch 0 train loss: 249676.84533691406\nINFO:root:2: Epoch 0 train loss: 88306.70699055989\nINFO:root:0: Epoch 0 validation loss: 70896.22032791877\nINFO:root:3: Epoch 1 train loss: 267541.4059244792\nINFO:root:2: Epoch 1 train loss: 241948.84691874185\nINFO:root:0: Epoch 1 train loss: 123400.53192138672\nINFO:root:1: Epoch 1 train loss: 163279.73661295572\nINFO:root:0: Epoch 1 validation loss: 70873.64442145824\nINFO:root:1: Epoch 2 train loss: 260185.71931966147\nINFO:root:3: Epoch 2 train loss: 131953.61503092447\nINFO:root:0: Epoch 2 train loss: 256932.93794759116\nINFO:root:2: Epoch 2 train loss: 198244.12356567383\nINFO:root:0: Epoch 2 validation loss: 70846.58042453948\nINFO:root:0: Epoch 3 train loss: 266502.5386912028\nINFO:root:3: Epoch 3 train loss: 189460.97599283853\nINFO:root:2: Epoch 3 train loss: 242587.1533610026\nINFO:root:1: Epoch 3 train loss: 83501.4964650472\nINFO:root:0: Epoch 3 validation loss: 70812.38004537621\nINFO:root:1: Epoch 4 train loss: 294683.00068155926\nINFO:root:0: Epoch 4 train loss: 133101.6634724935\nINFO:root:2: Epoch 4 train loss: 261893.63654581705\nINFO:root:3: Epoch 4 train loss: 197306.93183390299\nINFO:root:0: Epoch 4 validation loss: 70764.41381346335\nINFO:root:1: Epoch 5 train loss: 14087.344441731771\nINFO:root:2: Epoch 5 train loss: 137656.77140299478\nINFO:root:3: Epoch 5 train loss: 78417.45448811848\nINFO:root:0: Epoch 5 train loss: 85083.82116699219\nINFO:root:0: Epoch 5 validation loss: 70698.71542233652\n", "seconds": 107.84276723861694, "batch_size": 128, "nodes": 1, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.15,192.168.2.2,192.168.2.15,192.168.2.2,192.168.2.15,192.168.2.2 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 3 batches\n7 Start Epoch 0\n7: 3 batches\n1 Start Epoch 0\n2 Start Epoch 0\n3 Start Epoch 0\n2: 3 batches\n4 Start Epoch 0\n4: 3 batches\n3: 3 batches\n1: 3 batches\n5 Start Epoch 0\n6 Start Epoch 0\n5: 3 batches\n6: 3 batches\n1 Start Epoch 1\n2 Start Epoch 1\n2: 3 batches\n3 Start Epoch 1\n3: 3 batches\n1: 3 batches\n5 Start Epoch 1\n5: 3 batches\n7 Start Epoch 1\n7: 3 batches\n4 Start Epoch 1\n4: 3 batches\n6 Start Epoch 1\n6: 3 batches\n0 Start Epoch 1\n0: 3 batches\n4 Start Epoch 2\n4: 3 batches\n5 Start Epoch 2\n7 Start Epoch 2\n6 Start Epoch 2\n6: 3 batches\n5: 3 batches\n7: 3 batches\n2 Start Epoch 2\n2: 3 batches\n1 Start Epoch 2\n1: 3 batches\n3 Start Epoch 2\n3: 3 batches\n0 Start Epoch 2\n0: 3 batches\n1 Start Epoch 3\n1: 3 batches\n7 Start Epoch 3\n7: 3 batches\n6 Start Epoch 3\n6: 3 batches\n5 Start Epoch 3\n5: 3 batches\n3 Start Epoch 3\n2 Start Epoch 3\n3: 3 batches\n2: 3 batches\n0 Start Epoch 3\n0: 3 batches\n4 Start Epoch 3\n4: 3 batches\n4 Start Epoch 4\n4: 3 batches\n3 Start Epoch 4\n3: 3 batches\n5 Start Epoch 4\n5: 3 batches\n1 Start Epoch 4\n2 Start Epoch 4\n1: 3 batches\n2: 3 batches\n7 Start Epoch 4\n6 Start Epoch 4\n7: 3 batches\n6: 3 batches\n0 Start Epoch 4\n0: 3 batches\n1 Start Epoch 5\n1: 3 batches\n4 Start Epoch 5\n4: 3 batches\n6 Start Epoch 5\n5 Start Epoch 5\n6: 3 batches\n5: 3 batches\n2 Start Epoch 5\n2: 3 batches\n3 Start Epoch 5\n3: 3 batches\n7 Start Epoch 5\n7: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:1: Epoch 0 train loss: 2032.713602701823\nINFO:root:2: Epoch 0 train loss: 317507.6932373047\nINFO:root:3: Epoch 0 train loss: 60217.822509765625\nINFO:root:0: Epoch 0 train loss: 321314.15445963544\nINFO:root:5: Epoch 0 train loss: 382679.4635416667\nINFO:root:7: Epoch 0 train loss: 5545.6193440755205\nINFO:root:4: Epoch 0 train loss: 59097.58056640625\nINFO:root:6: Epoch 0 train loss: 138389.6180013021\nINFO:root:0: Epoch 0 validation loss: 971590.8107859135\nINFO:root:4: Epoch 1 train loss: 313434.86592610675\nINFO:root:6: Epoch 1 train loss: 142562.3907877604\nINFO:root:5: Epoch 1 train loss: 63367.10567220052\nINFO:root:7: Epoch 1 train loss: 146818.2618815104\nINFO:root:1: Epoch 1 train loss: 229437.07100423178\nINFO:root:0: Epoch 1 train loss: 26354.118489583332\nINFO:root:2: Epoch 1 train loss: 202874.93583170572\nINFO:root:3: Epoch 1 train loss: 163673.04158528647\nINFO:root:0: Epoch 1 validation loss: 971548.9867389326\nINFO:root:1: Epoch 2 train loss: 250256.98741912842\nINFO:root:0: Epoch 2 train loss: 246839.10221354166\nINFO:root:7: Epoch 2 train loss: 288422.0501302083\nINFO:root:6: Epoch 2 train loss: 63577.1474609375\nINFO:root:5: Epoch 2 train loss: 139976.59615071616\nINFO:root:2: Epoch 2 train loss: 346799.1363932292\nINFO:root:3: Epoch 2 train loss: 429389.6194661458\nINFO:root:0: Epoch 2 validation loss: 971502.8764264699\nINFO:root:4: Epoch 2 train loss: 339504.4931640625\nINFO:root:4: Epoch 3 train loss: 504468.8645833333\nINFO:root:3: Epoch 3 train loss: 209202.16471354166\nINFO:root:0: Epoch 3 train loss: 227462.49072265625\nINFO:root:5: Epoch 3 train loss: 236765.5322265625\nINFO:root:1: Epoch 3 train loss: 332518.52596028644\nINFO:root:2: Epoch 3 train loss: 137903.82491048178\nINFO:root:7: Epoch 3 train loss: 375927.7506510417\nINFO:root:6: Epoch 3 train loss: 8529.671712239584\nINFO:root:0: Epoch 3 validation loss: 971450.7249663046\nINFO:root:1: Epoch 4 train loss: 519639.8606770833\nINFO:root:0: Epoch 4 train loss: 2426.369140625\nINFO:root:4: Epoch 4 train loss: 346950.1733805339\nINFO:root:5: Epoch 4 train loss: 185760.89973958334\nINFO:root:6: Epoch 4 train loss: 228784.8888346354\nINFO:root:2: Epoch 4 train loss: 138047.3728841146\nINFO:root:3: Epoch 4 train loss: 518482.78845214844\nINFO:root:7: Epoch 4 train loss: 409196.125\nINFO:root:0: Epoch 4 validation loss: 971392.6346189533\nINFO:root:6: Epoch 5 train loss: 218694.48795572916\nINFO:root:7: Epoch 5 train loss: 2418.2640380859375\nINFO:root:2: Epoch 5 train loss: 169519.62622070312\nINFO:root:1: Epoch 5 train loss: 194053.25032552084\nINFO:root:0: Epoch 5 train loss: 353483.5774739583\nINFO:root:3: Epoch 5 train loss: 226398.46797688803\nINFO:root:4: Epoch 5 train loss: 68616.49007161458\nINFO:root:5: Epoch 5 train loss: 146572.72589111328\nINFO:root:0: Epoch 5 validation loss: 971324.0916766565\n", "seconds": 56.54226899147034, "batch_size": 128, "nodes": 2, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.15,192.168.2.2,192.168.2.3 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "2 Start Epoch 0\n0 Start Epoch 0\n1 Start Epoch 0\n2: 2 batches\n0: 2 batches\n1: 2 batches\n11 Start Epoch 0\n11: 2 batches\n8 Start Epoch 0\n8: 2 batches\n3 Start Epoch 0\n3: 2 batches\n7 Start Epoch 0\n7: 2 batches\n4 Start Epoch 0\n4: 2 batches\n9 Start Epoch 0\n5 Start Epoch 0\n10 Start Epoch 0\n6 Start Epoch 0\n5: 2 batches\n9: 2 batches\n6: 2 batches\n10: 2 batches\n11 Start Epoch 1\n10 Start Epoch 1\n10: 2 batches\n11: 2 batches\n9 Start Epoch 1\n9: 2 batches\n1 Start Epoch 1\n1: 2 batches\n2 Start Epoch 1\n2: 2 batches\n3 Start Epoch 1\n3: 2 batches\n7 Start Epoch 1\n7: 2 batches\n6 Start Epoch 1\n6: 2 batches\n4 Start Epoch 1\n4: 2 batches\n5 Start Epoch 1\n5: 2 batches\n8 Start Epoch 1\n8: 2 batches\n0 Start Epoch 1\n0: 2 batches\n1 Start Epoch 2\n1: 2 batches\n11 Start Epoch 2\n10 Start Epoch 2\n10: 2 batches\n9 Start Epoch 2\n9: 2 batches\n11: 2 batches\n2 Start Epoch 2\n3 Start Epoch 2\n2: 2 batches\n3: 2 batches\n5 Start Epoch 2\n7 Start Epoch 2\n6 Start Epoch 2\n5: 2 batches\n6: 2 batches\n7: 2 batches\n8 Start Epoch 2\n8: 2 batches\n4 Start Epoch 2\n4: 2 batches\n0 Start Epoch 2\n0: 2 batches\n1 Start Epoch 3\n1: 2 batches\n11 Start Epoch 3\n11: 2 batches\n2 Start Epoch 3\n4 Start Epoch 3\n5 Start Epoch 3\n4: 2 batches\n3 Start Epoch 3\n2: 2 batches\n3: 2 batches\n5: 2 batches\n6 Start Epoch 3\n7 Start Epoch 3\n6: 2 batches\n7: 2 batches\n10 Start Epoch 3\n9 Start Epoch 3\n8 Start Epoch 3\n9: 2 batches\n10: 2 batches\n8: 2 batches\n0 Start Epoch 3\n0: 2 batches\n11 Start Epoch 4\n11: 2 batches\n10 Start Epoch 4\n10: 2 batches\n3 Start Epoch 4\n3: 2 batches\n9 Start Epoch 4\n8 Start Epoch 4\n8: 2 batches\n9: 2 batches\n5 Start Epoch 4\n7 Start Epoch 4\n4 Start Epoch 4\n4: 2 batches\n5: 2 batches\n7: 2 batches\n6 Start Epoch 4\n6: 2 batches\n2 Start Epoch 4\n1 Start Epoch 4\n2: 2 batches\n1: 2 batches\n0 Start Epoch 4\n0: 2 batches\n11 Start Epoch 5\n11: 2 batches\n10 Start Epoch 5\n10: 2 batches\n9 Start Epoch 5\n9: 2 batches\n1 Start Epoch 5\n1: 2 batches\n2 Start Epoch 5\n2: 2 batches\n6 Start Epoch 5\n7 Start Epoch 5\n6: 2 batches\n7: 2 batches\n4 Start Epoch 5\n5 Start Epoch 5\n4: 2 batches\n5: 2 batches\n3 Start Epoch 5\n3: 2 batches\n8 Start Epoch 5\n8: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:10: Epoch 0 train loss: 9893.310180664062\nINFO:root:11: Epoch 0 train loss: 255545.01806640625\nINFO:root:9: Epoch 0 train loss: 11213.35986328125\nINFO:root:0: Epoch 0 train loss: 94730.36236572266\nINFO:root:1: Epoch 0 train loss: 503043.69287109375\nINFO:root:2: Epoch 0 train loss: 250831.2695465088\nINFO:root:3: Epoch 0 train loss: 6337.293701171875\nINFO:root:7: Epoch 0 train loss: 32939.803955078125\nINFO:root:4: Epoch 0 train loss: 323303.0392150879\nINFO:root:6: Epoch 0 train loss: 3201.822265625\nINFO:root:5: Epoch 0 train loss: 302288.73376464844\nINFO:root:8: Epoch 0 train loss: 225797.67895507812\nINFO:root:0: Epoch 0 validation loss: 107731.4010950923\nINFO:root:0: Epoch 1 train loss: 5232.412109375\nINFO:root:1: Epoch 1 train loss: 282365.5090332031\nINFO:root:9: Epoch 1 train loss: 475979.3271484375\nINFO:root:11: Epoch 1 train loss: 3751.2589111328125\nINFO:root:10: Epoch 1 train loss: 12621.69580078125\nINFO:root:3: Epoch 1 train loss: 8811.93701171875\nINFO:root:2: Epoch 1 train loss: 280373.0516357422\nINFO:root:7: Epoch 1 train loss: 778331.0\nINFO:root:6: Epoch 1 train loss: 5312.852783203125\nINFO:root:5: Epoch 1 train loss: 209345.9267578125\nINFO:root:8: Epoch 1 train loss: 299854.3740234375\nINFO:root:4: Epoch 1 train loss: 302302.7131347656\nINFO:root:0: Epoch 1 validation loss: 107720.40566430113\nINFO:root:0: Epoch 2 train loss: 4387.3876953125\nINFO:root:1: Epoch 2 train loss: 475108.1025390625\nINFO:root:11: Epoch 2 train loss: 240524.46948242188\nINFO:root:2: Epoch 2 train loss: 97643.30590820312\nINFO:root:3: Epoch 2 train loss: 6012.3338623046875\nINFO:root:4: Epoch 2 train loss: 510279.3815917969\nINFO:root:5: Epoch 2 train loss: 546010.40625\nINFO:root:7: Epoch 2 train loss: 276382.8253173828\nINFO:root:6: Epoch 2 train loss: 1569.45166015625\nINFO:root:8: Epoch 2 train loss: 5150.398193359375\nINFO:root:9: Epoch 2 train loss: 206999.28491210938\nINFO:root:10: Epoch 2 train loss: 255524.27392578125\nINFO:root:0: Epoch 2 validation loss: 107709.09729512704\nINFO:root:11: Epoch 3 train loss: 4593.674072265625\nINFO:root:10: Epoch 3 train loss: 2537.45556640625\nINFO:root:3: Epoch 3 train loss: 9950.695617675781\nINFO:root:0: Epoch 3 train loss: 88116.09008789062\nINFO:root:8: Epoch 3 train loss: 1261.8712463378906\nINFO:root:9: Epoch 3 train loss: 519018.8356933594\nINFO:root:7: Epoch 3 train loss: 511361.796875\nINFO:root:4: Epoch 3 train loss: 2636.461181640625\nINFO:root:6: Epoch 3 train loss: 13967.5478515625\nINFO:root:5: Epoch 3 train loss: 100828.6123046875\nINFO:root:2: Epoch 3 train loss: 274279.71923828125\nINFO:root:1: Epoch 3 train loss: 32834.876953125\nINFO:root:0: Epoch 3 validation loss: 107697.19137843236\nINFO:root:11: Epoch 4 train loss: 9811.699951171875\nINFO:root:10: Epoch 4 train loss: 304630.25634765625\nINFO:root:9: Epoch 4 train loss: 5054.34130859375\nINFO:root:0: Epoch 4 train loss: 243905.25952148438\nINFO:root:1: Epoch 4 train loss: 260157.02880859375\nINFO:root:2: Epoch 4 train loss: 367330.3125\nINFO:root:3: Epoch 4 train loss: 13345.7158203125\nINFO:root:6: Epoch 4 train loss: 309274.416015625\nINFO:root:5: Epoch 4 train loss: 2207.35693359375\nINFO:root:7: Epoch 4 train loss: 2644.5700073242188\nINFO:root:4: Epoch 4 train loss: 512394.171875\nINFO:root:8: Epoch 4 train loss: 227704.111328125\nINFO:root:0: Epoch 4 validation loss: 107684.66968535169\nINFO:root:3: Epoch 5 train loss: 257268.81115722656\nINFO:root:2: Epoch 5 train loss: 302302.3494873047\nINFO:root:1: Epoch 5 train loss: 3821.3663330078125\nINFO:root:7: Epoch 5 train loss: 5584.12744140625\nINFO:root:6: Epoch 5 train loss: 7458.1435546875\nINFO:root:4: Epoch 5 train loss: 11179.251953125\nINFO:root:5: Epoch 5 train loss: 87979.99145507812\nINFO:root:9: Epoch 5 train loss: 272222.3913574219\nINFO:root:8: Epoch 5 train loss: 10677.8349609375\nINFO:root:11: Epoch 5 train loss: 3289.4924926757812\nINFO:root:10: Epoch 5 train loss: 34313.114013671875\nINFO:root:0: Epoch 5 train loss: 95832.83361816406\nINFO:root:0: Epoch 5 validation loss: 107671.1764125007\n", "seconds": 38.559043884277344, "batch_size": 128, "nodes": 3, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n15 Start Epoch 0\n15: 2 batches\n1 Start Epoch 0\n2 Start Epoch 0\n12 Start Epoch 0\n12: 2 batches\n8 Start Epoch 0\n8: 2 batches\n3 Start Epoch 0\n3: 2 batches\n2: 2 batches\n1: 2 batches\n11 Start Epoch 0\n11: 2 batches\n7 Start Epoch 0\n7: 2 batches\n4 Start Epoch 0\n4: 2 batches\n13 Start Epoch 0\n13: 2 batches\n5 Start Epoch 0\n6 Start Epoch 0\n6: 2 batches\n5: 2 batches\n9 Start Epoch 0\n10 Start Epoch 0\n10: 2 batches\n9: 2 batches\n14 Start Epoch 0\n14: 2 batches\n5 Start Epoch 1\n5: 2 batches\n1 Start Epoch 1\n15 Start Epoch 1\n15: 2 batches\n1: 2 batches\n9 Start Epoch 1\n4 Start Epoch 1\n8 Start Epoch 1\n8: 2 batches\n6 Start Epoch 1\n4: 2 batches\n11 Start Epoch 1\n6: 2 batches\n7 Start Epoch 1\n7: 2 batches\n3 Start Epoch 1\n3: 2 batches\n14 Start Epoch 1\n14: 2 batches\n11: 2 batches\n9: 2 batches\n12 Start Epoch 1\n13 Start Epoch 1\n12: 2 batches\n13: 2 batches\n2 Start Epoch 1\n2: 2 batches\n10 Start Epoch 1\n10: 2 batches\n0 Start Epoch 1\n0: 2 batches\n3 Start Epoch 2\n3: 2 batches\n13 Start Epoch 2\n12 Start Epoch 2\n13: 2 batches\n10 Start Epoch 2\n11 Start Epoch 2\n12: 2 batches\n11: 2 batches\n6 Start Epoch 2\n10: 2 batches\n5 Start Epoch 2\n9 Start Epoch 2\n9: 2 batches\n5: 2 batches\n6: 2 batches\n8 Start Epoch 2\n8: 2 batches\n7 Start Epoch 2\n7: 2 batches\n15 Start Epoch 2\n15: 2 batches\n4 Start Epoch 2\n14 Start Epoch 2\n4: 2 batches\n14: 2 batches\n2 Start Epoch 2\n2: 2 batches\n1 Start Epoch 2\n1: 2 batches\n0 Start Epoch 2\n0: 2 batches\n12 Start Epoch 3\n13 Start Epoch 3\n13: 2 batches\n12: 2 batches\n10 Start Epoch 3\n11 Start Epoch 3\n10: 2 batches\n9 Start Epoch 3\n9: 2 batches\n11: 2 batches\n3 Start Epoch 3\n3: 2 batches\n14 Start Epoch 3\n14: 2 batches\n5 Start Epoch 3\n7 Start Epoch 3\n7: 2 batches\n5: 2 batches\n8 Start Epoch 3\n8: 2 batches\n1 Start Epoch 3\n1: 2 batches\n2 Start Epoch 3\n2: 2 batches\n15 Start Epoch 3\n15: 2 batches\n6 Start Epoch 3\n6: 2 batches\n4 Start Epoch 3\n4: 2 batches\n0 Start Epoch 3\n0: 2 batches\n1 Start Epoch 4\n1: 2 batches\n2 Start Epoch 4\n2: 2 batches\n4 Start Epoch 4\n5 Start Epoch 4\n4: 2 batches\n5: 2 batches\n3 Start Epoch 4\n3: 2 batches\n11 Start Epoch 4\n10 Start Epoch 4\n9 Start Epoch 4\n11: 2 batches\n10: 2 batches\n8 Start Epoch 4\n12 Start Epoch 4\n15 Start Epoch 4\n8: 2 batches\n13 Start Epoch 4\n9: 2 batches\n12: 2 batches\n15: 2 batches\n13: 2 batches\n14 Start Epoch 4\n14: 2 batches\n7 Start Epoch 4\n7: 2 batches\n6 Start Epoch 4\n6: 2 batches\n0 Start Epoch 4\n0: 2 batches\n8 Start Epoch 5\n11 Start Epoch 5\n15 Start Epoch 5\n8: 2 batches\n14 Start Epoch 5\n11: 2 batches\n12 Start Epoch 5\n15: 2 batches\n14: 2 batches\n12: 2 batches\n13 Start Epoch 5\n13: 2 batches\n10 Start Epoch 5\n10: 2 batches\n9 Start Epoch 5\n9: 2 batches\n7 Start Epoch 5\n7: 2 batches\n6 Start Epoch 5\n2 Start Epoch 5\n2: 2 batches\n3 Start Epoch 5\n3: 2 batches\n6: 2 batches\n5 Start Epoch 5\n5: 2 batches\n4 Start Epoch 5\n4: 2 batches\n1 Start Epoch 5\n1: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:5: Epoch 0 train loss: 13409.120025634766\nINFO:root:0: Epoch 0 train loss: 11246.370239257812\nINFO:root:1: Epoch 0 train loss: 5329.333190917969\nINFO:root:14: Epoch 0 train loss: 1542.1663513183594\nINFO:root:15: Epoch 0 train loss: 573832.9189453125\nINFO:root:11: Epoch 0 train loss: 9169.327209472656\nINFO:root:4: Epoch 0 train loss: 86878.64477539062\nINFO:root:9: Epoch 0 train loss: 3633.8280639648438\nINFO:root:7: Epoch 0 train loss: 1168232.9803466797\nINFO:root:8: Epoch 0 train loss: 263748.53271484375\nINFO:root:6: Epoch 0 train loss: 14983.068359375\nINFO:root:3: Epoch 0 train loss: 1772.9213256835938\nINFO:root:12: Epoch 0 train loss: 479630.04931640625\nINFO:root:13: Epoch 0 train loss: 5203.209655761719\nINFO:root:2: Epoch 0 train loss: 28924.358528137207\nINFO:root:10: Epoch 0 train loss: 4856.0234375\nINFO:root:0: Epoch 0 validation loss: 131770.80983855273\nINFO:root:3: Epoch 1 train loss: 210925.171875\nINFO:root:13: Epoch 1 train loss: 388605.01725769043\nINFO:root:11: Epoch 1 train loss: 10426.79541015625\nINFO:root:9: Epoch 1 train loss: 302552.09020996094\nINFO:root:12: Epoch 1 train loss: 1727.703125\nINFO:root:10: Epoch 1 train loss: 11556.176513671875\nINFO:root:7: Epoch 1 train loss: 2584.51708984375\nINFO:root:6: Epoch 1 train loss: 571829.8765258789\nINFO:root:5: Epoch 1 train loss: 245524.47827148438\nINFO:root:8: Epoch 1 train loss: 536426.1318359375\nINFO:root:15: Epoch 1 train loss: 5520.572998046875\nINFO:root:14: Epoch 1 train loss: 1506.367172241211\nINFO:root:4: Epoch 1 train loss: 11443.91372680664\nINFO:root:2: Epoch 1 train loss: 454490.2316131592\nINFO:root:0: Epoch 1 train loss: 244893.70849609375\nINFO:root:1: Epoch 1 train loss: 288269.14990234375\nINFO:root:0: Epoch 1 validation loss: 131762.82664627995\nINFO:root:12: Epoch 2 train loss: 5222.856201171875\nINFO:root:13: Epoch 2 train loss: 8444.258178710938\nINFO:root:10: Epoch 2 train loss: 2684.5090255737305\nINFO:root:9: Epoch 2 train loss: 3637.157958984375\nINFO:root:11: Epoch 2 train loss: 9358.595031738281\nINFO:root:3: Epoch 2 train loss: 244014.27685546875\nINFO:root:1: Epoch 2 train loss: 563967.359375\nINFO:root:14: Epoch 2 train loss: 2548.7114868164062\nINFO:root:5: Epoch 2 train loss: 2925.008544921875\nINFO:root:7: Epoch 2 train loss: 7516.205810546875\nINFO:root:6: Epoch 2 train loss: 63445.15515136719\nINFO:root:8: Epoch 2 train loss: 272581.69885253906\nINFO:root:0: Epoch 2 train loss: 90121.54364299774\nINFO:root:2: Epoch 2 train loss: 1275.5689392089844\nINFO:root:15: Epoch 2 train loss: 248399.6953125\nINFO:root:4: Epoch 2 train loss: 94761.263671875\nINFO:root:0: Epoch 2 validation loss: 131754.97804033334\nINFO:root:1: Epoch 3 train loss: 1944.6676330566406\nINFO:root:0: Epoch 3 train loss: 977.6478576660156\nINFO:root:2: Epoch 3 train loss: 560402.7243041992\nINFO:root:3: Epoch 3 train loss: 5755.3121337890625\nINFO:root:4: Epoch 3 train loss: 694381.453125\nINFO:root:5: Epoch 3 train loss: 11659.501953125\nINFO:root:8: Epoch 3 train loss: 32425.973876953125\nINFO:root:10: Epoch 3 train loss: 251437.6036376953\nINFO:root:11: Epoch 3 train loss: 1026758.5320739746\nINFO:root:9: Epoch 3 train loss: 541192.4360351562\nINFO:root:14: Epoch 3 train loss: 675998.2141113281\nINFO:root:12: Epoch 3 train loss: 2979.2347412109375\nINFO:root:13: Epoch 3 train loss: 3807.3844604492188\nINFO:root:15: Epoch 3 train loss: 219265.95056152344\nINFO:root:6: Epoch 3 train loss: 2866.3297119140625\nINFO:root:7: Epoch 3 train loss: 4524.8145751953125\nINFO:root:0: Epoch 3 validation loss: 131747.1952869461\nINFO:root:14: Epoch 4 train loss: 10090.6923828125\nINFO:root:8: Epoch 4 train loss: 10830.86083984375\nINFO:root:10: Epoch 4 train loss: 5780.403564453125\nINFO:root:12: Epoch 4 train loss: 2678.336196899414\nINFO:root:13: Epoch 4 train loss: 2742.0125122070312\nINFO:root:11: Epoch 4 train loss: 7057.7283935546875\nINFO:root:15: Epoch 4 train loss: 244491.60913085938\nINFO:root:0: Epoch 4 train loss: 523997.84747314453\nINFO:root:7: Epoch 4 train loss: 8105.006103515625\nINFO:root:6: Epoch 4 train loss: 1470.201416015625\nINFO:root:9: Epoch 4 train loss: 11606.058876037598\nINFO:root:3: Epoch 4 train loss: 225986.47265625\nINFO:root:2: Epoch 4 train loss: 2568.4083862304688\nINFO:root:5: Epoch 4 train loss: 2546.0263671875\nINFO:root:4: Epoch 4 train loss: 3086.193878173828\nINFO:root:1: Epoch 4 train loss: 88979.31665039062\nINFO:root:0: Epoch 4 validation loss: 131739.4188608\nINFO:root:3: Epoch 5 train loss: 8980.26220703125\nINFO:root:11: Epoch 5 train loss: 2045.5426635742188\nINFO:root:7: Epoch 5 train loss: 5486.807220458984\nINFO:root:13: Epoch 5 train loss: 5213.31201171875\nINFO:root:5: Epoch 5 train loss: 481092.02783203125\nINFO:root:12: Epoch 5 train loss: 496087.5751953125\nINFO:root:6: Epoch 5 train loss: 490130.8083496094\nINFO:root:9: Epoch 5 train loss: 284164.376953125\nINFO:root:8: Epoch 5 train loss: 301773.55630493164\nINFO:root:10: Epoch 5 train loss: 240801.42477416992\nINFO:root:15: Epoch 5 train loss: 3424.4653930664062\nINFO:root:14: Epoch 5 train loss: 19210.83349609375\nINFO:root:2: Epoch 5 train loss: 10576.170166015625\nINFO:root:0: Epoch 5 train loss: 5241.3994140625\nINFO:root:1: Epoch 5 train loss: 4000.225341796875\nINFO:root:4: Epoch 5 train loss: 5245.4190673828125\nINFO:root:0: Epoch 5 validation loss: 131731.5807592575\n", "seconds": 26.546713829040527, "batch_size": 128, "nodes": 4, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "2 Start Epoch 0\n0 Start Epoch 0\n2: 2 batches\n0: 2 batches\n1 Start Epoch 0\n4 Start Epoch 0\n12 Start Epoch 0\n4: 2 batches\n12: 2 batches\n19 Start Epoch 0\n19: 2 batches\n14 Start Epoch 0\n5 Start Epoch 0\n6 Start Epoch 0\n13 Start Epoch 0\n5: 2 batches\n14: 2 batches\n13: 2 batches\n11 Start Epoch 0\n11: 2 batches\n3 Start Epoch 0\n3: 2 batches\n1: 2 batches\n8 Start Epoch 0\n8: 2 batches\n9 Start Epoch 0\n9: 2 batches\n10 Start Epoch 0\n10: 2 batches\n15 Start Epoch 0\n15: 2 batches\n6: 2 batches\n7 Start Epoch 0\n7: 2 batches\n18 Start Epoch 0\n17 Start Epoch 0\n18: 2 batches\n17: 2 batches\n16 Start Epoch 0\n16: 2 batches\n3 Start Epoch 1\n2 Start Epoch 1\n8 Start Epoch 1\n7 Start Epoch 1\n13 Start Epoch 1\n12 Start Epoch 1\n11 Start Epoch 1\n5 Start Epoch 1\n15 Start Epoch 1\n6 Start Epoch 1\n7: 2 batches\n13: 2 batches\n6: 2 batches\n15: 2 batches\n14 Start Epoch 1\n14: 2 batches\n12: 2 batches\n2: 2 batches\n17 Start Epoch 1\n17: 2 batches\n1 Start Epoch 1\n3: 2 batches\n18 Start Epoch 1\n19 Start Epoch 1\n18: 2 batches\n19: 2 batches\n16 Start Epoch 1\n16: 2 batches\n5: 2 batches\n4 Start Epoch 1\n4: 2 batches\n11: 2 batches\n10 Start Epoch 1\n10: 2 batches\n9 Start Epoch 1\n9: 2 batches\n1: 2 batches\n8: 2 batches\n0 Start Epoch 1\n0: 2 batches\n1 Start Epoch 2\n2 Start Epoch 2\n1: 2 batches\n2: 2 batches\n3 Start Epoch 2\n4 Start Epoch 2\n4: 2 batches\n3: 2 batches\n14 Start Epoch 2\n16 Start Epoch 2\n15 Start Epoch 2\n19 Start Epoch 2\n14: 2 batches\n16: 2 batches\n19: 2 batches\n17 Start Epoch 2\n18 Start Epoch 2\n18: 2 batches\n17: 2 batches\n5 Start Epoch 2\n5: 2 batches\n15: 2 batches\n13 Start Epoch 2\n13: 2 batches\n7 Start Epoch 2\n6 Start Epoch 2\n7: 2 batches\n10 Start Epoch 2\n10: 2 batches\n9 Start Epoch 2\n9: 2 batches\n8 Start Epoch 2\n8: 2 batches\n6: 2 batches\n11 Start Epoch 2\n12 Start Epoch 2\n12: 2 batches\n11: 2 batches\n0 Start Epoch 2\n0: 2 batches\n15 Start Epoch 3\n15: 2 batches\n6 Start Epoch 3\n7 Start Epoch 3\n11 Start Epoch 3\n7: 2 batches\n11: 2 batches\n10 Start Epoch 3\n10: 2 batches\n6: 2 batches\n8 Start Epoch 3\n8: 2 batches\n3 Start Epoch 3\n3: 2 batches\n1 Start Epoch 3\n1: 2 batches\n17 Start Epoch 3\n16 Start Epoch 3\n19 Start Epoch 3\n16: 2 batches\n9 Start Epoch 3\n19: 2 batches\n9: 2 batches\n18 Start Epoch 3\n5 Start Epoch 3\n5: 2 batches\n18: 2 batches\n17: 2 batches\n4 Start Epoch 3\n4: 2 batches\n12 Start Epoch 3\n12: 2 batches\n14 Start Epoch 3\n13 Start Epoch 3\n13: 2 batches\n14: 2 batches\n2 Start Epoch 3\n2: 2 batches\n0 Start Epoch 3\n0: 2 batches\n15 Start Epoch 4\n15: 2 batches\n13 Start Epoch 4\n13: 2 batches\n17 Start Epoch 4\n17: 2 batches\n16 Start Epoch 4\n16: 2 batches\n18 Start Epoch 4\n19 Start Epoch 4\n18: 2 batches\n19: 2 batches\n1 Start Epoch 4\n1: 2 batches\n14 Start Epoch 4\n12 Start Epoch 4\n14: 2 batches\n2 Start Epoch 4\n3 Start Epoch 4\n2: 2 batches\n3: 2 batches\n11 Start Epoch 4\n8 Start Epoch 4\n11: 2 batches\n8: 2 batches\n12: 2 batches\n9 Start Epoch 4\n9: 2 batches\n5 Start Epoch 4\n10 Start Epoch 4\n5: 2 batches\n10: 2 batches\n6 Start Epoch 4\n6: 2 batches\n7 Start Epoch 4\n4 Start Epoch 4\n4: 2 batches\n7: 2 batches\n0 Start Epoch 4\n0: 2 batches\n1 Start Epoch 5\n1: 2 batches\n2 Start Epoch 5\n2: 2 batches\n15 Start Epoch 5\n19 Start Epoch 5\n15: 2 batches\n19: 2 batches\n4 Start Epoch 5\n7 Start Epoch 5\n9 Start Epoch 5\n9: 2 batches\n4: 2 batches\n7: 2 batches\n5 Start Epoch 5\n8 Start Epoch 5\n5: 2 batches\n13 Start Epoch 5\n14 Start Epoch 5\n14: 2 batches\n13: 2 batches\n6 Start Epoch 5\n6: 2 batches\n10 Start Epoch 5\n10: 2 batches\n17 Start Epoch 5\n16 Start Epoch 5\n16: 2 batches\n17: 2 batches\n18 Start Epoch 5\n18: 2 batches\n3 Start Epoch 5\n3: 2 batches\n8: 2 batches\n12 Start Epoch 5\n12: 2 batches\n11 Start Epoch 5\n11: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:2: Epoch 0 train loss: 474.34932374954224\nINFO:root:3: Epoch 0 train loss: 4837.231689453125\nINFO:root:13: Epoch 0 train loss: 1422.9607009887695\nINFO:root:6: Epoch 0 train loss: 19186.720977783203\nINFO:root:14: Epoch 0 train loss: 901.7553086280823\nINFO:root:15: Epoch 0 train loss: 531619.7149009705\nINFO:root:11: Epoch 0 train loss: 7126.361755371094\nINFO:root:5: Epoch 0 train loss: 2506.3943939208984\nINFO:root:7: Epoch 0 train loss: 11854.66064453125\nINFO:root:12: Epoch 0 train loss: 30314.981018066406\nINFO:root:8: Epoch 0 train loss: 7050.888671875\nINFO:root:0: Epoch 0 train loss: 205575.15648651123\nINFO:root:18: Epoch 0 train loss: 210341.24951171875\nINFO:root:17: Epoch 0 train loss: 13284.337951660156\nINFO:root:1: Epoch 0 train loss: 254891.3583984375\nINFO:root:19: Epoch 0 train loss: 1737465.09375\nINFO:root:16: Epoch 0 train loss: 235.05788040161133\nINFO:root:4: Epoch 0 train loss: 1525829.7709960938\nINFO:root:10: Epoch 0 train loss: 1707.0108337402344\nINFO:root:9: Epoch 0 train loss: 85852.2174987793\nINFO:root:0: Epoch 0 validation loss: 39226.60963246355\nINFO:root:1: Epoch 1 train loss: 303550.26681518555\nINFO:root:2: Epoch 1 train loss: 4586.584899902344\nINFO:root:4: Epoch 1 train loss: 209509.97680664062\nINFO:root:3: Epoch 1 train loss: 2961.215133190155\nINFO:root:0: Epoch 1 train loss: 3217.2434463500977\nINFO:root:19: Epoch 1 train loss: 263823.767578125\nINFO:root:15: Epoch 1 train loss: 5104.220031738281\nINFO:root:16: Epoch 1 train loss: 2009.5589904785156\nINFO:root:14: Epoch 1 train loss: 273.6264419555664\nINFO:root:17: Epoch 1 train loss: 522326.4249572754\nINFO:root:18: Epoch 1 train loss: 250948.12326049805\nINFO:root:5: Epoch 1 train loss: 5415.2490234375\nINFO:root:13: Epoch 1 train loss: 1548.9236755371094\nINFO:root:6: Epoch 1 train loss: 217801.3647352457\nINFO:root:7: Epoch 1 train loss: 1499.0506782531738\nINFO:root:8: Epoch 1 train loss: 8599.260501861572\nINFO:root:9: Epoch 1 train loss: 4788.7076416015625\nINFO:root:10: Epoch 1 train loss: 21243.000732421875\nINFO:root:11: Epoch 1 train loss: 30649.39778137207\nINFO:root:12: Epoch 1 train loss: 7501.2218017578125\nINFO:root:0: Epoch 1 validation loss: 39220.843789313374\nINFO:root:15: Epoch 2 train loss: 252703.59288978577\nINFO:root:6: Epoch 2 train loss: 3320.6160430908203\nINFO:root:11: Epoch 2 train loss: 1908978.3125\nINFO:root:7: Epoch 2 train loss: 2933.8355865478516\nINFO:root:10: Epoch 2 train loss: 16281.9765625\nINFO:root:8: Epoch 2 train loss: 269246.1123046875\nINFO:root:1: Epoch 2 train loss: 1716050.78125\nINFO:root:0: Epoch 2 train loss: 10328.083923339844\nINFO:root:3: Epoch 2 train loss: 510989.1818008423\nINFO:root:18: Epoch 2 train loss: 5207.2054443359375\nINFO:root:17: Epoch 2 train loss: 867.7003173828125\nINFO:root:16: Epoch 2 train loss: 203.24185359477997\nINFO:root:19: Epoch 2 train loss: 1365.886516571045\nINFO:root:9: Epoch 2 train loss: 973852.0210142136\nINFO:root:5: Epoch 2 train loss: 3786.8499755859375\nINFO:root:4: Epoch 2 train loss: 261503.63793945312\nINFO:root:12: Epoch 2 train loss: 746.9162368774414\nINFO:root:14: Epoch 2 train loss: 1659.4186553955078\nINFO:root:13: Epoch 2 train loss: 3577.1542739868164\nINFO:root:2: Epoch 2 train loss: 6981.263671875\nINFO:root:0: Epoch 2 validation loss: 39215.15357573305\nINFO:root:15: Epoch 3 train loss: 1338182.3271484375\nINFO:root:13: Epoch 3 train loss: 261040.2033996582\nINFO:root:17: Epoch 3 train loss: 849.4385604858398\nINFO:root:16: Epoch 3 train loss: 2074941.1875\nINFO:root:18: Epoch 3 train loss: 17803.55078125\nINFO:root:19: Epoch 3 train loss: 2357.1463012695312\nINFO:root:1: Epoch 3 train loss: 1925.7495193481445\nINFO:root:0: Epoch 3 train loss: 34126.171142578125\nINFO:root:12: Epoch 3 train loss: 203568.8420600891\nINFO:root:14: Epoch 3 train loss: 5989.888427734375\nINFO:root:2: Epoch 3 train loss: 241681.3193359375\nINFO:root:3: Epoch 3 train loss: 5626.178985595703\nINFO:root:5: Epoch 3 train loss: 8260.74267578125\nINFO:root:8: Epoch 3 train loss: 1635.520534992218\nINFO:root:11: Epoch 3 train loss: 1097.9051971435547\nINFO:root:9: Epoch 3 train loss: 4944.683486938477\nINFO:root:10: Epoch 3 train loss: 7452.60107421875\nINFO:root:6: Epoch 3 train loss: 246011.89990234375\nINFO:root:7: Epoch 3 train loss: 4647.571449279785\nINFO:root:4: Epoch 3 train loss: 2699.9520111083984\nINFO:root:0: Epoch 3 validation loss: 39209.34568663096\nINFO:root:1: Epoch 4 train loss: 781.9340753555298\nINFO:root:2: Epoch 4 train loss: 1368.1496887207031\nINFO:root:0: Epoch 4 train loss: 3986.4853515625\nINFO:root:19: Epoch 4 train loss: 2418.640838623047\nINFO:root:4: Epoch 4 train loss: 11207.273318767548\nINFO:root:15: Epoch 4 train loss: 251282.02030944824\nINFO:root:5: Epoch 4 train loss: 463180.38330078125\nINFO:root:7: Epoch 4 train loss: 10074.554443359375\nINFO:root:9: Epoch 4 train loss: 7838.5257568359375\nINFO:root:13: Epoch 4 train loss: 1578485.9907226562\nINFO:root:8: Epoch 4 train loss: 1837.0974888801575\nINFO:root:14: Epoch 4 train loss: 1397.6479187011719\nINFO:root:11: Epoch 4 train loss: 422.02745056152344\nINFO:root:6: Epoch 4 train loss: 216882.30908203125\nINFO:root:10: Epoch 4 train loss: 8730.3525390625\nINFO:root:18: Epoch 4 train loss: 829.8301849365234\nINFO:root:16: Epoch 4 train loss: 1786359.40625\nINFO:root:17: Epoch 4 train loss: 3133.0135955810547\nINFO:root:3: Epoch 4 train loss: 1625.1088371276855\nINFO:root:12: Epoch 4 train loss: 2108.874644756317\nINFO:root:0: Epoch 4 validation loss: 39203.42644384195\nINFO:root:3: Epoch 5 train loss: 88470.84341430664\nINFO:root:2: Epoch 5 train loss: 11049.616505622864\nINFO:root:15: Epoch 5 train loss: 2843.982421875\nINFO:root:5: Epoch 5 train loss: 1062.0624933242798\nINFO:root:4: Epoch 5 train loss: 6046.258544921875\nINFO:root:14: Epoch 5 train loss: 4031.613660812378\nINFO:root:17: Epoch 5 train loss: 33189.046226501465\nINFO:root:18: Epoch 5 train loss: 252595.85028076172\nINFO:root:19: Epoch 5 train loss: 253505.10961914062\nINFO:root:9: Epoch 5 train loss: 5211.24764251709\nINFO:root:8: Epoch 5 train loss: 87276.4736328125\nINFO:root:10: Epoch 5 train loss: 1312493.8262634277\nINFO:root:11: Epoch 5 train loss: 452220.2263469696\nINFO:root:7: Epoch 5 train loss: 88726.43518066406\nINFO:root:6: Epoch 5 train loss: 38444.7392578125\nINFO:root:12: Epoch 5 train loss: 3914.015625\nINFO:root:0: Epoch 5 train loss: 1160.2749938964844\nINFO:root:1: Epoch 5 train loss: 224044.90747070312\nINFO:root:13: Epoch 5 train loss: 2091.2297973632812\nINFO:root:16: Epoch 5 train loss: 3458.1156425476074\nINFO:root:0: Epoch 5 validation loss: 39197.176764118776\n", "seconds": 22.634045124053955, "batch_size": 128, "nodes": 5, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "1 Start Epoch 0\n2 Start Epoch 0\n1: 1 batches\n2: 1 batches\n5 Start Epoch 0\n6 Start Epoch 0\n14 Start Epoch 0\n17 Start Epoch 0\n14: 1 batches\n18 Start Epoch 0\n12 Start Epoch 0\n13 Start Epoch 0\n12: 1 batches\n13: 1 batches\n9 Start Epoch 0\n9: 1 batches\n10 Start Epoch 0\n10: 1 batches\n8 Start Epoch 0\n8: 1 batches\n15 Start Epoch 0\n15: 1 batches\n3 Start Epoch 0\n3: 1 batches\n5: 1 batches\n21 Start Epoch 0\n6: 1 batches\n22 Start Epoch 0\n7 Start Epoch 0\n7: 1 batches\n21: 1 batches\n4 Start Epoch 0\n4: 1 batches\n22: 1 batches\n20 Start Epoch 0\n20: 1 batches\n17: 1 batches\n19 Start Epoch 0\n19: 1 batches\n18: 1 batches\n16 Start Epoch 0\n16: 1 batches\n0 Start Epoch 0\n11 Start Epoch 0\n0: 1 batches\n11: 1 batches\n23 Start Epoch 0\n23: 1 batches\n9 Start Epoch 1\n8 Start Epoch 1\n8: 1 batches\n9: 1 batches\n5 Start Epoch 1\n22 Start Epoch 1\n6 Start Epoch 1\n6: 1 batches\n21 Start Epoch 1\n21: 1 batches\n5: 1 batches\n23 Start Epoch 1\n15 Start Epoch 1\n12 Start Epoch 1\n13 Start Epoch 1\n15: 1 batches\n12: 1 batches\n14 Start Epoch 1\n14: 1 batches\n13: 1 batches\n23: 1 batches\n1 Start Epoch 1\n1: 1 batches\n3 Start Epoch 1\n3: 1 batches\n2 Start Epoch 1\n2: 1 batches\n10 Start Epoch 1\n4 Start Epoch 1\n10: 1 batches\n4: 1 batches\n20 Start Epoch 1\n7 Start Epoch 1\n20: 1 batches\n7: 1 batches\n22: 1 batches\n18 Start Epoch 1\n19 Start Epoch 1\n17 Start Epoch 1\n17: 1 batches\n18: 1 batches\n16 Start Epoch 1\n16: 1 batches\n19: 1 batches\n11 Start Epoch 1\n11: 1 batches\n0 Start Epoch 1\n0: 1 batches\n18 Start Epoch 2\n17 Start Epoch 2\n17: 1 batches\n16 Start Epoch 2\n14 Start Epoch 2\n14: 1 batches\n16: 1 batches\n15 Start Epoch 2\n15: 1 batches\n18: 1 batches\n1 Start Epoch 2\n1: 1 batches\n22 Start Epoch 2\n22: 1 batches\n21 Start Epoch 2\n21: 1 batches\n23 Start Epoch 2\n23: 1 batches\n20 Start Epoch 2\n20: 1 batches\n19 Start Epoch 2\n19: 1 batches\n5 Start Epoch 2\n5: 1 batches\n11 Start Epoch 2\n8 Start Epoch 2\n13 Start Epoch 2\n11: 1 batches\n8: 1 batches\n6 Start Epoch 2\n6: 1 batches\n3 Start Epoch 2\n3: 1 batches\n12 Start Epoch 2\n12: 1 batches\n13: 1 batches\n2 Start Epoch 2\n10 Start Epoch 2\n10: 1 batches\n9 Start Epoch 2\n9: 1 batches\n2: 1 batches\n4 Start Epoch 2\n4: 1 batches\n7 Start Epoch 2\n7: 1 batches\n0 Start Epoch 2\n0: 1 batches\n3 Start Epoch 3\n3: 1 batches\n4 Start Epoch 3\n4: 1 batches\n5 Start Epoch 3\n5: 1 batches\n8 Start Epoch 3\n8: 1 batches\n6 Start Epoch 3\n7 Start Epoch 3\n7: 1 batches\n6: 1 batches\n2 Start Epoch 3\n2: 1 batches\n9 Start Epoch 3\n9: 1 batches\n1 Start Epoch 3\n1: 1 batches\n23 Start Epoch 3\n13 Start Epoch 3\n22 Start Epoch 3\n12 Start Epoch 3\n23: 1 batches\n12: 1 batches\n13: 1 batches\n11 Start Epoch 3\n10 Start Epoch 3\n10: 1 batches\n11: 1 batches\n19 Start Epoch 3\n15 Start Epoch 3\n15: 1 batches\n14 Start Epoch 3\n14: 1 batches\n19: 1 batches\n17 Start Epoch 3\n18 Start Epoch 3\n17: 1 batches\n18: 1 batches\n21 Start Epoch 3\n21: 1 batches\n20 Start Epoch 3\n20: 1 batches\n22: 1 batches\n16 Start Epoch 3\n16: 1 batches\n0 Start Epoch 3\n0: 1 batches\n3 Start Epoch 4\n3: 1 batches\n6 Start Epoch 4\n6: 1 batches\n13 Start Epoch 4\n9 Start Epoch 4\n11 Start Epoch 4\n7 Start Epoch 4\n7: 1 batches\n12 Start Epoch 4\n12: 1 batches\n10 Start Epoch 4\n15 Start Epoch 4\n10: 1 batches\n15: 1 batches\n11: 1 batches\n9: 1 batches\n23 Start Epoch 4\n23: 1 batches\n17 Start Epoch 4\n16 Start Epoch 4\n16: 1 batches\n17: 1 batches\n13: 1 batches\n5 Start Epoch 4\n5: 1 batches\n8 Start Epoch 4\n18 Start Epoch 4\n20 Start Epoch 4\n20: 1 batches\n14 Start Epoch 4\n8: 1 batches\n18: 1 batches\n4 Start Epoch 4\n4: 1 batches\n21 Start Epoch 4\n14: 1 batches\n19 Start Epoch 4\n22 Start Epoch 4\n19: 1 batches\n21: 1 batches\n22: 1 batches\n1 Start Epoch 4\n1: 1 batches\n2 Start Epoch 4\n2: 1 batches\n0 Start Epoch 4\n0: 1 batches\n13 Start Epoch 5\n10 Start Epoch 5\n12 Start Epoch 5\n11 Start Epoch 5\n12: 1 batches\n11: 1 batches\n10: 1 batches\n13: 1 batches\n17 Start Epoch 5\n17: 1 batches\n14 Start Epoch 5\n14: 1 batches\n21 Start Epoch 5\n21: 1 batches\n20 Start Epoch 5\n20: 1 batches\n8 Start Epoch 5\n9 Start Epoch 5\n16 Start Epoch 5\n16: 1 batches\n9: 1 batches\n15 Start Epoch 5\n15: 1 batches\n7 Start Epoch 5\n7: 1 batches\n18 Start Epoch 5\n18: 1 batches\n19 Start Epoch 5\n1 Start Epoch 5\n1: 1 batches\n3 Start Epoch 5\n3: 1 batches\n22 Start Epoch 5\n5 Start Epoch 5\n5: 1 batches\n22: 1 batches\n4 Start Epoch 5\n4: 1 batches\n6 Start Epoch 5\n6: 1 batches\n19: 1 batches\n2 Start Epoch 5\n2: 1 batches\n23 Start Epoch 5\n8: 1 batches\n23: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:8: Epoch 0 train loss: 60298.2734375\nINFO:root:9: Epoch 0 train loss: 4057.67431640625\nINFO:root:23: Epoch 0 train loss: 3041.224609375\nINFO:root:6: Epoch 0 train loss: 18044.52734375\nINFO:root:22: Epoch 0 train loss: 906.50439453125\nINFO:root:5: Epoch 0 train loss: 61153.03515625\nINFO:root:21: Epoch 0 train loss: 5208.92724609375\nINFO:root:13: Epoch 0 train loss: 11160.076171875\nINFO:root:12: Epoch 0 train loss: 517868.59375\nINFO:root:14: Epoch 0 train loss: 1637.3399658203125\nINFO:root:15: Epoch 0 train loss: 4682.8935546875\nINFO:root:4: Epoch 0 train loss: 5140.3330078125\nINFO:root:10: Epoch 0 train loss: 1259.5321044921875\nINFO:root:2: Epoch 0 train loss: 3721.947021484375\nINFO:root:1: Epoch 0 train loss: 2852.87841796875\nINFO:root:3: Epoch 0 train loss: 607.1764526367188\nINFO:root:7: Epoch 0 train loss: 7780.83544921875\nINFO:root:20: Epoch 0 train loss: 2052.241455078125\nINFO:root:18: Epoch 0 train loss: 4535.7919921875\nINFO:root:16: Epoch 0 train loss: 805.8558959960938\nINFO:root:19: Epoch 0 train loss: 5523.1875\nINFO:root:17: Epoch 0 train loss: 11205.7568359375\nINFO:root:11: Epoch 0 train loss: 4040.495849609375\nINFO:root:0: Epoch 0 train loss: 2255.28564453125\nINFO:root:0: Epoch 0 validation loss: 1331571.9065939183\nINFO:root:16: Epoch 1 train loss: 11903.2705078125\nINFO:root:18: Epoch 1 train loss: 8975.548828125\nINFO:root:17: Epoch 1 train loss: 11379.552734375\nINFO:root:14: Epoch 1 train loss: 468.4186706542969\nINFO:root:15: Epoch 1 train loss: 2451.5576171875\nINFO:root:1: Epoch 1 train loss: 10242.720703125\nINFO:root:21: Epoch 1 train loss: 457.6790771484375\nINFO:root:23: Epoch 1 train loss: 2861.52490234375\nINFO:root:22: Epoch 1 train loss: 1256649.0\nINFO:root:20: Epoch 1 train loss: 3463.337890625\nINFO:root:19: Epoch 1 train loss: 2003.7890625\nINFO:root:5: Epoch 1 train loss: 10169.5625\nINFO:root:11: Epoch 1 train loss: 1310.26806640625\nINFO:root:8: Epoch 1 train loss: 539365.3125\nINFO:root:13: Epoch 1 train loss: 1811.0311279296875\nINFO:root:12: Epoch 1 train loss: 1709.5025634765625\nINFO:root:6: Epoch 1 train loss: 1033370.1875\nINFO:root:3: Epoch 1 train loss: 661.8721313476562\nINFO:root:0: Epoch 1 train loss: 10928.306640625\nINFO:root:9: Epoch 1 train loss: 858.2450561523438\nINFO:root:2: Epoch 1 train loss: 460.80535888671875\nINFO:root:10: Epoch 1 train loss: 21739.509765625\nINFO:root:4: Epoch 1 train loss: 2151.060302734375\nINFO:root:7: Epoch 1 train loss: 3711.362548828125\nINFO:root:0: Epoch 1 validation loss: 1331562.1130046507\nINFO:root:3: Epoch 2 train loss: 6245.27197265625\nINFO:root:5: Epoch 2 train loss: 3255.66748046875\nINFO:root:4: Epoch 2 train loss: 562944.375\nINFO:root:8: Epoch 2 train loss: 5725.3857421875\nINFO:root:7: Epoch 2 train loss: 743.818359375\nINFO:root:6: Epoch 2 train loss: 3203.908203125\nINFO:root:2: Epoch 2 train loss: 2614.47021484375\nINFO:root:9: Epoch 2 train loss: 8389.4736328125\nINFO:root:1: Epoch 2 train loss: 528120.0625\nINFO:root:22: Epoch 2 train loss: 598269.4375\nINFO:root:13: Epoch 2 train loss: 10690.2880859375\nINFO:root:23: Epoch 2 train loss: 431763.34375\nINFO:root:12: Epoch 2 train loss: 5371.37109375\nINFO:root:11: Epoch 2 train loss: 181539.84375\nINFO:root:10: Epoch 2 train loss: 2547.1044921875\nINFO:root:19: Epoch 2 train loss: 12044.0693359375\nINFO:root:14: Epoch 2 train loss: 12220.939453125\nINFO:root:15: Epoch 2 train loss: 873.0259399414062\nINFO:root:18: Epoch 2 train loss: 149.58998107910156\nINFO:root:17: Epoch 2 train loss: 1070.5531005859375\nINFO:root:16: Epoch 2 train loss: 19405.79296875\nINFO:root:21: Epoch 2 train loss: 437576.40625\nINFO:root:20: Epoch 2 train loss: 9144.23828125\nINFO:root:0: Epoch 2 train loss: 424675.5625\nINFO:root:0: Epoch 2 validation loss: 1331552.3146066817\nINFO:root:3: Epoch 3 train loss: 80027.34375\nINFO:root:6: Epoch 3 train loss: 447211.875\nINFO:root:15: Epoch 3 train loss: 3157.731689453125\nINFO:root:10: Epoch 3 train loss: 497131.40625\nINFO:root:11: Epoch 3 train loss: 3269.769775390625\nINFO:root:7: Epoch 3 train loss: 2270.76611328125\nINFO:root:12: Epoch 3 train loss: 3617.28857421875\nINFO:root:13: Epoch 3 train loss: 438518.03125\nINFO:root:9: Epoch 3 train loss: 2054.051025390625\nINFO:root:16: Epoch 3 train loss: 6625.1220703125\nINFO:root:23: Epoch 3 train loss: 528434.4375\nINFO:root:17: Epoch 3 train loss: 1487.67138671875\nINFO:root:8: Epoch 3 train loss: 1007.8252563476562\nINFO:root:18: Epoch 3 train loss: 1743.2889404296875\nINFO:root:20: Epoch 3 train loss: 622225.75\nINFO:root:21: Epoch 3 train loss: 521006.71875\nINFO:root:14: Epoch 3 train loss: 3427.7626953125\nINFO:root:5: Epoch 3 train loss: 965328.625\nINFO:root:4: Epoch 3 train loss: 5460.16796875\nINFO:root:19: Epoch 3 train loss: 4031.1943359375\nINFO:root:22: Epoch 3 train loss: 536366.1875\nINFO:root:0: Epoch 3 train loss: 1256.21484375\nINFO:root:1: Epoch 3 train loss: 1004.101318359375\nINFO:root:2: Epoch 3 train loss: 5590.431640625\nINFO:root:0: Epoch 3 validation loss: 1331542.520019051\nINFO:root:12: Epoch 4 train loss: 4162.9091796875\nINFO:root:10: Epoch 4 train loss: 2072.4716796875\nINFO:root:11: Epoch 4 train loss: 534693.9375\nINFO:root:13: Epoch 4 train loss: 7908.0556640625\nINFO:root:17: Epoch 4 train loss: 422395.40625\nINFO:root:14: Epoch 4 train loss: 1317.6541748046875\nINFO:root:20: Epoch 4 train loss: 2901.91552734375\nINFO:root:21: Epoch 4 train loss: 618460.375\nINFO:root:16: Epoch 4 train loss: 2338.078125\nINFO:root:9: Epoch 4 train loss: 517063.625\nINFO:root:8: Epoch 4 train loss: 560896.0\nINFO:root:15: Epoch 4 train loss: 440948.625\nINFO:root:7: Epoch 4 train loss: 2131.495849609375\nINFO:root:19: Epoch 4 train loss: 433.0113220214844\nINFO:root:18: Epoch 4 train loss: 181170.375\nINFO:root:1: Epoch 4 train loss: 631547.1875\nINFO:root:0: Epoch 4 train loss: 6679.33837890625\nINFO:root:3: Epoch 4 train loss: 9576.4443359375\nINFO:root:6: Epoch 4 train loss: 2739.549072265625\nINFO:root:22: Epoch 4 train loss: 8101.3974609375\nINFO:root:5: Epoch 4 train loss: 519049.75\nINFO:root:4: Epoch 4 train loss: 4135.10791015625\nINFO:root:2: Epoch 4 train loss: 18717.134765625\nINFO:root:23: Epoch 4 train loss: 16364.24609375\nINFO:root:0: Epoch 4 validation loss: 1331532.5741831942\nINFO:root:19: Epoch 5 train loss: 2535.671142578125\nINFO:root:23: Epoch 5 train loss: 938378.125\nINFO:root:1: Epoch 5 train loss: 2575.039794921875\nINFO:root:0: Epoch 5 train loss: 7891.00830078125\nINFO:root:20: Epoch 5 train loss: 619785.75\nINFO:root:21: Epoch 5 train loss: 537041.4375\nINFO:root:22: Epoch 5 train loss: 4802.2646484375\nINFO:root:17: Epoch 5 train loss: 1144.1634521484375\nINFO:root:18: Epoch 5 train loss: 188.04090881347656\nINFO:root:4: Epoch 5 train loss: 1900.047119140625\nINFO:root:15: Epoch 5 train loss: 618887.875\nINFO:root:5: Epoch 5 train loss: 8902.30859375\nINFO:root:14: Epoch 5 train loss: 560211.125\nINFO:root:12: Epoch 5 train loss: 498174.40625\nINFO:root:13: Epoch 5 train loss: 64032.953125\nINFO:root:7: Epoch 5 train loss: 3367.66650390625\nINFO:root:6: Epoch 5 train loss: 448544.6875\nINFO:root:3: Epoch 5 train loss: 2038.290283203125\nINFO:root:2: Epoch 5 train loss: 19268.13671875\nINFO:root:16: Epoch 5 train loss: 12703.419921875\nINFO:root:11: Epoch 5 train loss: 1790.6376953125\nINFO:root:8: Epoch 5 train loss: 419363.90625\nINFO:root:10: Epoch 5 train loss: 2642.32568359375\nINFO:root:9: Epoch 5 train loss: 5147.7158203125\nINFO:root:0: Epoch 5 validation loss: 1331522.7659838712\n", "seconds": 21.49096703529358, "batch_size": 128, "nodes": 6, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 1 batches\n2: 1 batches\n27 Start Epoch 0\n27: 1 batches\n23 Start Epoch 0\n23: 1 batches\n20 Start Epoch 0\n20: 1 batches\n3 Start Epoch 0\n4 Start Epoch 0\n3: 1 batches\n16 Start Epoch 0\n8 Start Epoch 0\n24 Start Epoch 0\n15 Start Epoch 0\n7 Start Epoch 0\n16: 1 batches\n8: 1 batches\n24: 1 batches\n15: 1 batches\n4: 1 batches\n19 Start Epoch 0\n11 Start Epoch 0\n12 Start Epoch 0\n7: 1 batches\n19: 1 batches\n11: 1 batches\n12: 1 batches\n10 Start Epoch 0\n9 Start Epoch 0\n9: 1 batches\n10: 1 batches\n5 Start Epoch 0\n5: 1 batches\n17 Start Epoch 0\n6 Start Epoch 0\n18 Start Epoch 0\n6: 1 batches\n18: 1 batches\n26 Start Epoch 0\n25 Start Epoch 0\n17: 1 batches\n26: 1 batches\n25: 1 batches\n13 Start Epoch 0\n14 Start Epoch 0\n13: 1 batches\n14: 1 batches\n21 Start Epoch 0\n22 Start Epoch 0\n21: 1 batches\n22: 1 batches\n21 Start Epoch 1\n22 Start Epoch 1\n23 Start Epoch 1\n23: 1 batches\n22: 1 batches\n21: 1 batches\n24 Start Epoch 1\n24: 1 batches\n20 Start Epoch 1\n20: 1 batches\n19 Start Epoch 1\n19: 1 batches\n18 Start Epoch 1\n18: 1 batches\n17 Start Epoch 1\n16 Start Epoch 1\n16: 1 batches\n17: 1 batches\n15 Start Epoch 1\n15: 1 batches\n14 Start Epoch 1\n14: 1 batches\n13 Start Epoch 1\n13: 1 batches\n12 Start Epoch 1\n12: 1 batches\n11 Start Epoch 1\n11: 1 batches\n10 Start Epoch 1\n10: 1 batches\n7 Start Epoch 1\n7: 1 batches\n9 Start Epoch 1\n9: 1 batches\n8 Start Epoch 1\n8: 1 batches\n5 Start Epoch 1\n5: 1 batches\n6 Start Epoch 1\n6: 1 batches\n4 Start Epoch 1\n4: 1 batches\n3 Start Epoch 1\n3: 1 batches\n1 Start Epoch 1\n1: 1 batches\n2 Start Epoch 1\n2: 1 batches\n27 Start Epoch 1\n27: 1 batches\n26 Start Epoch 1\n26: 1 batches\n25 Start Epoch 1\n25: 1 batches\n0 Start Epoch 1\n0: 1 batches\n27 Start Epoch 2\n27: 1 batches\n25 Start Epoch 2\n25: 1 batches\n26 Start Epoch 2\n26: 1 batches\n24 Start Epoch 2\n24: 1 batches\n23 Start Epoch 2\n23: 1 batches\n1 Start Epoch 2\n1: 1 batches\n22 Start Epoch 2\n22: 1 batches\n21 Start Epoch 2\n21: 1 batches\n20 Start Epoch 2\n20: 1 batches\n19 Start Epoch 2\n18 Start Epoch 2\n19: 1 batches\n17 Start Epoch 2\n18: 1 batches\n17: 1 batches\n11 Start Epoch 2\n12 Start Epoch 2\n10 Start Epoch 2\n12: 1 batches\n11: 1 batches\n15 Start Epoch 2\n10: 1 batches\n5 Start Epoch 2\n2 Start Epoch 2\n2: 1 batches\n4 Start Epoch 2\n16 Start Epoch 2\n7 Start Epoch 2\n4: 1 batches\n16: 1 batches\n8 Start Epoch 2\n8: 1 batches\n7: 1 batches\n5: 1 batches\n9 Start Epoch 2\n9: 1 batches\n6 Start Epoch 2\n6: 1 batches\n3 Start Epoch 2\n3: 1 batches\n15: 1 batches\n13 Start Epoch 2\n13: 1 batches\n14 Start Epoch 2\n14: 1 batches\n0 Start Epoch 2\n0: 1 batches\n23 Start Epoch 3\n23: 1 batches\n25 Start Epoch 3\n21 Start Epoch 3\n24 Start Epoch 3\n22 Start Epoch 3\n25: 1 batches\n21: 1 batches\n20 Start Epoch 3\n24: 1 batches\n19 Start Epoch 3\n20: 1 batches\n18 Start Epoch 3\n19: 1 batches\n17 Start Epoch 3\n18: 1 batches\n26 Start Epoch 3\n27 Start Epoch 3\n27: 1 batches\n26: 1 batches\n22: 1 batches\n17: 1 batches\n15 Start Epoch 3\n15: 1 batches\n11 Start Epoch 3\n11: 1 batches\n16 Start Epoch 3\n16: 1 batches\n10 Start Epoch 3\n10: 1 batches\n2 Start Epoch 3\n1 Start Epoch 3\n1: 1 batches\n2: 1 batches\n3 Start Epoch 3\n3: 1 batches\n8 Start Epoch 3\n8: 1 batches\n14 Start Epoch 3\n6 Start Epoch 3\n6: 1 batches\n12 Start Epoch 3\n5 Start Epoch 3\n5: 1 batches\n7 Start Epoch 3\n7: 1 batches\n13 Start Epoch 3\n14: 1 batches\n4 Start Epoch 3\n4: 1 batches\n13: 1 batches\n12: 1 batches\n9 Start Epoch 3\n9: 1 batches\n0 Start Epoch 3\n0: 1 batches\n19 Start Epoch 4\n18 Start Epoch 4\n19: 1 batches\n18: 1 batches\n17 Start Epoch 4\n17: 1 batches\n16 Start Epoch 4\n3 Start Epoch 4\n2 Start Epoch 4\n2: 1 batches\n3: 1 batches\n7 Start Epoch 4\n23 Start Epoch 4\n23: 1 batches\n7: 1 batches\n22 Start Epoch 4\n22: 1 batches\n15 Start Epoch 4\n9 Start Epoch 4\n9: 1 batches\n25 Start Epoch 4\n15: 1 batches\n20 Start Epoch 4\n20: 1 batches\n8 Start Epoch 4\n25: 1 batches\n11 Start Epoch 4\n24 Start Epoch 4\n8: 1 batches\n24: 1 batches\n21 Start Epoch 4\n21: 1 batches\n11: 1 batches\n12 Start Epoch 4\n14 Start Epoch 4\n12: 1 batches\n13 Start Epoch 4\n13: 1 batches\n14: 1 batches\n16: 1 batches\n10 Start Epoch 4\n10: 1 batches\n6 Start Epoch 4\n5 Start Epoch 4\n6: 1 batches\n5: 1 batches\n4 Start Epoch 4\n4: 1 batches\n1 Start Epoch 4\n1: 1 batches\n27 Start Epoch 4\n26 Start Epoch 4\n27: 1 batches\n26: 1 batches\n0 Start Epoch 4\n0: 1 batches\n15 Start Epoch 5\n15: 1 batches\n23 Start Epoch 5\n23: 1 batches\n22 Start Epoch 5\n22: 1 batches\n20 Start Epoch 5\n20: 1 batches\n16 Start Epoch 5\n16: 1 batches\n24 Start Epoch 5\n24: 1 batches\n3 Start Epoch 5\n3: 1 batches\n1 Start Epoch 5\n1: 1 batches\n27 Start Epoch 5\n7 Start Epoch 5\n7: 1 batches\n18 Start Epoch 5\n26 Start Epoch 5\n27: 1 batches\n13 Start Epoch 5\n6 Start Epoch 5\n26: 1 batches\n12 Start Epoch 5\n6: 1 batches\n18: 1 batches\n25 Start Epoch 5\n13: 1 batches\n25: 1 batches\n12: 1 batches\n14 Start Epoch 5\n14: 1 batches\n19 Start Epoch 5\n5 Start Epoch 5\n19: 1 batches\n10 Start Epoch 5\n5: 1 batches\n17 Start Epoch 5\n10: 1 batches\n17: 1 batches\n9 Start Epoch 5\n9: 1 batches\n11 Start Epoch 5\n11: 1 batches\n8 Start Epoch 5\n21 Start Epoch 5\n21: 1 batches\n8: 1 batches\n2 Start Epoch 5\n2: 1 batches\n4 Start Epoch 5\n4: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:21: Epoch 0 train loss: 506377.8125\nINFO:root:23: Epoch 0 train loss: 654717.5625\nINFO:root:22: Epoch 0 train loss: 16587.7734375\nINFO:root:24: Epoch 0 train loss: 627768.4375\nINFO:root:20: Epoch 0 train loss: 536758.5\nINFO:root:19: Epoch 0 train loss: 4432.7490234375\nINFO:root:18: Epoch 0 train loss: 6447.2451171875\nINFO:root:17: Epoch 0 train loss: 2040.16259765625\nINFO:root:16: Epoch 0 train loss: 5875.0595703125\nINFO:root:15: Epoch 0 train loss: 585339.625\nINFO:root:14: Epoch 0 train loss: 5617.3515625\nINFO:root:13: Epoch 0 train loss: 3171.262451171875\nINFO:root:12: Epoch 0 train loss: 1214780.75\nINFO:root:11: Epoch 0 train loss: 595768.6875\nINFO:root:10: Epoch 0 train loss: 4292.232421875\nINFO:root:7: Epoch 0 train loss: 4390.25146484375\nINFO:root:9: Epoch 0 train loss: 640794.6875\nINFO:root:8: Epoch 0 train loss: 11760.865234375\nINFO:root:6: Epoch 0 train loss: 2153.392333984375\nINFO:root:5: Epoch 0 train loss: 3010.00390625\nINFO:root:4: Epoch 0 train loss: 2772.802001953125\nINFO:root:3: Epoch 0 train loss: 1899.4566650390625\nINFO:root:1: Epoch 0 train loss: 28485.59375\nINFO:root:2: Epoch 0 train loss: 9231.36328125\nINFO:root:0: Epoch 0 train loss: 568.1641845703125\nINFO:root:27: Epoch 0 train loss: 1226984.875\nINFO:root:26: Epoch 0 train loss: 3515.06494140625\nINFO:root:25: Epoch 0 train loss: 4106.69384765625\nINFO:root:0: Epoch 0 validation loss: 29773.892447868016\nINFO:root:25: Epoch 1 train loss: 549.3504028320312\nINFO:root:27: Epoch 1 train loss: 3670.867919921875\nINFO:root:0: Epoch 1 train loss: 7306.02734375\nINFO:root:26: Epoch 1 train loss: 4993.4765625\nINFO:root:24: Epoch 1 train loss: 3311.717041015625\nINFO:root:23: Epoch 1 train loss: 1650.07861328125\nINFO:root:1: Epoch 1 train loss: 607125.375\nINFO:root:22: Epoch 1 train loss: 73559.0390625\nINFO:root:21: Epoch 1 train loss: 6018.73046875\nINFO:root:19: Epoch 1 train loss: 5789.6904296875\nINFO:root:18: Epoch 1 train loss: 2350.45654296875\nINFO:root:20: Epoch 1 train loss: 1514.10498046875\nINFO:root:17: Epoch 1 train loss: 4387.10302734375\nINFO:root:11: Epoch 1 train loss: 656665.0625\nINFO:root:15: Epoch 1 train loss: 218891.625\nINFO:root:12: Epoch 1 train loss: 16255.857421875\nINFO:root:10: Epoch 1 train loss: 1470.429443359375\nINFO:root:7: Epoch 1 train loss: 4118.2197265625\nINFO:root:4: Epoch 1 train loss: 6070.14697265625\nINFO:root:5: Epoch 1 train loss: 6697.02490234375\nINFO:root:6: Epoch 1 train loss: 1000.9647216796875\nINFO:root:2: Epoch 1 train loss: 13027.8671875\nINFO:root:16: Epoch 1 train loss: 223722.421875\nINFO:root:9: Epoch 1 train loss: 491133.09375\nINFO:root:8: Epoch 1 train loss: 5645.14404296875\nINFO:root:3: Epoch 1 train loss: 2448.104736328125\nINFO:root:13: Epoch 1 train loss: 3450.153564453125\nINFO:root:14: Epoch 1 train loss: 9653.4326171875\nINFO:root:0: Epoch 1 validation loss: 29770.979361922648\nINFO:root:23: Epoch 2 train loss: 462.0438232421875\nINFO:root:22: Epoch 2 train loss: 1012903.875\nINFO:root:24: Epoch 2 train loss: 628059.5625\nINFO:root:25: Epoch 2 train loss: 2263.98193359375\nINFO:root:20: Epoch 2 train loss: 2236.2021484375\nINFO:root:21: Epoch 2 train loss: 585.8407592773438\nINFO:root:19: Epoch 2 train loss: 3749.615478515625\nINFO:root:18: Epoch 2 train loss: 4195.13037109375\nINFO:root:17: Epoch 2 train loss: 7930.81298828125\nINFO:root:26: Epoch 2 train loss: 1647.4945068359375\nINFO:root:27: Epoch 2 train loss: 9832.6484375\nINFO:root:15: Epoch 2 train loss: 4373.9716796875\nINFO:root:11: Epoch 2 train loss: 1005.7737426757812\nINFO:root:0: Epoch 2 train loss: 1145.3026123046875\nINFO:root:16: Epoch 2 train loss: 14600.9326171875\nINFO:root:10: Epoch 2 train loss: 520673.46875\nINFO:root:1: Epoch 2 train loss: 14815.62109375\nINFO:root:2: Epoch 2 train loss: 7971.5146484375\nINFO:root:3: Epoch 2 train loss: 490812.59375\nINFO:root:8: Epoch 2 train loss: 10714.03515625\nINFO:root:12: Epoch 2 train loss: 8071.36962890625\nINFO:root:13: Epoch 2 train loss: 1428.0679931640625\nINFO:root:14: Epoch 2 train loss: 1637.4329833984375\nINFO:root:7: Epoch 2 train loss: 622.1121826171875\nINFO:root:4: Epoch 2 train loss: 3904.396728515625\nINFO:root:5: Epoch 2 train loss: 672.615478515625\nINFO:root:6: Epoch 2 train loss: 13443.2763671875\nINFO:root:9: Epoch 2 train loss: 7802.54443359375\nINFO:root:0: Epoch 2 validation loss: 29768.165699332952\nINFO:root:18: Epoch 3 train loss: 21102.189453125\nINFO:root:19: Epoch 3 train loss: 615053.3125\nINFO:root:23: Epoch 3 train loss: 73853.0625\nINFO:root:16: Epoch 3 train loss: 4434.181640625\nINFO:root:17: Epoch 3 train loss: 674.8416137695312\nINFO:root:7: Epoch 3 train loss: 3978.58984375\nINFO:root:3: Epoch 3 train loss: 1403.5396728515625\nINFO:root:2: Epoch 3 train loss: 18185.16015625\nINFO:root:11: Epoch 3 train loss: 7919.44091796875\nINFO:root:25: Epoch 3 train loss: 5109.6396484375\nINFO:root:15: Epoch 3 train loss: 14472.806640625\nINFO:root:8: Epoch 3 train loss: 3371.767578125\nINFO:root:9: Epoch 3 train loss: 5062.53662109375\nINFO:root:24: Epoch 3 train loss: 14983.568359375\nINFO:root:22: Epoch 3 train loss: 2130.424072265625\nINFO:root:12: Epoch 3 train loss: 304.5295715332031\nINFO:root:20: Epoch 3 train loss: 1283.9603271484375\nINFO:root:13: Epoch 3 train loss: 1284.9991455078125\nINFO:root:21: Epoch 3 train loss: 3092.040283203125\nINFO:root:14: Epoch 3 train loss: 9420.640625\nINFO:root:10: Epoch 3 train loss: 655167.125\nINFO:root:5: Epoch 3 train loss: 213741.625\nINFO:root:6: Epoch 3 train loss: 2918.48681640625\nINFO:root:4: Epoch 3 train loss: 556.9686889648438\nINFO:root:1: Epoch 3 train loss: 1292.5611572265625\nINFO:root:27: Epoch 3 train loss: 2722.701904296875\nINFO:root:26: Epoch 3 train loss: 81744.5546875\nINFO:root:0: Epoch 3 train loss: 660826.625\nINFO:root:0: Epoch 3 validation loss: 29765.328064095036\nINFO:root:15: Epoch 4 train loss: 603048.3125\nINFO:root:23: Epoch 4 train loss: 724038.8125\nINFO:root:20: Epoch 4 train loss: 1490.39990234375\nINFO:root:22: Epoch 4 train loss: 15226.994140625\nINFO:root:16: Epoch 4 train loss: 879.5848388671875\nINFO:root:24: Epoch 4 train loss: 606327.125\nINFO:root:25: Epoch 4 train loss: 525213.875\nINFO:root:0: Epoch 4 train loss: 1720.158935546875\nINFO:root:1: Epoch 4 train loss: 11842.8076171875\nINFO:root:3: Epoch 4 train loss: 6579.787109375\nINFO:root:26: Epoch 4 train loss: 1732.7691650390625\nINFO:root:6: Epoch 4 train loss: 2529.35498046875\nINFO:root:14: Epoch 4 train loss: 520757.25\nINFO:root:7: Epoch 4 train loss: 5263.84130859375\nINFO:root:19: Epoch 4 train loss: 2873.90087890625\nINFO:root:27: Epoch 4 train loss: 609755.4375\nINFO:root:12: Epoch 4 train loss: 9443.677734375\nINFO:root:18: Epoch 4 train loss: 309.1202697753906\nINFO:root:13: Epoch 4 train loss: 1132698.625\nINFO:root:5: Epoch 4 train loss: 9249.4619140625\nINFO:root:10: Epoch 4 train loss: 525964.0625\nINFO:root:17: Epoch 4 train loss: 155.80812072753906\nINFO:root:9: Epoch 4 train loss: 13613.8583984375\nINFO:root:11: Epoch 4 train loss: 731934.3125\nINFO:root:21: Epoch 4 train loss: 1004.96337890625\nINFO:root:8: Epoch 4 train loss: 1260388.125\nINFO:root:2: Epoch 4 train loss: 2204.936279296875\nINFO:root:4: Epoch 4 train loss: 2589.6630859375\nINFO:root:0: Epoch 4 validation loss: 29762.476364145376\nINFO:root:7: Epoch 5 train loss: 3774.73486328125\nINFO:root:16: Epoch 5 train loss: 1275.178466796875\nINFO:root:15: Epoch 5 train loss: 2118.38037109375\nINFO:root:17: Epoch 5 train loss: 1202.036865234375\nINFO:root:11: Epoch 5 train loss: 2794.3916015625\nINFO:root:10: Epoch 5 train loss: 5376.1982421875\nINFO:root:9: Epoch 5 train loss: 6956.79296875\nINFO:root:14: Epoch 5 train loss: 2157.682373046875\nINFO:root:12: Epoch 5 train loss: 3384.759765625\nINFO:root:13: Epoch 5 train loss: 581928.4375\nINFO:root:6: Epoch 5 train loss: 1527.155029296875\nINFO:root:5: Epoch 5 train loss: 208774.15625\nINFO:root:23: Epoch 5 train loss: 11155.0615234375\nINFO:root:8: Epoch 5 train loss: 4613.0224609375\nINFO:root:3: Epoch 5 train loss: 3866.53125\nINFO:root:1: Epoch 5 train loss: 10132.0908203125\nINFO:root:22: Epoch 5 train loss: 7223.2568359375\nINFO:root:25: Epoch 5 train loss: 4293.1201171875\nINFO:root:27: Epoch 5 train loss: 499845.9375\nINFO:root:24: Epoch 5 train loss: 1283.135009765625\nINFO:root:26: Epoch 5 train loss: 932974.5625\nINFO:root:4: Epoch 5 train loss: 229296.96875\nINFO:root:19: Epoch 5 train loss: 2579.8212890625\nINFO:root:18: Epoch 5 train loss: 16723.24609375\nINFO:root:0: Epoch 5 train loss: 3793.695556640625\nINFO:root:20: Epoch 5 train loss: 2422.916015625\nINFO:root:21: Epoch 5 train loss: 8829.033203125\nINFO:root:2: Epoch 5 train loss: 2911.673828125\nINFO:root:0: Epoch 5 validation loss: 29759.610486637448\n", "seconds": 23.697705030441284, "batch_size": 128, "nodes": 7, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 1 batches\n2: 1 batches\n4 Start Epoch 0\n4: 1 batches\n5 Start Epoch 0\n6 Start Epoch 0\n5: 1 batches\n6: 1 batches\n3 Start Epoch 0\n3: 1 batches\n15 Start Epoch 0\n7 Start Epoch 0\n15: 1 batches\n7: 1 batches\n31 Start Epoch 0\n12 Start Epoch 0\n12: 1 batches\n8 Start Epoch 0\n11 Start Epoch 0\n16 Start Epoch 0\n24 Start Epoch 0\n24: 1 batches\n11: 1 batches\n8: 1 batches\n19 Start Epoch 0\n27 Start Epoch 0\n19: 1 batches\n16: 1 batches\n27: 1 batches\n21 Start Epoch 0\n21: 1 batches\n14 Start Epoch 0\n22 Start Epoch 0\n22: 1 batches\n14: 1 batches\n23 Start Epoch 0\n23: 1 batches\n13 Start Epoch 0\n13: 1 batches\n20 Start Epoch 0\n20: 1 batches\n31: 1 batches\n28 Start Epoch 0\n29 Start Epoch 0\n28: 1 batches\n29: 1 batches\n30 Start Epoch 0\n30: 1 batches\n26 Start Epoch 0\n25 Start Epoch 0\n26: 1 batches\n25: 1 batches\n17 Start Epoch 0\n9 Start Epoch 0\n18 Start Epoch 0\n9: 1 batches\n18: 1 batches\n10 Start Epoch 0\n17: 1 batches\n10: 1 batches\n28 Start Epoch 1\n29 Start Epoch 1\n30 Start Epoch 1\n28: 1 batches\n29: 1 batches\n31 Start Epoch 1\n31: 1 batches\n30: 1 batches\n27 Start Epoch 1\n27: 1 batches\n9 Start Epoch 1\n11 Start Epoch 1\n9: 1 batches\n11: 1 batches\n10 Start Epoch 1\n10: 1 batches\n12 Start Epoch 1\n14 Start Epoch 1\n14: 1 batches\n15 Start Epoch 1\n15: 1 batches\n12: 1 batches\n13 Start Epoch 1\n13: 1 batches\n16 Start Epoch 1\n16: 1 batches\n23 Start Epoch 1\n23: 1 batches\n22 Start Epoch 1\n22: 1 batches\n17 Start Epoch 1\n17: 1 batches\n7 Start Epoch 1\n6 Start Epoch 1\n6: 1 batches\n7: 1 batches\n25 Start Epoch 1\n26 Start Epoch 1\n24 Start Epoch 1\n26: 1 batches\n24: 1 batches\n25: 1 batches\n4 Start Epoch 1\n4: 1 batches\n8 Start Epoch 1\n8: 1 batches\n1 Start Epoch 1\n1: 1 batches\n18 Start Epoch 1\n18: 1 batches\n20 Start Epoch 1\n21 Start Epoch 1\n21: 1 batches\n20: 1 batches\n5 Start Epoch 1\n5: 1 batches\n19 Start Epoch 1\n19: 1 batches\n2 Start Epoch 1\n2: 1 batches\n3 Start Epoch 1\n3: 1 batches\n0 Start Epoch 1\n0: 1 batches\n11 Start Epoch 2\n11: 1 batches\n27 Start Epoch 2\n23 Start Epoch 2\n30 Start Epoch 2\n30: 1 batches\n27: 1 batches\n15 Start Epoch 2\n24 Start Epoch 2\n12 Start Epoch 2\n16 Start Epoch 2\n21 Start Epoch 2\n12: 1 batches\n15: 1 batches\n16: 1 batches\n20 Start Epoch 2\n26 Start Epoch 2\n24: 1 batches\n13 Start Epoch 2\n20: 1 batches\n26: 1 batches\n13: 1 batches\n21: 1 batches\n18 Start Epoch 2\n25 Start Epoch 2\n14 Start Epoch 2\n19 Start Epoch 2\n22 Start Epoch 2\n25: 1 batches\n14: 1 batches\n19: 1 batches\n23: 1 batches\n17 Start Epoch 2\n17: 1 batches\n18: 1 batches\n22: 1 batches\n31 Start Epoch 2\n31: 1 batches\n28 Start Epoch 2\n28: 1 batches\n29 Start Epoch 2\n29: 1 batches\n1 Start Epoch 2\n1: 1 batches\n7 Start Epoch 2\n6 Start Epoch 2\n5 Start Epoch 2\n6: 1 batches\n5: 1 batches\n7: 1 batches\n4 Start Epoch 2\n4: 1 batches\n2 Start Epoch 2\n2: 1 batches\n10 Start Epoch 2\n10: 1 batches\n3 Start Epoch 2\n3: 1 batches\n8 Start Epoch 2\n9 Start Epoch 2\n9: 1 batches\n8: 1 batches\n0 Start Epoch 2\n0: 1 batches\n20 Start Epoch 3\n21 Start Epoch 3\n21: 1 batches\n20: 1 batches\n17 Start Epoch 3\n18 Start Epoch 3\n18: 1 batches\n19 Start Epoch 3\n19: 1 batches\n17: 1 batches\n8 Start Epoch 3\n10 Start Epoch 3\n8: 1 batches\n10: 1 batches\n7 Start Epoch 3\n9 Start Epoch 3\n5 Start Epoch 3\n4 Start Epoch 3\n9: 1 batches\n4: 1 batches\n5: 1 batches\n7: 1 batches\n6 Start Epoch 3\n6: 1 batches\n2 Start Epoch 3\n3 Start Epoch 3\n2: 1 batches\n3: 1 batches\n14 Start Epoch 3\n14: 1 batches\n15 Start Epoch 3\n15: 1 batches\n11 Start Epoch 3\n16 Start Epoch 3\n11: 1 batches\n16: 1 batches\n12 Start Epoch 3\n12: 1 batches\n13 Start Epoch 3\n13: 1 batches\n22 Start Epoch 3\n22: 1 batches\n26 Start Epoch 3\n26: 1 batches\n25 Start Epoch 3\n25: 1 batches\n30 Start Epoch 3\n31 Start Epoch 3\n27 Start Epoch 3\n27: 1 batches\n28 Start Epoch 3\n28: 1 batches\n31: 1 batches\n29 Start Epoch 3\n30: 1 batches\n29: 1 batches\n24 Start Epoch 3\n1 Start Epoch 3\n1: 1 batches\n23 Start Epoch 3\n23: 1 batches\n24: 1 batches\n0 Start Epoch 3\n0: 1 batches\n1 Start Epoch 4\n1: 1 batches\n23 Start Epoch 4\n23: 1 batches\n30 Start Epoch 4\n30: 1 batches\n29 Start Epoch 4\n29: 1 batches\n20 Start Epoch 4\n28 Start Epoch 4\n20: 1 batches\n22 Start Epoch 4\n22: 1 batches\n28: 1 batches\n31 Start Epoch 4\n31: 1 batches\n25 Start Epoch 4\n19 Start Epoch 4\n25: 1 batches\n24 Start Epoch 4\n19: 1 batches\n26 Start Epoch 4\n24: 1 batches\n26: 1 batches\n27 Start Epoch 4\n27: 1 batches\n2 Start Epoch 4\n2: 1 batches\n3 Start Epoch 4\n3: 1 batches\n14 Start Epoch 4\n11 Start Epoch 4\n8 Start Epoch 4\n8: 1 batches\n15 Start Epoch 4\n6 Start Epoch 4\n15: 1 batches\n7 Start Epoch 4\n11: 1 batches\n7: 1 batches\n6: 1 batches\n4 Start Epoch 4\n4: 1 batches\n13 Start Epoch 4\n13: 1 batches\n14: 1 batches\n9 Start Epoch 4\n18 Start Epoch 4\n9: 1 batches\n16 Start Epoch 4\n10 Start Epoch 4\n18: 1 batches\n10: 1 batches\n16: 1 batches\n12 Start Epoch 4\n21 Start Epoch 4\n21: 1 batches\n12: 1 batches\n17 Start Epoch 4\n17: 1 batches\n5 Start Epoch 4\n5: 1 batches\n0 Start Epoch 4\n0: 1 batches\n11 Start Epoch 5\n11: 1 batches\n15 Start Epoch 5\n15: 1 batches\n14 Start Epoch 5\n23 Start Epoch 5\n14: 1 batches\n20 Start Epoch 5\n23: 1 batches\n20: 1 batches\n31 Start Epoch 5\n31: 1 batches\n3 Start Epoch 5\n3: 1 batches\n12 Start Epoch 5\n13 Start Epoch 5\n12: 1 batches\n13: 1 batches\n10 Start Epoch 5\n8 Start Epoch 5\n8: 1 batches\n17 Start Epoch 5\n7 Start Epoch 5\n17: 1 batches\n7: 1 batches\n4 Start Epoch 5\n10: 1 batches\n6 Start Epoch 5\n6: 1 batches\n4: 1 batches\n5 Start Epoch 5\n5: 1 batches\n25 Start Epoch 5\n21 Start Epoch 5\n21: 1 batches\n22 Start Epoch 5\n22: 1 batches\n25: 1 batches\n26 Start Epoch 5\n27 Start Epoch 5\n26: 1 batches\n27: 1 batches\n24 Start Epoch 5\n19 Start Epoch 5\n24: 1 batches\n19: 1 batches\n1 Start Epoch 5\n1: 1 batches\n2 Start Epoch 5\n2: 1 batches\n9 Start Epoch 5\n9: 1 batches\n29 Start Epoch 5\n28 Start Epoch 5\n16 Start Epoch 5\n28: 1 batches\n29: 1 batches\n18 Start Epoch 5\n16: 1 batches\n18: 1 batches\n30 Start Epoch 5\n30: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:29: Epoch 0 train loss: 1095.4560546875\nINFO:root:31: Epoch 0 train loss: 1428.560791015625\nINFO:root:28: Epoch 0 train loss: 3138.70068359375\nINFO:root:30: Epoch 0 train loss: 2177.603271484375\nINFO:root:27: Epoch 0 train loss: 961.6412963867188\nINFO:root:10: Epoch 0 train loss: 267.74053955078125\nINFO:root:9: Epoch 0 train loss: 237.95526123046875\nINFO:root:11: Epoch 0 train loss: 1048.043212890625\nINFO:root:13: Epoch 0 train loss: 172.11363220214844\nINFO:root:14: Epoch 0 train loss: 1709.1280517578125\nINFO:root:15: Epoch 0 train loss: 8904.50390625\nINFO:root:12: Epoch 0 train loss: 2043.217041015625\nINFO:root:16: Epoch 0 train loss: 7277.1357421875\nINFO:root:0: Epoch 0 train loss: 1539400.75\nINFO:root:23: Epoch 0 train loss: 10163.451171875\nINFO:root:22: Epoch 0 train loss: 6548.32861328125\nINFO:root:17: Epoch 0 train loss: 4304.0693359375\nINFO:root:7: Epoch 0 train loss: 17200.26171875\nINFO:root:6: Epoch 0 train loss: 1983.441162109375\nINFO:root:24: Epoch 0 train loss: 4607.2958984375\nINFO:root:26: Epoch 0 train loss: 325.2987365722656\nINFO:root:25: Epoch 0 train loss: 16040.3466796875\nINFO:root:4: Epoch 0 train loss: 7253.8681640625\nINFO:root:8: Epoch 0 train loss: 3662.984619140625\nINFO:root:1: Epoch 0 train loss: 936.5437622070312\nINFO:root:18: Epoch 0 train loss: 2878.373046875\nINFO:root:21: Epoch 0 train loss: 558923.25\nINFO:root:20: Epoch 0 train loss: 666426.1875\nINFO:root:19: Epoch 0 train loss: 562871.9375\nINFO:root:5: Epoch 0 train loss: 4022.013427734375\nINFO:root:2: Epoch 0 train loss: 15392.1640625\nINFO:root:3: Epoch 0 train loss: 2386.3828125\nINFO:root:0: Epoch 0 validation loss: 607347.8745295515\nINFO:root:11: Epoch 1 train loss: 4100.1708984375\nINFO:root:23: Epoch 1 train loss: 717642.0\nINFO:root:30: Epoch 1 train loss: 1172.8851318359375\nINFO:root:27: Epoch 1 train loss: 1939.670654296875\nINFO:root:12: Epoch 1 train loss: 22340.416015625\nINFO:root:13: Epoch 1 train loss: 2744.36279296875\nINFO:root:15: Epoch 1 train loss: 5273.166015625\nINFO:root:21: Epoch 1 train loss: 315.0893249511719\nINFO:root:24: Epoch 1 train loss: 4255.984375\nINFO:root:16: Epoch 1 train loss: 823725.4375\nINFO:root:20: Epoch 1 train loss: 11321.6689453125\nINFO:root:26: Epoch 1 train loss: 7236.94091796875\nINFO:root:18: Epoch 1 train loss: 851.5391235351562\nINFO:root:19: Epoch 1 train loss: 15111.5283203125\nINFO:root:22: Epoch 1 train loss: 1306219.375\nINFO:root:25: Epoch 1 train loss: 6666.1826171875\nINFO:root:14: Epoch 1 train loss: 608799.375\nINFO:root:17: Epoch 1 train loss: 2686.833740234375\nINFO:root:0: Epoch 1 train loss: 4310.48779296875\nINFO:root:29: Epoch 1 train loss: 3896.983154296875\nINFO:root:31: Epoch 1 train loss: 975.7722778320312\nINFO:root:28: Epoch 1 train loss: 8838.521484375\nINFO:root:1: Epoch 1 train loss: 77653.5703125\nINFO:root:4: Epoch 1 train loss: 9059.330078125\nINFO:root:6: Epoch 1 train loss: 13024.880859375\nINFO:root:7: Epoch 1 train loss: 7277.3505859375\nINFO:root:5: Epoch 1 train loss: 5871.81201171875\nINFO:root:2: Epoch 1 train loss: 1924.4556884765625\nINFO:root:10: Epoch 1 train loss: 250.4579315185547\nINFO:root:3: Epoch 1 train loss: 721134.125\nINFO:root:9: Epoch 1 train loss: 9543.5322265625\nINFO:root:8: Epoch 1 train loss: 1546.728271484375\nINFO:root:0: Epoch 1 validation loss: 607340.7404998153\nINFO:root:21: Epoch 2 train loss: 748752.25\nINFO:root:20: Epoch 2 train loss: 595031.8125\nINFO:root:18: Epoch 2 train loss: 3400.60595703125\nINFO:root:17: Epoch 2 train loss: 4646.5302734375\nINFO:root:19: Epoch 2 train loss: 5104.7119140625\nINFO:root:10: Epoch 2 train loss: 1416.1905517578125\nINFO:root:8: Epoch 2 train loss: 714735.25\nINFO:root:5: Epoch 2 train loss: 747931.0\nINFO:root:6: Epoch 2 train loss: 688242.75\nINFO:root:7: Epoch 2 train loss: 8873.53515625\nINFO:root:4: Epoch 2 train loss: 4565.57470703125\nINFO:root:9: Epoch 2 train loss: 4140.29052734375\nINFO:root:2: Epoch 2 train loss: 5173.90625\nINFO:root:3: Epoch 2 train loss: 1068.0206298828125\nINFO:root:11: Epoch 2 train loss: 25098.98828125\nINFO:root:16: Epoch 2 train loss: 13602.8505859375\nINFO:root:15: Epoch 2 train loss: 673224.125\nINFO:root:14: Epoch 2 train loss: 2516.59130859375\nINFO:root:12: Epoch 2 train loss: 9880.12109375\nINFO:root:13: Epoch 2 train loss: 3377.196533203125\nINFO:root:22: Epoch 2 train loss: 2337.61279296875\nINFO:root:23: Epoch 2 train loss: 4915.3544921875\nINFO:root:28: Epoch 2 train loss: 3941.555419921875\nINFO:root:26: Epoch 2 train loss: 3011.4453125\nINFO:root:29: Epoch 2 train loss: 7250.431640625\nINFO:root:31: Epoch 2 train loss: 1208.9190673828125\nINFO:root:27: Epoch 2 train loss: 5021.572265625\nINFO:root:30: Epoch 2 train loss: 2208.613525390625\nINFO:root:25: Epoch 2 train loss: 1412.6031494140625\nINFO:root:24: Epoch 2 train loss: 7176.107421875\nINFO:root:1: Epoch 2 train loss: 31892.3203125\nINFO:root:0: Epoch 2 train loss: 1414.451904296875\nINFO:root:0: Epoch 2 validation loss: 607333.6812527162\nINFO:root:23: Epoch 3 train loss: 7507.30224609375\nINFO:root:1: Epoch 3 train loss: 4984.61865234375\nINFO:root:0: Epoch 3 train loss: 942.4541625976562\nINFO:root:30: Epoch 3 train loss: 688098.0\nINFO:root:29: Epoch 3 train loss: 14173.3896484375\nINFO:root:20: Epoch 3 train loss: 10856.1435546875\nINFO:root:22: Epoch 3 train loss: 10025.8759765625\nINFO:root:28: Epoch 3 train loss: 9248.6337890625\nINFO:root:31: Epoch 3 train loss: 3321.985107421875\nINFO:root:25: Epoch 3 train loss: 301.3280334472656\nINFO:root:19: Epoch 3 train loss: 8244.7880859375\nINFO:root:24: Epoch 3 train loss: 716193.9375\nINFO:root:26: Epoch 3 train loss: 2714.333251953125\nINFO:root:27: Epoch 3 train loss: 1426.9173583984375\nINFO:root:3: Epoch 3 train loss: 5362.822265625\nINFO:root:2: Epoch 3 train loss: 6957.85205078125\nINFO:root:4: Epoch 3 train loss: 2567.841796875\nINFO:root:11: Epoch 3 train loss: 2314.443359375\nINFO:root:15: Epoch 3 train loss: 689105.1875\nINFO:root:8: Epoch 3 train loss: 237.55604553222656\nINFO:root:14: Epoch 3 train loss: 5993.11279296875\nINFO:root:6: Epoch 3 train loss: 1375190.75\nINFO:root:7: Epoch 3 train loss: 6031.00341796875\nINFO:root:13: Epoch 3 train loss: 1832.044189453125\nINFO:root:9: Epoch 3 train loss: 20597.548828125\nINFO:root:18: Epoch 3 train loss: 10879.546875\nINFO:root:16: Epoch 3 train loss: 1043.606689453125\nINFO:root:10: Epoch 3 train loss: 717179.25\nINFO:root:12: Epoch 3 train loss: 549.33056640625\nINFO:root:21: Epoch 3 train loss: 7494.9697265625\nINFO:root:17: Epoch 3 train loss: 15974.5009765625\nINFO:root:5: Epoch 3 train loss: 11056.724609375\nINFO:root:0: Epoch 3 validation loss: 607326.591278087\nINFO:root:11: Epoch 4 train loss: 242.7174835205078\nINFO:root:15: Epoch 4 train loss: 716297.25\nINFO:root:14: Epoch 4 train loss: 26522.822265625\nINFO:root:23: Epoch 4 train loss: 233948.875\nINFO:root:20: Epoch 4 train loss: 2822.151611328125\nINFO:root:31: Epoch 4 train loss: 592804.625\nINFO:root:0: Epoch 4 train loss: 3086.076904296875\nINFO:root:3: Epoch 4 train loss: 243.81260681152344\nINFO:root:13: Epoch 4 train loss: 5848.6572265625\nINFO:root:12: Epoch 4 train loss: 6609.7236328125\nINFO:root:10: Epoch 4 train loss: 1089.2786865234375\nINFO:root:17: Epoch 4 train loss: 9740.1220703125\nINFO:root:7: Epoch 4 train loss: 3482.2412109375\nINFO:root:8: Epoch 4 train loss: 688.225830078125\nINFO:root:4: Epoch 4 train loss: 690244.0\nINFO:root:6: Epoch 4 train loss: 662528.4375\nINFO:root:5: Epoch 4 train loss: 239112.640625\nINFO:root:25: Epoch 4 train loss: 9049.6162109375\nINFO:root:9: Epoch 4 train loss: 2235.95166015625\nINFO:root:22: Epoch 4 train loss: 6606.80712890625\nINFO:root:27: Epoch 4 train loss: 3310.032958984375\nINFO:root:26: Epoch 4 train loss: 235253.3125\nINFO:root:21: Epoch 4 train loss: 520.6815795898438\nINFO:root:19: Epoch 4 train loss: 3636.401611328125\nINFO:root:24: Epoch 4 train loss: 2775.9541015625\nINFO:root:1: Epoch 4 train loss: 714615.9375\nINFO:root:2: Epoch 4 train loss: 2002.24560546875\nINFO:root:29: Epoch 4 train loss: 1530.0804443359375\nINFO:root:28: Epoch 4 train loss: 716120.0\nINFO:root:16: Epoch 4 train loss: 12401.5078125\nINFO:root:18: Epoch 4 train loss: 10133.6220703125\nINFO:root:30: Epoch 4 train loss: 1133.623779296875\nINFO:root:0: Epoch 4 validation loss: 607319.5454905032\nINFO:root:21: Epoch 5 train loss: 4806.08935546875\nINFO:root:23: Epoch 5 train loss: 26214.134765625\nINFO:root:22: Epoch 5 train loss: 595328.375\nINFO:root:31: Epoch 5 train loss: 280.7611999511719\nINFO:root:1: Epoch 5 train loss: 1910.1915283203125\nINFO:root:0: Epoch 5 train loss: 7924.9677734375\nINFO:root:25: Epoch 5 train loss: 24329.53515625\nINFO:root:27: Epoch 5 train loss: 428.5059509277344\nINFO:root:29: Epoch 5 train loss: 747086.875\nINFO:root:30: Epoch 5 train loss: 2186.39794921875\nINFO:root:28: Epoch 5 train loss: 663948.625\nINFO:root:24: Epoch 5 train loss: 234448.4375\nINFO:root:20: Epoch 5 train loss: 1507.7398681640625\nINFO:root:13: Epoch 5 train loss: 3238.77783203125\nINFO:root:26: Epoch 5 train loss: 6124.00537109375\nINFO:root:14: Epoch 5 train loss: 3944.261474609375\nINFO:root:15: Epoch 5 train loss: 2486.7685546875\nINFO:root:7: Epoch 5 train loss: 823692.625\nINFO:root:8: Epoch 5 train loss: 770213.0625\nINFO:root:4: Epoch 5 train loss: 1864.054931640625\nINFO:root:9: Epoch 5 train loss: 23912.173828125\nINFO:root:6: Epoch 5 train loss: 9669.650390625\nINFO:root:11: Epoch 5 train loss: 24243.501953125\nINFO:root:5: Epoch 5 train loss: 1672.4302978515625\nINFO:root:10: Epoch 5 train loss: 7633.24609375\nINFO:root:3: Epoch 5 train loss: 287.0683898925781\nINFO:root:19: Epoch 5 train loss: 831395.6875\nINFO:root:18: Epoch 5 train loss: 1646.653076171875\nINFO:root:17: Epoch 5 train loss: 2802.74755859375\nINFO:root:16: Epoch 5 train loss: 241201.734375\nINFO:root:2: Epoch 5 train loss: 5118.9521484375\nINFO:root:12: Epoch 5 train loss: 761266.75\nINFO:root:0: Epoch 5 validation loss: 607312.4285862974\n", "seconds": 23.715014934539795, "batch_size": 128, "nodes": 8, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n1: 1 batches\n2 Start Epoch 0\n2: 1 batches\n35 Start Epoch 0\n35: 1 batches\n24 Start Epoch 0\n24: 1 batches\n4 Start Epoch 0\n4: 1 batches\n23 Start Epoch 0\n16 Start Epoch 0\n8 Start Epoch 0\n32 Start Epoch 0\n8: 1 batches\n31 Start Epoch 0\n23: 1 batches\n16: 1 batches\n15 Start Epoch 0\n7 Start Epoch 0\n15: 1 batches\n32: 1 batches\n31: 1 batches\n7: 1 batches\n3 Start Epoch 0\n28 Start Epoch 0\n28: 1 batches\n20 Start Epoch 0\n19 Start Epoch 0\n20: 1 batches\n19: 1 batches\n27 Start Epoch 0\n27: 1 batches\n5 Start Epoch 0\n6 Start Epoch 0\n9 Start Epoch 0\n25 Start Epoch 0\n25: 1 batches\n6: 1 batches\n10 Start Epoch 0\n29 Start Epoch 0\n26 Start Epoch 0\n26: 1 batches\n5: 1 batches\n10: 1 batches\n3: 1 batches\n30 Start Epoch 0\n11 Start Epoch 0\n29: 1 batches\n11: 1 batches\n30: 1 batches\n9: 1 batches\n21 Start Epoch 0\n22 Start Epoch 0\n21: 1 batches\n12 Start Epoch 0\n12: 1 batches\n34 Start Epoch 0\n22: 1 batches\n18 Start Epoch 0\n33 Start Epoch 0\n18: 1 batches\n33: 1 batches\n17 Start Epoch 0\n13 Start Epoch 0\n34: 1 batches\n17: 1 batches\n14 Start Epoch 0\n13: 1 batches\n14: 1 batches\n24 Start Epoch 1\n15 Start Epoch 1\n34 Start Epoch 1\n31 Start Epoch 1\n4 Start Epoch 1\n15: 1 batches\n35 Start Epoch 1\n29 Start Epoch 1\n19 Start Epoch 1\n27 Start Epoch 1\n4: 1 batches\n35: 1 batches\n29: 1 batches\n18 Start Epoch 1\n18: 1 batches\n27: 1 batches\n7 Start Epoch 1\n14 Start Epoch 1\n31: 1 batches\n20 Start Epoch 1\n19: 1 batches\n24: 1 batches\n7: 1 batches\n14: 1 batches\n9 Start Epoch 1\n21 Start Epoch 1\n17 Start Epoch 1\n25 Start Epoch 1\n5 Start Epoch 1\n8 Start Epoch 1\n22 Start Epoch 1\n17: 1 batches\n13 Start Epoch 1\n10 Start Epoch 1\n10: 1 batches\n30 Start Epoch 1\n21: 1 batches\n25: 1 batches\n12 Start Epoch 1\n8: 1 batches\n28 Start Epoch 1\n22: 1 batches\n6 Start Epoch 1\n26 Start Epoch 1\n12: 1 batches\n11 Start Epoch 1\n30: 1 batches\n23 Start Epoch 1\n11: 1 batches\n28: 1 batches\n23: 1 batches\n6: 1 batches\n13: 1 batches\n9: 1 batches\n20: 1 batches\n5: 1 batches\n2 Start Epoch 1\n2: 1 batches\n26: 1 batches\n3 Start Epoch 1\n3: 1 batches\n16 Start Epoch 1\n16: 1 batches\n1 Start Epoch 1\n1: 1 batches\n32 Start Epoch 1\n32: 1 batches\n33 Start Epoch 1\n33: 1 batches\n34: 1 batches\n0 Start Epoch 1\n0: 1 batches\n14 Start Epoch 2\n10 Start Epoch 2\n10: 1 batches\n11 Start Epoch 2\n8 Start Epoch 2\n17 Start Epoch 2\n16 Start Epoch 2\n16: 1 batches\n30 Start Epoch 2\n30: 1 batches\n23 Start Epoch 2\n31 Start Epoch 2\n31: 1 batches\n17: 1 batches\n15 Start Epoch 2\n15: 1 batches\n23: 1 batches\n14: 1 batches\n34 Start Epoch 2\n35 Start Epoch 2\n35: 1 batches\n34: 1 batches\n5 Start Epoch 2\n5: 1 batches\n27 Start Epoch 2\n27: 1 batches\n7 Start Epoch 2\n7: 1 batches\n6 Start Epoch 2\n6: 1 batches\n8: 1 batches\n11: 1 batches\n9 Start Epoch 2\n9: 1 batches\n33 Start Epoch 2\n32 Start Epoch 2\n32: 1 batches\n33: 1 batches\n29 Start Epoch 2\n29: 1 batches\n28 Start Epoch 2\n26 Start Epoch 2\n26: 1 batches\n24 Start Epoch 2\n24: 1 batches\n22 Start Epoch 2\n25 Start Epoch 2\n21 Start Epoch 2\n20 Start Epoch 2\n21: 1 batches\n22: 1 batches\n20: 1 batches\n25: 1 batches\n28: 1 batches\n13 Start Epoch 2\n12 Start Epoch 2\n12: 1 batches\n13: 1 batches\n4 Start Epoch 2\n4: 1 batches\n19 Start Epoch 2\n19: 1 batches\n18 Start Epoch 2\n18: 1 batches\n3 Start Epoch 2\n3: 1 batches\n2 Start Epoch 2\n2: 1 batches\n1 Start Epoch 2\n1: 1 batches\n0 Start Epoch 2\n0: 1 batches\n16 Start Epoch 3\n15 Start Epoch 3\n15: 1 batches\n35 Start Epoch 3\n17 Start Epoch 3\n35: 1 batches\n16: 1 batches\n17: 1 batches\n7 Start Epoch 3\n7: 1 batches\n28 Start Epoch 3\n28: 1 batches\n19 Start Epoch 3\n25 Start Epoch 3\n22 Start Epoch 3\n29 Start Epoch 3\n29: 1 batches\n23 Start Epoch 3\n27 Start Epoch 3\n10 Start Epoch 3\n26 Start Epoch 3\n8 Start Epoch 3\n21 Start Epoch 3\n22: 1 batches\n9 Start Epoch 3\n21: 1 batches\n10: 1 batches\n8: 1 batches\n11 Start Epoch 3\n20 Start Epoch 3\n20: 1 batches\n11: 1 batches\n9: 1 batches\n23: 1 batches\n3 Start Epoch 3\n3: 1 batches\n13 Start Epoch 3\n13: 1 batches\n24 Start Epoch 3\n25: 1 batches\n27: 1 batches\n26: 1 batches\n19: 1 batches\n18 Start Epoch 3\n18: 1 batches\n1 Start Epoch 3\n1: 1 batches\n12 Start Epoch 3\n12: 1 batches\n14 Start Epoch 3\n14: 1 batches\n2 Start Epoch 3\n2: 1 batches\n24: 1 batches\n32 Start Epoch 3\n34 Start Epoch 3\n33 Start Epoch 3\n33: 1 batches\n32: 1 batches\n34: 1 batches\n30 Start Epoch 3\n30: 1 batches\n31 Start Epoch 3\n31: 1 batches\n5 Start Epoch 3\n5: 1 batches\n4 Start Epoch 3\n4: 1 batches\n6 Start Epoch 3\n6: 1 batches\n0 Start Epoch 3\n0: 1 batches\n28 Start Epoch 4\n31 Start Epoch 4\n31: 1 batches\n28: 1 batches\n27 Start Epoch 4\n27: 1 batches\n6 Start Epoch 4\n5 Start Epoch 4\n5: 1 batches\n7 Start Epoch 4\n7: 1 batches\n6: 1 batches\n23 Start Epoch 4\n23: 1 batches\n26 Start Epoch 4\n25 Start Epoch 4\n25: 1 batches\n26: 1 batches\n21 Start Epoch 4\n21: 1 batches\n19 Start Epoch 4\n22 Start Epoch 4\n19: 1 batches\n15 Start Epoch 4\n32 Start Epoch 4\n8 Start Epoch 4\n8: 1 batches\n17 Start Epoch 4\n15: 1 batches\n32: 1 batches\n29 Start Epoch 4\n29: 1 batches\n35 Start Epoch 4\n18 Start Epoch 4\n17: 1 batches\n9 Start Epoch 4\n9: 1 batches\n18: 1 batches\n35: 1 batches\n34 Start Epoch 4\n34: 1 batches\n10 Start Epoch 4\n10: 1 batches\n33 Start Epoch 4\n33: 1 batches\n11 Start Epoch 4\n11: 1 batches\n13 Start Epoch 4\n30 Start Epoch 4\n30: 1 batches\n20 Start Epoch 4\n22: 1 batches\n20: 1 batches\n16 Start Epoch 4\n24 Start Epoch 4\n13: 1 batches\n16: 1 batches\n24: 1 batches\n4 Start Epoch 4\n14 Start Epoch 4\n4: 1 batches\n14: 1 batches\n12 Start Epoch 4\n12: 1 batches\n2 Start Epoch 4\n2: 1 batches\n3 Start Epoch 4\n3: 1 batches\n1 Start Epoch 4\n1: 1 batches\n0 Start Epoch 4\n0: 1 batches\n10 Start Epoch 5\n14 Start Epoch 5\n14: 1 batches\n11 Start Epoch 5\n13 Start Epoch 5\n13: 1 batches\n10: 1 batches\n6 Start Epoch 5\n15 Start Epoch 5\n15: 1 batches\n11: 1 batches\n7 Start Epoch 5\n7: 1 batches\n6: 1 batches\n12 Start Epoch 5\n1 Start Epoch 5\n1: 1 batches\n3 Start Epoch 5\n3: 1 batches\n12: 1 batches\n5 Start Epoch 5\n35 Start Epoch 5\n17 Start Epoch 5\n35: 1 batches\n9 Start Epoch 5\n21 Start Epoch 5\n26 Start Epoch 5\n5: 1 batches\n21: 1 batches\n27 Start Epoch 5\n8 Start Epoch 5\n29 Start Epoch 5\n9: 1 batches\n30 Start Epoch 5\n20 Start Epoch 5\n19 Start Epoch 5\n26: 1 batches\n16 Start Epoch 5\n27: 1 batches\n8: 1 batches\n29: 1 batches\n20: 1 batches\n17: 1 batches\n30: 1 batches\n31 Start Epoch 5\n16: 1 batches\n19: 1 batches\n28 Start Epoch 5\n18 Start Epoch 5\n28: 1 batches\n31: 1 batches\n18: 1 batches\n23 Start Epoch 5\n4 Start Epoch 5\n24 Start Epoch 5\n4: 1 batches\n23: 1 batches\n34 Start Epoch 5\n24: 1 batches\n33 Start Epoch 5\n22 Start Epoch 5\n25 Start Epoch 5\n22: 1 batches\n25: 1 batches\n33: 1 batches\n34: 1 batches\n32 Start Epoch 5\n32: 1 batches\n2 Start Epoch 5\n2: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:15: Epoch 0 train loss: 838286.1875\nINFO:root:35: Epoch 0 train loss: 3248.807861328125\nINFO:root:31: Epoch 0 train loss: 356275.09375\nINFO:root:19: Epoch 0 train loss: 3561.4951171875\nINFO:root:27: Epoch 0 train loss: 910.7718505859375\nINFO:root:7: Epoch 0 train loss: 6164.48291015625\nINFO:root:18: Epoch 0 train loss: 88035.390625\nINFO:root:4: Epoch 0 train loss: 4756.26171875\nINFO:root:29: Epoch 0 train loss: 930756.3125\nINFO:root:23: Epoch 0 train loss: 2884.4638671875\nINFO:root:20: Epoch 0 train loss: 3301.81298828125\nINFO:root:17: Epoch 0 train loss: 22042.552734375\nINFO:root:24: Epoch 0 train loss: 3932.588134765625\nINFO:root:8: Epoch 0 train loss: 5863.64697265625\nINFO:root:14: Epoch 0 train loss: 808363.8125\nINFO:root:34: Epoch 0 train loss: 1847.237548828125\nINFO:root:9: Epoch 0 train loss: 5402.1611328125\nINFO:root:22: Epoch 0 train loss: 3143.90966796875\nINFO:root:10: Epoch 0 train loss: 3750.463134765625\nINFO:root:21: Epoch 0 train loss: 901.84130859375\nINFO:root:11: Epoch 0 train loss: 673989.5625\nINFO:root:5: Epoch 0 train loss: 2877.896240234375\nINFO:root:12: Epoch 0 train loss: 3998.158447265625\nINFO:root:30: Epoch 0 train loss: 3331.45751953125\nINFO:root:25: Epoch 0 train loss: 266020.65625\nINFO:root:13: Epoch 0 train loss: 788630.8125\nINFO:root:28: Epoch 0 train loss: 1159.1732177734375\nINFO:root:6: Epoch 0 train loss: 11517.8095703125\nINFO:root:26: Epoch 0 train loss: 3717.62158203125\nINFO:root:0: Epoch 0 train loss: 523.1763305664062\nINFO:root:2: Epoch 0 train loss: 1120.1990966796875\nINFO:root:3: Epoch 0 train loss: 22647.201171875\nINFO:root:16: Epoch 0 train loss: 8074.640625\nINFO:root:1: Epoch 0 train loss: 4475.08447265625\nINFO:root:32: Epoch 0 train loss: 14313.3505859375\nINFO:root:33: Epoch 0 train loss: 841659.25\nINFO:root:0: Epoch 0 validation loss: 10405.131349687786\nINFO:root:15: Epoch 1 train loss: 3930.647705078125\nINFO:root:14: Epoch 1 train loss: 12213.1884765625\nINFO:root:10: Epoch 1 train loss: 926451.6875\nINFO:root:11: Epoch 1 train loss: 1299572.375\nINFO:root:8: Epoch 1 train loss: 18701.109375\nINFO:root:17: Epoch 1 train loss: 742856.0\nINFO:root:16: Epoch 1 train loss: 54.965789794921875\nINFO:root:30: Epoch 1 train loss: 1989.32421875\nINFO:root:23: Epoch 1 train loss: 2982.106201171875\nINFO:root:31: Epoch 1 train loss: 1810492.875\nINFO:root:34: Epoch 1 train loss: 448.01434326171875\nINFO:root:35: Epoch 1 train loss: 789372.5\nINFO:root:5: Epoch 1 train loss: 35148.17578125\nINFO:root:27: Epoch 1 train loss: 4681.59375\nINFO:root:7: Epoch 1 train loss: 7864.9140625\nINFO:root:6: Epoch 1 train loss: 17009.013671875\nINFO:root:9: Epoch 1 train loss: 332.70703125\nINFO:root:32: Epoch 1 train loss: 12131.435546875\nINFO:root:33: Epoch 1 train loss: 7329.984375\nINFO:root:24: Epoch 1 train loss: 393.27197265625\nINFO:root:29: Epoch 1 train loss: 23027.84375\nINFO:root:28: Epoch 1 train loss: 1966.9246826171875\nINFO:root:0: Epoch 1 train loss: 827.4588012695312\nINFO:root:25: Epoch 1 train loss: 5504.6728515625\nINFO:root:21: Epoch 1 train loss: 263022.1875\nINFO:root:20: Epoch 1 train loss: 3097.44921875\nINFO:root:22: Epoch 1 train loss: 928.8866577148438\nINFO:root:26: Epoch 1 train loss: 4795.21337890625\nINFO:root:12: Epoch 1 train loss: 9670.7255859375\nINFO:root:13: Epoch 1 train loss: 2599.666748046875\nINFO:root:4: Epoch 1 train loss: 774263.0625\nINFO:root:19: Epoch 1 train loss: 153.2543487548828\nINFO:root:18: Epoch 1 train loss: 2728.95361328125\nINFO:root:3: Epoch 1 train loss: 3905.9716796875\nINFO:root:2: Epoch 1 train loss: 2053.93017578125\nINFO:root:1: Epoch 1 train loss: 774875.25\nINFO:root:0: Epoch 1 validation loss: 10403.649133494102\nINFO:root:16: Epoch 2 train loss: 2568.49072265625\nINFO:root:15: Epoch 2 train loss: 3993.317138671875\nINFO:root:17: Epoch 2 train loss: 443.44464111328125\nINFO:root:35: Epoch 2 train loss: 16376.9912109375\nINFO:root:0: Epoch 2 train loss: 2809.65576171875\nINFO:root:22: Epoch 2 train loss: 614.041748046875\nINFO:root:19: Epoch 2 train loss: 2334.11279296875\nINFO:root:25: Epoch 2 train loss: 3752.084228515625\nINFO:root:8: Epoch 2 train loss: 2405.955810546875\nINFO:root:7: Epoch 2 train loss: 841588.125\nINFO:root:9: Epoch 2 train loss: 3047.108642578125\nINFO:root:28: Epoch 2 train loss: 375.58404541015625\nINFO:root:23: Epoch 2 train loss: 7126.29052734375\nINFO:root:11: Epoch 2 train loss: 264340.53125\nINFO:root:29: Epoch 2 train loss: 2482.9189453125\nINFO:root:27: Epoch 2 train loss: 1699.7603759765625\nINFO:root:10: Epoch 2 train loss: 19283.75\nINFO:root:21: Epoch 2 train loss: 3207.773681640625\nINFO:root:26: Epoch 2 train loss: 22000.814453125\nINFO:root:20: Epoch 2 train loss: 12529.865234375\nINFO:root:3: Epoch 2 train loss: 5528.20068359375\nINFO:root:24: Epoch 2 train loss: 11476.5234375\nINFO:root:13: Epoch 2 train loss: 15630.203125\nINFO:root:18: Epoch 2 train loss: 528.6536865234375\nINFO:root:1: Epoch 2 train loss: 2694.805419921875\nINFO:root:12: Epoch 2 train loss: 1888.242431640625\nINFO:root:14: Epoch 2 train loss: 4171.69189453125\nINFO:root:2: Epoch 2 train loss: 3717.470947265625\nINFO:root:33: Epoch 2 train loss: 2084.03662109375\nINFO:root:34: Epoch 2 train loss: 6800.55712890625\nINFO:root:32: Epoch 2 train loss: 1487.0830078125\nINFO:root:31: Epoch 2 train loss: 9761.4208984375\nINFO:root:30: Epoch 2 train loss: 9058.013671875\nINFO:root:6: Epoch 2 train loss: 2128.38037109375\nINFO:root:4: Epoch 2 train loss: 2262.609619140625\nINFO:root:5: Epoch 2 train loss: 1540.8984375\nINFO:root:0: Epoch 2 validation loss: 10402.175534313894\nINFO:root:28: Epoch 3 train loss: 868.8060302734375\nINFO:root:31: Epoch 3 train loss: 13946.05078125\nINFO:root:27: Epoch 3 train loss: 2860.153076171875\nINFO:root:5: Epoch 3 train loss: 1540107.0\nINFO:root:7: Epoch 3 train loss: 7835.55419921875\nINFO:root:6: Epoch 3 train loss: 3544.129638671875\nINFO:root:23: Epoch 3 train loss: 3330.125732421875\nINFO:root:26: Epoch 3 train loss: 1449.883544921875\nINFO:root:25: Epoch 3 train loss: 507.1673583984375\nINFO:root:21: Epoch 3 train loss: 88582.3125\nINFO:root:19: Epoch 3 train loss: 86453.0390625\nINFO:root:22: Epoch 3 train loss: 805793.5625\nINFO:root:32: Epoch 3 train loss: 108357.7578125\nINFO:root:30: Epoch 3 train loss: 5487.888671875\nINFO:root:17: Epoch 3 train loss: 3770.7021484375\nINFO:root:15: Epoch 3 train loss: 29162.873046875\nINFO:root:29: Epoch 3 train loss: 7890.3134765625\nINFO:root:18: Epoch 3 train loss: 858.7998046875\nINFO:root:8: Epoch 3 train loss: 8015.1015625\nINFO:root:9: Epoch 3 train loss: 1936.466064453125\nINFO:root:35: Epoch 3 train loss: 288.5745849609375\nINFO:root:34: Epoch 3 train loss: 263689.71875\nINFO:root:10: Epoch 3 train loss: 658.4239501953125\nINFO:root:33: Epoch 3 train loss: 11039.4990234375\nINFO:root:11: Epoch 3 train loss: 16392.3671875\nINFO:root:0: Epoch 3 train loss: 1842.50244140625\nINFO:root:20: Epoch 3 train loss: 2969.291748046875\nINFO:root:13: Epoch 3 train loss: 676287.375\nINFO:root:16: Epoch 3 train loss: 79.16515350341797\nINFO:root:24: Epoch 3 train loss: 366.7305603027344\nINFO:root:14: Epoch 3 train loss: 94184.3515625\nINFO:root:4: Epoch 3 train loss: 6092.92236328125\nINFO:root:12: Epoch 3 train loss: 2096.464599609375\nINFO:root:1: Epoch 3 train loss: 2225.0224609375\nINFO:root:2: Epoch 3 train loss: 742817.125\nINFO:root:3: Epoch 3 train loss: 271.2658386230469\nINFO:root:0: Epoch 3 validation loss: 10400.69523542778\nINFO:root:14: Epoch 4 train loss: 922949.6875\nINFO:root:15: Epoch 4 train loss: 627805.6875\nINFO:root:11: Epoch 4 train loss: 3091.021484375\nINFO:root:10: Epoch 4 train loss: 10699.1572265625\nINFO:root:7: Epoch 4 train loss: 36199.50390625\nINFO:root:13: Epoch 4 train loss: 4376.1513671875\nINFO:root:6: Epoch 4 train loss: 107.82313537597656\nINFO:root:12: Epoch 4 train loss: 667.895751953125\nINFO:root:0: Epoch 4 train loss: 9618.1044921875\nINFO:root:1: Epoch 4 train loss: 1025.3787841796875\nINFO:root:3: Epoch 4 train loss: 22523.916015625\nINFO:root:30: Epoch 4 train loss: 698.599609375\nINFO:root:20: Epoch 4 train loss: 4692.19091796875\nINFO:root:17: Epoch 4 train loss: 3730.816162109375\nINFO:root:27: Epoch 4 train loss: 4811.93701171875\nINFO:root:5: Epoch 4 train loss: 1163.31982421875\nINFO:root:35: Epoch 4 train loss: 3815.941162109375\nINFO:root:9: Epoch 4 train loss: 922199.875\nINFO:root:8: Epoch 4 train loss: 7148.41845703125\nINFO:root:31: Epoch 4 train loss: 861168.125\nINFO:root:21: Epoch 4 train loss: 928.6749877929688\nINFO:root:26: Epoch 4 train loss: 14789.349609375\nINFO:root:29: Epoch 4 train loss: 771477.125\nINFO:root:19: Epoch 4 train loss: 2685.574462890625\nINFO:root:16: Epoch 4 train loss: 14915.466796875\nINFO:root:28: Epoch 4 train loss: 2899.233642578125\nINFO:root:18: Epoch 4 train loss: 12194.1826171875\nINFO:root:23: Epoch 4 train loss: 1589.9862060546875\nINFO:root:25: Epoch 4 train loss: 2953.5361328125\nINFO:root:4: Epoch 4 train loss: 2202751.75\nINFO:root:33: Epoch 4 train loss: 888326.625\nINFO:root:32: Epoch 4 train loss: 3330.446044921875\nINFO:root:24: Epoch 4 train loss: 1185556.25\nINFO:root:34: Epoch 4 train loss: 262976.375\nINFO:root:22: Epoch 4 train loss: 3270.997802734375\nINFO:root:2: Epoch 4 train loss: 3295.27587890625\nINFO:root:0: Epoch 4 validation loss: 10399.206594785019\nINFO:root:15: Epoch 5 train loss: 1908.4517822265625\nINFO:root:35: Epoch 5 train loss: 362.8996887207031\nINFO:root:14: Epoch 5 train loss: 2427.545166015625\nINFO:root:13: Epoch 5 train loss: 632654.5625\nINFO:root:3: Epoch 5 train loss: 4027.517578125\nINFO:root:2: Epoch 5 train loss: 2042.6072998046875\nINFO:root:33: Epoch 5 train loss: 3834.145751953125\nINFO:root:8: Epoch 5 train loss: 21804.755859375\nINFO:root:31: Epoch 5 train loss: 824352.3125\nINFO:root:16: Epoch 5 train loss: 13193.994140625\nINFO:root:25: Epoch 5 train loss: 28886.189453125\nINFO:root:32: Epoch 5 train loss: 324.4569396972656\nINFO:root:9: Epoch 5 train loss: 3726.81591796875\nINFO:root:29: Epoch 5 train loss: 6393.9736328125\nINFO:root:11: Epoch 5 train loss: 11618.4091796875\nINFO:root:30: Epoch 5 train loss: 318.032470703125\nINFO:root:34: Epoch 5 train loss: 3682.8203125\nINFO:root:28: Epoch 5 train loss: 1932.392333984375\nINFO:root:17: Epoch 5 train loss: 4132.39111328125\nINFO:root:7: Epoch 5 train loss: 195.11441040039062\nINFO:root:6: Epoch 5 train loss: 65.3013916015625\nINFO:root:5: Epoch 5 train loss: 8607.0810546875\nINFO:root:4: Epoch 5 train loss: 3177.704345703125\nINFO:root:27: Epoch 5 train loss: 786343.5625\nINFO:root:12: Epoch 5 train loss: 125.306396484375\nINFO:root:23: Epoch 5 train loss: 7827.212890625\nINFO:root:10: Epoch 5 train loss: 1277.0509033203125\nINFO:root:22: Epoch 5 train loss: 846819.375\nINFO:root:20: Epoch 5 train loss: 8086.38720703125\nINFO:root:21: Epoch 5 train loss: 5060.63525390625\nINFO:root:18: Epoch 5 train loss: 5242.8173828125\nINFO:root:19: Epoch 5 train loss: 3247.267578125\nINFO:root:24: Epoch 5 train loss: 6435.77734375\nINFO:root:1: Epoch 5 train loss: 926741.5\nINFO:root:26: Epoch 5 train loss: 36642.6875\nINFO:root:0: Epoch 5 train loss: 270.71142578125\nINFO:root:0: Epoch 5 validation loss: 10397.6933563451\n", "seconds": 23.61491894721985, "batch_size": 128, "nodes": 9, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n39 Start Epoch 0\n39: 1 batches\n4 Start Epoch 0\n4: 1 batches\n1 Start Epoch 0\n1: 1 batches\n2 Start Epoch 0\n2: 1 batches\n3 Start Epoch 0\n3: 1 batches\n15 Start Epoch 0\n15: 1 batches\n24 Start Epoch 0\n8 Start Epoch 0\n24: 1 batches\n23 Start Epoch 0\n8: 1 batches\n7 Start Epoch 0\n23: 1 batches\n31 Start Epoch 0\n16 Start Epoch 0\n32 Start Epoch 0\n7: 1 batches\n31: 1 batches\n16: 1 batches\n32: 1 batches\n6 Start Epoch 0\n5 Start Epoch 0\n6: 1 batches\n5: 1 batches\n12 Start Epoch 0\n12: 1 batches\n10 Start Epoch 0\n9 Start Epoch 0\n20 Start Epoch 0\n36 Start Epoch 0\n20: 1 batches\n19 Start Epoch 0\n35 Start Epoch 0\n36: 1 batches\n28 Start Epoch 0\n19: 1 batches\n35: 1 batches\n28: 1 batches\n26 Start Epoch 0\n26: 1 batches\n27 Start Epoch 0\n11 Start Epoch 0\n11: 1 batches\n25 Start Epoch 0\n25: 1 batches\n9: 1 batches\n10: 1 batches\n27: 1 batches\n29 Start Epoch 0\n29: 1 batches\n34 Start Epoch 0\n33 Start Epoch 0\n21 Start Epoch 0\n34: 1 batches\n22 Start Epoch 0\n33: 1 batches\n22: 1 batches\n30 Start Epoch 0\n21: 1 batches\n30: 1 batches\n13 Start Epoch 0\n14 Start Epoch 0\n13: 1 batches\n14: 1 batches\n17 Start Epoch 0\n18 Start Epoch 0\n17: 1 batches\n18: 1 batches\n37 Start Epoch 0\n38 Start Epoch 0\n37: 1 batches\n38: 1 batches\n20 Start Epoch 1\n20: 1 batches\n19 Start Epoch 1\n19: 1 batches\n21 Start Epoch 1\n21: 1 batches\n15 Start Epoch 1\n15: 1 batches\n11 Start Epoch 1\n11: 1 batches\n12 Start Epoch 1\n12: 1 batches\n13 Start Epoch 1\n13: 1 batches\n14 Start Epoch 1\n14: 1 batches\n17 Start Epoch 1\n18 Start Epoch 1\n18: 1 batches\n17: 1 batches\n16 Start Epoch 1\n16: 1 batches\n7 Start Epoch 1\n9 Start Epoch 1\n10 Start Epoch 1\n9: 1 batches\n6 Start Epoch 1\n35 Start Epoch 1\n10: 1 batches\n31 Start Epoch 1\n31: 1 batches\n35: 1 batches\n5 Start Epoch 1\n1 Start Epoch 1\n2 Start Epoch 1\n1: 1 batches\n2: 1 batches\n6: 1 batches\n5: 1 batches\n38 Start Epoch 1\n25 Start Epoch 1\n7: 1 batches\n36 Start Epoch 1\n22 Start Epoch 1\n37 Start Epoch 1\n22: 1 batches\n3 Start Epoch 1\n3: 1 batches\n24 Start Epoch 1\n32 Start Epoch 1\n4 Start Epoch 1\n37: 1 batches\n23 Start Epoch 1\n25: 1 batches\n34 Start Epoch 1\n8 Start Epoch 1\n34: 1 batches\n4: 1 batches\n38: 1 batches\n23: 1 batches\n26 Start Epoch 1\n32: 1 batches\n39 Start Epoch 1\n8: 1 batches\n29 Start Epoch 1\n26: 1 batches\n33 Start Epoch 1\n39: 1 batches\n30 Start Epoch 1\n29: 1 batches\n24: 1 batches\n33: 1 batches\n36: 1 batches\n30: 1 batches\n27 Start Epoch 1\n28 Start Epoch 1\n27: 1 batches\n28: 1 batches\n0 Start Epoch 1\n0: 1 batches\n35 Start Epoch 2\n35: 1 batches\n27 Start Epoch 2\n27: 1 batches\n39 Start Epoch 2\n39: 1 batches\n36 Start Epoch 2\n36: 1 batches\n38 Start Epoch 2\n38: 1 batches\n26 Start Epoch 2\n26: 1 batches\n1 Start Epoch 2\n1: 1 batches\n34 Start Epoch 2\n34: 1 batches\n33 Start Epoch 2\n33: 1 batches\n32 Start Epoch 2\n30 Start Epoch 2\n30: 1 batches\n31 Start Epoch 2\n31: 1 batches\n29 Start Epoch 2\n29: 1 batches\n28 Start Epoch 2\n28: 1 batches\n37 Start Epoch 2\n37: 1 batches\n5 Start Epoch 2\n4 Start Epoch 2\n5: 1 batches\n15 Start Epoch 2\n32: 1 batches\n15: 1 batches\n2 Start Epoch 2\n2: 1 batches\n3 Start Epoch 2\n3: 1 batches\n18 Start Epoch 2\n22 Start Epoch 2\n21 Start Epoch 2\n22: 1 batches\n18: 1 batches\n4: 1 batches\n21: 1 batches\n6 Start Epoch 2\n6: 1 batches\n7 Start Epoch 2\n7: 1 batches\n8 Start Epoch 2\n9 Start Epoch 2\n9: 1 batches\n8: 1 batches\n24 Start Epoch 2\n17 Start Epoch 2\n16 Start Epoch 2\n16: 1 batches\n17: 1 batches\n24: 1 batches\n23 Start Epoch 2\n23: 1 batches\n25 Start Epoch 2\n25: 1 batches\n13 Start Epoch 2\n13: 1 batches\n14 Start Epoch 2\n14: 1 batches\n19 Start Epoch 2\n19: 1 batches\n12 Start Epoch 2\n12: 1 batches\n20 Start Epoch 2\n20: 1 batches\n10 Start Epoch 2\n11 Start Epoch 2\n10: 1 batches\n11: 1 batches\n0 Start Epoch 2\n0: 1 batches\n2 Start Epoch 3\n2: 1 batches\n7 Start Epoch 3\n24 Start Epoch 3\n16 Start Epoch 3\n22 Start Epoch 3\n22: 1 batches\n8 Start Epoch 3\n30 Start Epoch 3\n15 Start Epoch 3\n24: 1 batches\n16: 1 batches\n35 Start Epoch 3\n35: 1 batches\n7: 1 batches\n39 Start Epoch 3\n39: 1 batches\n30: 1 batches\n15: 1 batches\n23 Start Epoch 3\n8: 1 batches\n23: 1 batches\n11 Start Epoch 3\n25 Start Epoch 3\n17 Start Epoch 3\n11: 1 batches\n20 Start Epoch 3\n14 Start Epoch 3\n26 Start Epoch 3\n18 Start Epoch 3\n5 Start Epoch 3\n5: 1 batches\n18: 1 batches\n20: 1 batches\n13 Start Epoch 3\n1 Start Epoch 3\n1: 1 batches\n3 Start Epoch 3\n3: 1 batches\n25: 1 batches\n38 Start Epoch 3\n38: 1 batches\n9 Start Epoch 3\n31 Start Epoch 3\n31: 1 batches\n13: 1 batches\n27 Start Epoch 3\n17: 1 batches\n33 Start Epoch 3\n33: 1 batches\n4 Start Epoch 3\n21 Start Epoch 3\n10 Start Epoch 3\n19 Start Epoch 3\n32 Start Epoch 3\n32: 1 batches\n4: 1 batches\n21: 1 batches\n9: 1 batches\n12 Start Epoch 3\n27: 1 batches\n10: 1 batches\n12: 1 batches\n26: 1 batches\n19: 1 batches\n6 Start Epoch 3\n14: 1 batches\n34 Start Epoch 3\n6: 1 batches\n28 Start Epoch 3\n34: 1 batches\n29 Start Epoch 3\n28: 1 batches\n29: 1 batches\n36 Start Epoch 3\n37 Start Epoch 3\n36: 1 batches\n37: 1 batches\n0 Start Epoch 3\n0: 1 batches\n30 Start Epoch 4\n6 Start Epoch 4\n30: 1 batches\n6: 1 batches\n32 Start Epoch 4\n7 Start Epoch 4\n7: 1 batches\n35 Start Epoch 4\n34 Start Epoch 4\n1 Start Epoch 4\n3 Start Epoch 4\n35: 1 batches\n32: 1 batches\n33 Start Epoch 4\n8 Start Epoch 4\n34: 1 batches\n9 Start Epoch 4\n33: 1 batches\n8: 1 batches\n9: 1 batches\n38 Start Epoch 4\n38: 1 batches\n39 Start Epoch 4\n39: 1 batches\n37 Start Epoch 4\n37: 1 batches\n36 Start Epoch 4\n36: 1 batches\n13 Start Epoch 4\n14 Start Epoch 4\n14: 1 batches\n15 Start Epoch 4\n13: 1 batches\n15: 1 batches\n3: 1 batches\n1: 1 batches\n2 Start Epoch 4\n2: 1 batches\n5 Start Epoch 4\n5: 1 batches\n31 Start Epoch 4\n31: 1 batches\n12 Start Epoch 4\n4 Start Epoch 4\n4: 1 batches\n23 Start Epoch 4\n11 Start Epoch 4\n28 Start Epoch 4\n28: 1 batches\n12: 1 batches\n17 Start Epoch 4\n11: 1 batches\n29 Start Epoch 4\n29: 1 batches\n19 Start Epoch 4\n22 Start Epoch 4\n24 Start Epoch 4\n17: 1 batches\n22: 1 batches\n10 Start Epoch 4\n23: 1 batches\n10: 1 batches\n27 Start Epoch 4\n19: 1 batches\n25 Start Epoch 4\n21 Start Epoch 4\n27: 1 batches\n18 Start Epoch 4\n21: 1 batches\n25: 1 batches\n26 Start Epoch 4\n18: 1 batches\n20 Start Epoch 4\n24: 1 batches\n16 Start Epoch 4\n20: 1 batches\n26: 1 batches\n16: 1 batches\n0 Start Epoch 4\n0: 1 batches\n30 Start Epoch 5\n39 Start Epoch 5\n30: 1 batches\n39: 1 batches\n36 Start Epoch 5\n37 Start Epoch 5\n37: 1 batches\n36: 1 batches\n38 Start Epoch 5\n38: 1 batches\n34 Start Epoch 5\n35 Start Epoch 5\n35: 1 batches\n34: 1 batches\n33 Start Epoch 5\n33: 1 batches\n31 Start Epoch 5\n31: 1 batches\n29 Start Epoch 5\n29: 1 batches\n32 Start Epoch 5\n32: 1 batches\n1 Start Epoch 5\n9 Start Epoch 5\n9: 1 batches\n1: 1 batches\n19 Start Epoch 5\n18 Start Epoch 5\n18: 1 batches\n23 Start Epoch 5\n25 Start Epoch 5\n24 Start Epoch 5\n27 Start Epoch 5\n27: 1 batches\n25: 1 batches\n23: 1 batches\n26 Start Epoch 5\n26: 1 batches\n24: 1 batches\n28 Start Epoch 5\n28: 1 batches\n20 Start Epoch 5\n20: 1 batches\n22 Start Epoch 5\n22: 1 batches\n21 Start Epoch 5\n19: 1 batches\n15 Start Epoch 5\n21: 1 batches\n15: 1 batches\n13 Start Epoch 5\n13: 1 batches\n10 Start Epoch 5\n10: 1 batches\n11 Start Epoch 5\n11: 1 batches\n16 Start Epoch 5\n16: 1 batches\n17 Start Epoch 5\n17: 1 batches\n7 Start Epoch 5\n7: 1 batches\n4 Start Epoch 5\n4: 1 batches\n8 Start Epoch 5\n8: 1 batches\n14 Start Epoch 5\n14: 1 batches\n5 Start Epoch 5\n5: 1 batches\n6 Start Epoch 5\n3 Start Epoch 5\n2 Start Epoch 5\n2: 1 batches\n6: 1 batches\n12 Start Epoch 5\n3: 1 batches\n12: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:20: Epoch 0 train loss: 737052.9375\nINFO:root:19: Epoch 0 train loss: 30164.9140625\nINFO:root:21: Epoch 0 train loss: 5198.76416015625\nINFO:root:15: Epoch 0 train loss: 10942.712890625\nINFO:root:11: Epoch 0 train loss: 825.3987426757812\nINFO:root:12: Epoch 0 train loss: 28613.060546875\nINFO:root:13: Epoch 0 train loss: 3943.72412109375\nINFO:root:14: Epoch 0 train loss: 2211.141845703125\nINFO:root:16: Epoch 0 train loss: 754192.5625\nINFO:root:17: Epoch 0 train loss: 2972.706787109375\nINFO:root:18: Epoch 0 train loss: 3071.925537109375\nINFO:root:9: Epoch 0 train loss: 84.18978118896484\nINFO:root:10: Epoch 0 train loss: 242.44180297851562\nINFO:root:7: Epoch 0 train loss: 6098.28271484375\nINFO:root:6: Epoch 0 train loss: 26629.271484375\nINFO:root:31: Epoch 0 train loss: 4106.18505859375\nINFO:root:35: Epoch 0 train loss: 1266.9127197265625\nINFO:root:39: Epoch 0 train loss: 2535.564697265625\nINFO:root:5: Epoch 0 train loss: 830280.0\nINFO:root:36: Epoch 0 train loss: 72.36170196533203\nINFO:root:1: Epoch 0 train loss: 10447.0498046875\nINFO:root:2: Epoch 0 train loss: 2792.556396484375\nINFO:root:38: Epoch 0 train loss: 4506.24365234375\nINFO:root:24: Epoch 0 train loss: 139.39759826660156\nINFO:root:34: Epoch 0 train loss: 837864.1875\nINFO:root:37: Epoch 0 train loss: 21802.92578125\nINFO:root:22: Epoch 0 train loss: 7570.9931640625\nINFO:root:25: Epoch 0 train loss: 10196.671875\nINFO:root:32: Epoch 0 train loss: 2332.818603515625\nINFO:root:23: Epoch 0 train loss: 291827.15625\nINFO:root:33: Epoch 0 train loss: 1033514.6875\nINFO:root:4: Epoch 0 train loss: 8532.05078125\nINFO:root:3: Epoch 0 train loss: 911253.625\nINFO:root:8: Epoch 0 train loss: 926956.5\nINFO:root:29: Epoch 0 train loss: 416.89117431640625\nINFO:root:30: Epoch 0 train loss: 1618694.375\nINFO:root:26: Epoch 0 train loss: 1316.1942138671875\nINFO:root:27: Epoch 0 train loss: 5286.0390625\nINFO:root:28: Epoch 0 train loss: 5366.17626953125\nINFO:root:0: Epoch 0 train loss: 823524.3125\nINFO:root:0: Epoch 0 validation loss: 1411802.6107108167\nINFO:root:35: Epoch 1 train loss: 5541.19140625\nINFO:root:27: Epoch 1 train loss: 6149.98779296875\nINFO:root:39: Epoch 1 train loss: 2725.346923828125\nINFO:root:36: Epoch 1 train loss: 4363.1865234375\nINFO:root:38: Epoch 1 train loss: 289128.96875\nINFO:root:26: Epoch 1 train loss: 925563.3125\nINFO:root:0: Epoch 1 train loss: 4851.533203125\nINFO:root:1: Epoch 1 train loss: 2345.485107421875\nINFO:root:34: Epoch 1 train loss: 19481.87109375\nINFO:root:33: Epoch 1 train loss: 7777.9814453125\nINFO:root:32: Epoch 1 train loss: 499.5041809082031\nINFO:root:30: Epoch 1 train loss: 927413.625\nINFO:root:31: Epoch 1 train loss: 1911.953125\nINFO:root:29: Epoch 1 train loss: 28288.595703125\nINFO:root:28: Epoch 1 train loss: 140.7852325439453\nINFO:root:37: Epoch 1 train loss: 3924.339599609375\nINFO:root:5: Epoch 1 train loss: 230.60354614257812\nINFO:root:4: Epoch 1 train loss: 2793.228271484375\nINFO:root:15: Epoch 1 train loss: 298.89764404296875\nINFO:root:2: Epoch 1 train loss: 883591.4375\nINFO:root:3: Epoch 1 train loss: 809.6089477539062\nINFO:root:18: Epoch 1 train loss: 6768.41259765625\nINFO:root:22: Epoch 1 train loss: 461.6318359375\nINFO:root:21: Epoch 1 train loss: 16089.775390625\nINFO:root:7: Epoch 1 train loss: 3397.080322265625\nINFO:root:6: Epoch 1 train loss: 289026.59375\nINFO:root:8: Epoch 1 train loss: 2423.816162109375\nINFO:root:9: Epoch 1 train loss: 748.1775512695312\nINFO:root:24: Epoch 1 train loss: 514.9555053710938\nINFO:root:17: Epoch 1 train loss: 2305.213623046875\nINFO:root:16: Epoch 1 train loss: 4307.46533203125\nINFO:root:23: Epoch 1 train loss: 11503.326171875\nINFO:root:25: Epoch 1 train loss: 1046.2596435546875\nINFO:root:10: Epoch 1 train loss: 3518.155029296875\nINFO:root:13: Epoch 1 train loss: 63.50958251953125\nINFO:root:19: Epoch 1 train loss: 573.0650024414062\nINFO:root:14: Epoch 1 train loss: 4801.203125\nINFO:root:12: Epoch 1 train loss: 18644.201171875\nINFO:root:20: Epoch 1 train loss: 7607.47021484375\nINFO:root:11: Epoch 1 train loss: 5924.2763671875\nINFO:root:0: Epoch 1 validation loss: 1411789.1327489964\nINFO:root:0: Epoch 2 train loss: 1531.4598388671875\nINFO:root:11: Epoch 2 train loss: 4887.92431640625\nINFO:root:31: Epoch 2 train loss: 4465.93505859375\nINFO:root:24: Epoch 2 train loss: 779.1939697265625\nINFO:root:2: Epoch 2 train loss: 3896.441650390625\nINFO:root:16: Epoch 2 train loss: 17932.392578125\nINFO:root:22: Epoch 2 train loss: 841227.1875\nINFO:root:35: Epoch 2 train loss: 10123.91015625\nINFO:root:7: Epoch 2 train loss: 415.7417907714844\nINFO:root:39: Epoch 2 train loss: 1266.912353515625\nINFO:root:8: Epoch 2 train loss: 915319.0625\nINFO:root:30: Epoch 2 train loss: 5335.52880859375\nINFO:root:15: Epoch 2 train loss: 1754.9691162109375\nINFO:root:23: Epoch 2 train loss: 925605.875\nINFO:root:25: Epoch 2 train loss: 7539.8642578125\nINFO:root:18: Epoch 2 train loss: 6211.3564453125\nINFO:root:14: Epoch 2 train loss: 824568.875\nINFO:root:17: Epoch 2 train loss: 9788.2265625\nINFO:root:26: Epoch 2 train loss: 292289.375\nINFO:root:20: Epoch 2 train loss: 3667.270751953125\nINFO:root:13: Epoch 2 train loss: 31820.88671875\nINFO:root:9: Epoch 2 train loss: 11766.4248046875\nINFO:root:5: Epoch 2 train loss: 441.4980773925781\nINFO:root:10: Epoch 2 train loss: 16494.208984375\nINFO:root:3: Epoch 2 train loss: 6978.24658203125\nINFO:root:1: Epoch 2 train loss: 544.726806640625\nINFO:root:4: Epoch 2 train loss: 5508.4521484375\nINFO:root:21: Epoch 2 train loss: 497.85369873046875\nINFO:root:19: Epoch 2 train loss: 134.36268615722656\nINFO:root:33: Epoch 2 train loss: 735357.625\nINFO:root:38: Epoch 2 train loss: 291924.5625\nINFO:root:12: Epoch 2 train loss: 1746.3021240234375\nINFO:root:27: Epoch 2 train loss: 495.1645202636719\nINFO:root:32: Epoch 2 train loss: 2972.6923828125\nINFO:root:6: Epoch 2 train loss: 891.678466796875\nINFO:root:34: Epoch 2 train loss: 204.5270538330078\nINFO:root:29: Epoch 2 train loss: 894202.375\nINFO:root:28: Epoch 2 train loss: 740933.875\nINFO:root:37: Epoch 2 train loss: 29481.583984375\nINFO:root:36: Epoch 2 train loss: 4734.10986328125\nINFO:root:0: Epoch 2 validation loss: 1411775.3765602768\nINFO:root:33: Epoch 3 train loss: 1144.7230224609375\nINFO:root:7: Epoch 3 train loss: 926225.0625\nINFO:root:31: Epoch 3 train loss: 14488.2099609375\nINFO:root:30: Epoch 3 train loss: 5018.6884765625\nINFO:root:34: Epoch 3 train loss: 6822.7958984375\nINFO:root:6: Epoch 3 train loss: 216.74951171875\nINFO:root:35: Epoch 3 train loss: 3026.51220703125\nINFO:root:32: Epoch 3 train loss: 3436.149658203125\nINFO:root:1: Epoch 3 train loss: 1607.50048828125\nINFO:root:3: Epoch 3 train loss: 188.31634521484375\nINFO:root:8: Epoch 3 train loss: 702956.875\nINFO:root:9: Epoch 3 train loss: 884022.0\nINFO:root:13: Epoch 3 train loss: 8495.7490234375\nINFO:root:15: Epoch 3 train loss: 2108.42236328125\nINFO:root:14: Epoch 3 train loss: 291293.71875\nINFO:root:39: Epoch 3 train loss: 4426.80078125\nINFO:root:37: Epoch 3 train loss: 696831.5\nINFO:root:36: Epoch 3 train loss: 1026720.125\nINFO:root:38: Epoch 3 train loss: 1862208.25\nINFO:root:28: Epoch 3 train loss: 306.242919921875\nINFO:root:2: Epoch 3 train loss: 5304.58935546875\nINFO:root:22: Epoch 3 train loss: 6940.5537109375\nINFO:root:11: Epoch 3 train loss: 6498.01611328125\nINFO:root:12: Epoch 3 train loss: 29815.716796875\nINFO:root:27: Epoch 3 train loss: 1196.0955810546875\nINFO:root:19: Epoch 3 train loss: 18824.6953125\nINFO:root:25: Epoch 3 train loss: 23416.8359375\nINFO:root:17: Epoch 3 train loss: 4965.60693359375\nINFO:root:4: Epoch 3 train loss: 923917.125\nINFO:root:23: Epoch 3 train loss: 4238.490234375\nINFO:root:10: Epoch 3 train loss: 2841.222412109375\nINFO:root:29: Epoch 3 train loss: 5200.00146484375\nINFO:root:24: Epoch 3 train loss: 823.341064453125\nINFO:root:26: Epoch 3 train loss: 1612916.0\nINFO:root:5: Epoch 3 train loss: 98773.59375\nINFO:root:21: Epoch 3 train loss: 4939.66552734375\nINFO:root:18: Epoch 3 train loss: 7669.947265625\nINFO:root:16: Epoch 3 train loss: 3595.05615234375\nINFO:root:20: Epoch 3 train loss: 815.5660400390625\nINFO:root:0: Epoch 3 train loss: 826477.0\nINFO:root:0: Epoch 3 validation loss: 1411761.7238462402\nINFO:root:31: Epoch 4 train loss: 1023527.5625\nINFO:root:30: Epoch 4 train loss: 314.806884765625\nINFO:root:39: Epoch 4 train loss: 290.7005615234375\nINFO:root:37: Epoch 4 train loss: 6183.19970703125\nINFO:root:36: Epoch 4 train loss: 1026602.4375\nINFO:root:38: Epoch 4 train loss: 6848.078125\nINFO:root:34: Epoch 4 train loss: 1047576.4375\nINFO:root:35: Epoch 4 train loss: 2728.019775390625\nINFO:root:33: Epoch 4 train loss: 3248.835693359375\nINFO:root:29: Epoch 4 train loss: 3488.705810546875\nINFO:root:32: Epoch 4 train loss: 8950.666015625\nINFO:root:0: Epoch 4 train loss: 4565.4091796875\nINFO:root:1: Epoch 4 train loss: 5700.27880859375\nINFO:root:9: Epoch 4 train loss: 13806.4228515625\nINFO:root:19: Epoch 4 train loss: 18700.05078125\nINFO:root:18: Epoch 4 train loss: 804.3380737304688\nINFO:root:23: Epoch 4 train loss: 668.0296020507812\nINFO:root:24: Epoch 4 train loss: 7019.47607421875\nINFO:root:27: Epoch 4 train loss: 2932.356689453125\nINFO:root:26: Epoch 4 train loss: 2542.558837890625\nINFO:root:25: Epoch 4 train loss: 1115.7509765625\nINFO:root:20: Epoch 4 train loss: 16972.5234375\nINFO:root:28: Epoch 4 train loss: 9859.10546875\nINFO:root:21: Epoch 4 train loss: 10245.04296875\nINFO:root:15: Epoch 4 train loss: 2061.099853515625\nINFO:root:22: Epoch 4 train loss: 8896.3095703125\nINFO:root:13: Epoch 4 train loss: 261.1883239746094\nINFO:root:12: Epoch 4 train loss: 33478.421875\nINFO:root:11: Epoch 4 train loss: 4950.4443359375\nINFO:root:10: Epoch 4 train loss: 24592.251953125\nINFO:root:16: Epoch 4 train loss: 776.55615234375\nINFO:root:17: Epoch 4 train loss: 927551.5625\nINFO:root:4: Epoch 4 train loss: 2824.596435546875\nINFO:root:7: Epoch 4 train loss: 155.45932006835938\nINFO:root:8: Epoch 4 train loss: 595.3114013671875\nINFO:root:14: Epoch 4 train loss: 2797.081787109375\nINFO:root:5: Epoch 4 train loss: 12144.9111328125\nINFO:root:6: Epoch 4 train loss: 605.911376953125\nINFO:root:3: Epoch 4 train loss: 17767.1171875\nINFO:root:2: Epoch 4 train loss: 3507.850341796875\nINFO:root:0: Epoch 4 validation loss: 1411747.7321439947\nINFO:root:39: Epoch 5 train loss: 5588.68798828125\nINFO:root:38: Epoch 5 train loss: 95723.1875\nINFO:root:31: Epoch 5 train loss: 9195.9150390625\nINFO:root:37: Epoch 5 train loss: 287.54766845703125\nINFO:root:28: Epoch 5 train loss: 1025756.0625\nINFO:root:36: Epoch 5 train loss: 3485.680908203125\nINFO:root:7: Epoch 5 train loss: 722.656494140625\nINFO:root:22: Epoch 5 train loss: 2771.718505859375\nINFO:root:21: Epoch 5 train loss: 2638.978759765625\nINFO:root:9: Epoch 5 train loss: 3335.387939453125\nINFO:root:23: Epoch 5 train loss: 885225.0\nINFO:root:8: Epoch 5 train loss: 3810.85009765625\nINFO:root:20: Epoch 5 train loss: 2589.349365234375\nINFO:root:10: Epoch 5 train loss: 6390.96435546875\nINFO:root:11: Epoch 5 train loss: 2082.815185546875\nINFO:root:35: Epoch 5 train loss: 1591.31005859375\nINFO:root:34: Epoch 5 train loss: 940.355224609375\nINFO:root:0: Epoch 5 train loss: 2378.22119140625\nINFO:root:19: Epoch 5 train loss: 4414.41650390625\nINFO:root:25: Epoch 5 train loss: 543.257080078125\nINFO:root:16: Epoch 5 train loss: 5285.3984375\nINFO:root:24: Epoch 5 train loss: 1356.2686767578125\nINFO:root:27: Epoch 5 train loss: 207.4336395263672\nINFO:root:26: Epoch 5 train loss: 2314.31640625\nINFO:root:2: Epoch 5 train loss: 18231.849609375\nINFO:root:15: Epoch 5 train loss: 695734.125\nINFO:root:5: Epoch 5 train loss: 3501.3837890625\nINFO:root:4: Epoch 5 train loss: 415.84130859375\nINFO:root:3: Epoch 5 train loss: 9947.1904296875\nINFO:root:18: Epoch 5 train loss: 3215.270751953125\nINFO:root:29: Epoch 5 train loss: 755.6316528320312\nINFO:root:30: Epoch 5 train loss: 5638.53564453125\nINFO:root:1: Epoch 5 train loss: 72.1088638305664\nINFO:root:32: Epoch 5 train loss: 1159.0010986328125\nINFO:root:33: Epoch 5 train loss: 1481.5274658203125\nINFO:root:17: Epoch 5 train loss: 1755.4810791015625\nINFO:root:14: Epoch 5 train loss: 3107.76611328125\nINFO:root:6: Epoch 5 train loss: 296184.78125\nINFO:root:12: Epoch 5 train loss: 4803.0498046875\nINFO:root:13: Epoch 5 train loss: 1875.0999755859375\nINFO:root:0: Epoch 5 validation loss: 1411733.3854798377\n", "seconds": 24.058449268341064, "batch_size": 128, "nodes": 10, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n43 Start Epoch 0\n1: 1 batches\n43: 1 batches\n2 Start Epoch 0\n2: 1 batches\n3 Start Epoch 0\n3: 1 batches\n4 Start Epoch 0\n4: 1 batches\n7 Start Epoch 0\n7: 1 batches\n8 Start Epoch 0\n32 Start Epoch 0\n8: 1 batches\n12 Start Epoch 0\n31 Start Epoch 0\n32: 1 batches\n36 Start Epoch 0\n27 Start Epoch 0\n11 Start Epoch 0\n20 Start Epoch 0\n15 Start Epoch 0\n28 Start Epoch 0\n36: 1 batches\n27: 1 batches\n40 Start Epoch 0\n11: 1 batches\n20: 1 batches\n15: 1 batches\n28: 1 batches\n35 Start Epoch 0\n40: 1 batches\n31: 1 batches\n35: 1 batches\n39 Start Epoch 0\n24 Start Epoch 0\n12: 1 batches\n24: 1 batches\n16 Start Epoch 0\n16: 1 batches\n23 Start Epoch 0\n39: 1 batches\n23: 1 batches\n5 Start Epoch 0\n19 Start Epoch 0\n19: 1 batches\n6 Start Epoch 0\n5: 1 batches\n6: 1 batches\n9 Start Epoch 0\n10 Start Epoch 0\n10: 1 batches\n9: 1 batches\n18 Start Epoch 0\n17 Start Epoch 0\n17: 1 batches\n33 Start Epoch 0\n18: 1 batches\n34 Start Epoch 0\n34: 1 batches\n33: 1 batches\n37 Start Epoch 0\n38 Start Epoch 0\n38: 1 batches\n37: 1 batches\n14 Start Epoch 0\n29 Start Epoch 0\n22 Start Epoch 0\n13 Start Epoch 0\n30 Start Epoch 0\n13: 1 batches\n29: 1 batches\n21 Start Epoch 0\n22: 1 batches\n14: 1 batches\n30: 1 batches\n21: 1 batches\n25 Start Epoch 0\n26 Start Epoch 0\n25: 1 batches\n26: 1 batches\n41 Start Epoch 0\n41: 1 batches\n42 Start Epoch 0\n42: 1 batches\n41 Start Epoch 1\n41: 1 batches\n42 Start Epoch 1\n42: 1 batches\n37 Start Epoch 1\n38 Start Epoch 1\n37: 1 batches\n39 Start Epoch 1\n39: 1 batches\n38: 1 batches\n43 Start Epoch 1\n43: 1 batches\n35 Start Epoch 1\n35: 1 batches\n34 Start Epoch 1\n34: 1 batches\n32 Start Epoch 1\n32: 1 batches\n33 Start Epoch 1\n22 Start Epoch 1\n6 Start Epoch 1\n40 Start Epoch 1\n22: 1 batches\n7 Start Epoch 1\n33: 1 batches\n40: 1 batches\n23 Start Epoch 1\n6: 1 batches\n15 Start Epoch 1\n3 Start Epoch 1\n2 Start Epoch 1\n2: 1 batches\n3: 1 batches\n7: 1 batches\n15: 1 batches\n14 Start Epoch 1\n28 Start Epoch 1\n27 Start Epoch 1\n17 Start Epoch 1\n11 Start Epoch 1\n13 Start Epoch 1\n31 Start Epoch 1\n25 Start Epoch 1\n18 Start Epoch 1\n8 Start Epoch 1\n13: 1 batches\n1 Start Epoch 1\n28: 1 batches\n36 Start Epoch 1\n26 Start Epoch 1\n26: 1 batches\n1: 1 batches\n17: 1 batches\n23: 1 batches\n11: 1 batches\n14: 1 batches\n30 Start Epoch 1\n36: 1 batches\n25: 1 batches\n18: 1 batches\n8: 1 batches\n21 Start Epoch 1\n30: 1 batches\n27: 1 batches\n12 Start Epoch 1\n31: 1 batches\n16 Start Epoch 1\n9 Start Epoch 1\n21: 1 batches\n9: 1 batches\n20 Start Epoch 1\n20: 1 batches\n4 Start Epoch 1\n12: 1 batches\n24 Start Epoch 1\n16: 1 batches\n24: 1 batches\n5 Start Epoch 1\n29 Start Epoch 1\n29: 1 batches\n10 Start Epoch 1\n5: 1 batches\n10: 1 batches\n4: 1 batches\n19 Start Epoch 1\n19: 1 batches\n0 Start Epoch 1\n0: 1 batches\n43 Start Epoch 2\n43: 1 batches\n1 Start Epoch 2\n1: 1 batches\n35 Start Epoch 2\n35: 1 batches\n15 Start Epoch 2\n15: 1 batches\n5 Start Epoch 2\n6 Start Epoch 2\n7 Start Epoch 2\n7: 1 batches\n2 Start Epoch 2\n2: 1 batches\n6: 1 batches\n5: 1 batches\n3 Start Epoch 2\n3: 1 batches\n33 Start Epoch 2\n9 Start Epoch 2\n23 Start Epoch 2\n23: 1 batches\n14 Start Epoch 2\n34 Start Epoch 2\n17 Start Epoch 2\n9: 1 batches\n12 Start Epoch 2\n32 Start Epoch 2\n27 Start Epoch 2\n16 Start Epoch 2\n14: 1 batches\n32: 1 batches\n38 Start Epoch 2\n38: 1 batches\n27: 1 batches\n16: 1 batches\n12: 1 batches\n28 Start Epoch 2\n34: 1 batches\n26 Start Epoch 2\n17: 1 batches\n11 Start Epoch 2\n26: 1 batches\n10 Start Epoch 2\n29 Start Epoch 2\n33: 1 batches\n11: 1 batches\n20 Start Epoch 2\n10: 1 batches\n21 Start Epoch 2\n4 Start Epoch 2\n39 Start Epoch 2\n39: 1 batches\n24 Start Epoch 2\n18 Start Epoch 2\n19 Start Epoch 2\n21: 1 batches\n4: 1 batches\n37 Start Epoch 2\n37: 1 batches\n24: 1 batches\n20: 1 batches\n13 Start Epoch 2\n13: 1 batches\n18: 1 batches\n25 Start Epoch 2\n19: 1 batches\n36 Start Epoch 2\n36: 1 batches\n22 Start Epoch 2\n25: 1 batches\n41 Start Epoch 2\n22: 1 batches\n42 Start Epoch 2\n42: 1 batches\n41: 1 batches\n40 Start Epoch 2\n40: 1 batches\n28: 1 batches\n30 Start Epoch 2\n30: 1 batches\n29: 1 batches\n31 Start Epoch 2\n31: 1 batches\n8 Start Epoch 2\n8: 1 batches\n0 Start Epoch 2\n0: 1 batches\n39 Start Epoch 3\n39: 1 batches\n43 Start Epoch 3\n41 Start Epoch 3\n42 Start Epoch 3\n43: 1 batches\n42: 1 batches\n41: 1 batches\n40 Start Epoch 3\n40: 1 batches\n37 Start Epoch 3\n38 Start Epoch 3\n37: 1 batches\n38: 1 batches\n36 Start Epoch 3\n36: 1 batches\n1 Start Epoch 3\n1: 1 batches\n35 Start Epoch 3\n35: 1 batches\n7 Start Epoch 3\n31 Start Epoch 3\n7: 1 batches\n31: 1 batches\n2 Start Epoch 3\n2: 1 batches\n34 Start Epoch 3\n27 Start Epoch 3\n27: 1 batches\n15 Start Epoch 3\n15: 1 batches\n34: 1 batches\n14 Start Epoch 3\n4 Start Epoch 3\n14: 1 batches\n29 Start Epoch 3\n3 Start Epoch 3\n6 Start Epoch 3\n6: 1 batches\n28 Start Epoch 3\n24 Start Epoch 3\n19 Start Epoch 3\n11 Start Epoch 3\n11: 1 batches\n22 Start Epoch 3\n5 Start Epoch 3\n29: 1 batches\n33 Start Epoch 3\n17 Start Epoch 3\n20 Start Epoch 3\n5: 1 batches\n12 Start Epoch 3\n30 Start Epoch 3\n33: 1 batches\n24: 1 batches\n16 Start Epoch 3\n21 Start Epoch 3\n4: 1 batches\n13 Start Epoch 3\n28: 1 batches\n26 Start Epoch 3\n16: 1 batches\n10 Start Epoch 3\n10: 1 batches\n22: 1 batches\n13: 1 batches\n30: 1 batches\n19: 1 batches\n25 Start Epoch 3\n17: 1 batches\n20: 1 batches\n12: 1 batches\n8 Start Epoch 3\n23 Start Epoch 3\n26: 1 batches\n25: 1 batches\n18 Start Epoch 3\n8: 1 batches\n23: 1 batches\n21: 1 batches\n18: 1 batches\n3: 1 batches\n9 Start Epoch 3\n9: 1 batches\n32 Start Epoch 3\n32: 1 batches\n0 Start Epoch 3\n0: 1 batches\n23 Start Epoch 4\n23: 1 batches\n20 Start Epoch 4\n20: 1 batches\n13 Start Epoch 4\n13: 1 batches\n25 Start Epoch 4\n24 Start Epoch 4\n14 Start Epoch 4\n24: 1 batches\n25: 1 batches\n19 Start Epoch 4\n19: 1 batches\n22 Start Epoch 4\n14: 1 batches\n21 Start Epoch 4\n22: 1 batches\n21: 1 batches\n16 Start Epoch 4\n16: 1 batches\n15 Start Epoch 4\n15: 1 batches\n31 Start Epoch 4\n38 Start Epoch 4\n39 Start Epoch 4\n39: 1 batches\n18 Start Epoch 4\n18: 1 batches\n17 Start Epoch 4\n17: 1 batches\n4 Start Epoch 4\n6 Start Epoch 4\n6: 1 batches\n7 Start Epoch 4\n31: 1 batches\n4: 1 batches\n26 Start Epoch 4\n8 Start Epoch 4\n8: 1 batches\n5 Start Epoch 4\n27 Start Epoch 4\n11 Start Epoch 4\n11: 1 batches\n5: 1 batches\n35 Start Epoch 4\n27: 1 batches\n43 Start Epoch 4\n7: 1 batches\n32 Start Epoch 4\n26: 1 batches\n3 Start Epoch 4\n3: 1 batches\n2 Start Epoch 4\n2: 1 batches\n1 Start Epoch 4\n1: 1 batches\n42 Start Epoch 4\n30 Start Epoch 4\n41 Start Epoch 4\n28 Start Epoch 4\n33 Start Epoch 4\n29 Start Epoch 4\n33: 1 batches\n42: 1 batches\n10 Start Epoch 4\n30: 1 batches\n35: 1 batches\n43: 1 batches\n10: 1 batches\n28: 1 batches\n34 Start Epoch 4\n41: 1 batches\n29: 1 batches\n32: 1 batches\n40 Start Epoch 4\n9 Start Epoch 4\n9: 1 batches\n34: 1 batches\n40: 1 batches\n12 Start Epoch 4\n12: 1 batches\n38: 1 batches\n36 Start Epoch 4\n37 Start Epoch 4\n37: 1 batches\n36: 1 batches\n0 Start Epoch 4\n0: 1 batches\n15 Start Epoch 5\n15: 1 batches\n12 Start Epoch 5\n12: 1 batches\n4 Start Epoch 5\n4: 1 batches\n6 Start Epoch 5\n6: 1 batches\n5 Start Epoch 5\n1 Start Epoch 5\n1: 1 batches\n2 Start Epoch 5\n2: 1 batches\n5: 1 batches\n39 Start Epoch 5\n18 Start Epoch 5\n13 Start Epoch 5\n19 Start Epoch 5\n8 Start Epoch 5\n14 Start Epoch 5\n38 Start Epoch 5\n14: 1 batches\n38: 1 batches\n18: 1 batches\n10 Start Epoch 5\n19: 1 batches\n10: 1 batches\n13: 1 batches\n39: 1 batches\n23 Start Epoch 5\n8: 1 batches\n16 Start Epoch 5\n23: 1 batches\n16: 1 batches\n41 Start Epoch 5\n9 Start Epoch 5\n11 Start Epoch 5\n21 Start Epoch 5\n36 Start Epoch 5\n21: 1 batches\n36: 1 batches\n24 Start Epoch 5\n17 Start Epoch 5\n42 Start Epoch 5\n9: 1 batches\n11: 1 batches\n37 Start Epoch 5\n25 Start Epoch 5\n17: 1 batches\n42: 1 batches\n35 Start Epoch 5\n24: 1 batches\n43 Start Epoch 5\n25: 1 batches\n43: 1 batches\n41: 1 batches\n40 Start Epoch 5\n35: 1 batches\n40: 1 batches\n20 Start Epoch 5\n20: 1 batches\n27 Start Epoch 5\n27: 1 batches\n29 Start Epoch 5\n32 Start Epoch 5\n32: 1 batches\n28 Start Epoch 5\n34 Start Epoch 5\n34: 1 batches\n30 Start Epoch 5\n28: 1 batches\n29: 1 batches\n31 Start Epoch 5\n31: 1 batches\n30: 1 batches\n37: 1 batches\n33 Start Epoch 5\n26 Start Epoch 5\n33: 1 batches\n26: 1 batches\n7 Start Epoch 5\n7: 1 batches\n3 Start Epoch 5\n22 Start Epoch 5\n22: 1 batches\n3: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 7929.80712890625\nINFO:root:42: Epoch 0 train loss: 2685.67724609375\nINFO:root:41: Epoch 0 train loss: 8189.60546875\nINFO:root:37: Epoch 0 train loss: 2315.585205078125\nINFO:root:38: Epoch 0 train loss: 3841.6298828125\nINFO:root:39: Epoch 0 train loss: 300.7121276855469\nINFO:root:43: Epoch 0 train loss: 18035.052734375\nINFO:root:35: Epoch 0 train loss: 5450.13916015625\nINFO:root:34: Epoch 0 train loss: 1877.6400146484375\nINFO:root:32: Epoch 0 train loss: 953219.1875\nINFO:root:22: Epoch 0 train loss: 9144.5888671875\nINFO:root:7: Epoch 0 train loss: 3982.974609375\nINFO:root:33: Epoch 0 train loss: 362.36102294921875\nINFO:root:23: Epoch 0 train loss: 975361.8125\nINFO:root:6: Epoch 0 train loss: 13300.509765625\nINFO:root:40: Epoch 0 train loss: 16234.033203125\nINFO:root:15: Epoch 0 train loss: 2213.369873046875\nINFO:root:3: Epoch 0 train loss: 37433.66015625\nINFO:root:2: Epoch 0 train loss: 4327.3232421875\nINFO:root:27: Epoch 0 train loss: 8473.5078125\nINFO:root:28: Epoch 0 train loss: 243.38580322265625\nINFO:root:11: Epoch 0 train loss: 972137.25\nINFO:root:13: Epoch 0 train loss: 773.5048217773438\nINFO:root:30: Epoch 0 train loss: 372.2702331542969\nINFO:root:25: Epoch 0 train loss: 7521.72216796875\nINFO:root:18: Epoch 0 train loss: 4707.17919921875\nINFO:root:8: Epoch 0 train loss: 546.17138671875\nINFO:root:14: Epoch 0 train loss: 9529.4892578125\nINFO:root:31: Epoch 0 train loss: 671.0008544921875\nINFO:root:26: Epoch 0 train loss: 388.6319580078125\nINFO:root:17: Epoch 0 train loss: 18912.171875\nINFO:root:36: Epoch 0 train loss: 945911.0\nINFO:root:1: Epoch 0 train loss: 2959.02685546875\nINFO:root:9: Epoch 0 train loss: 3613.558349609375\nINFO:root:21: Epoch 0 train loss: 14836.4130859375\nINFO:root:4: Epoch 0 train loss: 2181.265869140625\nINFO:root:12: Epoch 0 train loss: 18205.5234375\nINFO:root:16: Epoch 0 train loss: 2122.63330078125\nINFO:root:24: Epoch 0 train loss: 6490.96142578125\nINFO:root:5: Epoch 0 train loss: 24257.03515625\nINFO:root:29: Epoch 0 train loss: 1266.5286865234375\nINFO:root:10: Epoch 0 train loss: 1938100.75\nINFO:root:20: Epoch 0 train loss: 2567.339599609375\nINFO:root:19: Epoch 0 train loss: 107.68682861328125\nINFO:root:0: Epoch 0 validation loss: 172806.41053845515\nINFO:root:43: Epoch 1 train loss: 1966.9669189453125\nINFO:root:0: Epoch 1 train loss: 975988.0\nINFO:root:1: Epoch 1 train loss: 1454.3626708984375\nINFO:root:35: Epoch 1 train loss: 5981.03515625\nINFO:root:15: Epoch 1 train loss: 1826.28662109375\nINFO:root:6: Epoch 1 train loss: 105620.0703125\nINFO:root:2: Epoch 1 train loss: 3239.476318359375\nINFO:root:7: Epoch 1 train loss: 70.57475280761719\nINFO:root:32: Epoch 1 train loss: 5694.4384765625\nINFO:root:5: Epoch 1 train loss: 1791.1549072265625\nINFO:root:34: Epoch 1 train loss: 783.4215087890625\nINFO:root:9: Epoch 1 train loss: 18263.57421875\nINFO:root:23: Epoch 1 train loss: 6935.11474609375\nINFO:root:3: Epoch 1 train loss: 19233.40625\nINFO:root:14: Epoch 1 train loss: 449.6673278808594\nINFO:root:33: Epoch 1 train loss: 13909.5244140625\nINFO:root:16: Epoch 1 train loss: 2057.140869140625\nINFO:root:26: Epoch 1 train loss: 911597.3125\nINFO:root:17: Epoch 1 train loss: 3616.410888671875\nINFO:root:12: Epoch 1 train loss: 275.7063293457031\nINFO:root:31: Epoch 1 train loss: 21035.115234375\nINFO:root:27: Epoch 1 train loss: 383.94189453125\nINFO:root:10: Epoch 1 train loss: 2648.2060546875\nINFO:root:28: Epoch 1 train loss: 5733.47705078125\nINFO:root:29: Epoch 1 train loss: 6599.85546875\nINFO:root:11: Epoch 1 train loss: 31572.154296875\nINFO:root:39: Epoch 1 train loss: 325349.53125\nINFO:root:20: Epoch 1 train loss: 20332.423828125\nINFO:root:37: Epoch 1 train loss: 2075.736328125\nINFO:root:18: Epoch 1 train loss: 1151.828369140625\nINFO:root:21: Epoch 1 train loss: 7580.52099609375\nINFO:root:4: Epoch 1 train loss: 2752.880859375\nINFO:root:13: Epoch 1 train loss: 4348.40234375\nINFO:root:36: Epoch 1 train loss: 116257.2265625\nINFO:root:24: Epoch 1 train loss: 5712.607421875\nINFO:root:19: Epoch 1 train loss: 9122.353515625\nINFO:root:38: Epoch 1 train loss: 2726.9912109375\nINFO:root:25: Epoch 1 train loss: 3441.487548828125\nINFO:root:41: Epoch 1 train loss: 434.3401794433594\nINFO:root:40: Epoch 1 train loss: 822585.75\nINFO:root:22: Epoch 1 train loss: 2805.34375\nINFO:root:42: Epoch 1 train loss: 352.1097717285156\nINFO:root:30: Epoch 1 train loss: 2969.253662109375\nINFO:root:8: Epoch 1 train loss: 2276.744873046875\nINFO:root:0: Epoch 1 validation loss: 172799.12882130465\nINFO:root:39: Epoch 2 train loss: 1128.384033203125\nINFO:root:41: Epoch 2 train loss: 477.592041015625\nINFO:root:42: Epoch 2 train loss: 907589.8125\nINFO:root:40: Epoch 2 train loss: 14779.4609375\nINFO:root:43: Epoch 2 train loss: 10119.05078125\nINFO:root:37: Epoch 2 train loss: 168.0671844482422\nINFO:root:38: Epoch 2 train loss: 2865.865234375\nINFO:root:36: Epoch 2 train loss: 215.79742431640625\nINFO:root:0: Epoch 2 train loss: 219.0444793701172\nINFO:root:1: Epoch 2 train loss: 15650.2900390625\nINFO:root:35: Epoch 2 train loss: 5432.27685546875\nINFO:root:7: Epoch 2 train loss: 6491.47265625\nINFO:root:31: Epoch 2 train loss: 2079.412841796875\nINFO:root:15: Epoch 2 train loss: 1093.6064453125\nINFO:root:2: Epoch 2 train loss: 2790.972412109375\nINFO:root:34: Epoch 2 train loss: 5573.2509765625\nINFO:root:30: Epoch 2 train loss: 3405.597900390625\nINFO:root:4: Epoch 2 train loss: 8710.3701171875\nINFO:root:22: Epoch 2 train loss: 697.1095581054688\nINFO:root:5: Epoch 2 train loss: 1506.6083984375\nINFO:root:14: Epoch 2 train loss: 1191.4390869140625\nINFO:root:29: Epoch 2 train loss: 1126790.875\nINFO:root:27: Epoch 2 train loss: 949515.4375\nINFO:root:19: Epoch 2 train loss: 9010.41015625\nINFO:root:6: Epoch 2 train loss: 914792.375\nINFO:root:28: Epoch 2 train loss: 2909.69921875\nINFO:root:16: Epoch 2 train loss: 1027.1243896484375\nINFO:root:21: Epoch 2 train loss: 9854.3603515625\nINFO:root:3: Epoch 2 train loss: 3337.573974609375\nINFO:root:24: Epoch 2 train loss: 15637.0546875\nINFO:root:17: Epoch 2 train loss: 811242.3125\nINFO:root:11: Epoch 2 train loss: 1286.6788330078125\nINFO:root:23: Epoch 2 train loss: 573.6996459960938\nINFO:root:12: Epoch 2 train loss: 2935.05126953125\nINFO:root:33: Epoch 2 train loss: 3363.461181640625\nINFO:root:20: Epoch 2 train loss: 892.0545043945312\nINFO:root:13: Epoch 2 train loss: 2131.06494140625\nINFO:root:26: Epoch 2 train loss: 1413.2642822265625\nINFO:root:10: Epoch 2 train loss: 696.8279418945312\nINFO:root:25: Epoch 2 train loss: 1127142.0\nINFO:root:8: Epoch 2 train loss: 10067.60546875\nINFO:root:18: Epoch 2 train loss: 2484.533447265625\nINFO:root:9: Epoch 2 train loss: 20117.921875\nINFO:root:32: Epoch 2 train loss: 14249.421875\nINFO:root:0: Epoch 2 validation loss: 172792.0156345264\nINFO:root:23: Epoch 3 train loss: 19809.244140625\nINFO:root:20: Epoch 3 train loss: 7793.14892578125\nINFO:root:13: Epoch 3 train loss: 2062.247802734375\nINFO:root:24: Epoch 3 train loss: 2558.82861328125\nINFO:root:25: Epoch 3 train loss: 110957.046875\nINFO:root:15: Epoch 3 train loss: 11322.2099609375\nINFO:root:19: Epoch 3 train loss: 1673.59375\nINFO:root:22: Epoch 3 train loss: 3305.3544921875\nINFO:root:21: Epoch 3 train loss: 3027.853515625\nINFO:root:14: Epoch 3 train loss: 1064.8662109375\nINFO:root:16: Epoch 3 train loss: 11029.7705078125\nINFO:root:31: Epoch 3 train loss: 107125.796875\nINFO:root:39: Epoch 3 train loss: 20173.830078125\nINFO:root:38: Epoch 3 train loss: 16662.908203125\nINFO:root:18: Epoch 3 train loss: 972893.0\nINFO:root:17: Epoch 3 train loss: 597.2789306640625\nINFO:root:4: Epoch 3 train loss: 2433.701416015625\nINFO:root:5: Epoch 3 train loss: 5322.90234375\nINFO:root:7: Epoch 3 train loss: 105514.84375\nINFO:root:6: Epoch 3 train loss: 944791.0625\nINFO:root:34: Epoch 3 train loss: 693.6531372070312\nINFO:root:27: Epoch 3 train loss: 1157.8480224609375\nINFO:root:42: Epoch 3 train loss: 454.75531005859375\nINFO:root:8: Epoch 3 train loss: 351.3529357910156\nINFO:root:32: Epoch 3 train loss: 2017.7958984375\nINFO:root:26: Epoch 3 train loss: 766141.125\nINFO:root:43: Epoch 3 train loss: 7098.37158203125\nINFO:root:11: Epoch 3 train loss: 15182.3935546875\nINFO:root:30: Epoch 3 train loss: 4737.37451171875\nINFO:root:35: Epoch 3 train loss: 12356.919921875\nINFO:root:40: Epoch 3 train loss: 1021178.9375\nINFO:root:41: Epoch 3 train loss: 13221.17578125\nINFO:root:28: Epoch 3 train loss: 15851.2099609375\nINFO:root:33: Epoch 3 train loss: 3139.89453125\nINFO:root:29: Epoch 3 train loss: 1593.053466796875\nINFO:root:2: Epoch 3 train loss: 1241.86083984375\nINFO:root:3: Epoch 3 train loss: 1796.1661376953125\nINFO:root:0: Epoch 3 train loss: 8042.935546875\nINFO:root:1: Epoch 3 train loss: 1054130.75\nINFO:root:10: Epoch 3 train loss: 2908.14990234375\nINFO:root:9: Epoch 3 train loss: 3399.60205078125\nINFO:root:12: Epoch 3 train loss: 23677.984375\nINFO:root:37: Epoch 3 train loss: 166.60769653320312\nINFO:root:36: Epoch 3 train loss: 811670.875\nINFO:root:0: Epoch 3 validation loss: 172784.8825166361\nINFO:root:15: Epoch 4 train loss: 3994.556640625\nINFO:root:12: Epoch 4 train loss: 1128758.875\nINFO:root:4: Epoch 4 train loss: 2860.341796875\nINFO:root:6: Epoch 4 train loss: 8328.5400390625\nINFO:root:5: Epoch 4 train loss: 18894.046875\nINFO:root:1: Epoch 4 train loss: 5881.8203125\nINFO:root:2: Epoch 4 train loss: 1028635.1875\nINFO:root:10: Epoch 4 train loss: 823.8848876953125\nINFO:root:14: Epoch 4 train loss: 1021791.625\nINFO:root:39: Epoch 4 train loss: 8283.10546875\nINFO:root:19: Epoch 4 train loss: 911193.5\nINFO:root:9: Epoch 4 train loss: 289.9673767089844\nINFO:root:13: Epoch 4 train loss: 4735.046875\nINFO:root:38: Epoch 4 train loss: 972233.8125\nINFO:root:18: Epoch 4 train loss: 473.3243103027344\nINFO:root:8: Epoch 4 train loss: 590.6459350585938\nINFO:root:21: Epoch 4 train loss: 1617.640869140625\nINFO:root:16: Epoch 4 train loss: 18055.556640625\nINFO:root:43: Epoch 4 train loss: 2675.497314453125\nINFO:root:23: Epoch 4 train loss: 2730.895751953125\nINFO:root:37: Epoch 4 train loss: 2828.275634765625\nINFO:root:42: Epoch 4 train loss: 15975.1015625\nINFO:root:11: Epoch 4 train loss: 1128328.0\nINFO:root:36: Epoch 4 train loss: 5325.09912109375\nINFO:root:24: Epoch 4 train loss: 4408.77880859375\nINFO:root:25: Epoch 4 train loss: 11330.611328125\nINFO:root:0: Epoch 4 train loss: 4365.7333984375\nINFO:root:17: Epoch 4 train loss: 3942.00048828125\nINFO:root:41: Epoch 4 train loss: 5027.5361328125\nINFO:root:35: Epoch 4 train loss: 3854.783203125\nINFO:root:27: Epoch 4 train loss: 1132131.5\nINFO:root:28: Epoch 4 train loss: 771647.875\nINFO:root:40: Epoch 4 train loss: 812485.125\nINFO:root:20: Epoch 4 train loss: 328009.125\nINFO:root:31: Epoch 4 train loss: 1276.4288330078125\nINFO:root:30: Epoch 4 train loss: 314.672119140625\nINFO:root:32: Epoch 4 train loss: 2325.356201171875\nINFO:root:29: Epoch 4 train loss: 682.177978515625\nINFO:root:34: Epoch 4 train loss: 2813.83544921875\nINFO:root:33: Epoch 4 train loss: 815059.5625\nINFO:root:26: Epoch 4 train loss: 37646.21875\nINFO:root:7: Epoch 4 train loss: 329.4267272949219\nINFO:root:3: Epoch 4 train loss: 3045.235595703125\nINFO:root:22: Epoch 4 train loss: 112293.0\nINFO:root:0: Epoch 4 validation loss: 172777.89184685086\nINFO:root:31: Epoch 5 train loss: 11727.6767578125\nINFO:root:39: Epoch 5 train loss: 2238.013916015625\nINFO:root:37: Epoch 5 train loss: 1324.9832763671875\nINFO:root:36: Epoch 5 train loss: 7288.95849609375\nINFO:root:38: Epoch 5 train loss: 106301.890625\nINFO:root:42: Epoch 5 train loss: 994216.375\nINFO:root:43: Epoch 5 train loss: 1020086.5625\nINFO:root:30: Epoch 5 train loss: 527.19482421875\nINFO:root:35: Epoch 5 train loss: 8538.3310546875\nINFO:root:41: Epoch 5 train loss: 5513.78369140625\nINFO:root:29: Epoch 5 train loss: 810699.125\nINFO:root:34: Epoch 5 train loss: 44137.984375\nINFO:root:40: Epoch 5 train loss: 5866.7919921875\nINFO:root:25: Epoch 5 train loss: 947387.125\nINFO:root:28: Epoch 5 train loss: 86.85651397705078\nINFO:root:0: Epoch 5 train loss: 4078.84423828125\nINFO:root:26: Epoch 5 train loss: 2092.507080078125\nINFO:root:27: Epoch 5 train loss: 9313.216796875\nINFO:root:33: Epoch 5 train loss: 590.8306884765625\nINFO:root:23: Epoch 5 train loss: 631.5936279296875\nINFO:root:32: Epoch 5 train loss: 3476.703369140625\nINFO:root:1: Epoch 5 train loss: 107.85181427001953\nINFO:root:24: Epoch 5 train loss: 3535.531005859375\nINFO:root:7: Epoch 5 train loss: 2516.412353515625\nINFO:root:18: Epoch 5 train loss: 4051.30322265625\nINFO:root:19: Epoch 5 train loss: 10121.4716796875\nINFO:root:8: Epoch 5 train loss: 5310.3701171875\nINFO:root:10: Epoch 5 train loss: 6969.5830078125\nINFO:root:20: Epoch 5 train loss: 1293.4761962890625\nINFO:root:22: Epoch 5 train loss: 779769.5\nINFO:root:21: Epoch 5 train loss: 1707.5693359375\nINFO:root:12: Epoch 5 train loss: 909695.875\nINFO:root:15: Epoch 5 train loss: 2014.312744140625\nINFO:root:11: Epoch 5 train loss: 908454.0\nINFO:root:2: Epoch 5 train loss: 218.06900024414062\nINFO:root:5: Epoch 5 train loss: 69.3683853149414\nINFO:root:6: Epoch 5 train loss: 985921.5\nINFO:root:4: Epoch 5 train loss: 2873.763916015625\nINFO:root:13: Epoch 5 train loss: 4737.822265625\nINFO:root:14: Epoch 5 train loss: 5336.76611328125\nINFO:root:3: Epoch 5 train loss: 105906.5546875\nINFO:root:9: Epoch 5 train loss: 17429.47265625\nINFO:root:16: Epoch 5 train loss: 5854.048828125\nINFO:root:17: Epoch 5 train loss: 7846.07275390625\nINFO:root:0: Epoch 5 validation loss: 172770.90117120364\n", "seconds": 24.156461000442505, "batch_size": 128, "nodes": 11, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 128 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n47 Start Epoch 0\n1 Start Epoch 0\n3 Start Epoch 0\n1: 1 batches\n3: 1 batches\n47: 1 batches\n4 Start Epoch 0\n4: 1 batches\n2 Start Epoch 0\n2: 1 batches\n16 Start Epoch 0\n8 Start Epoch 0\n16: 1 batches\n8: 1 batches\n7 Start Epoch 0\n31 Start Epoch 0\n31: 1 batches\n5 Start Epoch 0\n15 Start Epoch 0\n15: 1 batches\n6 Start Epoch 0\n5: 1 batches\n12 Start Epoch 0\n12: 1 batches\n6: 1 batches\n7: 1 batches\n20 Start Epoch 0\n36 Start Epoch 0\n36: 1 batches\n11 Start Epoch 0\n20: 1 batches\n11: 1 batches\n19 Start Epoch 0\n19: 1 batches\n35 Start Epoch 0\n35: 1 batches\n32 Start Epoch 0\n32: 1 batches\n27 Start Epoch 0\n28 Start Epoch 0\n44 Start Epoch 0\n27: 1 batches\n28: 1 batches\n44: 1 batches\n40 Start Epoch 0\n24 Start Epoch 0\n23 Start Epoch 0\n24: 1 batches\n14 Start Epoch 0\n23: 1 batches\n39 Start Epoch 0\n40: 1 batches\n13 Start Epoch 0\n39: 1 batches\n43 Start Epoch 0\n43: 1 batches\n13: 1 batches\n14: 1 batches\n37 Start Epoch 0\n21 Start Epoch 0\n38 Start Epoch 0\n22 Start Epoch 0\n38: 1 batches\n21: 1 batches\n33 Start Epoch 0\n37: 1 batches\n34 Start Epoch 0\n22: 1 batches\n34: 1 batches\n33: 1 batches\n9 Start Epoch 0\n10 Start Epoch 0\n9: 1 batches\n29 Start Epoch 0\n10: 1 batches\n30 Start Epoch 0\n45 Start Epoch 0\n18 Start Epoch 0\n30: 1 batches\n45: 1 batches\n17 Start Epoch 0\n29: 1 batches\n46 Start Epoch 0\n18: 1 batches\n46: 1 batches\n17: 1 batches\n41 Start Epoch 0\n26 Start Epoch 0\n42 Start Epoch 0\n26: 1 batches\n41: 1 batches\n25 Start Epoch 0\n25: 1 batches\n42: 1 batches\n14 Start Epoch 1\n13 Start Epoch 1\n13: 1 batches\n8 Start Epoch 1\n12 Start Epoch 1\n9 Start Epoch 1\n14: 1 batches\n11 Start Epoch 1\n11: 1 batches\n15 Start Epoch 1\n15: 1 batches\n9: 1 batches\n12: 1 batches\n10 Start Epoch 1\n10: 1 batches\n8: 1 batches\n17 Start Epoch 1\n16 Start Epoch 1\n16: 1 batches\n17: 1 batches\n6 Start Epoch 1\n4 Start Epoch 1\n6: 1 batches\n4: 1 batches\n5 Start Epoch 1\n35 Start Epoch 1\n35: 1 batches\n5: 1 batches\n33 Start Epoch 1\n1 Start Epoch 1\n1: 1 batches\n30 Start Epoch 1\n37 Start Epoch 1\n18 Start Epoch 1\n20 Start Epoch 1\n29 Start Epoch 1\n21 Start Epoch 1\n29: 1 batches\n34 Start Epoch 1\n38 Start Epoch 1\n18: 1 batches\n24 Start Epoch 1\n21: 1 batches\n30: 1 batches\n33: 1 batches\n36 Start Epoch 1\n19 Start Epoch 1\n25 Start Epoch 1\n34: 1 batches\n37: 1 batches\n44 Start Epoch 1\n19: 1 batches\n40 Start Epoch 1\n7 Start Epoch 1\n31 Start Epoch 1\n26 Start Epoch 1\n7: 1 batches\n2 Start Epoch 1\n20: 1 batches\n2: 1 batches\n31: 1 batches\n38: 1 batches\n47 Start Epoch 1\n42 Start Epoch 1\n22 Start Epoch 1\n32 Start Epoch 1\n39 Start Epoch 1\n45 Start Epoch 1\n41 Start Epoch 1\n22: 1 batches\n28 Start Epoch 1\n32: 1 batches\n39: 1 batches\n45: 1 batches\n40: 1 batches\n27 Start Epoch 1\n28: 1 batches\n36: 1 batches\n47: 1 batches\n41: 1 batches\n26: 1 batches\n23 Start Epoch 1\n44: 1 batches\n43 Start Epoch 1\n27: 1 batches\n42: 1 batches\n25: 1 batches\n3 Start Epoch 1\n3: 1 batches\n23: 1 batches\n46 Start Epoch 1\n46: 1 batches\n43: 1 batches\n24: 1 batches\n0 Start Epoch 1\n0: 1 batches\n45 Start Epoch 2\n47 Start Epoch 2\n47: 1 batches\n45: 1 batches\n46 Start Epoch 2\n46: 1 batches\n15 Start Epoch 2\n7 Start Epoch 2\n15: 1 batches\n7: 1 batches\n1 Start Epoch 2\n1: 1 batches\n11 Start Epoch 2\n11: 1 batches\n42 Start Epoch 2\n35 Start Epoch 2\n35: 1 batches\n41 Start Epoch 2\n3 Start Epoch 2\n3: 1 batches\n41: 1 batches\n36 Start Epoch 2\n16 Start Epoch 2\n43 Start Epoch 2\n17 Start Epoch 2\n43: 1 batches\n27 Start Epoch 2\n12 Start Epoch 2\n8 Start Epoch 2\n21 Start Epoch 2\n32 Start Epoch 2\n39 Start Epoch 2\n42: 1 batches\n26 Start Epoch 2\n5 Start Epoch 2\n13 Start Epoch 2\n9 Start Epoch 2\n22 Start Epoch 2\n29 Start Epoch 2\n32: 1 batches\n39: 1 batches\n16: 1 batches\n28 Start Epoch 2\n34 Start Epoch 2\n34: 1 batches\n36: 1 batches\n44 Start Epoch 2\n2 Start Epoch 2\n2: 1 batches\n26: 1 batches\n6 Start Epoch 2\n14 Start Epoch 2\n14: 1 batches\n9: 1 batches\n21: 1 batches\n18 Start Epoch 2\n40 Start Epoch 2\n25 Start Epoch 2\n6: 1 batches\n13: 1 batches\n22: 1 batches\n30 Start Epoch 2\n44: 1 batches\n18: 1 batches\n40: 1 batches\n5: 1 batches\n12: 1 batches\n10 Start Epoch 2\n23 Start Epoch 2\n30: 1 batches\n33 Start Epoch 2\n33: 1 batches\n17: 1 batches\n24 Start Epoch 2\n4 Start Epoch 2\n10: 1 batches\n23: 1 batches\n29: 1 batches\n38 Start Epoch 2\n8: 1 batches\n31 Start Epoch 2\n37 Start Epoch 2\n24: 1 batches\n4: 1 batches\n38: 1 batches\n19 Start Epoch 2\n25: 1 batches\n20 Start Epoch 2\n31: 1 batches\n28: 1 batches\n37: 1 batches\n19: 1 batches\n27: 1 batches\n20: 1 batches\n0 Start Epoch 2\n0: 1 batches\n1 Start Epoch 3\n1: 1 batches\n13 Start Epoch 3\n35 Start Epoch 3\n35: 1 batches\n47 Start Epoch 3\n47: 1 batches\n14 Start Epoch 3\n2 Start Epoch 3\n5 Start Epoch 3\n13: 1 batches\n3 Start Epoch 3\n5: 1 batches\n14: 1 batches\n41 Start Epoch 3\n37 Start Epoch 3\n21 Start Epoch 3\n38 Start Epoch 3\n44 Start Epoch 3\n42 Start Epoch 3\n6 Start Epoch 3\n12 Start Epoch 3\n11 Start Epoch 3\n15 Start Epoch 3\n9 Start Epoch 3\n22 Start Epoch 3\n29 Start Epoch 3\n34 Start Epoch 3\n38: 1 batches\n45 Start Epoch 3\n18 Start Epoch 3\n18: 1 batches\n41: 1 batches\n3: 1 batches\n26 Start Epoch 3\n6: 1 batches\n28 Start Epoch 3\n33 Start Epoch 3\n39 Start Epoch 3\n45: 1 batches\n16 Start Epoch 3\n16: 1 batches\n43 Start Epoch 3\n27 Start Epoch 3\n15: 1 batches\n9: 1 batches\n21: 1 batches\n32 Start Epoch 3\n37: 1 batches\n2: 1 batches\n44: 1 batches\n17 Start Epoch 3\n43: 1 batches\n24 Start Epoch 3\n4 Start Epoch 3\n12: 1 batches\n11: 1 batches\n22: 1 batches\n30 Start Epoch 3\n10 Start Epoch 3\n23 Start Epoch 3\n29: 1 batches\n34: 1 batches\n39: 1 batches\n19 Start Epoch 3\n42: 1 batches\n24: 1 batches\n4: 1 batches\n30: 1 batches\n33: 1 batches\n46 Start Epoch 3\n19: 1 batches\n26: 1 batches\n10: 1 batches\n23: 1 batches\n7 Start Epoch 3\n31 Start Epoch 3\n32: 1 batches\n36 Start Epoch 3\n46: 1 batches\n17: 1 batches\n40 Start Epoch 3\n25 Start Epoch 3\n36: 1 batches\n40: 1 batches\n25: 1 batches\n7: 1 batches\n8 Start Epoch 3\n20 Start Epoch 3\n31: 1 batches\n27: 1 batches\n8: 1 batches\n20: 1 batches\n28: 1 batches\n0 Start Epoch 3\n0: 1 batches\n37 Start Epoch 4\n29 Start Epoch 4\n30 Start Epoch 4\n30: 1 batches\n29: 1 batches\n31 Start Epoch 4\n31: 1 batches\n41 Start Epoch 4\n41: 1 batches\n1 Start Epoch 4\n43 Start Epoch 4\n1: 1 batches\n36 Start Epoch 4\n36: 1 batches\n37: 1 batches\n45 Start Epoch 4\n33 Start Epoch 4\n33: 1 batches\n38 Start Epoch 4\n35 Start Epoch 4\n35: 1 batches\n38: 1 batches\n47 Start Epoch 4\n43: 1 batches\n34 Start Epoch 4\n34: 1 batches\n44 Start Epoch 4\n32 Start Epoch 4\n32: 1 batches\n47: 1 batches\n42 Start Epoch 4\n39 Start Epoch 4\n45: 1 batches\n42: 1 batches\n39: 1 batches\n44: 1 batches\n46 Start Epoch 4\n46: 1 batches\n28 Start Epoch 4\n28: 1 batches\n27 Start Epoch 4\n27: 1 batches\n40 Start Epoch 4\n40: 1 batches\n2 Start Epoch 4\n7 Start Epoch 4\n7: 1 batches\n15 Start Epoch 4\n17 Start Epoch 4\n17: 1 batches\n14 Start Epoch 4\n14: 1 batches\n13 Start Epoch 4\n13: 1 batches\n8 Start Epoch 4\n18 Start Epoch 4\n15: 1 batches\n9 Start Epoch 4\n9: 1 batches\n18: 1 batches\n10 Start Epoch 4\n10: 1 batches\n24 Start Epoch 4\n8: 1 batches\n21 Start Epoch 4\n24: 1 batches\n22 Start Epoch 4\n16 Start Epoch 4\n21: 1 batches\n16: 1 batches\n11 Start Epoch 4\n19 Start Epoch 4\n11: 1 batches\n22: 1 batches\n23 Start Epoch 4\n19: 1 batches\n23: 1 batches\n20 Start Epoch 4\n20: 1 batches\n3 Start Epoch 4\n3: 1 batches\n2: 1 batches\n26 Start Epoch 4\n5 Start Epoch 4\n5: 1 batches\n4 Start Epoch 4\n4: 1 batches\n26: 1 batches\n12 Start Epoch 4\n12: 1 batches\n6 Start Epoch 4\n6: 1 batches\n25 Start Epoch 4\n25: 1 batches\n0 Start Epoch 4\n0: 1 batches\n35 Start Epoch 5\n32 Start Epoch 5\n32: 1 batches\n35: 1 batches\n34 Start Epoch 5\n33 Start Epoch 5\n34: 1 batches\n33: 1 batches\n47 Start Epoch 5\n47: 1 batches\n44 Start Epoch 5\n44: 1 batches\n19 Start Epoch 5\n45 Start Epoch 5\n45: 1 batches\n19: 1 batches\n39 Start Epoch 5\n46 Start Epoch 5\n27 Start Epoch 5\n22 Start Epoch 5\n36 Start Epoch 5\n46: 1 batches\n38 Start Epoch 5\n38: 1 batches\n24 Start Epoch 5\n23 Start Epoch 5\n28 Start Epoch 5\n22: 1 batches\n29 Start Epoch 5\n39: 1 batches\n24: 1 batches\n23: 1 batches\n30 Start Epoch 5\n37 Start Epoch 5\n18 Start Epoch 5\n25 Start Epoch 5\n30: 1 batches\n37: 1 batches\n18: 1 batches\n40 Start Epoch 5\n27: 1 batches\n29: 1 batches\n36: 1 batches\n42 Start Epoch 5\n25: 1 batches\n42: 1 batches\n20 Start Epoch 5\n31 Start Epoch 5\n31: 1 batches\n26 Start Epoch 5\n43 Start Epoch 5\n26: 1 batches\n28: 1 batches\n43: 1 batches\n41 Start Epoch 5\n41: 1 batches\n21 Start Epoch 5\n17 Start Epoch 5\n20: 1 batches\n17: 1 batches\n21: 1 batches\n40: 1 batches\n16 Start Epoch 5\n16: 1 batches\n15 Start Epoch 5\n15: 1 batches\n1 Start Epoch 5\n11 Start Epoch 5\n11: 1 batches\n1: 1 batches\n12 Start Epoch 5\n14 Start Epoch 5\n12: 1 batches\n14: 1 batches\n13 Start Epoch 5\n13: 1 batches\n10 Start Epoch 5\n10: 1 batches\n9 Start Epoch 5\n9: 1 batches\n3 Start Epoch 5\n3: 1 batches\n8 Start Epoch 5\n4 Start Epoch 5\n4: 1 batches\n8: 1 batches\n6 Start Epoch 5\n5 Start Epoch 5\n5: 1 batches\n7 Start Epoch 5\n6: 1 batches\n7: 1 batches\n2 Start Epoch 5\n2: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:13: Epoch 0 train loss: 3555.058349609375\nINFO:root:12: Epoch 0 train loss: 7587.37548828125\nINFO:root:11: Epoch 0 train loss: 267.9368896484375\nINFO:root:15: Epoch 0 train loss: 1423.7528076171875\nINFO:root:8: Epoch 0 train loss: 751.1183471679688\nINFO:root:14: Epoch 0 train loss: 7336.4345703125\nINFO:root:9: Epoch 0 train loss: 995291.6875\nINFO:root:10: Epoch 0 train loss: 272.5477600097656\nINFO:root:16: Epoch 0 train loss: 2779.104736328125\nINFO:root:17: Epoch 0 train loss: 161.47291564941406\nINFO:root:4: Epoch 0 train loss: 1291.2816162109375\nINFO:root:35: Epoch 0 train loss: 34538.28125\nINFO:root:6: Epoch 0 train loss: 557.3109130859375\nINFO:root:5: Epoch 0 train loss: 19110.341796875\nINFO:root:30: Epoch 0 train loss: 34182.65625\nINFO:root:38: Epoch 0 train loss: 1031965.75\nINFO:root:29: Epoch 0 train loss: 2250.634033203125\nINFO:root:37: Epoch 0 train loss: 785.3431396484375\nINFO:root:21: Epoch 0 train loss: 880.92138671875\nINFO:root:31: Epoch 0 train loss: 1091694.75\nINFO:root:34: Epoch 0 train loss: 13786.87890625\nINFO:root:39: Epoch 0 train loss: 23128.4140625\nINFO:root:18: Epoch 0 train loss: 1078453.125\nINFO:root:0: Epoch 0 train loss: 2463.686767578125\nINFO:root:36: Epoch 0 train loss: 733.2037963867188\nINFO:root:46: Epoch 0 train loss: 350525.40625\nINFO:root:1: Epoch 0 train loss: 10827.724609375\nINFO:root:19: Epoch 0 train loss: 2938.851806640625\nINFO:root:43: Epoch 0 train loss: 890787.1875\nINFO:root:24: Epoch 0 train loss: 1535.4296875\nINFO:root:20: Epoch 0 train loss: 3875.796875\nINFO:root:47: Epoch 0 train loss: 3650.757568359375\nINFO:root:40: Epoch 0 train loss: 947.259521484375\nINFO:root:25: Epoch 0 train loss: 348995.1875\nINFO:root:33: Epoch 0 train loss: 838752.6875\nINFO:root:44: Epoch 0 train loss: 1956.7554931640625\nINFO:root:41: Epoch 0 train loss: 5305.822265625\nINFO:root:45: Epoch 0 train loss: 6242.4990234375\nINFO:root:42: Epoch 0 train loss: 226.76222229003906\nINFO:root:7: Epoch 0 train loss: 6614.66064453125\nINFO:root:26: Epoch 0 train loss: 1336.6396484375\nINFO:root:22: Epoch 0 train loss: 2454.9453125\nINFO:root:2: Epoch 0 train loss: 2313.571044921875\nINFO:root:32: Epoch 0 train loss: 878.9335327148438\nINFO:root:28: Epoch 0 train loss: 560.6941528320312\nINFO:root:27: Epoch 0 train loss: 1374982.125\nINFO:root:23: Epoch 0 train loss: 320.8179931640625\nINFO:root:3: Epoch 0 train loss: 2548.074462890625\nINFO:root:0: Epoch 0 validation loss: 248458.73669303954\nINFO:root:0: Epoch 1 train loss: 224.9698486328125\nINFO:root:47: Epoch 1 train loss: 1068292.25\nINFO:root:45: Epoch 1 train loss: 2266813.75\nINFO:root:46: Epoch 1 train loss: 839409.5625\nINFO:root:15: Epoch 1 train loss: 1342477.875\nINFO:root:7: Epoch 1 train loss: 10344.2470703125\nINFO:root:43: Epoch 1 train loss: 919.1451416015625\nINFO:root:41: Epoch 1 train loss: 9764.228515625\nINFO:root:1: Epoch 1 train loss: 8938.4599609375\nINFO:root:42: Epoch 1 train loss: 21456.955078125\nINFO:root:30: Epoch 1 train loss: 2919.972900390625\nINFO:root:39: Epoch 1 train loss: 23181.9375\nINFO:root:17: Epoch 1 train loss: 3190.61572265625\nINFO:root:26: Epoch 1 train loss: 7713.17724609375\nINFO:root:12: Epoch 1 train loss: 2742.171875\nINFO:root:3: Epoch 1 train loss: 5615.98876953125\nINFO:root:11: Epoch 1 train loss: 924.2030639648438\nINFO:root:21: Epoch 1 train loss: 1576.11865234375\nINFO:root:36: Epoch 1 train loss: 332.9367980957031\nINFO:root:16: Epoch 1 train loss: 21774.24609375\nINFO:root:25: Epoch 1 train loss: 1256538.5\nINFO:root:6: Epoch 1 train loss: 1239541.375\nINFO:root:14: Epoch 1 train loss: 216.89675903320312\nINFO:root:8: Epoch 1 train loss: 891198.0\nINFO:root:23: Epoch 1 train loss: 3313.317138671875\nINFO:root:31: Epoch 1 train loss: 418.427978515625\nINFO:root:35: Epoch 1 train loss: 1068289.75\nINFO:root:27: Epoch 1 train loss: 988.2048950195312\nINFO:root:4: Epoch 1 train loss: 7694.9736328125\nINFO:root:13: Epoch 1 train loss: 19973.626953125\nINFO:root:9: Epoch 1 train loss: 360013.59375\nINFO:root:22: Epoch 1 train loss: 1021.9835205078125\nINFO:root:28: Epoch 1 train loss: 6902.70361328125\nINFO:root:32: Epoch 1 train loss: 1477.6644287109375\nINFO:root:5: Epoch 1 train loss: 2218.368896484375\nINFO:root:29: Epoch 1 train loss: 885806.1875\nINFO:root:44: Epoch 1 train loss: 167.97499084472656\nINFO:root:18: Epoch 1 train loss: 1254370.875\nINFO:root:2: Epoch 1 train loss: 4825.20166015625\nINFO:root:40: Epoch 1 train loss: 4137.9638671875\nINFO:root:10: Epoch 1 train loss: 1034579.6875\nINFO:root:34: Epoch 1 train loss: 19295.66796875\nINFO:root:38: Epoch 1 train loss: 1814.8682861328125\nINFO:root:24: Epoch 1 train loss: 8180.86865234375\nINFO:root:37: Epoch 1 train loss: 893979.375\nINFO:root:33: Epoch 1 train loss: 10997.681640625\nINFO:root:20: Epoch 1 train loss: 2709.242431640625\nINFO:root:19: Epoch 1 train loss: 774.461181640625\nINFO:root:0: Epoch 1 validation loss: 248452.87441425648\nINFO:root:14: Epoch 2 train loss: 5050.123046875\nINFO:root:13: Epoch 2 train loss: 36720.6015625\nINFO:root:15: Epoch 2 train loss: 815.6067504882812\nINFO:root:0: Epoch 2 train loss: 10833.9912109375\nINFO:root:1: Epoch 2 train loss: 1040294.375\nINFO:root:38: Epoch 2 train loss: 16836.47265625\nINFO:root:43: Epoch 2 train loss: 11134.1171875\nINFO:root:5: Epoch 2 train loss: 464.46734619140625\nINFO:root:29: Epoch 2 train loss: 1077.9013671875\nINFO:root:35: Epoch 2 train loss: 2293.6083984375\nINFO:root:37: Epoch 2 train loss: 761.9263305664062\nINFO:root:2: Epoch 2 train loss: 335.939453125\nINFO:root:47: Epoch 2 train loss: 1238152.5\nINFO:root:19: Epoch 2 train loss: 15235.9189453125\nINFO:root:42: Epoch 2 train loss: 9753.666015625\nINFO:root:24: Epoch 2 train loss: 1153.88232421875\nINFO:root:11: Epoch 2 train loss: 1932.4110107421875\nINFO:root:21: Epoch 2 train loss: 4780.3173828125\nINFO:root:16: Epoch 2 train loss: 215.3017120361328\nINFO:root:3: Epoch 2 train loss: 4896.72705078125\nINFO:root:41: Epoch 2 train loss: 349005.9375\nINFO:root:26: Epoch 2 train loss: 16054.98046875\nINFO:root:10: Epoch 2 train loss: 1567.324462890625\nINFO:root:22: Epoch 2 train loss: 1144893.375\nINFO:root:30: Epoch 2 train loss: 11238.7060546875\nINFO:root:34: Epoch 2 train loss: 1256932.625\nINFO:root:39: Epoch 2 train loss: 1188164.0\nINFO:root:44: Epoch 2 train loss: 2089.884033203125\nINFO:root:45: Epoch 2 train loss: 2009.1058349609375\nINFO:root:18: Epoch 2 train loss: 14257.6259765625\nINFO:root:25: Epoch 2 train loss: 119844.71875\nINFO:root:6: Epoch 2 train loss: 245.1829071044922\nINFO:root:12: Epoch 2 train loss: 826.2772216796875\nINFO:root:9: Epoch 2 train loss: 3654.71142578125\nINFO:root:23: Epoch 2 train loss: 219.7650909423828\nINFO:root:31: Epoch 2 train loss: 3347.17724609375\nINFO:root:32: Epoch 2 train loss: 130843.1328125\nINFO:root:28: Epoch 2 train loss: 116613.3203125\nINFO:root:33: Epoch 2 train loss: 2264.497802734375\nINFO:root:17: Epoch 2 train loss: 3919.859619140625\nINFO:root:27: Epoch 2 train loss: 28556.388671875\nINFO:root:4: Epoch 2 train loss: 2950.856689453125\nINFO:root:46: Epoch 2 train loss: 1527.43408203125\nINFO:root:36: Epoch 2 train loss: 1394.763427734375\nINFO:root:40: Epoch 2 train loss: 8367.9833984375\nINFO:root:7: Epoch 2 train loss: 141.8631591796875\nINFO:root:8: Epoch 2 train loss: 1117845.125\nINFO:root:20: Epoch 2 train loss: 1121.4384765625\nINFO:root:0: Epoch 2 validation loss: 248446.95153013174\nINFO:root:37: Epoch 3 train loss: 5262.9775390625\nINFO:root:36: Epoch 3 train loss: 3732.76611328125\nINFO:root:29: Epoch 3 train loss: 281.15704345703125\nINFO:root:30: Epoch 3 train loss: 206.26364135742188\nINFO:root:31: Epoch 3 train loss: 889284.5625\nINFO:root:43: Epoch 3 train loss: 662.686767578125\nINFO:root:41: Epoch 3 train loss: 403.5819396972656\nINFO:root:1: Epoch 3 train loss: 9764.814453125\nINFO:root:46: Epoch 3 train loss: 1239138.625\nINFO:root:33: Epoch 3 train loss: 5027.482421875\nINFO:root:35: Epoch 3 train loss: 411.1810607910156\nINFO:root:45: Epoch 3 train loss: 19461.35546875\nINFO:root:34: Epoch 3 train loss: 9840.6455078125\nINFO:root:47: Epoch 3 train loss: 1118608.625\nINFO:root:32: Epoch 3 train loss: 348.46307373046875\nINFO:root:38: Epoch 3 train loss: 2459.0595703125\nINFO:root:44: Epoch 3 train loss: 15718.6484375\nINFO:root:0: Epoch 3 train loss: 7115.47021484375\nINFO:root:42: Epoch 3 train loss: 7437.875\nINFO:root:39: Epoch 3 train loss: 3747.855712890625\nINFO:root:28: Epoch 3 train loss: 4027.888916015625\nINFO:root:27: Epoch 3 train loss: 1235546.75\nINFO:root:40: Epoch 3 train loss: 1236999.375\nINFO:root:14: Epoch 3 train loss: 1219.0543212890625\nINFO:root:7: Epoch 3 train loss: 1231.73876953125\nINFO:root:2: Epoch 3 train loss: 483.600341796875\nINFO:root:13: Epoch 3 train loss: 5853.65185546875\nINFO:root:15: Epoch 3 train loss: 6868.87744140625\nINFO:root:9: Epoch 3 train loss: 4397.716796875\nINFO:root:17: Epoch 3 train loss: 664.157470703125\nINFO:root:8: Epoch 3 train loss: 1614.29443359375\nINFO:root:10: Epoch 3 train loss: 579.3802490234375\nINFO:root:18: Epoch 3 train loss: 1422.4385986328125\nINFO:root:21: Epoch 3 train loss: 610.7906494140625\nINFO:root:22: Epoch 3 train loss: 1268.2552490234375\nINFO:root:23: Epoch 3 train loss: 2697.389404296875\nINFO:root:16: Epoch 3 train loss: 800.1585693359375\nINFO:root:24: Epoch 3 train loss: 3090.392578125\nINFO:root:19: Epoch 3 train loss: 304.9354248046875\nINFO:root:11: Epoch 3 train loss: 5301.47900390625\nINFO:root:20: Epoch 3 train loss: 764.8554077148438\nINFO:root:3: Epoch 3 train loss: 39339.86328125\nINFO:root:26: Epoch 3 train loss: 2475.53564453125\nINFO:root:5: Epoch 3 train loss: 390.27130126953125\nINFO:root:4: Epoch 3 train loss: 1164.9039306640625\nINFO:root:12: Epoch 3 train loss: 33.85898208618164\nINFO:root:6: Epoch 3 train loss: 604.0997314453125\nINFO:root:25: Epoch 3 train loss: 3491.435302734375\nINFO:root:0: Epoch 3 validation loss: 248441.290087645\nINFO:root:35: Epoch 4 train loss: 849322.1875\nINFO:root:32: Epoch 4 train loss: 2493.872802734375\nINFO:root:34: Epoch 4 train loss: 2014.871826171875\nINFO:root:33: Epoch 4 train loss: 121111.5390625\nINFO:root:46: Epoch 4 train loss: 21837.9609375\nINFO:root:47: Epoch 4 train loss: 3175.4521484375\nINFO:root:44: Epoch 4 train loss: 3328.006103515625\nINFO:root:39: Epoch 4 train loss: 3851.26318359375\nINFO:root:19: Epoch 4 train loss: 345.8982238769531\nINFO:root:37: Epoch 4 train loss: 3210.80908203125\nINFO:root:31: Epoch 4 train loss: 897.707763671875\nINFO:root:38: Epoch 4 train loss: 704.772216796875\nINFO:root:25: Epoch 4 train loss: 2488.025634765625\nINFO:root:22: Epoch 4 train loss: 25344.3203125\nINFO:root:28: Epoch 4 train loss: 7214.57568359375\nINFO:root:36: Epoch 4 train loss: 7499.74267578125\nINFO:root:45: Epoch 4 train loss: 889919.75\nINFO:root:27: Epoch 4 train loss: 4608.8583984375\nINFO:root:23: Epoch 4 train loss: 1894.4864501953125\nINFO:root:29: Epoch 4 train loss: 2523.573974609375\nINFO:root:24: Epoch 4 train loss: 3210.560791015625\nINFO:root:30: Epoch 4 train loss: 1749.9207763671875\nINFO:root:40: Epoch 4 train loss: 5123.9189453125\nINFO:root:18: Epoch 4 train loss: 4950.1083984375\nINFO:root:41: Epoch 4 train loss: 4786.67724609375\nINFO:root:42: Epoch 4 train loss: 25432.572265625\nINFO:root:20: Epoch 4 train loss: 12992.1552734375\nINFO:root:26: Epoch 4 train loss: 13945.10546875\nINFO:root:43: Epoch 4 train loss: 353196.0625\nINFO:root:17: Epoch 4 train loss: 503.4822692871094\nINFO:root:21: Epoch 4 train loss: 123.74076080322266\nINFO:root:16: Epoch 4 train loss: 1033920.375\nINFO:root:15: Epoch 4 train loss: 6286.14599609375\nINFO:root:0: Epoch 4 train loss: 684.5042724609375\nINFO:root:1: Epoch 4 train loss: 4340.74560546875\nINFO:root:11: Epoch 4 train loss: 14169.568359375\nINFO:root:12: Epoch 4 train loss: 3248.06494140625\nINFO:root:14: Epoch 4 train loss: 5420.646484375\nINFO:root:13: Epoch 4 train loss: 3308.042724609375\nINFO:root:10: Epoch 4 train loss: 1136.7333984375\nINFO:root:9: Epoch 4 train loss: 509.1239929199219\nINFO:root:3: Epoch 4 train loss: 802.30322265625\nINFO:root:4: Epoch 4 train loss: 6557.62939453125\nINFO:root:8: Epoch 4 train loss: 12463.4365234375\nINFO:root:6: Epoch 4 train loss: 2147.96923828125\nINFO:root:5: Epoch 4 train loss: 7377.18212890625\nINFO:root:7: Epoch 4 train loss: 1253.981201171875\nINFO:root:2: Epoch 4 train loss: 25.41358184814453\nINFO:root:0: Epoch 4 validation loss: 248435.58831251762\nINFO:root:15: Epoch 5 train loss: 9564.037109375\nINFO:root:7: Epoch 5 train loss: 842.2415771484375\nINFO:root:14: Epoch 5 train loss: 2065.083984375\nINFO:root:9: Epoch 5 train loss: 6324.21142578125\nINFO:root:23: Epoch 5 train loss: 838550.0625\nINFO:root:4: Epoch 5 train loss: 1849.2684326171875\nINFO:root:10: Epoch 5 train loss: 1587459.75\nINFO:root:8: Epoch 5 train loss: 3186.7236328125\nINFO:root:11: Epoch 5 train loss: 25086.220703125\nINFO:root:20: Epoch 5 train loss: 6336.287109375\nINFO:root:22: Epoch 5 train loss: 685.9511108398438\nINFO:root:21: Epoch 5 train loss: 217.3475341796875\nINFO:root:12: Epoch 5 train loss: 949.5690307617188\nINFO:root:47: Epoch 5 train loss: 1895212.5\nINFO:root:44: Epoch 5 train loss: 22418.859375\nINFO:root:45: Epoch 5 train loss: 12965.435546875\nINFO:root:46: Epoch 5 train loss: 1278.268310546875\nINFO:root:17: Epoch 5 train loss: 9491.6572265625\nINFO:root:25: Epoch 5 train loss: 112.12801361083984\nINFO:root:29: Epoch 5 train loss: 2645.733154296875\nINFO:root:33: Epoch 5 train loss: 9385.8359375\nINFO:root:30: Epoch 5 train loss: 6408.109375\nINFO:root:35: Epoch 5 train loss: 7683.93701171875\nINFO:root:36: Epoch 5 train loss: 8942.087890625\nINFO:root:19: Epoch 5 train loss: 6363.7431640625\nINFO:root:26: Epoch 5 train loss: 1328.292724609375\nINFO:root:34: Epoch 5 train loss: 21561.119140625\nINFO:root:38: Epoch 5 train loss: 1242929.625\nINFO:root:27: Epoch 5 train loss: 5177.55517578125\nINFO:root:32: Epoch 5 train loss: 733.9432983398438\nINFO:root:37: Epoch 5 train loss: 661.9591674804688\nINFO:root:2: Epoch 5 train loss: 1531.5006103515625\nINFO:root:28: Epoch 5 train loss: 79.90679931640625\nINFO:root:16: Epoch 5 train loss: 7688.53125\nINFO:root:41: Epoch 5 train loss: 35465.31640625\nINFO:root:42: Epoch 5 train loss: 4387.54736328125\nINFO:root:3: Epoch 5 train loss: 261.1248779296875\nINFO:root:0: Epoch 5 train loss: 19056.375\nINFO:root:31: Epoch 5 train loss: 20197.3203125\nINFO:root:18: Epoch 5 train loss: 9560.9599609375\nINFO:root:24: Epoch 5 train loss: 1969.7447509765625\nINFO:root:6: Epoch 5 train loss: 6161.11669921875\nINFO:root:13: Epoch 5 train loss: 4186.2744140625\nINFO:root:5: Epoch 5 train loss: 72.56310272216797\nINFO:root:1: Epoch 5 train loss: 349723.0\nINFO:root:43: Epoch 5 train loss: 4233.88232421875\nINFO:root:39: Epoch 5 train loss: 1246573.875\nINFO:root:40: Epoch 5 train loss: 7705.60595703125\nINFO:root:0: Epoch 5 validation loss: 248429.87354235613\n", "seconds": 11.598177909851074, "batch_size": 128, "nodes": 12, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 12 batches\n0 Start Epoch 1\n0: 12 batches\n0 Start Epoch 2\n0: 12 batches\n0 Start Epoch 3\n0: 12 batches\n0 Start Epoch 4\n0: 12 batches\n0 Start Epoch 5\n0: 12 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 70154.89065551758\nINFO:root:0: Epoch 0 validation loss: 338099191.12721086\nINFO:root:0: Epoch 1 train loss: 67632.4547551473\nINFO:root:0: Epoch 1 validation loss: 338097979.7200863\nINFO:root:0: Epoch 2 train loss: 67501.31224060059\nINFO:root:0: Epoch 2 validation loss: 338095754.2517826\nINFO:root:0: Epoch 3 train loss: 70202.61498006184\nINFO:root:0: Epoch 3 validation loss: 338091475.9831981\nINFO:root:0: Epoch 4 train loss: 67745.32087198894\nINFO:root:0: Epoch 4 validation loss: 338084589.04697496\nINFO:root:0: Epoch 5 train loss: 75157.78017171223\nINFO:root:0: Epoch 5 validation loss: 338077597.27884173\n", "seconds": 8.01826000213623, "batch_size": 256, "nodes": 1, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 6 batches\n1 Start Epoch 0\n1: 6 batches\n1 Start Epoch 1\n1: 6 batches\n0 Start Epoch 1\n0: 6 batches\n1 Start Epoch 2\n1: 6 batches\n0 Start Epoch 2\n0: 6 batches\n1 Start Epoch 3\n1: 6 batches\n0 Start Epoch 3\n0: 6 batches\n1 Start Epoch 4\n1: 6 batches\n0 Start Epoch 4\n0: 6 batches\n1 Start Epoch 5\n1: 6 batches\n0 Start Epoch 5\n0: 6 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 77344.28006998698\nINFO:root:1: Epoch 0 train loss: 48666.13755289713\nINFO:root:0: Epoch 0 validation loss: 62747.899881895886\nINFO:root:0: Epoch 1 train loss: 97805.61673990886\nINFO:root:1: Epoch 1 train loss: 53286.59045410156\nINFO:root:0: Epoch 1 validation loss: 62730.61104534043\nINFO:root:0: Epoch 2 train loss: 69973.66975911458\nINFO:root:1: Epoch 2 train loss: 135643.9135538737\nINFO:root:0: Epoch 2 validation loss: 62712.74439765182\nINFO:root:0: Epoch 3 train loss: 54153.38535563151\nINFO:root:1: Epoch 3 train loss: 74532.81612904866\nINFO:root:0: Epoch 3 validation loss: 62692.80033006426\nINFO:root:0: Epoch 4 train loss: 27898.90041097005\nINFO:root:1: Epoch 4 train loss: 68751.4798482259\nINFO:root:0: Epoch 4 validation loss: 62666.38767620449\nINFO:root:0: Epoch 5 train loss: 94487.76880900066\nINFO:root:1: Epoch 5 train loss: 69708.32713826497\nINFO:root:0: Epoch 5 validation loss: 62629.88687063252\n", "seconds": 5.2740561962127686, "batch_size": 256, "nodes": 2, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 4 batches\n2 Start Epoch 0\n1 Start Epoch 0\n2: 4 batches\n1: 4 batches\n1 Start Epoch 1\n1: 4 batches\n2 Start Epoch 1\n2: 4 batches\n0 Start Epoch 1\n0: 4 batches\n1 Start Epoch 2\n1: 4 batches\n2 Start Epoch 2\n2: 4 batches\n0 Start Epoch 2\n0: 4 batches\n1 Start Epoch 3\n1: 4 batches\n2 Start Epoch 3\n2: 4 batches\n0 Start Epoch 3\n0: 4 batches\n1 Start Epoch 4\n1: 4 batches\n2 Start Epoch 4\n2: 4 batches\n0 Start Epoch 4\n0: 4 batches\n2 Start Epoch 5\n1 Start Epoch 5\n1: 4 batches\n2: 4 batches\n0 Start Epoch 5\n0: 4 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:1: Epoch 0 train loss: 70093.27847290039\nINFO:root:2: Epoch 0 train loss: 38431.20361328125\nINFO:root:0: Epoch 0 train loss: 7021.388336181641\nINFO:root:0: Epoch 0 validation loss: 1202894.2631613226\nINFO:root:1: Epoch 1 train loss: 142328.7490234375\nINFO:root:0: Epoch 1 train loss: 95123.52307128906\nINFO:root:2: Epoch 1 train loss: 129597.36352539062\nINFO:root:0: Epoch 1 validation loss: 1202849.2917831128\nINFO:root:1: Epoch 2 train loss: 97365.85632324219\nINFO:root:0: Epoch 2 train loss: 63447.15540313721\nINFO:root:2: Epoch 2 train loss: 132054.31829833984\nINFO:root:0: Epoch 2 validation loss: 1202800.203249948\nINFO:root:0: Epoch 3 train loss: 29671.007064819336\nINFO:root:1: Epoch 3 train loss: 71315.72326660156\nINFO:root:2: Epoch 3 train loss: 72287.56378173828\nINFO:root:0: Epoch 3 validation loss: 1202742.6699446763\nINFO:root:0: Epoch 4 train loss: 102294.43920898438\nINFO:root:1: Epoch 4 train loss: 137372.70358276367\nINFO:root:2: Epoch 4 train loss: 36930.214904785156\nINFO:root:0: Epoch 4 validation loss: 1202671.7313214438\nINFO:root:0: Epoch 5 train loss: 13505.497619628906\nINFO:root:2: Epoch 5 train loss: 70652.23818969727\nINFO:root:1: Epoch 5 train loss: 42842.58270263672\nINFO:root:0: Epoch 5 validation loss: 1202581.7398664064\n", "seconds": 6.601052761077881, "batch_size": 256, "nodes": 3, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 3 batches\n3 Start Epoch 0\n3: 3 batches\n1 Start Epoch 0\n1: 3 batches\n2 Start Epoch 0\n2: 3 batches\n2 Start Epoch 1\n2: 3 batches\n3 Start Epoch 1\n3: 3 batches\n1 Start Epoch 1\n1: 3 batches\n0 Start Epoch 1\n0: 3 batches\n2 Start Epoch 2\n3 Start Epoch 2\n3: 3 batches\n2: 3 batches\n1 Start Epoch 2\n1: 3 batches\n0 Start Epoch 2\n0: 3 batches\n2 Start Epoch 3\n2: 3 batches\n3 Start Epoch 3\n3: 3 batches\n1 Start Epoch 3\n1: 3 batches\n0 Start Epoch 3\n0: 3 batches\n2 Start Epoch 4\n3 Start Epoch 4\n2: 3 batches\n3: 3 batches\n1 Start Epoch 4\n1: 3 batches\n0 Start Epoch 4\n0: 3 batches\n3 Start Epoch 5\n3: 3 batches\n2 Start Epoch 5\n2: 3 batches\n1 Start Epoch 5\n1: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 48491.4150390625\nINFO:root:2: Epoch 0 train loss: 91356.67236328125\nINFO:root:3: Epoch 0 train loss: 93833.15698242188\nINFO:root:1: Epoch 0 train loss: 93706.18017578125\nINFO:root:0: Epoch 0 validation loss: 47681.734366158475\nINFO:root:0: Epoch 1 train loss: 1985.9534708658855\nINFO:root:2: Epoch 1 train loss: 78515.07739257812\nINFO:root:3: Epoch 1 train loss: 142350.63053385416\nINFO:root:1: Epoch 1 train loss: 82267.70572916667\nINFO:root:0: Epoch 1 validation loss: 47674.38463212136\nINFO:root:2: Epoch 2 train loss: 93925.70446777344\nINFO:root:0: Epoch 2 train loss: 81675.8003133138\nINFO:root:3: Epoch 2 train loss: 52625.20947265625\nINFO:root:1: Epoch 2 train loss: 133019.42537434897\nINFO:root:0: Epoch 2 validation loss: 47666.64498292117\nINFO:root:2: Epoch 3 train loss: 98315.482421875\nINFO:root:3: Epoch 3 train loss: 94249.45247395833\nINFO:root:1: Epoch 3 train loss: 15158.08984375\nINFO:root:0: Epoch 3 train loss: 57143.138509114586\nINFO:root:0: Epoch 3 validation loss: 47658.53711758243\nINFO:root:3: Epoch 4 train loss: 80552.8125\nINFO:root:2: Epoch 4 train loss: 3117.1812947591147\nINFO:root:0: Epoch 4 train loss: 59977.099934895836\nINFO:root:1: Epoch 4 train loss: 92527.05908203125\nINFO:root:0: Epoch 4 validation loss: 47649.649041324294\nINFO:root:2: Epoch 5 train loss: 44729.04728190104\nINFO:root:3: Epoch 5 train loss: 18034.533447265625\nINFO:root:0: Epoch 5 train loss: 43668.62833658854\nINFO:root:1: Epoch 5 train loss: 93756.49235026042\nINFO:root:0: Epoch 5 validation loss: 47639.71132946211\n", "seconds": 5.888868093490601, "batch_size": 256, "nodes": 4, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 3 batches\n2 Start Epoch 0\n1 Start Epoch 0\n4 Start Epoch 0\n2: 3 batches\n3 Start Epoch 0\n4: 3 batches\n1: 3 batches\n3: 3 batches\n4 Start Epoch 1\n1 Start Epoch 1\n2 Start Epoch 1\n3 Start Epoch 1\n2: 3 batches\n3: 3 batches\n4: 3 batches\n1: 3 batches\n0 Start Epoch 1\n0: 3 batches\n2 Start Epoch 2\n3 Start Epoch 2\n1 Start Epoch 2\n1: 3 batches\n2: 3 batches\n3: 3 batches\n4 Start Epoch 2\n4: 3 batches\n0 Start Epoch 2\n0: 3 batches\n2 Start Epoch 3\n2: 3 batches\n4 Start Epoch 3\n4: 3 batches\n1 Start Epoch 3\n1: 3 batches\n3 Start Epoch 3\n3: 3 batches\n0 Start Epoch 3\n0: 3 batches\n1 Start Epoch 4\n2 Start Epoch 4\n3 Start Epoch 4\n1: 3 batches\n2: 3 batches\n3: 3 batches\n4 Start Epoch 4\n4: 3 batches\n0 Start Epoch 4\n0: 3 batches\n1 Start Epoch 5\n3 Start Epoch 5\n1: 3 batches\n3: 3 batches\n4 Start Epoch 5\n4: 3 batches\n2 Start Epoch 5\n2: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 127778.50487263997\nINFO:root:1: Epoch 0 train loss: 180591.1105143229\nINFO:root:2: Epoch 0 train loss: 90017.33968098958\nINFO:root:3: Epoch 0 train loss: 53523.64070638021\nINFO:root:4: Epoch 0 train loss: 8023.4411214192705\nINFO:root:0: Epoch 0 validation loss: 13122.685137579154\nINFO:root:2: Epoch 1 train loss: 101528.12068684895\nINFO:root:3: Epoch 1 train loss: 204713.9130859375\nINFO:root:1: Epoch 1 train loss: 79125.66298421223\nINFO:root:4: Epoch 1 train loss: 45762.553955078125\nINFO:root:0: Epoch 1 train loss: 192126.4269205729\nINFO:root:0: Epoch 1 validation loss: 13118.130144290626\nINFO:root:2: Epoch 2 train loss: 6358.7166748046875\nINFO:root:4: Epoch 2 train loss: 1934.5624593098958\nINFO:root:0: Epoch 2 train loss: 97099.0410970052\nINFO:root:1: Epoch 2 train loss: 42338.05916341146\nINFO:root:3: Epoch 2 train loss: 45198.827209472656\nINFO:root:0: Epoch 2 validation loss: 13113.52573273922\nINFO:root:1: Epoch 3 train loss: 121295.67803955078\nINFO:root:2: Epoch 3 train loss: 50494.230448404945\nINFO:root:3: Epoch 3 train loss: 15949.6396484375\nINFO:root:4: Epoch 3 train loss: 3385.2215169270835\nINFO:root:0: Epoch 3 train loss: 96403.71493530273\nINFO:root:0: Epoch 3 validation loss: 13108.723019480192\nINFO:root:3: Epoch 4 train loss: 57625.40665690104\nINFO:root:1: Epoch 4 train loss: 108817.54300944011\nINFO:root:0: Epoch 4 train loss: 37499.636322021484\nINFO:root:4: Epoch 4 train loss: 44032.45233154297\nINFO:root:2: Epoch 4 train loss: 775.0207939147949\nINFO:root:0: Epoch 4 validation loss: 13103.530535137344\nINFO:root:4: Epoch 5 train loss: 1865.8263549804688\nINFO:root:3: Epoch 5 train loss: 166605.16064453125\nINFO:root:1: Epoch 5 train loss: 37825.13293457031\nINFO:root:2: Epoch 5 train loss: 273408.6302083333\nINFO:root:0: Epoch 5 train loss: 128915.0673828125\nINFO:root:0: Epoch 5 validation loss: 13098.085444364055\n", "seconds": 9.858949184417725, "batch_size": 256, "nodes": 5, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "5 Start Epoch 0\n5: 2 batches\n4 Start Epoch 0\n4: 2 batches\n2 Start Epoch 0\n2: 2 batches\n0 Start Epoch 0\n0: 2 batches\n1 Start Epoch 0\n3 Start Epoch 0\n1: 2 batches\n3: 2 batches\n2 Start Epoch 1\n3 Start Epoch 1\n1 Start Epoch 1\n1: 2 batches\n2: 2 batches\n3: 2 batches\n5 Start Epoch 1\n5: 2 batches\n4 Start Epoch 1\n4: 2 batches\n0 Start Epoch 1\n0: 2 batches\n1 Start Epoch 2\n1: 2 batches\n3 Start Epoch 2\n3: 2 batches\n2 Start Epoch 2\n2: 2 batches\n5 Start Epoch 2\n5: 2 batches\n4 Start Epoch 2\n4: 2 batches\n0 Start Epoch 2\n0: 2 batches\n3 Start Epoch 3\n2 Start Epoch 3\n2: 2 batches\n3: 2 batches\n5 Start Epoch 3\n1 Start Epoch 3\n5: 2 batches\n1: 2 batches\n4 Start Epoch 3\n4: 2 batches\n0 Start Epoch 3\n0: 2 batches\n2 Start Epoch 4\n2: 2 batches\n3 Start Epoch 4\n3: 2 batches\n5 Start Epoch 4\n1 Start Epoch 4\n5: 2 batches\n1: 2 batches\n4 Start Epoch 4\n4: 2 batches\n0 Start Epoch 4\n0: 2 batches\n2 Start Epoch 5\n3 Start Epoch 5\n2: 2 batches\n3: 2 batches\n5 Start Epoch 5\n1 Start Epoch 5\n5: 2 batches\n1: 2 batches\n4 Start Epoch 5\n4: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:2: Epoch 0 train loss: 1389.3663330078125\nINFO:root:3: Epoch 0 train loss: 115888.43408203125\nINFO:root:1: Epoch 0 train loss: 65609.91912841797\nINFO:root:0: Epoch 0 train loss: 61935.49871826172\nINFO:root:5: Epoch 0 train loss: 82477.037109375\nINFO:root:4: Epoch 0 train loss: 9693.13134765625\nINFO:root:0: Epoch 0 validation loss: 422.11602367243154\nINFO:root:1: Epoch 1 train loss: 56274.2978515625\nINFO:root:3: Epoch 1 train loss: 120677.87109375\nINFO:root:2: Epoch 1 train loss: 126307.0625\nINFO:root:0: Epoch 1 train loss: 2952.06884765625\nINFO:root:5: Epoch 1 train loss: 26316.898193359375\nINFO:root:4: Epoch 1 train loss: 96705.34765625\nINFO:root:0: Epoch 1 validation loss: 421.5455053741252\nINFO:root:3: Epoch 2 train loss: 58447.3701171875\nINFO:root:2: Epoch 2 train loss: 77353.66882324219\nINFO:root:0: Epoch 2 train loss: 8876.125\nINFO:root:5: Epoch 2 train loss: 2005.7564697265625\nINFO:root:1: Epoch 2 train loss: 2298.8961791992188\nINFO:root:4: Epoch 2 train loss: 1961.9959716796875\nINFO:root:0: Epoch 2 validation loss: 420.9680130209218\nINFO:root:2: Epoch 3 train loss: 140130.3408203125\nINFO:root:3: Epoch 3 train loss: 140340.0751953125\nINFO:root:0: Epoch 3 train loss: 268084.40234375\nINFO:root:1: Epoch 3 train loss: 72274.99926757812\nINFO:root:5: Epoch 3 train loss: 74471.66082763672\nINFO:root:4: Epoch 3 train loss: 1016.4011383056641\nINFO:root:0: Epoch 3 validation loss: 420.3749903679127\nINFO:root:3: Epoch 4 train loss: 134847.00439453125\nINFO:root:2: Epoch 4 train loss: 5177.06884765625\nINFO:root:5: Epoch 4 train loss: 76233.59033203125\nINFO:root:1: Epoch 4 train loss: 67246.98266601562\nINFO:root:0: Epoch 4 train loss: 184527.8046875\nINFO:root:4: Epoch 4 train loss: 76393.86486816406\nINFO:root:0: Epoch 4 validation loss: 419.76055720947875\nINFO:root:2: Epoch 5 train loss: 144321.603515625\nINFO:root:3: Epoch 5 train loss: 71348.0615234375\nINFO:root:5: Epoch 5 train loss: 136474.07421875\nINFO:root:0: Epoch 5 train loss: 124907.18676757812\nINFO:root:4: Epoch 5 train loss: 2196.79638671875\nINFO:root:1: Epoch 5 train loss: 77332.86511230469\nINFO:root:0: Epoch 5 validation loss: 419.1169497606762\n", "seconds": 6.483590841293335, "batch_size": 256, "nodes": 6, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n4 Start Epoch 0\n4: 2 batches\n2 Start Epoch 0\n6 Start Epoch 0\n1 Start Epoch 0\n3 Start Epoch 0\n2: 2 batches\n5 Start Epoch 0\n6: 2 batches\n1: 2 batches\n3: 2 batches\n5: 2 batches\n5 Start Epoch 1\n5: 2 batches\n1 Start Epoch 1\n3 Start Epoch 1\n2 Start Epoch 1\n3: 2 batches\n2: 2 batches\n1: 2 batches\n6 Start Epoch 1\n4 Start Epoch 1\n6: 2 batches\n4: 2 batches\n0 Start Epoch 1\n0: 2 batches\n2 Start Epoch 2\n1 Start Epoch 2\n3 Start Epoch 2\n2: 2 batches\n1: 2 batches\n3: 2 batches\n5 Start Epoch 2\n5: 2 batches\n4 Start Epoch 2\n6 Start Epoch 2\n4: 2 batches\n6: 2 batches\n0 Start Epoch 2\n0: 2 batches\n5 Start Epoch 3\n5: 2 batches\n2 Start Epoch 3\n1 Start Epoch 3\n3 Start Epoch 3\n1: 2 batches\n3: 2 batches\n2: 2 batches\n6 Start Epoch 3\n6: 2 batches\n4 Start Epoch 3\n4: 2 batches\n0 Start Epoch 3\n0: 2 batches\n5 Start Epoch 4\n5: 2 batches\n1 Start Epoch 4\n3 Start Epoch 4\n2 Start Epoch 4\n2: 2 batches\n1: 2 batches\n3: 2 batches\n4 Start Epoch 4\n6 Start Epoch 4\n6: 2 batches\n4: 2 batches\n0 Start Epoch 4\n0: 2 batches\n6 Start Epoch 5\n1 Start Epoch 5\n6: 2 batches\n1: 2 batches\n2 Start Epoch 5\n3 Start Epoch 5\n3: 2 batches\n4 Start Epoch 5\n2: 2 batches\n5 Start Epoch 5\n4: 2 batches\n5: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:5: Epoch 0 train loss: 2027.1349487304688\nINFO:root:2: Epoch 0 train loss: 66432.0830078125\nINFO:root:1: Epoch 0 train loss: 184109.390625\nINFO:root:3: Epoch 0 train loss: 239904.265625\nINFO:root:0: Epoch 0 train loss: 1207.9127197265625\nINFO:root:6: Epoch 0 train loss: 180050.96484375\nINFO:root:4: Epoch 0 train loss: 3133.79638671875\nINFO:root:0: Epoch 0 validation loss: 218682.68017123736\nINFO:root:2: Epoch 1 train loss: 5373.271240234375\nINFO:root:1: Epoch 1 train loss: 233840.57421875\nINFO:root:3: Epoch 1 train loss: 111721.765625\nINFO:root:5: Epoch 1 train loss: 119012.71484375\nINFO:root:4: Epoch 1 train loss: 220029.068359375\nINFO:root:6: Epoch 1 train loss: 69702.6314086914\nINFO:root:0: Epoch 1 train loss: 1857.4291076660156\nINFO:root:0: Epoch 1 validation loss: 218667.67459984194\nINFO:root:5: Epoch 2 train loss: 1428.7841491699219\nINFO:root:1: Epoch 2 train loss: 374604.07421875\nINFO:root:3: Epoch 2 train loss: 1329.714599609375\nINFO:root:2: Epoch 2 train loss: 9764.122192382812\nINFO:root:0: Epoch 2 train loss: 210901.6015625\nINFO:root:6: Epoch 2 train loss: 98550.3037109375\nINFO:root:4: Epoch 2 train loss: 52020.88116455078\nINFO:root:0: Epoch 2 validation loss: 218652.69886629976\nINFO:root:5: Epoch 3 train loss: 56076.673583984375\nINFO:root:2: Epoch 3 train loss: 1809.8017883300781\nINFO:root:1: Epoch 3 train loss: 69337.51254272461\nINFO:root:3: Epoch 3 train loss: 65865.14556884766\nINFO:root:0: Epoch 3 train loss: 96540.66375732422\nINFO:root:4: Epoch 3 train loss: 99998.35400390625\nINFO:root:6: Epoch 3 train loss: 73220.2807006836\nINFO:root:0: Epoch 3 validation loss: 218637.7958944111\nINFO:root:6: Epoch 4 train loss: 213792.40625\nINFO:root:1: Epoch 4 train loss: 188845.05206298828\nINFO:root:3: Epoch 4 train loss: 323807.15625\nINFO:root:2: Epoch 4 train loss: 122898.24755859375\nINFO:root:5: Epoch 4 train loss: 168482.125\nINFO:root:4: Epoch 4 train loss: 24245.81005859375\nINFO:root:0: Epoch 4 train loss: 2922.8038330078125\nINFO:root:0: Epoch 4 validation loss: 218622.580129171\nINFO:root:5: Epoch 5 train loss: 3264.814208984375\nINFO:root:2: Epoch 5 train loss: 1100.1965942382812\nINFO:root:6: Epoch 5 train loss: 38347.91369628906\nINFO:root:4: Epoch 5 train loss: 2415.74755859375\nINFO:root:0: Epoch 5 train loss: 98993.86267089844\nINFO:root:3: Epoch 5 train loss: 78819.94665527344\nINFO:root:1: Epoch 5 train loss: 34227.04461669922\nINFO:root:0: Epoch 5 validation loss: 218606.775404165\n", "seconds": 7.366760015487671, "batch_size": 256, "nodes": 7, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n7 Start Epoch 0\n7: 2 batches\n4 Start Epoch 0\n4: 2 batches\n2 Start Epoch 0\n1 Start Epoch 0\n3 Start Epoch 0\n2: 2 batches\n1: 2 batches\n3: 2 batches\n5 Start Epoch 0\n6 Start Epoch 0\n5: 2 batches\n6: 2 batches\n1 Start Epoch 1\n1: 2 batches\n3 Start Epoch 1\n7 Start Epoch 1\n5 Start Epoch 1\n2 Start Epoch 1\n4 Start Epoch 1\n2: 2 batches\n3: 2 batches\n7: 2 batches\n5: 2 batches\n6 Start Epoch 1\n6: 2 batches\n4: 2 batches\n0 Start Epoch 1\n0: 2 batches\n7 Start Epoch 2\n5 Start Epoch 2\n1 Start Epoch 2\n7: 2 batches\n5: 2 batches\n1: 2 batches\n4 Start Epoch 2\n4: 2 batches\n6 Start Epoch 2\n6: 2 batches\n2 Start Epoch 2\n2: 2 batches\n3 Start Epoch 2\n3: 2 batches\n0 Start Epoch 2\n0: 2 batches\n5 Start Epoch 3\n5: 2 batches\n7 Start Epoch 3\n7: 2 batches\n1 Start Epoch 3\n1: 2 batches\n4 Start Epoch 3\n4: 2 batches\n6 Start Epoch 3\n6: 2 batches\n3 Start Epoch 3\n3: 2 batches\n2 Start Epoch 3\n2: 2 batches\n0 Start Epoch 3\n0: 2 batches\n5 Start Epoch 4\n5: 2 batches\n7 Start Epoch 4\n7: 2 batches\n4 Start Epoch 4\n4: 2 batches\n6 Start Epoch 4\n6: 2 batches\n3 Start Epoch 4\n3: 2 batches\n2 Start Epoch 4\n2: 2 batches\n1 Start Epoch 4\n1: 2 batches\n0 Start Epoch 4\n0: 2 batches\n2 Start Epoch 5\n3 Start Epoch 5\n2: 2 batches\n1 Start Epoch 5\n3: 2 batches\n6 Start Epoch 5\n6: 2 batches\n1: 2 batches\n7 Start Epoch 5\n4 Start Epoch 5\n7: 2 batches\n4: 2 batches\n5 Start Epoch 5\n5: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 327363.421875\nINFO:root:2: Epoch 0 train loss: 23291.123168945312\nINFO:root:1: Epoch 0 train loss: 155620.455078125\nINFO:root:3: Epoch 0 train loss: 123425.30383300781\nINFO:root:7: Epoch 0 train loss: 168435.40411376953\nINFO:root:5: Epoch 0 train loss: 1163.9957885742188\nINFO:root:6: Epoch 0 train loss: 2501.0784912109375\nINFO:root:4: Epoch 0 train loss: 23739.51416015625\nINFO:root:0: Epoch 0 validation loss: 2578.3945797542433\nINFO:root:7: Epoch 1 train loss: 88642.28137207031\nINFO:root:5: Epoch 1 train loss: 23344.60235595703\nINFO:root:1: Epoch 1 train loss: 2171.4285278320312\nINFO:root:4: Epoch 1 train loss: 1316.6483154296875\nINFO:root:6: Epoch 1 train loss: 2434.2222900390625\nINFO:root:0: Epoch 1 train loss: 238754.953125\nINFO:root:2: Epoch 1 train loss: 216865.38671875\nINFO:root:3: Epoch 1 train loss: 1376.0372009277344\nINFO:root:0: Epoch 1 validation loss: 2576.934817933702\nINFO:root:5: Epoch 2 train loss: 897.547607421875\nINFO:root:7: Epoch 2 train loss: 205505.6171875\nINFO:root:1: Epoch 2 train loss: 2496.3238525390625\nINFO:root:4: Epoch 2 train loss: 24179.49220275879\nINFO:root:6: Epoch 2 train loss: 111411.12890625\nINFO:root:0: Epoch 2 train loss: 144679.63647460938\nINFO:root:3: Epoch 2 train loss: 245749.5546875\nINFO:root:2: Epoch 2 train loss: 4365.9921875\nINFO:root:0: Epoch 2 validation loss: 2575.4659641956077\nINFO:root:5: Epoch 3 train loss: 62292.439208984375\nINFO:root:7: Epoch 3 train loss: 178582.48828125\nINFO:root:4: Epoch 3 train loss: 98810.08221435547\nINFO:root:6: Epoch 3 train loss: 77069.09423828125\nINFO:root:0: Epoch 3 train loss: 56393.066162109375\nINFO:root:3: Epoch 3 train loss: 1942.0347290039062\nINFO:root:1: Epoch 3 train loss: 135680.79724121094\nINFO:root:2: Epoch 3 train loss: 79712.02856445312\nINFO:root:0: Epoch 3 validation loss: 2574.0094144009618\nINFO:root:2: Epoch 4 train loss: 307532.8515625\nINFO:root:3: Epoch 4 train loss: 64525.117736816406\nINFO:root:1: Epoch 4 train loss: 146110.822265625\nINFO:root:6: Epoch 4 train loss: 152787.27294921875\nINFO:root:7: Epoch 4 train loss: 66877.93530654907\nINFO:root:4: Epoch 4 train loss: 2634.5390625\nINFO:root:5: Epoch 4 train loss: 154608.21313476562\nINFO:root:0: Epoch 4 train loss: 145305.24682617188\nINFO:root:0: Epoch 4 validation loss: 2572.5548199061805\nINFO:root:2: Epoch 5 train loss: 57118.073974609375\nINFO:root:1: Epoch 5 train loss: 2696.505859375\nINFO:root:3: Epoch 5 train loss: 154783.1102294922\nINFO:root:6: Epoch 5 train loss: 145883.986328125\nINFO:root:5: Epoch 5 train loss: 195042.63671875\nINFO:root:7: Epoch 5 train loss: 4119.63835144043\nINFO:root:4: Epoch 5 train loss: 187758.0\nINFO:root:0: Epoch 5 train loss: 1470.3524780273438\nINFO:root:0: Epoch 5 validation loss: 2571.0978029657513\n", "seconds": 8.530287742614746, "batch_size": 256, "nodes": 8, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n6 Start Epoch 0\n6: 2 batches\n2 Start Epoch 0\n2: 2 batches\n5 Start Epoch 0\n1 Start Epoch 0\n1: 2 batches\n5: 2 batches\n4 Start Epoch 0\n3 Start Epoch 0\n4: 2 batches\n3: 2 batches\n8 Start Epoch 0\n7 Start Epoch 0\n8: 2 batches\n7: 2 batches\n1 Start Epoch 1\n8 Start Epoch 1\n7 Start Epoch 1\n1: 2 batches\n8: 2 batches\n7: 2 batches\n4 Start Epoch 1\n4: 2 batches\n6 Start Epoch 1\n2 Start Epoch 1\n5 Start Epoch 1\n2: 2 batches\n5: 2 batches\n6: 2 batches\n3 Start Epoch 1\n3: 2 batches\n0 Start Epoch 1\n0: 2 batches\n1 Start Epoch 2\n1: 2 batches\n8 Start Epoch 2\n7 Start Epoch 2\n8: 2 batches\n7: 2 batches\n2 Start Epoch 2\n4 Start Epoch 2\n2: 2 batches\n5 Start Epoch 2\n4: 2 batches\n6 Start Epoch 2\n5: 2 batches\n6: 2 batches\n3 Start Epoch 2\n3: 2 batches\n0 Start Epoch 2\n0: 2 batches\n1 Start Epoch 3\n1: 2 batches\n7 Start Epoch 3\n7: 2 batches\n2 Start Epoch 3\n2: 2 batches\n5 Start Epoch 3\n3 Start Epoch 3\n3: 2 batches\n4 Start Epoch 3\n6 Start Epoch 3\n5: 2 batches\n4: 2 batches\n6: 2 batches\n8 Start Epoch 3\n8: 2 batches\n0 Start Epoch 3\n0: 2 batches\n2 Start Epoch 4\n1 Start Epoch 4\n7 Start Epoch 4\n1: 2 batches\n7: 2 batches\n2: 2 batches\n4 Start Epoch 4\n6 Start Epoch 4\n5 Start Epoch 4\n4: 2 batches\n6: 2 batches\n5: 2 batches\n3 Start Epoch 4\n3: 2 batches\n8 Start Epoch 4\n8: 2 batches\n0 Start Epoch 4\n0: 2 batches\n3 Start Epoch 5\n7 Start Epoch 5\n2 Start Epoch 5\n5 Start Epoch 5\n1 Start Epoch 5\n7: 2 batches\n2: 2 batches\n5: 2 batches\n3: 2 batches\n1: 2 batches\n8 Start Epoch 5\n8: 2 batches\n4 Start Epoch 5\n6 Start Epoch 5\n4: 2 batches\n6: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:7: Epoch 0 train loss: 1962.6082878112793\nINFO:root:1: Epoch 0 train loss: 60940.34671783447\nINFO:root:8: Epoch 0 train loss: 63683.22819709778\nINFO:root:4: Epoch 0 train loss: 8704.003692626953\nINFO:root:0: Epoch 0 train loss: 252807.421875\nINFO:root:6: Epoch 0 train loss: 301720.0\nINFO:root:2: Epoch 0 train loss: 800.5824584960938\nINFO:root:5: Epoch 0 train loss: 59529.734283447266\nINFO:root:3: Epoch 0 train loss: 69732.34765625\nINFO:root:0: Epoch 0 validation loss: 50010.31124494016\nINFO:root:1: Epoch 1 train loss: 24418.82373046875\nINFO:root:8: Epoch 1 train loss: 1824.6278991699219\nINFO:root:7: Epoch 1 train loss: 2303.9024658203125\nINFO:root:0: Epoch 1 train loss: 8801.800109863281\nINFO:root:2: Epoch 1 train loss: 56503.19046020508\nINFO:root:4: Epoch 1 train loss: 1610.2955627441406\nINFO:root:6: Epoch 1 train loss: 15225.63720703125\nINFO:root:5: Epoch 1 train loss: 1752.9483642578125\nINFO:root:3: Epoch 1 train loss: 3137.22509765625\nINFO:root:0: Epoch 1 validation loss: 50003.01158791235\nINFO:root:1: Epoch 2 train loss: 217366.529296875\nINFO:root:7: Epoch 2 train loss: 315571.77734375\nINFO:root:2: Epoch 2 train loss: 3301.2061767578125\nINFO:root:0: Epoch 2 train loss: 8295.839172363281\nINFO:root:5: Epoch 2 train loss: 6811.781005859375\nINFO:root:3: Epoch 2 train loss: 24583.408203125\nINFO:root:4: Epoch 2 train loss: 68007.9287109375\nINFO:root:6: Epoch 2 train loss: 3208.8402099609375\nINFO:root:8: Epoch 2 train loss: 261500.7576904297\nINFO:root:0: Epoch 2 validation loss: 49995.289361344585\nINFO:root:7: Epoch 3 train loss: 63391.59013366699\nINFO:root:2: Epoch 3 train loss: 53162.31478881836\nINFO:root:1: Epoch 3 train loss: 3241.7440185546875\nINFO:root:0: Epoch 3 train loss: 425095.42321777344\nINFO:root:4: Epoch 3 train loss: 459737.931640625\nINFO:root:6: Epoch 3 train loss: 3718.6990966796875\nINFO:root:5: Epoch 3 train loss: 8957.209899902344\nINFO:root:3: Epoch 3 train loss: 218700.326171875\nINFO:root:8: Epoch 3 train loss: 236766.9736328125\nINFO:root:0: Epoch 3 validation loss: 49987.65355492409\nINFO:root:1: Epoch 4 train loss: 1505.4721450805664\nINFO:root:7: Epoch 4 train loss: 3204.656219482422\nINFO:root:2: Epoch 4 train loss: 148707.20611572266\nINFO:root:5: Epoch 4 train loss: 9334.353515625\nINFO:root:3: Epoch 4 train loss: 61434.33544921875\nINFO:root:8: Epoch 4 train loss: 267453.42626953125\nINFO:root:4: Epoch 4 train loss: 61557.4755859375\nINFO:root:6: Epoch 4 train loss: 62391.4326171875\nINFO:root:0: Epoch 4 train loss: 1447.7984924316406\nINFO:root:0: Epoch 4 validation loss: 49980.003107045486\nINFO:root:0: Epoch 5 train loss: 125586.9228515625\nINFO:root:4: Epoch 5 train loss: 3686.259765625\nINFO:root:7: Epoch 5 train loss: 1654.6686706542969\nINFO:root:5: Epoch 5 train loss: 2306.215301513672\nINFO:root:3: Epoch 5 train loss: 52468.69006347656\nINFO:root:1: Epoch 5 train loss: 1805.4248962402344\nINFO:root:6: Epoch 5 train loss: 150703.73217773438\nINFO:root:8: Epoch 5 train loss: 1968.7193603515625\nINFO:root:2: Epoch 5 train loss: 1668.4854736328125\nINFO:root:0: Epoch 5 validation loss: 49972.06144519279\n", "seconds": 10.016136169433594, "batch_size": 256, "nodes": 9, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n9 Start Epoch 0\n9: 2 batches\n2 Start Epoch 0\n4 Start Epoch 0\n6 Start Epoch 0\n8 Start Epoch 0\n2: 2 batches\n6: 2 batches\n1 Start Epoch 0\n3 Start Epoch 0\n1: 2 batches\n8: 2 batches\n7 Start Epoch 0\n3: 2 batches\n4: 2 batches\n5 Start Epoch 0\n5: 2 batches\n7: 2 batches\n1 Start Epoch 1\n1: 2 batches\n5 Start Epoch 1\n8 Start Epoch 1\n7 Start Epoch 1\n6 Start Epoch 1\n9 Start Epoch 1\n7: 2 batches\n6: 2 batches\n9: 2 batches\n8: 2 batches\n2 Start Epoch 1\n5: 2 batches\n2: 2 batches\n4 Start Epoch 1\n3 Start Epoch 1\n4: 2 batches\n3: 2 batches\n0 Start Epoch 1\n0: 2 batches\n4 Start Epoch 2\n4: 2 batches\n8 Start Epoch 2\n7 Start Epoch 2\n5 Start Epoch 2\n6 Start Epoch 2\n9 Start Epoch 2\n5: 2 batches\n6: 2 batches\n9: 2 batches\n8: 2 batches\n7: 2 batches\n1 Start Epoch 2\n1: 2 batches\n2 Start Epoch 2\n2: 2 batches\n3 Start Epoch 2\n3: 2 batches\n0 Start Epoch 2\n0: 2 batches\n1 Start Epoch 3\n1: 2 batches\n7 Start Epoch 3\n5 Start Epoch 3\n6 Start Epoch 3\n6: 2 batches\n9 Start Epoch 3\n8 Start Epoch 3\n7: 2 batches\n2 Start Epoch 3\n4 Start Epoch 3\n5: 2 batches\n2: 2 batches\n4: 2 batches\n9: 2 batches\n8: 2 batches\n3 Start Epoch 3\n3: 2 batches\n0 Start Epoch 3\n0: 2 batches\n3 Start Epoch 4\n3: 2 batches\n1 Start Epoch 4\n1: 2 batches\n5 Start Epoch 4\n6 Start Epoch 4\n8 Start Epoch 4\n7 Start Epoch 4\n4 Start Epoch 4\n6: 2 batches\n9 Start Epoch 4\n8: 2 batches\n7: 2 batches\n2 Start Epoch 4\n4: 2 batches\n5: 2 batches\n2: 2 batches\n9: 2 batches\n0 Start Epoch 4\n0: 2 batches\n1 Start Epoch 5\n3 Start Epoch 5\n1: 2 batches\n3: 2 batches\n9 Start Epoch 5\n9: 2 batches\n5 Start Epoch 5\n2 Start Epoch 5\n4 Start Epoch 5\n5: 2 batches\n6 Start Epoch 5\n8 Start Epoch 5\n7 Start Epoch 5\n2: 2 batches\n4: 2 batches\n6: 2 batches\n8: 2 batches\n7: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:1: Epoch 0 train loss: 120458.21276855469\nINFO:root:5: Epoch 0 train loss: 5145.869873046875\nINFO:root:0: Epoch 0 train loss: 65439.066093444824\nINFO:root:8: Epoch 0 train loss: 2419.6112670898438\nINFO:root:7: Epoch 0 train loss: 124594.87377929688\nINFO:root:6: Epoch 0 train loss: 2925.1616821289062\nINFO:root:9: Epoch 0 train loss: 218218.8984375\nINFO:root:2: Epoch 0 train loss: 3991.8138427734375\nINFO:root:4: Epoch 0 train loss: 44405.333892822266\nINFO:root:3: Epoch 0 train loss: 4875.259521484375\nINFO:root:0: Epoch 0 validation loss: 17509.7212254134\nINFO:root:4: Epoch 1 train loss: 2170.0723266601562\nINFO:root:6: Epoch 1 train loss: 10841.72314453125\nINFO:root:9: Epoch 1 train loss: 64426.439208984375\nINFO:root:8: Epoch 1 train loss: 67373.10607910156\nINFO:root:7: Epoch 1 train loss: 3980.7518310546875\nINFO:root:5: Epoch 1 train loss: 432662.87890625\nINFO:root:1: Epoch 1 train loss: 1134.37109375\nINFO:root:0: Epoch 1 train loss: 70261.4213256836\nINFO:root:2: Epoch 1 train loss: 376854.2862548828\nINFO:root:3: Epoch 1 train loss: 4660.39697265625\nINFO:root:0: Epoch 1 validation loss: 17505.069066495602\nINFO:root:1: Epoch 2 train loss: 2344.748372077942\nINFO:root:0: Epoch 2 train loss: 411622.63720703125\nINFO:root:6: Epoch 2 train loss: 10293.66943359375\nINFO:root:7: Epoch 2 train loss: 65377.5732421875\nINFO:root:5: Epoch 2 train loss: 25257.159057617188\nINFO:root:8: Epoch 2 train loss: 16016.661376953125\nINFO:root:2: Epoch 2 train loss: 339391.80126953125\nINFO:root:4: Epoch 2 train loss: 76717.35266113281\nINFO:root:9: Epoch 2 train loss: 63614.45671081543\nINFO:root:3: Epoch 2 train loss: 2408.504977583885\nINFO:root:0: Epoch 2 validation loss: 17500.455813194658\nINFO:root:3: Epoch 3 train loss: 5332.887451171875\nINFO:root:1: Epoch 3 train loss: 9226.86929321289\nINFO:root:6: Epoch 3 train loss: 54232.50141906738\nINFO:root:8: Epoch 3 train loss: 1902.521725654602\nINFO:root:7: Epoch 3 train loss: 1457.6372680664062\nINFO:root:4: Epoch 3 train loss: 62365.52282714844\nINFO:root:5: Epoch 3 train loss: 83272.86083984375\nINFO:root:9: Epoch 3 train loss: 378421.22509765625\nINFO:root:2: Epoch 3 train loss: 22440.943687438965\nINFO:root:0: Epoch 3 train loss: 1211.8575134277344\nINFO:root:0: Epoch 3 validation loss: 17495.787822463903\nINFO:root:3: Epoch 4 train loss: 86329.17852020264\nINFO:root:1: Epoch 4 train loss: 65894.78036499023\nINFO:root:9: Epoch 4 train loss: 64722.75511932373\nINFO:root:2: Epoch 4 train loss: 21873.732131004333\nINFO:root:4: Epoch 4 train loss: 68669.66375732422\nINFO:root:5: Epoch 4 train loss: 56101.42333984375\nINFO:root:6: Epoch 4 train loss: 741.4833602905273\nINFO:root:8: Epoch 4 train loss: 77083.1763856411\nINFO:root:7: Epoch 4 train loss: 133768.71325683594\nINFO:root:0: Epoch 4 train loss: 905.4791259765625\nINFO:root:0: Epoch 4 validation loss: 17490.8879896631\nINFO:root:3: Epoch 5 train loss: 64151.158142089844\nINFO:root:4: Epoch 5 train loss: 1143.3311004638672\nINFO:root:2: Epoch 5 train loss: 7386.71875\nINFO:root:7: Epoch 5 train loss: 2264.1636962890625\nINFO:root:9: Epoch 5 train loss: 2194.128089904785\nINFO:root:5: Epoch 5 train loss: 65341.032653808594\nINFO:root:0: Epoch 5 train loss: 73532.8447265625\nINFO:root:1: Epoch 5 train loss: 61492.11073303223\nINFO:root:6: Epoch 5 train loss: 21722.1787109375\nINFO:root:8: Epoch 5 train loss: 1626.2983856201172\nINFO:root:0: Epoch 5 validation loss: 17485.7169431782\n", "seconds": 7.168749094009399, "batch_size": 256, "nodes": 10, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n2 Start Epoch 0\n8 Start Epoch 0\n4 Start Epoch 0\n2: 2 batches\n7 Start Epoch 0\n4: 2 batches\n7: 2 batches\n8: 2 batches\n1 Start Epoch 0\n3 Start Epoch 0\n3: 2 batches\n1: 2 batches\n5 Start Epoch 0\n5: 2 batches\n9 Start Epoch 0\n9: 2 batches\n6 Start Epoch 0\n6: 2 batches\n10 Start Epoch 0\n10: 2 batches\n3 Start Epoch 1\n1 Start Epoch 1\n1: 2 batches\n3: 2 batches\n5 Start Epoch 1\n6 Start Epoch 1\n10 Start Epoch 1\n5: 2 batches\n4 Start Epoch 1\n2 Start Epoch 1\n7 Start Epoch 1\n9 Start Epoch 1\n8 Start Epoch 1\n10: 2 batches\n4: 2 batches\n2: 2 batches\n7: 2 batches\n9: 2 batches\n8: 2 batches\n6: 2 batches\n0 Start Epoch 1\n0: 2 batches\n10 Start Epoch 2\n5 Start Epoch 2\n3 Start Epoch 2\n4 Start Epoch 2\n2 Start Epoch 2\n7 Start Epoch 2\n9 Start Epoch 2\n8 Start Epoch 2\n1 Start Epoch 2\n6 Start Epoch 2\n2: 2 batches\n7: 2 batches\n9: 2 batches\n8: 2 batches\n1: 2 batches\n6: 2 batches\n10: 2 batches\n5: 2 batches\n3: 2 batches\n4: 2 batches\n0 Start Epoch 2\n0: 2 batches\n3 Start Epoch 3\n3: 2 batches\n2 Start Epoch 3\n6 Start Epoch 3\n5 Start Epoch 3\n4 Start Epoch 3\n2: 2 batches\n7 Start Epoch 3\n1 Start Epoch 3\n6: 2 batches\n10 Start Epoch 3\n5: 2 batches\n4: 2 batches\n7: 2 batches\n9 Start Epoch 3\n8 Start Epoch 3\n9: 2 batches\n8: 2 batches\n1: 2 batches\n10: 2 batches\n0 Start Epoch 3\n0: 2 batches\n8 Start Epoch 4\n1 Start Epoch 4\n6 Start Epoch 4\n10 Start Epoch 4\n5 Start Epoch 4\n3 Start Epoch 4\n4 Start Epoch 4\n2 Start Epoch 4\n7 Start Epoch 4\n9 Start Epoch 4\n2: 2 batches\n7: 2 batches\n9: 2 batches\n8: 2 batches\n1: 2 batches\n6: 2 batches\n10: 2 batches\n5: 2 batches\n3: 2 batches\n4: 2 batches\n0 Start Epoch 4\n0: 2 batches\n1 Start Epoch 5\n3 Start Epoch 5\n3: 2 batches\n1: 2 batches\n5 Start Epoch 5\n4 Start Epoch 5\n4: 2 batches\n2 Start Epoch 5\n7 Start Epoch 5\n9 Start Epoch 5\n8 Start Epoch 5\n6 Start Epoch 5\n5: 2 batches\n8: 2 batches\n6: 2 batches\n10 Start Epoch 5\n2: 2 batches\n7: 2 batches\n9: 2 batches\n10: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:1: Epoch 0 train loss: 54961.537271499634\nINFO:root:3: Epoch 0 train loss: 826.3199844360352\nINFO:root:0: Epoch 0 train loss: 700.5608291625977\nINFO:root:5: Epoch 0 train loss: 7603.980144500732\nINFO:root:6: Epoch 0 train loss: 28956.679428100586\nINFO:root:10: Epoch 0 train loss: 22151.301223754883\nINFO:root:4: Epoch 0 train loss: 55626.328125\nINFO:root:2: Epoch 0 train loss: 51492.99505853653\nINFO:root:7: Epoch 0 train loss: 870.4022727012634\nINFO:root:9: Epoch 0 train loss: 386.3341112136841\nINFO:root:8: Epoch 0 train loss: 574.5537943840027\nINFO:root:0: Epoch 0 validation loss: 1907647.58312828\nINFO:root:0: Epoch 1 train loss: 61019.62341594696\nINFO:root:9: Epoch 1 train loss: 57118.262546002865\nINFO:root:8: Epoch 1 train loss: 124976.67237854004\nINFO:root:1: Epoch 1 train loss: 22406.948776245117\nINFO:root:6: Epoch 1 train loss: 102159.39453125\nINFO:root:10: Epoch 1 train loss: 82407.91259765625\nINFO:root:5: Epoch 1 train loss: 10116.657915115356\nINFO:root:3: Epoch 1 train loss: 1669.087287902832\nINFO:root:4: Epoch 1 train loss: 77326.82067871094\nINFO:root:2: Epoch 1 train loss: 1368294.0166931152\nINFO:root:7: Epoch 1 train loss: 8276.2509765625\nINFO:root:0: Epoch 1 validation loss: 1907623.1458665668\nINFO:root:3: Epoch 2 train loss: 129673.2529296875\nINFO:root:2: Epoch 2 train loss: 433.39428329467773\nINFO:root:6: Epoch 2 train loss: 9255.619923591614\nINFO:root:5: Epoch 2 train loss: 506419.6640625\nINFO:root:4: Epoch 2 train loss: 5177.405029296875\nINFO:root:7: Epoch 2 train loss: 55971.106758117676\nINFO:root:8: Epoch 2 train loss: 77797.3676147461\nINFO:root:1: Epoch 2 train loss: 76404.14208984375\nINFO:root:10: Epoch 2 train loss: 51572.34684175253\nINFO:root:9: Epoch 2 train loss: 69647.95223617554\nINFO:root:0: Epoch 2 train loss: 981.0325546264648\nINFO:root:0: Epoch 2 validation loss: 1907599.4603218583\nINFO:root:5: Epoch 3 train loss: 1241.2701721191406\nINFO:root:3: Epoch 3 train loss: 3800.51465511322\nINFO:root:4: Epoch 3 train loss: 63389.41867828369\nINFO:root:2: Epoch 3 train loss: 984912.6926879883\nINFO:root:7: Epoch 3 train loss: 557.5452537536621\nINFO:root:9: Epoch 3 train loss: 119567.04418849945\nINFO:root:8: Epoch 3 train loss: 52830.704902648926\nINFO:root:1: Epoch 3 train loss: 77628.3968590945\nINFO:root:6: Epoch 3 train loss: 184540.546875\nINFO:root:10: Epoch 3 train loss: 96717.80327606201\nINFO:root:0: Epoch 3 train loss: 67132.3226928711\nINFO:root:0: Epoch 3 validation loss: 1907575.7169661275\nINFO:root:3: Epoch 4 train loss: 75199.58230403066\nINFO:root:1: Epoch 4 train loss: 1259.9253540039062\nINFO:root:5: Epoch 4 train loss: 60492.004222780466\nINFO:root:4: Epoch 4 train loss: 2724.638078689575\nINFO:root:7: Epoch 4 train loss: 2947.482147216797\nINFO:root:9: Epoch 4 train loss: 1228.1133728027344\nINFO:root:8: Epoch 4 train loss: 75997.5031787157\nINFO:root:6: Epoch 4 train loss: 2373.348846435547\nINFO:root:2: Epoch 4 train loss: 86555.77734375\nINFO:root:10: Epoch 4 train loss: 126002.71086406708\nINFO:root:0: Epoch 4 train loss: 804.6342754364014\nINFO:root:0: Epoch 4 validation loss: 1907552.7192229796\nINFO:root:1: Epoch 5 train loss: 1728.137351989746\nINFO:root:6: Epoch 5 train loss: 123541.02367591858\nINFO:root:10: Epoch 5 train loss: 64952.28877258301\nINFO:root:5: Epoch 5 train loss: 1127.506070137024\nINFO:root:4: Epoch 5 train loss: 1454.5036010742188\nINFO:root:2: Epoch 5 train loss: 743.3127822875977\nINFO:root:7: Epoch 5 train loss: 538.6126351952553\nINFO:root:9: Epoch 5 train loss: 843.886579990387\nINFO:root:8: Epoch 5 train loss: 123156.1022849083\nINFO:root:0: Epoch 5 train loss: 671.3900680541992\nINFO:root:3: Epoch 5 train loss: 55194.46646118164\nINFO:root:0: Epoch 5 validation loss: 1907530.147805509\n", "seconds": 7.142776012420654, "batch_size": 256, "nodes": 11, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "2 Start Epoch 0\n2: 1 batches\n9 Start Epoch 0\n1 Start Epoch 0\n5 Start Epoch 0\n9: 1 batches\n1: 1 batches\n5: 1 batches\n7 Start Epoch 0\n4 Start Epoch 0\n7: 1 batches\n4: 1 batches\n0 Start Epoch 0\n0: 1 batches\n6 Start Epoch 0\n10 Start Epoch 0\n11 Start Epoch 0\n3 Start Epoch 0\n8 Start Epoch 0\n3: 1 batches\n6: 1 batches\n10: 1 batches\n11: 1 batches\n8: 1 batches\n3 Start Epoch 1\n3: 1 batches\n1 Start Epoch 1\n1: 1 batches\n4 Start Epoch 1\n6 Start Epoch 1\n8 Start Epoch 1\n6: 1 batches\n5 Start Epoch 1\n4: 1 batches\n10 Start Epoch 1\n11 Start Epoch 1\n2 Start Epoch 1\n5: 1 batches\n9 Start Epoch 1\n7 Start Epoch 1\n8: 1 batches\n10: 1 batches\n11: 1 batches\n2: 1 batches\n9: 1 batches\n7: 1 batches\n0 Start Epoch 1\n0: 1 batches\n1 Start Epoch 2\n1: 1 batches\n3 Start Epoch 2\n3: 1 batches\n11 Start Epoch 2\n11: 1 batches\n2 Start Epoch 2\n9 Start Epoch 2\n2: 1 batches\n9: 1 batches\n6 Start Epoch 2\n10 Start Epoch 2\n5 Start Epoch 2\n4 Start Epoch 2\n7 Start Epoch 2\n8 Start Epoch 2\n5: 1 batches\n4: 1 batches\n7: 1 batches\n8: 1 batches\n6: 1 batches\n10: 1 batches\n0 Start Epoch 2\n0: 1 batches\n1 Start Epoch 3\n1: 1 batches\n3 Start Epoch 3\n3: 1 batches\n11 Start Epoch 3\n11: 1 batches\n2 Start Epoch 3\n4 Start Epoch 3\n8 Start Epoch 3\n2: 1 batches\n5 Start Epoch 3\n4: 1 batches\n9 Start Epoch 3\n8: 1 batches\n6 Start Epoch 3\n10 Start Epoch 3\n5: 1 batches\n9: 1 batches\n7 Start Epoch 3\n7: 1 batches\n6: 1 batches\n10: 1 batches\n0 Start Epoch 3\n0: 1 batches\n1 Start Epoch 4\n3 Start Epoch 4\n1: 1 batches\n3: 1 batches\n5 Start Epoch 4\n5: 1 batches\n6 Start Epoch 4\n8 Start Epoch 4\n6: 1 batches\n10 Start Epoch 4\n11 Start Epoch 4\n2 Start Epoch 4\n4 Start Epoch 4\n9 Start Epoch 4\n7 Start Epoch 4\n8: 1 batches\n10: 1 batches\n11: 1 batches\n2: 1 batches\n4: 1 batches\n9: 1 batches\n7: 1 batches\n0 Start Epoch 4\n0: 1 batches\n1 Start Epoch 5\n3 Start Epoch 5\n1: 1 batches\n3: 1 batches\n11 Start Epoch 5\n11: 1 batches\n7 Start Epoch 5\n8 Start Epoch 5\n6 Start Epoch 5\n10 Start Epoch 5\n2 Start Epoch 5\n5 Start Epoch 5\n4 Start Epoch 5\n5: 1 batches\n4: 1 batches\n9 Start Epoch 5\n7: 1 batches\n8: 1 batches\n6: 1 batches\n10: 1 batches\n2: 1 batches\n9: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:3: Epoch 0 train loss: 6379.03173828125\nINFO:root:1: Epoch 0 train loss: 155949.984375\nINFO:root:6: Epoch 0 train loss: 5609.0166015625\nINFO:root:4: Epoch 0 train loss: 7241.22314453125\nINFO:root:5: Epoch 0 train loss: 157052.609375\nINFO:root:0: Epoch 0 train loss: 867.3264770507812\nINFO:root:8: Epoch 0 train loss: 140834.21875\nINFO:root:7: Epoch 0 train loss: 180909.828125\nINFO:root:10: Epoch 0 train loss: 141942.625\nINFO:root:11: Epoch 0 train loss: 1431.517578125\nINFO:root:2: Epoch 0 train loss: 128658.59375\nINFO:root:9: Epoch 0 train loss: 130733.96875\nINFO:root:0: Epoch 0 validation loss: 11645.59850265769\nINFO:root:1: Epoch 1 train loss: 4388.05859375\nINFO:root:3: Epoch 1 train loss: 115355.5859375\nINFO:root:11: Epoch 1 train loss: 1906.3192138671875\nINFO:root:0: Epoch 1 train loss: 150948.546875\nINFO:root:2: Epoch 1 train loss: 3529.850830078125\nINFO:root:9: Epoch 1 train loss: 3448.56982421875\nINFO:root:10: Epoch 1 train loss: 1800.1378173828125\nINFO:root:5: Epoch 1 train loss: 114099.1796875\nINFO:root:4: Epoch 1 train loss: 292657.96875\nINFO:root:7: Epoch 1 train loss: 130791.9296875\nINFO:root:8: Epoch 1 train loss: 7177.08935546875\nINFO:root:6: Epoch 1 train loss: 145157.46875\nINFO:root:0: Epoch 1 validation loss: 11644.040334567764\nINFO:root:1: Epoch 2 train loss: 3719.954345703125\nINFO:root:3: Epoch 2 train loss: 2061.51416015625\nINFO:root:11: Epoch 2 train loss: 5839.953125\nINFO:root:0: Epoch 2 train loss: 132042.453125\nINFO:root:2: Epoch 2 train loss: 121969.859375\nINFO:root:4: Epoch 2 train loss: 2167.862060546875\nINFO:root:8: Epoch 2 train loss: 2815.403564453125\nINFO:root:5: Epoch 2 train loss: 1553.7938232421875\nINFO:root:9: Epoch 2 train loss: 1276.8094482421875\nINFO:root:7: Epoch 2 train loss: 5187.86083984375\nINFO:root:6: Epoch 2 train loss: 7394.40625\nINFO:root:10: Epoch 2 train loss: 522.508056640625\nINFO:root:0: Epoch 2 validation loss: 11642.44508915739\nINFO:root:1: Epoch 3 train loss: 2251.1328125\nINFO:root:3: Epoch 3 train loss: 879.0719604492188\nINFO:root:0: Epoch 3 train loss: 241335.5625\nINFO:root:5: Epoch 3 train loss: 3454.700927734375\nINFO:root:6: Epoch 3 train loss: 4289.11083984375\nINFO:root:10: Epoch 3 train loss: 2169.267822265625\nINFO:root:11: Epoch 3 train loss: 63782.35546875\nINFO:root:2: Epoch 3 train loss: 2829.839599609375\nINFO:root:4: Epoch 3 train loss: 1949.6724853515625\nINFO:root:9: Epoch 3 train loss: 262807.40625\nINFO:root:7: Epoch 3 train loss: 3889.775146484375\nINFO:root:8: Epoch 3 train loss: 125057.6171875\nINFO:root:0: Epoch 3 validation loss: 11640.8257702201\nINFO:root:1: Epoch 4 train loss: 129744.9140625\nINFO:root:3: Epoch 4 train loss: 114096.71875\nINFO:root:11: Epoch 4 train loss: 162372.578125\nINFO:root:8: Epoch 4 train loss: 113023.1640625\nINFO:root:6: Epoch 4 train loss: 2924.784912109375\nINFO:root:10: Epoch 4 train loss: 400077.6875\nINFO:root:2: Epoch 4 train loss: 136445.546875\nINFO:root:5: Epoch 4 train loss: 155691.21875\nINFO:root:4: Epoch 4 train loss: 1597.342529296875\nINFO:root:7: Epoch 4 train loss: 6159.150390625\nINFO:root:9: Epoch 4 train loss: 125138.3515625\nINFO:root:0: Epoch 4 train loss: 2026.0264892578125\nINFO:root:0: Epoch 4 validation loss: 11639.200795435321\nINFO:root:3: Epoch 5 train loss: 2403.572509765625\nINFO:root:7: Epoch 5 train loss: 882.7843017578125\nINFO:root:1: Epoch 5 train loss: 47490.3046875\nINFO:root:2: Epoch 5 train loss: 1624.99169921875\nINFO:root:9: Epoch 5 train loss: 142749.546875\nINFO:root:5: Epoch 5 train loss: 1382.7467041015625\nINFO:root:0: Epoch 5 train loss: 2752.707275390625\nINFO:root:6: Epoch 5 train loss: 1194.2977294921875\nINFO:root:4: Epoch 5 train loss: 45108.05859375\nINFO:root:8: Epoch 5 train loss: 131799.140625\nINFO:root:10: Epoch 5 train loss: 4491.224609375\nINFO:root:11: Epoch 5 train loss: 163388.6875\nINFO:root:0: Epoch 5 validation loss: 11637.530209343358\n", "seconds": 7.291049003601074, "batch_size": 256, "nodes": 12, "processes_per_node": 1, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.15 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n1 Start Epoch 0\n0: 6 batches\n1: 6 batches\n1 Start Epoch 1\n1: 6 batches\n0 Start Epoch 1\n0: 6 batches\n1 Start Epoch 2\n1: 6 batches\n0 Start Epoch 2\n0: 6 batches\n1 Start Epoch 3\n1: 6 batches\n0 Start Epoch 3\n0: 6 batches\n1 Start Epoch 4\n1: 6 batches\n0 Start Epoch 4\n0: 6 batches\n1 Start Epoch 5\n1: 6 batches\n0 Start Epoch 5\n0: 6 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:1: Epoch 0 train loss: 9644.614318847656\nINFO:root:0: Epoch 0 train loss: 123602.51789347331\nINFO:root:0: Epoch 0 validation loss: 175236.60439838815\nINFO:root:0: Epoch 1 train loss: 73509.26397705078\nINFO:root:1: Epoch 1 train loss: 73260.87859090169\nINFO:root:0: Epoch 1 validation loss: 175211.42906021726\nINFO:root:0: Epoch 2 train loss: 93303.28462727864\nINFO:root:1: Epoch 2 train loss: 106256.56811523438\nINFO:root:0: Epoch 2 validation loss: 175181.5328763063\nINFO:root:0: Epoch 3 train loss: 47406.342346191406\nINFO:root:1: Epoch 3 train loss: 111970.32666015625\nINFO:root:0: Epoch 3 validation loss: 175143.415503803\nINFO:root:0: Epoch 4 train loss: 55626.90481567383\nINFO:root:1: Epoch 4 train loss: 53609.15279134115\nINFO:root:0: Epoch 4 validation loss: 175092.22727885534\nINFO:root:1: Epoch 5 train loss: 171570.50162760416\nINFO:root:0: Epoch 5 train loss: 60527.82238769531\nINFO:root:0: Epoch 5 validation loss: 175021.79826586644\n", "seconds": 5.457418918609619, "batch_size": 256, "nodes": 1, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.15,192.168.2.2 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n1 Start Epoch 0\n0: 3 batches\n1: 3 batches\n2 Start Epoch 0\n3 Start Epoch 0\n2: 3 batches\n3: 3 batches\n1 Start Epoch 1\n1: 3 batches\n2 Start Epoch 1\n2: 3 batches\n3 Start Epoch 1\n3: 3 batches\n0 Start Epoch 1\n0: 3 batches\n2 Start Epoch 2\n2: 3 batches\n3 Start Epoch 2\n3: 3 batches\n1 Start Epoch 2\n1: 3 batches\n0 Start Epoch 2\n0: 3 batches\n1 Start Epoch 3\n1: 3 batches\n2 Start Epoch 3\n2: 3 batches\n3 Start Epoch 3\n3: 3 batches\n0 Start Epoch 3\n0: 3 batches\n1 Start Epoch 4\n1: 3 batches\n2 Start Epoch 4\n3 Start Epoch 4\n2: 3 batches\n3: 3 batches\n0 Start Epoch 4\n0: 3 batches\n1 Start Epoch 5\n1: 3 batches\n3 Start Epoch 5\n3: 3 batches\n2 Start Epoch 5\n2: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 169368.97916666666\nINFO:root:1: Epoch 0 train loss: 43593.54931640625\nINFO:root:2: Epoch 0 train loss: 54549.645345052086\nINFO:root:3: Epoch 0 train loss: 42378.32657877604\nINFO:root:0: Epoch 0 validation loss: 48072.55819482588\nINFO:root:2: Epoch 1 train loss: 78979.63427734375\nINFO:root:3: Epoch 1 train loss: 52683.458984375\nINFO:root:0: Epoch 1 train loss: 98750.81217447917\nINFO:root:1: Epoch 1 train loss: 136047.8262125651\nINFO:root:0: Epoch 1 validation loss: 48064.71110980142\nINFO:root:1: Epoch 2 train loss: 115966.84883626302\nINFO:root:0: Epoch 2 train loss: 73223.4819946289\nINFO:root:3: Epoch 2 train loss: 89056.59334309895\nINFO:root:2: Epoch 2 train loss: 41949.61759440104\nINFO:root:0: Epoch 2 validation loss: 48056.47932868851\nINFO:root:0: Epoch 3 train loss: 129583.39322916667\nINFO:root:1: Epoch 3 train loss: 107380.66715494792\nINFO:root:2: Epoch 3 train loss: 129259.46875\nINFO:root:3: Epoch 3 train loss: 52730.165852864586\nINFO:root:0: Epoch 3 validation loss: 48047.66769768244\nINFO:root:0: Epoch 4 train loss: 80798.94254557292\nINFO:root:1: Epoch 4 train loss: 2876.5323893229165\nINFO:root:2: Epoch 4 train loss: 17200.108235677082\nINFO:root:3: Epoch 4 train loss: 90402.10986328125\nINFO:root:0: Epoch 4 validation loss: 48038.256928063136\nINFO:root:1: Epoch 5 train loss: 7698.8171793619795\nINFO:root:0: Epoch 5 train loss: 103194.96077473958\nINFO:root:3: Epoch 5 train loss: 3251.8853759765625\nINFO:root:2: Epoch 5 train loss: 206609.02860514322\nINFO:root:0: Epoch 5 validation loss: 48028.173858122966\n", "seconds": 33.0719051361084, "batch_size": 256, "nodes": 2, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.15,192.168.2.2,192.168.2.3 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n1 Start Epoch 0\n1: 2 batches\n0: 2 batches\n3 Start Epoch 0\n3: 2 batches\n4 Start Epoch 0\n5 Start Epoch 0\n5: 2 batches\n2 Start Epoch 0\n4: 2 batches\n2: 2 batches\n1 Start Epoch 1\n1: 2 batches\n3 Start Epoch 1\n2 Start Epoch 1\n3: 2 batches\n2: 2 batches\n5 Start Epoch 1\n5: 2 batches\n4 Start Epoch 1\n4: 2 batches\n0 Start Epoch 1\n0: 2 batches\n1 Start Epoch 2\n3 Start Epoch 2\n2 Start Epoch 2\n2: 2 batches\n3: 2 batches\n5 Start Epoch 2\n1: 2 batches\n5: 2 batches\n4 Start Epoch 2\n4: 2 batches\n0 Start Epoch 2\n0: 2 batches\n1 Start Epoch 3\n2 Start Epoch 3\n2: 2 batches\n4 Start Epoch 3\n4: 2 batches\n5 Start Epoch 3\n5: 2 batches\n1: 2 batches\n3 Start Epoch 3\n3: 2 batches\n0 Start Epoch 3\n0: 2 batches\n1 Start Epoch 4\n1: 2 batches\n5 Start Epoch 4\n5: 2 batches\n2 Start Epoch 4\n2: 2 batches\n3 Start Epoch 4\n3: 2 batches\n4 Start Epoch 4\n4: 2 batches\n0 Start Epoch 4\n0: 2 batches\n5 Start Epoch 5\n3 Start Epoch 5\n2 Start Epoch 5\n4 Start Epoch 5\n3: 2 batches\n5: 2 batches\n2: 2 batches\n4: 2 batches\n1 Start Epoch 5\n1: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:1: Epoch 0 train loss: 65632.64227294922\nINFO:root:3: Epoch 0 train loss: 152878.68212890625\nINFO:root:2: Epoch 0 train loss: 10130.255859375\nINFO:root:4: Epoch 0 train loss: 125600.19659423828\nINFO:root:5: Epoch 0 train loss: 2124.4541015625\nINFO:root:0: Epoch 0 train loss: 125661.80932617188\nINFO:root:0: Epoch 0 validation loss: 654324.7251527997\nINFO:root:1: Epoch 1 train loss: 24517.839477539062\nINFO:root:0: Epoch 1 train loss: 3796.0673828125\nINFO:root:3: Epoch 1 train loss: 119631.13586425781\nINFO:root:2: Epoch 1 train loss: 73696.97119140625\nINFO:root:5: Epoch 1 train loss: 124838.56958007812\nINFO:root:4: Epoch 1 train loss: 65511.41589355469\nINFO:root:0: Epoch 1 validation loss: 654311.0327133551\nINFO:root:1: Epoch 2 train loss: 53241.608154296875\nINFO:root:2: Epoch 2 train loss: 118206.453125\nINFO:root:5: Epoch 2 train loss: 57670.10205078125\nINFO:root:4: Epoch 2 train loss: 90396.97216796875\nINFO:root:0: Epoch 2 train loss: 67757.44995117188\nINFO:root:3: Epoch 2 train loss: 75729.4609375\nINFO:root:0: Epoch 2 validation loss: 654297.4240181905\nINFO:root:0: Epoch 3 train loss: 118863.89453125\nINFO:root:1: Epoch 3 train loss: 144538.21264648438\nINFO:root:5: Epoch 3 train loss: 199436.484375\nINFO:root:4: Epoch 3 train loss: 5043.491424560547\nINFO:root:2: Epoch 3 train loss: 32216.867919921875\nINFO:root:3: Epoch 3 train loss: 64255.069580078125\nINFO:root:0: Epoch 3 validation loss: 654282.9195649207\nINFO:root:0: Epoch 4 train loss: 73501.35571289062\nINFO:root:3: Epoch 4 train loss: 158638.9500732422\nINFO:root:4: Epoch 4 train loss: 134366.53515625\nINFO:root:2: Epoch 4 train loss: 2303.9307250976562\nINFO:root:5: Epoch 4 train loss: 68097.76684570312\nINFO:root:1: Epoch 4 train loss: 24801.7802734375\nINFO:root:0: Epoch 4 validation loss: 654267.5421017843\nINFO:root:3: Epoch 5 train loss: 3027.2166748046875\nINFO:root:2: Epoch 5 train loss: 2545.9169311523438\nINFO:root:5: Epoch 5 train loss: 71178.302734375\nINFO:root:4: Epoch 5 train loss: 138196.02014160156\nINFO:root:0: Epoch 5 train loss: 66842.4453125\nINFO:root:1: Epoch 5 train loss: 76758.40563964844\nINFO:root:0: Epoch 5 validation loss: 654251.5173424251\n", "seconds": 21.994601011276245, "batch_size": 256, "nodes": 3, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n7 Start Epoch 0\n0: 2 batches\n7: 2 batches\n1 Start Epoch 0\n1: 2 batches\n2 Start Epoch 0\n2: 2 batches\n4 Start Epoch 0\n6 Start Epoch 0\n6: 2 batches\n4: 2 batches\n5 Start Epoch 0\n3 Start Epoch 0\n5: 2 batches\n3: 2 batches\n7 Start Epoch 1\n6 Start Epoch 1\n2 Start Epoch 1\n4 Start Epoch 1\n6: 2 batches\n3 Start Epoch 1\n4: 2 batches\n2: 2 batches\n3: 2 batches\n1 Start Epoch 1\n1: 2 batches\n5 Start Epoch 1\n7: 2 batches\n5: 2 batches\n0 Start Epoch 1\n0: 2 batches\n3 Start Epoch 2\n4 Start Epoch 2\n5 Start Epoch 2\n2 Start Epoch 2\n4: 2 batches\n6 Start Epoch 2\n3: 2 batches\n7 Start Epoch 2\n2: 2 batches\n6: 2 batches\n7: 2 batches\n1 Start Epoch 2\n1: 2 batches\n5: 2 batches\n0 Start Epoch 2\n0: 2 batches\n5 Start Epoch 3\n5: 2 batches\n6 Start Epoch 3\n7 Start Epoch 3\n6: 2 batches\n3 Start Epoch 3\n7: 2 batches\n2 Start Epoch 3\n4 Start Epoch 3\n3: 2 batches\n2: 2 batches\n1 Start Epoch 3\n1: 2 batches\n4: 2 batches\n0 Start Epoch 3\n0: 2 batches\n3 Start Epoch 4\n4 Start Epoch 4\n5 Start Epoch 4\n3: 2 batches\n5: 2 batches\n2 Start Epoch 4\n7 Start Epoch 4\n4: 2 batches\n6 Start Epoch 4\n6: 2 batches\n7: 2 batches\n2: 2 batches\n1 Start Epoch 4\n1: 2 batches\n0 Start Epoch 4\n0: 2 batches\n4 Start Epoch 5\n5 Start Epoch 5\n5: 2 batches\n4: 2 batches\n3 Start Epoch 5\n2 Start Epoch 5\n3: 2 batches\n7 Start Epoch 5\n7: 2 batches\n6 Start Epoch 5\n6: 2 batches\n1 Start Epoch 5\n1: 2 batches\n2: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:6: Epoch 0 train loss: 65077.40246582031\nINFO:root:3: Epoch 0 train loss: 259674.63061523438\nINFO:root:4: Epoch 0 train loss: 209380.1484375\nINFO:root:5: Epoch 0 train loss: 2359.8814392089844\nINFO:root:7: Epoch 0 train loss: 70125.333984375\nINFO:root:2: Epoch 0 train loss: 163184.62048339844\nINFO:root:1: Epoch 0 train loss: 198750.359375\nINFO:root:0: Epoch 0 train loss: 1684.2249450683594\nINFO:root:0: Epoch 0 validation loss: 115289.85166559042\nINFO:root:1: Epoch 1 train loss: 68378.50354003906\nINFO:root:0: Epoch 1 train loss: 198016.9453125\nINFO:root:4: Epoch 1 train loss: 2332.2161560058594\nINFO:root:3: Epoch 1 train loss: 49553.0712890625\nINFO:root:5: Epoch 1 train loss: 7806.881896972656\nINFO:root:7: Epoch 1 train loss: 144169.66177368164\nINFO:root:6: Epoch 1 train loss: 3116.861083984375\nINFO:root:2: Epoch 1 train loss: 281305.22760009766\nINFO:root:0: Epoch 1 validation loss: 115282.81447776727\nINFO:root:5: Epoch 2 train loss: 3114.6361083984375\nINFO:root:7: Epoch 2 train loss: 4849.256134033203\nINFO:root:6: Epoch 2 train loss: 70508.64697265625\nINFO:root:2: Epoch 2 train loss: 3774.081298828125\nINFO:root:4: Epoch 2 train loss: 5748.634338378906\nINFO:root:3: Epoch 2 train loss: 62859.82373046875\nINFO:root:1: Epoch 2 train loss: 128350.91455078125\nINFO:root:0: Epoch 2 train loss: 974.9903717041016\nINFO:root:0: Epoch 2 validation loss: 115275.3623281453\nINFO:root:3: Epoch 3 train loss: 94688.4140625\nINFO:root:5: Epoch 3 train loss: 65934.05224609375\nINFO:root:4: Epoch 3 train loss: 1809.2413330078125\nINFO:root:6: Epoch 3 train loss: 63019.74951171875\nINFO:root:7: Epoch 3 train loss: 146174.84899902344\nINFO:root:2: Epoch 3 train loss: 260233.53125\nINFO:root:1: Epoch 3 train loss: 151869.93313598633\nINFO:root:0: Epoch 3 train loss: 142968.44311523438\nINFO:root:0: Epoch 3 validation loss: 115267.36444585671\nINFO:root:4: Epoch 4 train loss: 4061.138427734375\nINFO:root:5: Epoch 4 train loss: 2508.9121704101562\nINFO:root:3: Epoch 4 train loss: 9674.365234375\nINFO:root:2: Epoch 4 train loss: 1029.6954345703125\nINFO:root:6: Epoch 4 train loss: 67246.10955810547\nINFO:root:7: Epoch 4 train loss: 76427.91381835938\nINFO:root:1: Epoch 4 train loss: 327950.5341796875\nINFO:root:0: Epoch 4 train loss: 67470.80004882812\nINFO:root:0: Epoch 4 validation loss: 115258.77023825239\nINFO:root:0: Epoch 5 train loss: 57317.977294921875\nINFO:root:1: Epoch 5 train loss: 7947.362365722656\nINFO:root:6: Epoch 5 train loss: 135774.7080078125\nINFO:root:7: Epoch 5 train loss: 22485.9520072937\nINFO:root:5: Epoch 5 train loss: 61773.24353027344\nINFO:root:4: Epoch 5 train loss: 200108.9921875\nINFO:root:3: Epoch 5 train loss: 198489.578125\nINFO:root:2: Epoch 5 train loss: 1715.09521484375\nINFO:root:0: Epoch 5 validation loss: 115249.47923077925\n", "seconds": 22.43703007698059, "batch_size": 256, "nodes": 4, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n1 Start Epoch 0\n1: 2 batches\n2 Start Epoch 0\n2: 2 batches\n8 Start Epoch 0\n3 Start Epoch 0\n6 Start Epoch 0\n9 Start Epoch 0\n3: 2 batches\n7 Start Epoch 0\n4 Start Epoch 0\n8: 2 batches\n6: 2 batches\n5 Start Epoch 0\n9: 2 batches\n7: 2 batches\n5: 2 batches\n4: 2 batches\n7 Start Epoch 1\n6 Start Epoch 1\n6: 2 batches\n7: 2 batches\n5 Start Epoch 1\n5: 2 batches\n4 Start Epoch 1\n4: 2 batches\n1 Start Epoch 1\n1: 2 batches\n8 Start Epoch 1\n9 Start Epoch 1\n8: 2 batches\n9: 2 batches\n2 Start Epoch 1\n2: 2 batches\n3 Start Epoch 1\n3: 2 batches\n0 Start Epoch 1\n0: 2 batches\n6 Start Epoch 2\n7 Start Epoch 2\n6: 2 batches\n7: 2 batches\n5 Start Epoch 2\n5: 2 batches\n4 Start Epoch 2\n4: 2 batches\n3 Start Epoch 2\n3: 2 batches\n2 Start Epoch 2\n2: 2 batches\n1 Start Epoch 2\n1: 2 batches\n9 Start Epoch 2\n9: 2 batches\n8 Start Epoch 2\n8: 2 batches\n0 Start Epoch 2\n0: 2 batches\n1 Start Epoch 3\n1: 2 batches\n9 Start Epoch 3\n9: 2 batches\n6 Start Epoch 3\n7 Start Epoch 3\n6: 2 batches\n7: 2 batches\n4 Start Epoch 3\n4: 2 batches\n5 Start Epoch 3\n5: 2 batches\n8 Start Epoch 3\n3 Start Epoch 3\n3: 2 batches\n8: 2 batches\n2 Start Epoch 3\n2: 2 batches\n0 Start Epoch 3\n0: 2 batches\n2 Start Epoch 4\n3 Start Epoch 4\n3: 2 batches\n2: 2 batches\n4 Start Epoch 4\n5 Start Epoch 4\n4: 2 batches\n5: 2 batches\n1 Start Epoch 4\n1: 2 batches\n7 Start Epoch 4\n6 Start Epoch 4\n6: 2 batches\n7: 2 batches\n9 Start Epoch 4\n9: 2 batches\n8 Start Epoch 4\n8: 2 batches\n0 Start Epoch 4\n0: 2 batches\n4 Start Epoch 5\n1 Start Epoch 5\n1: 2 batches\n5 Start Epoch 5\n4: 2 batches\n3 Start Epoch 5\n5: 2 batches\n2 Start Epoch 5\n3: 2 batches\n2: 2 batches\n8 Start Epoch 5\n9 Start Epoch 5\n8: 2 batches\n9: 2 batches\n6 Start Epoch 5\n6: 2 batches\n7 Start Epoch 5\n7: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:6: Epoch 0 train loss: 1560.6107788085938\nINFO:root:7: Epoch 0 train loss: 2010.4624938964844\nINFO:root:5: Epoch 0 train loss: 26143.56298828125\nINFO:root:4: Epoch 0 train loss: 22074.750061035156\nINFO:root:0: Epoch 0 train loss: 25726.868286132812\nINFO:root:1: Epoch 0 train loss: 2175.9923095703125\nINFO:root:8: Epoch 0 train loss: 62561.20251464844\nINFO:root:9: Epoch 0 train loss: 71443.35758972168\nINFO:root:2: Epoch 0 train loss: 1536.8443298339844\nINFO:root:3: Epoch 0 train loss: 69748.13012695312\nINFO:root:0: Epoch 0 validation loss: 2627.8332458936834\nINFO:root:7: Epoch 1 train loss: 75433.60856628418\nINFO:root:6: Epoch 1 train loss: 391212.03942871094\nINFO:root:5: Epoch 1 train loss: 63443.587890625\nINFO:root:4: Epoch 1 train loss: 2435.0692749023438\nINFO:root:3: Epoch 1 train loss: 67072.64831542969\nINFO:root:2: Epoch 1 train loss: 3532.4378662109375\nINFO:root:1: Epoch 1 train loss: 66571.33500671387\nINFO:root:0: Epoch 1 train loss: 2317.5328674316406\nINFO:root:9: Epoch 1 train loss: 1271.3803100585938\nINFO:root:8: Epoch 1 train loss: 126929.5066986084\nINFO:root:0: Epoch 1 validation loss: 2625.836137810401\nINFO:root:0: Epoch 2 train loss: 3667.3463134765625\nINFO:root:1: Epoch 2 train loss: 7645.676834106445\nINFO:root:9: Epoch 2 train loss: 35048.2880859375\nINFO:root:7: Epoch 2 train loss: 473518.6848144531\nINFO:root:6: Epoch 2 train loss: 60317.89794921875\nINFO:root:4: Epoch 2 train loss: 71051.79248046875\nINFO:root:5: Epoch 2 train loss: 68819.86180114746\nINFO:root:8: Epoch 2 train loss: 14032.4794921875\nINFO:root:3: Epoch 2 train loss: 1346.0149536132812\nINFO:root:2: Epoch 2 train loss: 2606.4630126953125\nINFO:root:0: Epoch 2 validation loss: 2623.7792740958776\nINFO:root:2: Epoch 3 train loss: 150127.25537109375\nINFO:root:3: Epoch 3 train loss: 78650.11669158936\nINFO:root:5: Epoch 3 train loss: 1120.0127258300781\nINFO:root:4: Epoch 3 train loss: 70288.17041015625\nINFO:root:1: Epoch 3 train loss: 136709.1096496582\nINFO:root:0: Epoch 3 train loss: 16690.497680664062\nINFO:root:6: Epoch 3 train loss: 61988.74285888672\nINFO:root:7: Epoch 3 train loss: 5170.618347167969\nINFO:root:8: Epoch 3 train loss: 78033.640625\nINFO:root:9: Epoch 3 train loss: 51418.51231384277\nINFO:root:0: Epoch 3 validation loss: 2621.657016037867\nINFO:root:0: Epoch 4 train loss: 3363.393310546875\nINFO:root:1: Epoch 4 train loss: 454135.84765625\nINFO:root:4: Epoch 4 train loss: 22257.01382446289\nINFO:root:5: Epoch 4 train loss: 193031.06842041016\nINFO:root:3: Epoch 4 train loss: 77387.25424194336\nINFO:root:2: Epoch 4 train loss: 1943.7823486328125\nINFO:root:8: Epoch 4 train loss: 4290.7142333984375\nINFO:root:9: Epoch 4 train loss: 46752.867431640625\nINFO:root:7: Epoch 4 train loss: 69655.20475769043\nINFO:root:6: Epoch 4 train loss: 1565.830940246582\nINFO:root:0: Epoch 4 validation loss: 2619.443424962718\nINFO:root:4: Epoch 5 train loss: 469278.5546875\nINFO:root:5: Epoch 5 train loss: 325112.201171875\nINFO:root:1: Epoch 5 train loss: 2265.695526123047\nINFO:root:0: Epoch 5 train loss: 125089.8759765625\nINFO:root:9: Epoch 5 train loss: 84971.73986816406\nINFO:root:8: Epoch 5 train loss: 1521.8295364379883\nINFO:root:2: Epoch 5 train loss: 64552.54577636719\nINFO:root:3: Epoch 5 train loss: 379350.23046875\nINFO:root:6: Epoch 5 train loss: 1782.5932006835938\nINFO:root:7: Epoch 5 train loss: 2488.8348388671875\nINFO:root:0: Epoch 5 validation loss: 2617.1225729065723\n", "seconds": 16.48635172843933, "batch_size": 256, "nodes": 5, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n1: 1 batches\n2 Start Epoch 0\n2: 1 batches\n11 Start Epoch 0\n11: 1 batches\n4 Start Epoch 0\n3 Start Epoch 0\n4: 1 batches\n3: 1 batches\n7 Start Epoch 0\n7: 1 batches\n8 Start Epoch 0\n8: 1 batches\n6 Start Epoch 0\n6: 1 batches\n9 Start Epoch 0\n10 Start Epoch 0\n5 Start Epoch 0\n5: 1 batches\n9: 1 batches\n10: 1 batches\n1 Start Epoch 1\n1: 1 batches\n3 Start Epoch 1\n6 Start Epoch 1\n7 Start Epoch 1\n2 Start Epoch 1\n5 Start Epoch 1\n7: 1 batches\n3: 1 batches\n11 Start Epoch 1\n4 Start Epoch 1\n2: 1 batches\n10 Start Epoch 1\n4: 1 batches\n6: 1 batches\n11: 1 batches\n5: 1 batches\n10: 1 batches\n8 Start Epoch 1\n8: 1 batches\n9 Start Epoch 1\n9: 1 batches\n0 Start Epoch 1\n0: 1 batches\n1 Start Epoch 2\n1: 1 batches\n11 Start Epoch 2\n11: 1 batches\n5 Start Epoch 2\n3 Start Epoch 2\n3: 1 batches\n4 Start Epoch 2\n2 Start Epoch 2\n10 Start Epoch 2\n10: 1 batches\n5: 1 batches\n6 Start Epoch 2\n4: 1 batches\n7 Start Epoch 2\n6: 1 batches\n7: 1 batches\n8 Start Epoch 2\n8: 1 batches\n9 Start Epoch 2\n9: 1 batches\n2: 1 batches\n0 Start Epoch 2\n0: 1 batches\n11 Start Epoch 3\n11: 1 batches\n4 Start Epoch 3\n5 Start Epoch 3\n2 Start Epoch 3\n3 Start Epoch 3\n3: 1 batches\n4: 1 batches\n5: 1 batches\n2: 1 batches\n1 Start Epoch 3\n1: 1 batches\n10 Start Epoch 3\n7 Start Epoch 3\n10: 1 batches\n6 Start Epoch 3\n7: 1 batches\n6: 1 batches\n8 Start Epoch 3\n8: 1 batches\n9 Start Epoch 3\n9: 1 batches\n0 Start Epoch 3\n0: 1 batches\n3 Start Epoch 4\n5 Start Epoch 4\n6 Start Epoch 4\n8 Start Epoch 4\n3: 1 batches\n11 Start Epoch 4\n10 Start Epoch 4\n5: 1 batches\n7 Start Epoch 4\n9 Start Epoch 4\n2 Start Epoch 4\n4 Start Epoch 4\n6: 1 batches\n9: 1 batches\n10: 1 batches\n2: 1 batches\n11: 1 batches\n4: 1 batches\n7: 1 batches\n8: 1 batches\n1 Start Epoch 4\n1: 1 batches\n0 Start Epoch 4\n0: 1 batches\n4 Start Epoch 5\n10 Start Epoch 5\n6 Start Epoch 5\n6: 1 batches\n11 Start Epoch 5\n5 Start Epoch 5\n5: 1 batches\n10: 1 batches\n4: 1 batches\n1 Start Epoch 5\n1: 1 batches\n8 Start Epoch 5\n8: 1 batches\n9 Start Epoch 5\n9: 1 batches\n2 Start Epoch 5\n2: 1 batches\n3 Start Epoch 5\n3: 1 batches\n7 Start Epoch 5\n7: 1 batches\n11: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:1: Epoch 0 train loss: 1617.9521484375\nINFO:root:3: Epoch 0 train loss: 7194.56689453125\nINFO:root:6: Epoch 0 train loss: 116074.6640625\nINFO:root:4: Epoch 0 train loss: 2173.236083984375\nINFO:root:7: Epoch 0 train loss: 1169.6795654296875\nINFO:root:2: Epoch 0 train loss: 134806.453125\nINFO:root:10: Epoch 0 train loss: 5669.49951171875\nINFO:root:5: Epoch 0 train loss: 699.8609619140625\nINFO:root:11: Epoch 0 train loss: 2337.158203125\nINFO:root:8: Epoch 0 train loss: 290426.875\nINFO:root:9: Epoch 0 train loss: 107565.03125\nINFO:root:0: Epoch 0 train loss: 3209.826171875\nINFO:root:0: Epoch 0 validation loss: 295081.67384011304\nINFO:root:1: Epoch 1 train loss: 6538.7802734375\nINFO:root:0: Epoch 1 train loss: 584.1427001953125\nINFO:root:5: Epoch 1 train loss: 17996.62890625\nINFO:root:2: Epoch 1 train loss: 155548.75\nINFO:root:11: Epoch 1 train loss: 16485.734375\nINFO:root:4: Epoch 1 train loss: 3509.371337890625\nINFO:root:7: Epoch 1 train loss: 161473.765625\nINFO:root:3: Epoch 1 train loss: 687.415283203125\nINFO:root:6: Epoch 1 train loss: 3915.990234375\nINFO:root:10: Epoch 1 train loss: 6764.984375\nINFO:root:9: Epoch 1 train loss: 1521.4456787109375\nINFO:root:8: Epoch 1 train loss: 48008.58203125\nINFO:root:0: Epoch 1 validation loss: 295075.50332263607\nINFO:root:11: Epoch 2 train loss: 2332.59619140625\nINFO:root:4: Epoch 2 train loss: 175776.421875\nINFO:root:2: Epoch 2 train loss: 3390.374267578125\nINFO:root:3: Epoch 2 train loss: 46248.8671875\nINFO:root:5: Epoch 2 train loss: 2696.054443359375\nINFO:root:0: Epoch 2 train loss: 379000.34375\nINFO:root:1: Epoch 2 train loss: 1504.055908203125\nINFO:root:7: Epoch 2 train loss: 6835.9169921875\nINFO:root:10: Epoch 2 train loss: 6365.5673828125\nINFO:root:6: Epoch 2 train loss: 155995.671875\nINFO:root:8: Epoch 2 train loss: 260375.359375\nINFO:root:9: Epoch 2 train loss: 6456.2109375\nINFO:root:0: Epoch 2 validation loss: 295069.4641447374\nINFO:root:9: Epoch 3 train loss: 1568.2208251953125\nINFO:root:3: Epoch 3 train loss: 5342.86376953125\nINFO:root:10: Epoch 3 train loss: 141161.09375\nINFO:root:5: Epoch 3 train loss: 145079.75\nINFO:root:7: Epoch 3 train loss: 299384.15625\nINFO:root:11: Epoch 3 train loss: 126091.9453125\nINFO:root:6: Epoch 3 train loss: 240510.234375\nINFO:root:8: Epoch 3 train loss: 11898.5283203125\nINFO:root:4: Epoch 3 train loss: 681.8579711914062\nINFO:root:2: Epoch 3 train loss: 3726.5390625\nINFO:root:1: Epoch 3 train loss: 2104.264892578125\nINFO:root:0: Epoch 3 train loss: 2063.781005859375\nINFO:root:0: Epoch 3 validation loss: 295063.6448986177\nINFO:root:1: Epoch 4 train loss: 1470.2984619140625\nINFO:root:0: Epoch 4 train loss: 2400.899169921875\nINFO:root:11: Epoch 4 train loss: 247220.34375\nINFO:root:6: Epoch 4 train loss: 4335.54833984375\nINFO:root:4: Epoch 4 train loss: 2044.130859375\nINFO:root:7: Epoch 4 train loss: 158618.1875\nINFO:root:10: Epoch 4 train loss: 392107.625\nINFO:root:5: Epoch 4 train loss: 141446.78125\nINFO:root:8: Epoch 4 train loss: 1315.13232421875\nINFO:root:9: Epoch 4 train loss: 3900.577392578125\nINFO:root:2: Epoch 4 train loss: 5812.31005859375\nINFO:root:3: Epoch 4 train loss: 110299.421875\nINFO:root:0: Epoch 4 validation loss: 295057.9083326992\nINFO:root:1: Epoch 5 train loss: 363.7706604003906\nINFO:root:0: Epoch 5 train loss: 17392.78125\nINFO:root:8: Epoch 5 train loss: 2095.10546875\nINFO:root:3: Epoch 5 train loss: 7028.22412109375\nINFO:root:10: Epoch 5 train loss: 3142.794189453125\nINFO:root:4: Epoch 5 train loss: 2905.69873046875\nINFO:root:7: Epoch 5 train loss: 1928.418701171875\nINFO:root:2: Epoch 5 train loss: 130858.171875\nINFO:root:11: Epoch 5 train loss: 143118.796875\nINFO:root:5: Epoch 5 train loss: 3371.772216796875\nINFO:root:6: Epoch 5 train loss: 1345.38818359375\nINFO:root:9: Epoch 5 train loss: 2102.0517578125\nINFO:root:0: Epoch 5 validation loss: 295052.25967323757\n", "seconds": 14.170339107513428, "batch_size": 256, "nodes": 6, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n13 Start Epoch 0\n13: 1 batches\n1 Start Epoch 0\n1: 1 batches\n6 Start Epoch 0\n6: 1 batches\n8 Start Epoch 0\n8: 1 batches\n7 Start Epoch 0\n9 Start Epoch 0\n9: 1 batches\n7: 1 batches\n2 Start Epoch 0\n2: 1 batches\n12 Start Epoch 0\n12: 1 batches\n4 Start Epoch 0\n11 Start Epoch 0\n5 Start Epoch 0\n10 Start Epoch 0\n3 Start Epoch 0\n5: 1 batches\n10: 1 batches\n3: 1 batches\n4: 1 batches\n11: 1 batches\n7 Start Epoch 1\n7: 1 batches\n6 Start Epoch 1\n6: 1 batches\n5 Start Epoch 1\n11 Start Epoch 1\n12 Start Epoch 1\n4 Start Epoch 1\n10 Start Epoch 1\n2 Start Epoch 1\n13 Start Epoch 1\n12: 1 batches\n8 Start Epoch 1\n5: 1 batches\n10: 1 batches\n3 Start Epoch 1\n11: 1 batches\n3: 1 batches\n13: 1 batches\n9 Start Epoch 1\n4: 1 batches\n2: 1 batches\n8: 1 batches\n9: 1 batches\n1 Start Epoch 1\n1: 1 batches\n0 Start Epoch 1\n0: 1 batches\n1 Start Epoch 2\n1: 1 batches\n5 Start Epoch 2\n6 Start Epoch 2\n4 Start Epoch 2\n11 Start Epoch 2\n8 Start Epoch 2\n10 Start Epoch 2\n2 Start Epoch 2\n9 Start Epoch 2\n6: 1 batches\n9: 1 batches\n7 Start Epoch 2\n5: 1 batches\n10: 1 batches\n3 Start Epoch 2\n2: 1 batches\n8: 1 batches\n7: 1 batches\n3: 1 batches\n13 Start Epoch 2\n12 Start Epoch 2\n12: 1 batches\n13: 1 batches\n11: 1 batches\n4: 1 batches\n0 Start Epoch 2\n0: 1 batches\n11 Start Epoch 3\n11: 1 batches\n10 Start Epoch 3\n3 Start Epoch 3\n2 Start Epoch 3\n3: 1 batches\n2: 1 batches\n12 Start Epoch 3\n13 Start Epoch 3\n12: 1 batches\n13: 1 batches\n1 Start Epoch 3\n1: 1 batches\n9 Start Epoch 3\n9: 1 batches\n10: 1 batches\n5 Start Epoch 3\n6 Start Epoch 3\n4 Start Epoch 3\n7 Start Epoch 3\n4: 1 batches\n6: 1 batches\n5: 1 batches\n7: 1 batches\n8 Start Epoch 3\n8: 1 batches\n0 Start Epoch 3\n0: 1 batches\n11 Start Epoch 4\n9 Start Epoch 4\n11: 1 batches\n13 Start Epoch 4\n12 Start Epoch 4\n4 Start Epoch 4\n12: 1 batches\n2 Start Epoch 4\n13: 1 batches\n5 Start Epoch 4\n5: 1 batches\n3 Start Epoch 4\n2: 1 batches\n4: 1 batches\n3: 1 batches\n7 Start Epoch 4\n7: 1 batches\n6 Start Epoch 4\n6: 1 batches\n1 Start Epoch 4\n1: 1 batches\n9: 1 batches\n8 Start Epoch 4\n8: 1 batches\n10 Start Epoch 4\n10: 1 batches\n0 Start Epoch 4\n0: 1 batches\n5 Start Epoch 5\n11 Start Epoch 5\n10 Start Epoch 5\n6 Start Epoch 5\n5: 1 batches\n11: 1 batches\n6: 1 batches\n10: 1 batches\n7 Start Epoch 5\n7: 1 batches\n2 Start Epoch 5\n2: 1 batches\n12 Start Epoch 5\n9 Start Epoch 5\n9: 1 batches\n3 Start Epoch 5\n3: 1 batches\n12: 1 batches\n1 Start Epoch 5\n8 Start Epoch 5\n13 Start Epoch 5\n13: 1 batches\n8: 1 batches\n1: 1 batches\n4 Start Epoch 5\n4: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:7: Epoch 0 train loss: 2918.15869140625\nINFO:root:6: Epoch 0 train loss: 1369.8963623046875\nINFO:root:5: Epoch 0 train loss: 1412.2388916015625\nINFO:root:10: Epoch 0 train loss: 689.6546020507812\nINFO:root:12: Epoch 0 train loss: 4325.53369140625\nINFO:root:4: Epoch 0 train loss: 182137.03125\nINFO:root:11: Epoch 0 train loss: 2205.513916015625\nINFO:root:3: Epoch 0 train loss: 3142.036376953125\nINFO:root:13: Epoch 0 train loss: 130401.1875\nINFO:root:2: Epoch 0 train loss: 19750.826171875\nINFO:root:8: Epoch 0 train loss: 166423.09375\nINFO:root:9: Epoch 0 train loss: 1176.505126953125\nINFO:root:0: Epoch 0 train loss: 3260.931884765625\nINFO:root:1: Epoch 0 train loss: 1735.527099609375\nINFO:root:0: Epoch 0 validation loss: 3924080.2790563023\nINFO:root:0: Epoch 1 train loss: 4562.59912109375\nINFO:root:6: Epoch 1 train loss: 147966.96875\nINFO:root:4: Epoch 1 train loss: 2748.05810546875\nINFO:root:11: Epoch 1 train loss: 1189.9388427734375\nINFO:root:8: Epoch 1 train loss: 182098.203125\nINFO:root:10: Epoch 1 train loss: 150684.859375\nINFO:root:1: Epoch 1 train loss: 53631.90625\nINFO:root:3: Epoch 1 train loss: 6402.7607421875\nINFO:root:9: Epoch 1 train loss: 165035.53125\nINFO:root:7: Epoch 1 train loss: 9486.185546875\nINFO:root:2: Epoch 1 train loss: 4225.21484375\nINFO:root:5: Epoch 1 train loss: 320397.875\nINFO:root:12: Epoch 1 train loss: 223398.546875\nINFO:root:13: Epoch 1 train loss: 3541.474853515625\nINFO:root:0: Epoch 1 validation loss: 3924055.5119418986\nINFO:root:10: Epoch 2 train loss: 181648.203125\nINFO:root:11: Epoch 2 train loss: 1847.6796875\nINFO:root:3: Epoch 2 train loss: 1408.130615234375\nINFO:root:2: Epoch 2 train loss: 187407.984375\nINFO:root:13: Epoch 2 train loss: 7942.9345703125\nINFO:root:12: Epoch 2 train loss: 1479.5068359375\nINFO:root:0: Epoch 2 train loss: 124204.8359375\nINFO:root:1: Epoch 2 train loss: 55223.10546875\nINFO:root:9: Epoch 2 train loss: 54469.51953125\nINFO:root:4: Epoch 2 train loss: 332184.34375\nINFO:root:7: Epoch 2 train loss: 615.5333251953125\nINFO:root:5: Epoch 2 train loss: 876.9927978515625\nINFO:root:6: Epoch 2 train loss: 53167.60546875\nINFO:root:8: Epoch 2 train loss: 2106.340576171875\nINFO:root:0: Epoch 2 validation loss: 3924030.1407867507\nINFO:root:9: Epoch 3 train loss: 1479.9495849609375\nINFO:root:11: Epoch 3 train loss: 165948.640625\nINFO:root:13: Epoch 3 train loss: 330616.1875\nINFO:root:8: Epoch 3 train loss: 165840.9375\nINFO:root:12: Epoch 3 train loss: 914.7255249023438\nINFO:root:3: Epoch 3 train loss: 57681.0078125\nINFO:root:2: Epoch 3 train loss: 183626.171875\nINFO:root:4: Epoch 3 train loss: 166278.203125\nINFO:root:5: Epoch 3 train loss: 2039.5162353515625\nINFO:root:0: Epoch 3 train loss: 2340.157470703125\nINFO:root:6: Epoch 3 train loss: 158771.34375\nINFO:root:7: Epoch 3 train loss: 23148.53125\nINFO:root:1: Epoch 3 train loss: 165235.53125\nINFO:root:10: Epoch 3 train loss: 8238.251953125\nINFO:root:0: Epoch 3 validation loss: 3924005.2956201895\nINFO:root:11: Epoch 4 train loss: 3591.265380859375\nINFO:root:5: Epoch 4 train loss: 5497.82666015625\nINFO:root:10: Epoch 4 train loss: 125729.9140625\nINFO:root:6: Epoch 4 train loss: 159315.734375\nINFO:root:7: Epoch 4 train loss: 149133.296875\nINFO:root:3: Epoch 4 train loss: 159147.296875\nINFO:root:12: Epoch 4 train loss: 3130.10498046875\nINFO:root:9: Epoch 4 train loss: 133812.828125\nINFO:root:1: Epoch 4 train loss: 439004.21875\nINFO:root:13: Epoch 4 train loss: 2473.21826171875\nINFO:root:2: Epoch 4 train loss: 19222.3828125\nINFO:root:8: Epoch 4 train loss: 2734.256591796875\nINFO:root:0: Epoch 4 train loss: 273974.59375\nINFO:root:4: Epoch 4 train loss: 319350.5625\nINFO:root:0: Epoch 4 validation loss: 3923980.5725434422\nINFO:root:7: Epoch 5 train loss: 252206.359375\nINFO:root:3: Epoch 5 train loss: 53645.07421875\nINFO:root:12: Epoch 5 train loss: 51818.87890625\nINFO:root:13: Epoch 5 train loss: 203996.375\nINFO:root:1: Epoch 5 train loss: 559.7493896484375\nINFO:root:0: Epoch 5 train loss: 2820.234130859375\nINFO:root:9: Epoch 5 train loss: 147153.4375\nINFO:root:8: Epoch 5 train loss: 182944.578125\nINFO:root:4: Epoch 5 train loss: 185242.0625\nINFO:root:6: Epoch 5 train loss: 23033.11328125\nINFO:root:5: Epoch 5 train loss: 2142.129638671875\nINFO:root:2: Epoch 5 train loss: 158555.4375\nINFO:root:11: Epoch 5 train loss: 9844.7568359375\nINFO:root:10: Epoch 5 train loss: 2338.938720703125\nINFO:root:0: Epoch 5 validation loss: 3923955.160727643\n", "seconds": 14.21234941482544, "batch_size": 256, "nodes": 7, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n1: 1 batches\n2 Start Epoch 0\n2: 1 batches\n15 Start Epoch 0\n11 Start Epoch 0\n15: 1 batches\n3 Start Epoch 0\n11: 1 batches\n4 Start Epoch 0\n3: 1 batches\n8 Start Epoch 0\n4: 1 batches\n8: 1 batches\n7 Start Epoch 0\n12 Start Epoch 0\n7: 1 batches\n12: 1 batches\n10 Start Epoch 0\n5 Start Epoch 0\n6 Start Epoch 0\n9 Start Epoch 0\n6: 1 batches\n13 Start Epoch 0\n10: 1 batches\n14 Start Epoch 0\n5: 1 batches\n13: 1 batches\n14: 1 batches\n9: 1 batches\n15 Start Epoch 1\n15: 1 batches\n11 Start Epoch 1\n11: 1 batches\n5 Start Epoch 1\n6 Start Epoch 1\n13 Start Epoch 1\n5: 1 batches\n3 Start Epoch 1\n2 Start Epoch 1\n7 Start Epoch 1\n12 Start Epoch 1\n10 Start Epoch 1\n4 Start Epoch 1\n3: 1 batches\n6: 1 batches\n12: 1 batches\n1 Start Epoch 1\n1: 1 batches\n10: 1 batches\n7: 1 batches\n13: 1 batches\n4: 1 batches\n2: 1 batches\n14 Start Epoch 1\n8 Start Epoch 1\n14: 1 batches\n9 Start Epoch 1\n8: 1 batches\n9: 1 batches\n0 Start Epoch 1\n0: 1 batches\n1 Start Epoch 2\n1: 1 batches\n3 Start Epoch 2\n7 Start Epoch 2\n7: 1 batches\n4 Start Epoch 2\n3: 1 batches\n4: 1 batches\n5 Start Epoch 2\n5: 1 batches\n6 Start Epoch 2\n6: 1 batches\n9 Start Epoch 2\n12 Start Epoch 2\n8 Start Epoch 2\n12: 1 batches\n8: 1 batches\n15 Start Epoch 2\n13 Start Epoch 2\n14 Start Epoch 2\n15: 1 batches\n14: 1 batches\n9: 1 batches\n13: 1 batches\n2 Start Epoch 2\n2: 1 batches\n11 Start Epoch 2\n11: 1 batches\n10 Start Epoch 2\n10: 1 batches\n0 Start Epoch 2\n0: 1 batches\n11 Start Epoch 3\n14 Start Epoch 3\n3 Start Epoch 3\n7 Start Epoch 3\n7: 1 batches\n11: 1 batches\n3: 1 batches\n15 Start Epoch 3\n4 Start Epoch 3\n6 Start Epoch 3\n10 Start Epoch 3\n5 Start Epoch 3\n6: 1 batches\n1 Start Epoch 3\n1: 1 batches\n14: 1 batches\n4: 1 batches\n10: 1 batches\n15: 1 batches\n5: 1 batches\n9 Start Epoch 3\n13 Start Epoch 3\n8 Start Epoch 3\n12 Start Epoch 3\n8: 1 batches\n12: 1 batches\n9: 1 batches\n13: 1 batches\n2 Start Epoch 3\n2: 1 batches\n0 Start Epoch 3\n0: 1 batches\n7 Start Epoch 4\n4 Start Epoch 4\n6 Start Epoch 4\n6: 1 batches\n4: 1 batches\n5 Start Epoch 4\n2 Start Epoch 4\n13 Start Epoch 4\n10 Start Epoch 4\n14 Start Epoch 4\n5: 1 batches\n3 Start Epoch 4\n7: 1 batches\n12 Start Epoch 4\n12: 1 batches\n11 Start Epoch 4\n15 Start Epoch 4\n10: 1 batches\n14: 1 batches\n1 Start Epoch 4\n1: 1 batches\n11: 1 batches\n15: 1 batches\n2: 1 batches\n3: 1 batches\n9 Start Epoch 4\n8 Start Epoch 4\n8: 1 batches\n9: 1 batches\n13: 1 batches\n0 Start Epoch 4\n0: 1 batches\n15 Start Epoch 5\n5 Start Epoch 5\n3 Start Epoch 5\n14 Start Epoch 5\n4 Start Epoch 5\n3: 1 batches\n15: 1 batches\n1 Start Epoch 5\n1: 1 batches\n4: 1 batches\n5: 1 batches\n14: 1 batches\n2 Start Epoch 5\n13 Start Epoch 5\n13: 1 batches\n10 Start Epoch 5\n10: 1 batches\n2: 1 batches\n11 Start Epoch 5\n11: 1 batches\n12 Start Epoch 5\n12: 1 batches\n6 Start Epoch 5\n7 Start Epoch 5\n7: 1 batches\n6: 1 batches\n8 Start Epoch 5\n9 Start Epoch 5\n8: 1 batches\n9: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:15: Epoch 0 train loss: 189575.3125\nINFO:root:11: Epoch 0 train loss: 331252.9375\nINFO:root:6: Epoch 0 train loss: 180886.515625\nINFO:root:12: Epoch 0 train loss: 2356.167724609375\nINFO:root:5: Epoch 0 train loss: 781.493896484375\nINFO:root:3: Epoch 0 train loss: 3570.807861328125\nINFO:root:7: Epoch 0 train loss: 353368.125\nINFO:root:13: Epoch 0 train loss: 360205.78125\nINFO:root:2: Epoch 0 train loss: 7580.2138671875\nINFO:root:10: Epoch 0 train loss: 142747.96875\nINFO:root:4: Epoch 0 train loss: 210308.4375\nINFO:root:1: Epoch 0 train loss: 187647.140625\nINFO:root:9: Epoch 0 train loss: 3288.42431640625\nINFO:root:8: Epoch 0 train loss: 1478.0924072265625\nINFO:root:14: Epoch 0 train loss: 289266.8125\nINFO:root:0: Epoch 0 train loss: 1580.1414794921875\nINFO:root:0: Epoch 0 validation loss: 142400.70234602512\nINFO:root:1: Epoch 1 train loss: 167466.421875\nINFO:root:0: Epoch 1 train loss: 1090.322021484375\nINFO:root:7: Epoch 1 train loss: 7163.6943359375\nINFO:root:4: Epoch 1 train loss: 2941.182861328125\nINFO:root:3: Epoch 1 train loss: 1912.410400390625\nINFO:root:5: Epoch 1 train loss: 2507.69775390625\nINFO:root:6: Epoch 1 train loss: 179841.671875\nINFO:root:9: Epoch 1 train loss: 379751.4375\nINFO:root:12: Epoch 1 train loss: 210178.453125\nINFO:root:8: Epoch 1 train loss: 174282.140625\nINFO:root:13: Epoch 1 train loss: 188599.71875\nINFO:root:15: Epoch 1 train loss: 3826.820556640625\nINFO:root:14: Epoch 1 train loss: 2008.2808837890625\nINFO:root:2: Epoch 1 train loss: 3981.068603515625\nINFO:root:11: Epoch 1 train loss: 1035.571044921875\nINFO:root:10: Epoch 1 train loss: 5149.78955078125\nINFO:root:0: Epoch 1 validation loss: 142396.31720293305\nINFO:root:11: Epoch 2 train loss: 3695.340087890625\nINFO:root:3: Epoch 2 train loss: 167818.5\nINFO:root:7: Epoch 2 train loss: 1011.010986328125\nINFO:root:5: Epoch 2 train loss: 175263.84375\nINFO:root:14: Epoch 2 train loss: 343.202880859375\nINFO:root:4: Epoch 2 train loss: 2683.31201171875\nINFO:root:6: Epoch 2 train loss: 167948.859375\nINFO:root:15: Epoch 2 train loss: 19397.3125\nINFO:root:1: Epoch 2 train loss: 2157.091796875\nINFO:root:12: Epoch 2 train loss: 396.3289794921875\nINFO:root:10: Epoch 2 train loss: 59779.0\nINFO:root:9: Epoch 2 train loss: 174765.671875\nINFO:root:8: Epoch 2 train loss: 141514.28125\nINFO:root:13: Epoch 2 train loss: 579.0714721679688\nINFO:root:0: Epoch 2 train loss: 1518.7017822265625\nINFO:root:2: Epoch 2 train loss: 20099.923828125\nINFO:root:0: Epoch 2 validation loss: 142391.90921779492\nINFO:root:4: Epoch 3 train loss: 167580.296875\nINFO:root:5: Epoch 3 train loss: 403568.5625\nINFO:root:7: Epoch 3 train loss: 1714.7005615234375\nINFO:root:13: Epoch 3 train loss: 9690.779296875\nINFO:root:10: Epoch 3 train loss: 206766.6875\nINFO:root:15: Epoch 3 train loss: 6731.42333984375\nINFO:root:12: Epoch 3 train loss: 20614.73046875\nINFO:root:11: Epoch 3 train loss: 2805.915283203125\nINFO:root:14: Epoch 3 train loss: 60942.50390625\nINFO:root:3: Epoch 3 train loss: 151474.640625\nINFO:root:6: Epoch 3 train loss: 2595.717529296875\nINFO:root:1: Epoch 3 train loss: 229408.390625\nINFO:root:2: Epoch 3 train loss: 155135.21875\nINFO:root:9: Epoch 3 train loss: 1424.4974365234375\nINFO:root:8: Epoch 3 train loss: 385829.21875\nINFO:root:0: Epoch 3 train loss: 207309.953125\nINFO:root:0: Epoch 3 validation loss: 142387.52017932473\nINFO:root:4: Epoch 4 train loss: 6980.1533203125\nINFO:root:3: Epoch 4 train loss: 2324.518798828125\nINFO:root:15: Epoch 4 train loss: 374462.4375\nINFO:root:14: Epoch 4 train loss: 2113.076904296875\nINFO:root:5: Epoch 4 train loss: 360132.1875\nINFO:root:1: Epoch 4 train loss: 20512.337890625\nINFO:root:2: Epoch 4 train loss: 210320.734375\nINFO:root:13: Epoch 4 train loss: 536.8579711914062\nINFO:root:11: Epoch 4 train loss: 60409.625\nINFO:root:10: Epoch 4 train loss: 151947.609375\nINFO:root:12: Epoch 4 train loss: 152310.34375\nINFO:root:0: Epoch 4 train loss: 4219.916015625\nINFO:root:7: Epoch 4 train loss: 192932.609375\nINFO:root:6: Epoch 4 train loss: 4519.26025390625\nINFO:root:8: Epoch 4 train loss: 165837.65625\nINFO:root:9: Epoch 4 train loss: 1005.4964599609375\nINFO:root:0: Epoch 4 validation loss: 142383.10263178148\nINFO:root:11: Epoch 5 train loss: 166982.8125\nINFO:root:5: Epoch 5 train loss: 3543.412353515625\nINFO:root:10: Epoch 5 train loss: 6550.84765625\nINFO:root:4: Epoch 5 train loss: 3676.76318359375\nINFO:root:1: Epoch 5 train loss: 973.2632446289062\nINFO:root:0: Epoch 5 train loss: 191.6902313232422\nINFO:root:13: Epoch 5 train loss: 2304.857666015625\nINFO:root:8: Epoch 5 train loss: 151084.359375\nINFO:root:12: Epoch 5 train loss: 60325.71484375\nINFO:root:9: Epoch 5 train loss: 187839.703125\nINFO:root:2: Epoch 5 train loss: 1324.1846923828125\nINFO:root:3: Epoch 5 train loss: 684.4302978515625\nINFO:root:15: Epoch 5 train loss: 174202.203125\nINFO:root:14: Epoch 5 train loss: 2618.217041015625\nINFO:root:7: Epoch 5 train loss: 2261.451416015625\nINFO:root:6: Epoch 5 train loss: 3038.156494140625\nINFO:root:0: Epoch 5 validation loss: 142378.67363985794\n", "seconds": 14.272284746170044, "batch_size": 256, "nodes": 8, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n2 Start Epoch 0\n2: 1 batches\n1: 1 batches\n17 Start Epoch 0\n17: 1 batches\n4 Start Epoch 0\n12 Start Epoch 0\n3 Start Epoch 0\n3: 1 batches\n12: 1 batches\n4: 1 batches\n8 Start Epoch 0\n11 Start Epoch 0\n8: 1 batches\n11: 1 batches\n7 Start Epoch 0\n16 Start Epoch 0\n7: 1 batches\n16: 1 batches\n15 Start Epoch 0\n15: 1 batches\n10 Start Epoch 0\n6 Start Epoch 0\n5 Start Epoch 0\n9 Start Epoch 0\n10: 1 batches\n6: 1 batches\n14 Start Epoch 0\n14: 1 batches\n13 Start Epoch 0\n5: 1 batches\n9: 1 batches\n13: 1 batches\n15 Start Epoch 1\n15: 1 batches\n1 Start Epoch 1\n1: 1 batches\n3 Start Epoch 1\n2 Start Epoch 1\n2: 1 batches\n3: 1 batches\n6 Start Epoch 1\n7 Start Epoch 1\n7: 1 batches\n6: 1 batches\n16 Start Epoch 1\n16: 1 batches\n17 Start Epoch 1\n17: 1 batches\n5 Start Epoch 1\n5: 1 batches\n4 Start Epoch 1\n9 Start Epoch 1\n11 Start Epoch 1\n11: 1 batches\n4: 1 batches\n8 Start Epoch 1\n8: 1 batches\n10 Start Epoch 1\n10: 1 batches\n9: 1 batches\n14 Start Epoch 1\n14: 1 batches\n13 Start Epoch 1\n13: 1 batches\n12 Start Epoch 1\n12: 1 batches\n0 Start Epoch 1\n0: 1 batches\n6 Start Epoch 2\n7 Start Epoch 2\n3 Start Epoch 2\n7: 1 batches\n2 Start Epoch 2\n2: 1 batches\n15 Start Epoch 2\n3: 1 batches\n14 Start Epoch 2\n15: 1 batches\n1 Start Epoch 2\n5 Start Epoch 2\n5: 1 batches\n16 Start Epoch 2\n13 Start Epoch 2\n16: 1 batches\n13: 1 batches\n8 Start Epoch 2\n1: 1 batches\n11 Start Epoch 2\n17 Start Epoch 2\n12 Start Epoch 2\n17: 1 batches\n12: 1 batches\n9 Start Epoch 2\n11: 1 batches\n10 Start Epoch 2\n10: 1 batches\n14: 1 batches\n6: 1 batches\n9: 1 batches\n8: 1 batches\n4 Start Epoch 2\n4: 1 batches\n0 Start Epoch 2\n0: 1 batches\n7 Start Epoch 3\n16 Start Epoch 3\n3 Start Epoch 3\n15 Start Epoch 3\n6 Start Epoch 3\n2 Start Epoch 3\n15: 1 batches\n7: 1 batches\n3: 1 batches\n17 Start Epoch 3\n17: 1 batches\n6: 1 batches\n2: 1 batches\n14 Start Epoch 3\n16: 1 batches\n14: 1 batches\n11 Start Epoch 3\n11: 1 batches\n1 Start Epoch 3\n1: 1 batches\n9 Start Epoch 3\n4 Start Epoch 3\n9: 1 batches\n12 Start Epoch 3\n5 Start Epoch 3\n8 Start Epoch 3\n13 Start Epoch 3\n4: 1 batches\n8: 1 batches\n10 Start Epoch 3\n12: 1 batches\n5: 1 batches\n13: 1 batches\n10: 1 batches\n0 Start Epoch 3\n0: 1 batches\n3 Start Epoch 4\n3: 1 batches\n7 Start Epoch 4\n6 Start Epoch 4\n7: 1 batches\n6: 1 batches\n5 Start Epoch 4\n4 Start Epoch 4\n9 Start Epoch 4\n11 Start Epoch 4\n9: 1 batches\n11: 1 batches\n4: 1 batches\n5: 1 batches\n8 Start Epoch 4\n10 Start Epoch 4\n8: 1 batches\n10: 1 batches\n15 Start Epoch 4\n16 Start Epoch 4\n14 Start Epoch 4\n17 Start Epoch 4\n15: 1 batches\n16: 1 batches\n14: 1 batches\n17: 1 batches\n12 Start Epoch 4\n13 Start Epoch 4\n13: 1 batches\n12: 1 batches\n1 Start Epoch 4\n1: 1 batches\n2 Start Epoch 4\n2: 1 batches\n0 Start Epoch 4\n0: 1 batches\n17 Start Epoch 5\n6 Start Epoch 5\n14 Start Epoch 5\n17: 1 batches\n13 Start Epoch 5\n7 Start Epoch 5\n14: 1 batches\n12 Start Epoch 5\n7: 1 batches\n15 Start Epoch 5\n13: 1 batches\n6: 1 batches\n15: 1 batches\n12: 1 batches\n11 Start Epoch 5\n10 Start Epoch 5\n11: 1 batches\n10: 1 batches\n8 Start Epoch 5\n5 Start Epoch 5\n5: 1 batches\n4 Start Epoch 5\n9 Start Epoch 5\n3 Start Epoch 5\n4: 1 batches\n8: 1 batches\n3: 1 batches\n9: 1 batches\n2 Start Epoch 5\n2: 1 batches\n1 Start Epoch 5\n16 Start Epoch 5\n16: 1 batches\n1: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:15: Epoch 0 train loss: 1315.180419921875\nINFO:root:0: Epoch 0 train loss: 228755.828125\nINFO:root:1: Epoch 0 train loss: 1048.6087646484375\nINFO:root:2: Epoch 0 train loss: 3774.125\nINFO:root:3: Epoch 0 train loss: 28148.990234375\nINFO:root:6: Epoch 0 train loss: 362194.03125\nINFO:root:7: Epoch 0 train loss: 3008.9296875\nINFO:root:16: Epoch 0 train loss: 7008.41064453125\nINFO:root:17: Epoch 0 train loss: 208962.5\nINFO:root:5: Epoch 0 train loss: 160459.546875\nINFO:root:4: Epoch 0 train loss: 196671.390625\nINFO:root:8: Epoch 0 train loss: 830.3223266601562\nINFO:root:11: Epoch 0 train loss: 1341.0498046875\nINFO:root:9: Epoch 0 train loss: 1074.471923828125\nINFO:root:10: Epoch 0 train loss: 1364.6153564453125\nINFO:root:14: Epoch 0 train loss: 187903.609375\nINFO:root:12: Epoch 0 train loss: 202698.1875\nINFO:root:13: Epoch 0 train loss: 389976.03125\nINFO:root:0: Epoch 0 validation loss: 121008.29561594868\nINFO:root:7: Epoch 1 train loss: 6622.369140625\nINFO:root:6: Epoch 1 train loss: 299140.375\nINFO:root:2: Epoch 1 train loss: 212185.09375\nINFO:root:3: Epoch 1 train loss: 4065.451416015625\nINFO:root:15: Epoch 1 train loss: 516.2860717773438\nINFO:root:14: Epoch 1 train loss: 521.884521484375\nINFO:root:1: Epoch 1 train loss: 1204.8104248046875\nINFO:root:5: Epoch 1 train loss: 434668.5\nINFO:root:12: Epoch 1 train loss: 4542.20361328125\nINFO:root:17: Epoch 1 train loss: 70865.8046875\nINFO:root:10: Epoch 1 train loss: 232927.0\nINFO:root:16: Epoch 1 train loss: 354529.4375\nINFO:root:13: Epoch 1 train loss: 1311.5052490234375\nINFO:root:9: Epoch 1 train loss: 7254.46435546875\nINFO:root:11: Epoch 1 train loss: 2782.269775390625\nINFO:root:8: Epoch 1 train loss: 574.5173950195312\nINFO:root:4: Epoch 1 train loss: 1056.88330078125\nINFO:root:0: Epoch 1 train loss: 68351.046875\nINFO:root:0: Epoch 1 validation loss: 121004.62857364342\nINFO:root:6: Epoch 2 train loss: 22052.396484375\nINFO:root:3: Epoch 2 train loss: 3041.48095703125\nINFO:root:2: Epoch 2 train loss: 1182.857666015625\nINFO:root:15: Epoch 2 train loss: 988.6021728515625\nINFO:root:16: Epoch 2 train loss: 496.8024597167969\nINFO:root:7: Epoch 2 train loss: 66988.2265625\nINFO:root:17: Epoch 2 train loss: 1252.0234375\nINFO:root:14: Epoch 2 train loss: 210367.296875\nINFO:root:11: Epoch 2 train loss: 1720.309326171875\nINFO:root:8: Epoch 2 train loss: 821.4089965820312\nINFO:root:1: Epoch 2 train loss: 6727.5888671875\nINFO:root:4: Epoch 2 train loss: 233946.0625\nINFO:root:9: Epoch 2 train loss: 1825.214599609375\nINFO:root:12: Epoch 2 train loss: 161116.6875\nINFO:root:5: Epoch 2 train loss: 3095.414306640625\nINFO:root:13: Epoch 2 train loss: 2458.697265625\nINFO:root:10: Epoch 2 train loss: 26910.466796875\nINFO:root:0: Epoch 2 train loss: 355321.28125\nINFO:root:0: Epoch 2 validation loss: 121000.98839728907\nINFO:root:3: Epoch 3 train loss: 2837.4296875\nINFO:root:7: Epoch 3 train loss: 25585.494140625\nINFO:root:6: Epoch 3 train loss: 232793.984375\nINFO:root:4: Epoch 3 train loss: 189637.546875\nINFO:root:5: Epoch 3 train loss: 1042.8536376953125\nINFO:root:9: Epoch 3 train loss: 1369.8017578125\nINFO:root:11: Epoch 3 train loss: 29619.94921875\nINFO:root:8: Epoch 3 train loss: 2535.435302734375\nINFO:root:10: Epoch 3 train loss: 211370.453125\nINFO:root:15: Epoch 3 train loss: 1415.1373291015625\nINFO:root:17: Epoch 3 train loss: 188513.703125\nINFO:root:14: Epoch 3 train loss: 2225.0771484375\nINFO:root:16: Epoch 3 train loss: 2490.58837890625\nINFO:root:2: Epoch 3 train loss: 22985.984375\nINFO:root:12: Epoch 3 train loss: 1883.77001953125\nINFO:root:13: Epoch 3 train loss: 246.8318634033203\nINFO:root:0: Epoch 3 train loss: 277730.65625\nINFO:root:1: Epoch 3 train loss: 990.820556640625\nINFO:root:0: Epoch 3 validation loss: 120997.39575791846\nINFO:root:6: Epoch 4 train loss: 379.8952331542969\nINFO:root:14: Epoch 4 train loss: 1511.29541015625\nINFO:root:17: Epoch 4 train loss: 954.7613525390625\nINFO:root:12: Epoch 4 train loss: 751.6481323242188\nINFO:root:15: Epoch 4 train loss: 212846.671875\nINFO:root:13: Epoch 4 train loss: 5125.734375\nINFO:root:7: Epoch 4 train loss: 232991.953125\nINFO:root:11: Epoch 4 train loss: 3997.421142578125\nINFO:root:10: Epoch 4 train loss: 3239.390869140625\nINFO:root:8: Epoch 4 train loss: 3055.7314453125\nINFO:root:5: Epoch 4 train loss: 2359.50537109375\nINFO:root:2: Epoch 4 train loss: 1958.8472900390625\nINFO:root:4: Epoch 4 train loss: 2884.810302734375\nINFO:root:3: Epoch 4 train loss: 8971.28125\nINFO:root:9: Epoch 4 train loss: 4926.02294921875\nINFO:root:0: Epoch 4 train loss: 835.908447265625\nINFO:root:1: Epoch 4 train loss: 329.001708984375\nINFO:root:16: Epoch 4 train loss: 1403.8936767578125\nINFO:root:0: Epoch 4 validation loss: 120993.85289252973\nINFO:root:12: Epoch 5 train loss: 232474.203125\nINFO:root:13: Epoch 5 train loss: 2665.621337890625\nINFO:root:7: Epoch 5 train loss: 1802.4285888671875\nINFO:root:6: Epoch 5 train loss: 23730.380859375\nINFO:root:5: Epoch 5 train loss: 5156.1201171875\nINFO:root:4: Epoch 5 train loss: 201135.046875\nINFO:root:9: Epoch 5 train loss: 6522.71142578125\nINFO:root:8: Epoch 5 train loss: 2737.9052734375\nINFO:root:1: Epoch 5 train loss: 298011.9375\nINFO:root:11: Epoch 5 train loss: 994.3094482421875\nINFO:root:10: Epoch 5 train loss: 656.1651611328125\nINFO:root:0: Epoch 5 train loss: 882.4431762695312\nINFO:root:16: Epoch 5 train loss: 2351.400634765625\nINFO:root:2: Epoch 5 train loss: 2405.21240234375\nINFO:root:17: Epoch 5 train loss: 1502.638916015625\nINFO:root:3: Epoch 5 train loss: 22972.025390625\nINFO:root:15: Epoch 5 train loss: 237004.359375\nINFO:root:14: Epoch 5 train loss: 473.36041259765625\nINFO:root:0: Epoch 5 validation loss: 120990.29206496823\n", "seconds": 14.8491530418396, "batch_size": 256, "nodes": 9, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 1 batches\n2: 1 batches\n7 Start Epoch 0\n4 Start Epoch 0\n7: 1 batches\n8 Start Epoch 0\n3 Start Epoch 0\n15 Start Epoch 0\n16 Start Epoch 0\n3: 1 batches\n15: 1 batches\n11 Start Epoch 0\n4: 1 batches\n12 Start Epoch 0\n19 Start Epoch 0\n8: 1 batches\n11: 1 batches\n12: 1 batches\n19: 1 batches\n16: 1 batches\n9 Start Epoch 0\n5 Start Epoch 0\n17 Start Epoch 0\n14 Start Epoch 0\n10 Start Epoch 0\n5: 1 batches\n13 Start Epoch 0\n6 Start Epoch 0\n9: 1 batches\n18 Start Epoch 0\n6: 1 batches\n17: 1 batches\n14: 1 batches\n10: 1 batches\n13: 1 batches\n18: 1 batches\n15 Start Epoch 1\n14 Start Epoch 1\n15: 1 batches\n14: 1 batches\n11 Start Epoch 1\n11: 1 batches\n13 Start Epoch 1\n13: 1 batches\n17 Start Epoch 1\n16 Start Epoch 1\n17: 1 batches\n16: 1 batches\n18 Start Epoch 1\n19 Start Epoch 1\n18: 1 batches\n19: 1 batches\n12 Start Epoch 1\n12: 1 batches\n9 Start Epoch 1\n9: 1 batches\n10 Start Epoch 1\n10: 1 batches\n2 Start Epoch 1\n4 Start Epoch 1\n6 Start Epoch 1\n3 Start Epoch 1\n5 Start Epoch 1\n7 Start Epoch 1\n3: 1 batches\n2: 1 batches\n5: 1 batches\n6: 1 batches\n4: 1 batches\n7: 1 batches\n1 Start Epoch 1\n1: 1 batches\n8 Start Epoch 1\n8: 1 batches\n0 Start Epoch 1\n0: 1 batches\n4 Start Epoch 2\n2 Start Epoch 2\n4: 1 batches\n19 Start Epoch 2\n5 Start Epoch 2\n5: 1 batches\n18 Start Epoch 2\n18: 1 batches\n19: 1 batches\n6 Start Epoch 2\n6: 1 batches\n14 Start Epoch 2\n7 Start Epoch 2\n7: 1 batches\n9 Start Epoch 2\n8 Start Epoch 2\n15 Start Epoch 2\n8: 1 batches\n14: 1 batches\n9: 1 batches\n15: 1 batches\n11 Start Epoch 2\n10 Start Epoch 2\n11: 1 batches\n13 Start Epoch 2\n10: 1 batches\n12 Start Epoch 2\n13: 1 batches\n12: 1 batches\n1 Start Epoch 2\n1: 1 batches\n16 Start Epoch 2\n16: 1 batches\n2: 1 batches\n3 Start Epoch 2\n3: 1 batches\n17 Start Epoch 2\n17: 1 batches\n0 Start Epoch 2\n0: 1 batches\n2 Start Epoch 3\n15 Start Epoch 3\n12 Start Epoch 3\n19 Start Epoch 3\n16 Start Epoch 3\n3 Start Epoch 3\n15: 1 batches\n11 Start Epoch 3\n13 Start Epoch 3\n18 Start Epoch 3\n16: 1 batches\n13: 1 batches\n18: 1 batches\n2: 1 batches\n10 Start Epoch 3\n17 Start Epoch 3\n3: 1 batches\n11: 1 batches\n12: 1 batches\n17: 1 batches\n10: 1 batches\n14 Start Epoch 3\n9 Start Epoch 3\n4 Start Epoch 3\n14: 1 batches\n5 Start Epoch 3\n8 Start Epoch 3\n6 Start Epoch 3\n6: 1 batches\n8: 1 batches\n4: 1 batches\n19: 1 batches\n5: 1 batches\n9: 1 batches\n7 Start Epoch 3\n7: 1 batches\n1 Start Epoch 3\n1: 1 batches\n0 Start Epoch 3\n0: 1 batches\n11 Start Epoch 4\n11: 1 batches\n19 Start Epoch 4\n17 Start Epoch 4\n19: 1 batches\n7 Start Epoch 4\n17: 1 batches\n7: 1 batches\n3 Start Epoch 4\n2 Start Epoch 4\n3: 1 batches\n2: 1 batches\n6 Start Epoch 4\n6: 1 batches\n16 Start Epoch 4\n16: 1 batches\n8 Start Epoch 4\n5 Start Epoch 4\n8: 1 batches\n14 Start Epoch 4\n5: 1 batches\n12 Start Epoch 4\n15 Start Epoch 4\n13 Start Epoch 4\n18 Start Epoch 4\n18: 1 batches\n14: 1 batches\n4 Start Epoch 4\n13: 1 batches\n12: 1 batches\n15: 1 batches\n4: 1 batches\n1 Start Epoch 4\n1: 1 batches\n10 Start Epoch 4\n9 Start Epoch 4\n10: 1 batches\n9: 1 batches\n0 Start Epoch 4\n0: 1 batches\n7 Start Epoch 5\n9 Start Epoch 5\n13 Start Epoch 5\n18 Start Epoch 5\n7: 1 batches\n9: 1 batches\n17 Start Epoch 5\n2 Start Epoch 5\n15 Start Epoch 5\n15: 1 batches\n11 Start Epoch 5\n4 Start Epoch 5\n3 Start Epoch 5\n14 Start Epoch 5\n11: 1 batches\n5 Start Epoch 5\n5: 1 batches\n12 Start Epoch 5\n19 Start Epoch 5\n16 Start Epoch 5\n13: 1 batches\n18: 1 batches\n6 Start Epoch 5\n17: 1 batches\n3: 1 batches\n14: 1 batches\n10 Start Epoch 5\n4: 1 batches\n2: 1 batches\n10: 1 batches\n12: 1 batches\n19: 1 batches\n6: 1 batches\n16: 1 batches\n8 Start Epoch 5\n8: 1 batches\n1 Start Epoch 5\n1: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:14: Epoch 0 train loss: 4834.16064453125\nINFO:root:15: Epoch 0 train loss: 4744.123046875\nINFO:root:11: Epoch 0 train loss: 252.9374542236328\nINFO:root:13: Epoch 0 train loss: 2276.51806640625\nINFO:root:16: Epoch 0 train loss: 3312.0703125\nINFO:root:17: Epoch 0 train loss: 1044.4095458984375\nINFO:root:18: Epoch 0 train loss: 1345.87841796875\nINFO:root:19: Epoch 0 train loss: 3717.115234375\nINFO:root:12: Epoch 0 train loss: 423732.75\nINFO:root:9: Epoch 0 train loss: 25190.841796875\nINFO:root:10: Epoch 0 train loss: 9572.6279296875\nINFO:root:0: Epoch 0 train loss: 2097.912841796875\nINFO:root:2: Epoch 0 train loss: 6654.6357421875\nINFO:root:3: Epoch 0 train loss: 234548.1875\nINFO:root:4: Epoch 0 train loss: 233.21987915039062\nINFO:root:7: Epoch 0 train loss: 2376.91845703125\nINFO:root:6: Epoch 0 train loss: 4857.400390625\nINFO:root:5: Epoch 0 train loss: 5868.7099609375\nINFO:root:1: Epoch 0 train loss: 363250.84375\nINFO:root:8: Epoch 0 train loss: 2943.784912109375\nINFO:root:0: Epoch 0 validation loss: 77597.52655700868\nINFO:root:4: Epoch 1 train loss: 2128.274658203125\nINFO:root:3: Epoch 1 train loss: 6192.70751953125\nINFO:root:5: Epoch 1 train loss: 187281.375\nINFO:root:19: Epoch 1 train loss: 24479.244140625\nINFO:root:18: Epoch 1 train loss: 3210.50830078125\nINFO:root:2: Epoch 1 train loss: 2618.273193359375\nINFO:root:14: Epoch 1 train loss: 235028.5625\nINFO:root:6: Epoch 1 train loss: 28151.255859375\nINFO:root:7: Epoch 1 train loss: 283.4082946777344\nINFO:root:8: Epoch 1 train loss: 215454.515625\nINFO:root:9: Epoch 1 train loss: 215734.390625\nINFO:root:15: Epoch 1 train loss: 6380.7958984375\nINFO:root:11: Epoch 1 train loss: 2267.2841796875\nINFO:root:10: Epoch 1 train loss: 1142.44482421875\nINFO:root:12: Epoch 1 train loss: 6301.11865234375\nINFO:root:13: Epoch 1 train loss: 259242.171875\nINFO:root:1: Epoch 1 train loss: 4003.7685546875\nINFO:root:0: Epoch 1 train loss: 1249.1640625\nINFO:root:17: Epoch 1 train loss: 1482.4984130859375\nINFO:root:16: Epoch 1 train loss: 5290.328125\nINFO:root:0: Epoch 1 validation loss: 77592.85672483372\nINFO:root:18: Epoch 2 train loss: 393763.3125\nINFO:root:2: Epoch 2 train loss: 191251.921875\nINFO:root:13: Epoch 2 train loss: 4293.06884765625\nINFO:root:15: Epoch 2 train loss: 3995.305419921875\nINFO:root:10: Epoch 2 train loss: 858.0567626953125\nINFO:root:12: Epoch 2 train loss: 370.4868469238281\nINFO:root:19: Epoch 2 train loss: 3016.519775390625\nINFO:root:16: Epoch 2 train loss: 4186.4794921875\nINFO:root:3: Epoch 2 train loss: 216730.625\nINFO:root:11: Epoch 2 train loss: 185252.609375\nINFO:root:17: Epoch 2 train loss: 6419.22509765625\nINFO:root:0: Epoch 2 train loss: 5901.0029296875\nINFO:root:9: Epoch 2 train loss: 3645.71044921875\nINFO:root:14: Epoch 2 train loss: 2818.3046875\nINFO:root:4: Epoch 2 train loss: 905.26416015625\nINFO:root:5: Epoch 2 train loss: 1395.65380859375\nINFO:root:8: Epoch 2 train loss: 220049.875\nINFO:root:7: Epoch 2 train loss: 1569.9476318359375\nINFO:root:6: Epoch 2 train loss: 2498.251708984375\nINFO:root:1: Epoch 2 train loss: 604.146484375\nINFO:root:0: Epoch 2 validation loss: 77588.21408043937\nINFO:root:17: Epoch 3 train loss: 233105.5625\nINFO:root:11: Epoch 3 train loss: 443.2667236328125\nINFO:root:19: Epoch 3 train loss: 263304.75\nINFO:root:7: Epoch 3 train loss: 2707.97998046875\nINFO:root:3: Epoch 3 train loss: 5868.7451171875\nINFO:root:2: Epoch 3 train loss: 2249.61865234375\nINFO:root:6: Epoch 3 train loss: 7992.5947265625\nINFO:root:16: Epoch 3 train loss: 759.482177734375\nINFO:root:8: Epoch 3 train loss: 3191.529296875\nINFO:root:0: Epoch 3 train loss: 216835.703125\nINFO:root:15: Epoch 3 train loss: 913.258056640625\nINFO:root:5: Epoch 3 train loss: 1866.151611328125\nINFO:root:13: Epoch 3 train loss: 1969.8143310546875\nINFO:root:14: Epoch 3 train loss: 1118.18359375\nINFO:root:12: Epoch 3 train loss: 457.0317687988281\nINFO:root:18: Epoch 3 train loss: 33869.3671875\nINFO:root:4: Epoch 3 train loss: 265307.90625\nINFO:root:1: Epoch 3 train loss: 2491.52392578125\nINFO:root:10: Epoch 3 train loss: 128.32432556152344\nINFO:root:9: Epoch 3 train loss: 4965.00927734375\nINFO:root:0: Epoch 3 validation loss: 77583.5419625153\nINFO:root:2: Epoch 4 train loss: 137.6302947998047\nINFO:root:15: Epoch 4 train loss: 234805.078125\nINFO:root:11: Epoch 4 train loss: 423.36029052734375\nINFO:root:4: Epoch 4 train loss: 2362.42626953125\nINFO:root:12: Epoch 4 train loss: 6807.87109375\nINFO:root:19: Epoch 4 train loss: 25047.216796875\nINFO:root:7: Epoch 4 train loss: 40.521812438964844\nINFO:root:9: Epoch 4 train loss: 573.3084106445312\nINFO:root:16: Epoch 4 train loss: 1643.0406494140625\nINFO:root:17: Epoch 4 train loss: 503883.125\nINFO:root:3: Epoch 4 train loss: 215334.0\nINFO:root:14: Epoch 4 train loss: 200793.53125\nINFO:root:10: Epoch 4 train loss: 259114.953125\nINFO:root:5: Epoch 4 train loss: 4230.7958984375\nINFO:root:13: Epoch 4 train loss: 1441.52392578125\nINFO:root:18: Epoch 4 train loss: 2378.87939453125\nINFO:root:6: Epoch 4 train loss: 1285.7186279296875\nINFO:root:0: Epoch 4 train loss: 235794.46875\nINFO:root:8: Epoch 4 train loss: 186609.625\nINFO:root:1: Epoch 4 train loss: 2300.035400390625\nINFO:root:0: Epoch 4 validation loss: 77578.8572625435\nINFO:root:15: Epoch 5 train loss: 2002.3848876953125\nINFO:root:4: Epoch 5 train loss: 185762.25\nINFO:root:3: Epoch 5 train loss: 2671.97998046875\nINFO:root:5: Epoch 5 train loss: 1505.958984375\nINFO:root:2: Epoch 5 train loss: 658.3517456054688\nINFO:root:6: Epoch 5 train loss: 264733.0625\nINFO:root:17: Epoch 5 train loss: 441782.375\nINFO:root:16: Epoch 5 train loss: 32693.1640625\nINFO:root:18: Epoch 5 train loss: 1295.005859375\nINFO:root:12: Epoch 5 train loss: 818.5198364257812\nINFO:root:19: Epoch 5 train loss: 407145.5\nINFO:root:7: Epoch 5 train loss: 2897.617431640625\nINFO:root:8: Epoch 5 train loss: 233178.875\nINFO:root:9: Epoch 5 train loss: 222072.84375\nINFO:root:13: Epoch 5 train loss: 921.8394775390625\nINFO:root:0: Epoch 5 train loss: 873.5353393554688\nINFO:root:14: Epoch 5 train loss: 193119.21875\nINFO:root:10: Epoch 5 train loss: 1613.029052734375\nINFO:root:11: Epoch 5 train loss: 715.4088745117188\nINFO:root:1: Epoch 5 train loss: 72866.2734375\nINFO:root:0: Epoch 5 validation loss: 77574.12785959063\n", "seconds": 15.198071956634521, "batch_size": 256, "nodes": 10, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n1: 1 batches\n2 Start Epoch 0\n2: 1 batches\n3 Start Epoch 0\n3: 1 batches\n7 Start Epoch 0\n7: 1 batches\n4 Start Epoch 0\n4: 1 batches\n21 Start Epoch 0\n8 Start Epoch 0\n21: 1 batches\n8: 1 batches\n16 Start Epoch 0\n6 Start Epoch 0\n16: 1 batches\n6: 1 batches\n15 Start Epoch 0\n15: 1 batches\n13 Start Epoch 0\n5 Start Epoch 0\n13: 1 batches\n14 Start Epoch 0\n14: 1 batches\n5: 1 batches\n9 Start Epoch 0\n9: 1 batches\n18 Start Epoch 0\n17 Start Epoch 0\n18: 1 batches\n17: 1 batches\n10 Start Epoch 0\n10: 1 batches\n12 Start Epoch 0\n12: 1 batches\n20 Start Epoch 0\n20: 1 batches\n19 Start Epoch 0\n19: 1 batches\n11 Start Epoch 0\n11: 1 batches\n10 Start Epoch 1\n19 Start Epoch 1\n10: 1 batches\n19: 1 batches\n11 Start Epoch 1\n4 Start Epoch 1\n6 Start Epoch 1\n11: 1 batches\n4: 1 batches\n7 Start Epoch 1\n16 Start Epoch 1\n5 Start Epoch 1\n7: 1 batches\n3 Start Epoch 1\n16: 1 batches\n5: 1 batches\n6: 1 batches\n3: 1 batches\n17 Start Epoch 1\n17: 1 batches\n2 Start Epoch 1\n2: 1 batches\n9 Start Epoch 1\n9: 1 batches\n18 Start Epoch 1\n13 Start Epoch 1\n18: 1 batches\n13: 1 batches\n15 Start Epoch 1\n14 Start Epoch 1\n20 Start Epoch 1\n12 Start Epoch 1\n12: 1 batches\n14: 1 batches\n20: 1 batches\n15: 1 batches\n21 Start Epoch 1\n21: 1 batches\n1 Start Epoch 1\n1: 1 batches\n8 Start Epoch 1\n8: 1 batches\n0 Start Epoch 1\n0: 1 batches\n3 Start Epoch 2\n2 Start Epoch 2\n3: 1 batches\n6 Start Epoch 2\n7 Start Epoch 2\n6: 1 batches\n19 Start Epoch 2\n16 Start Epoch 2\n18 Start Epoch 2\n18: 1 batches\n17 Start Epoch 2\n16: 1 batches\n19: 1 batches\n17: 1 batches\n2: 1 batches\n15 Start Epoch 2\n11 Start Epoch 2\n1 Start Epoch 2\n1: 1 batches\n9 Start Epoch 2\n7: 1 batches\n5 Start Epoch 2\n15: 1 batches\n11: 1 batches\n20 Start Epoch 2\n9: 1 batches\n20: 1 batches\n4 Start Epoch 2\n5: 1 batches\n14 Start Epoch 2\n21 Start Epoch 2\n14: 1 batches\n21: 1 batches\n4: 1 batches\n13 Start Epoch 2\n12 Start Epoch 2\n12: 1 batches\n13: 1 batches\n10 Start Epoch 2\n10: 1 batches\n8 Start Epoch 2\n8: 1 batches\n0 Start Epoch 2\n0: 1 batches\n10 Start Epoch 3\n19 Start Epoch 3\n7 Start Epoch 3\n11 Start Epoch 3\n18 Start Epoch 3\n4 Start Epoch 3\n6 Start Epoch 3\n15 Start Epoch 3\n5 Start Epoch 3\n7: 1 batches\n10: 1 batches\n14 Start Epoch 3\n18: 1 batches\n5: 1 batches\n6: 1 batches\n3 Start Epoch 3\n16 Start Epoch 3\n16: 1 batches\n19: 1 batches\n4: 1 batches\n3: 1 batches\n2 Start Epoch 3\n14: 1 batches\n15: 1 batches\n2: 1 batches\n17 Start Epoch 3\n12 Start Epoch 3\n11: 1 batches\n20 Start Epoch 3\n8 Start Epoch 3\n17: 1 batches\n12: 1 batches\n20: 1 batches\n9 Start Epoch 3\n13 Start Epoch 3\n21 Start Epoch 3\n9: 1 batches\n13: 1 batches\n21: 1 batches\n8: 1 batches\n1 Start Epoch 3\n1: 1 batches\n0 Start Epoch 3\n0: 1 batches\n7 Start Epoch 4\n6 Start Epoch 4\n7: 1 batches\n6: 1 batches\n19 Start Epoch 4\n17 Start Epoch 4\n18 Start Epoch 4\n19: 1 batches\n16 Start Epoch 4\n15 Start Epoch 4\n15: 1 batches\n18: 1 batches\n16: 1 batches\n14 Start Epoch 4\n14: 1 batches\n9 Start Epoch 4\n21 Start Epoch 4\n12 Start Epoch 4\n11 Start Epoch 4\n21: 1 batches\n8 Start Epoch 4\n8: 1 batches\n13 Start Epoch 4\n10 Start Epoch 4\n20 Start Epoch 4\n20: 1 batches\n9: 1 batches\n12: 1 batches\n10: 1 batches\n13: 1 batches\n11: 1 batches\n3 Start Epoch 4\n3: 1 batches\n17: 1 batches\n2 Start Epoch 4\n2: 1 batches\n1 Start Epoch 4\n1: 1 batches\n4 Start Epoch 4\n4: 1 batches\n5 Start Epoch 4\n5: 1 batches\n0 Start Epoch 4\n0: 1 batches\n19 Start Epoch 5\n19: 1 batches\n17 Start Epoch 5\n17: 1 batches\n3 Start Epoch 5\n3: 1 batches\n15 Start Epoch 5\n4 Start Epoch 5\n16 Start Epoch 5\n4: 1 batches\n16: 1 batches\n20 Start Epoch 5\n21 Start Epoch 5\n21: 1 batches\n20: 1 batches\n1 Start Epoch 5\n1: 1 batches\n14 Start Epoch 5\n14: 1 batches\n15: 1 batches\n5 Start Epoch 5\n5: 1 batches\n18 Start Epoch 5\n18: 1 batches\n7 Start Epoch 5\n7: 1 batches\n6 Start Epoch 5\n6: 1 batches\n2 Start Epoch 5\n2: 1 batches\n11 Start Epoch 5\n10 Start Epoch 5\n10: 1 batches\n11: 1 batches\n13 Start Epoch 5\n13: 1 batches\n8 Start Epoch 5\n9 Start Epoch 5\n9: 1 batches\n8: 1 batches\n12 Start Epoch 5\n12: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:11: Epoch 0 train loss: 27337.12890625\nINFO:root:10: Epoch 0 train loss: 933.6996459960938\nINFO:root:19: Epoch 0 train loss: 193846.84375\nINFO:root:5: Epoch 0 train loss: 1377.5634765625\nINFO:root:6: Epoch 0 train loss: 4611.10205078125\nINFO:root:16: Epoch 0 train loss: 1563.19873046875\nINFO:root:4: Epoch 0 train loss: 1268.48193359375\nINFO:root:7: Epoch 0 train loss: 2422.16943359375\nINFO:root:2: Epoch 0 train loss: 4681.17626953125\nINFO:root:17: Epoch 0 train loss: 1495.427001953125\nINFO:root:3: Epoch 0 train loss: 2051.329345703125\nINFO:root:9: Epoch 0 train loss: 728.7493896484375\nINFO:root:18: Epoch 0 train loss: 503.1100158691406\nINFO:root:13: Epoch 0 train loss: 3055.895751953125\nINFO:root:15: Epoch 0 train loss: 220.17906188964844\nINFO:root:0: Epoch 0 train loss: 228131.4375\nINFO:root:14: Epoch 0 train loss: 237939.0\nINFO:root:21: Epoch 0 train loss: 134.4613800048828\nINFO:root:12: Epoch 0 train loss: 2394.49951171875\nINFO:root:20: Epoch 0 train loss: 242508.546875\nINFO:root:1: Epoch 0 train loss: 245750.625\nINFO:root:8: Epoch 0 train loss: 3695.11474609375\nINFO:root:0: Epoch 0 validation loss: 338500015.52094257\nINFO:root:3: Epoch 1 train loss: 1885.321044921875\nINFO:root:2: Epoch 1 train loss: 1728.5919189453125\nINFO:root:7: Epoch 1 train loss: 236980.734375\nINFO:root:6: Epoch 1 train loss: 205623.546875\nINFO:root:19: Epoch 1 train loss: 287098.09375\nINFO:root:18: Epoch 1 train loss: 245927.328125\nINFO:root:17: Epoch 1 train loss: 2691.85791015625\nINFO:root:16: Epoch 1 train loss: 85880.765625\nINFO:root:4: Epoch 1 train loss: 2152.419189453125\nINFO:root:15: Epoch 1 train loss: 207092.265625\nINFO:root:11: Epoch 1 train loss: 283887.625\nINFO:root:20: Epoch 1 train loss: 982.080078125\nINFO:root:9: Epoch 1 train loss: 4109.0048828125\nINFO:root:21: Epoch 1 train loss: 2227.030029296875\nINFO:root:1: Epoch 1 train loss: 3395.3720703125\nINFO:root:0: Epoch 1 train loss: 1065.66650390625\nINFO:root:5: Epoch 1 train loss: 30242.83984375\nINFO:root:13: Epoch 1 train loss: 1443.6842041015625\nINFO:root:14: Epoch 1 train loss: 813.5073852539062\nINFO:root:12: Epoch 1 train loss: 1324.4044189453125\nINFO:root:10: Epoch 1 train loss: 2116.155517578125\nINFO:root:8: Epoch 1 train loss: 198111.9375\nINFO:root:0: Epoch 1 validation loss: 338499899.56921124\nINFO:root:11: Epoch 2 train loss: 2316.716552734375\nINFO:root:6: Epoch 2 train loss: 3114.70849609375\nINFO:root:19: Epoch 2 train loss: 946.3807983398438\nINFO:root:4: Epoch 2 train loss: 200791.15625\nINFO:root:7: Epoch 2 train loss: 2149.27734375\nINFO:root:10: Epoch 2 train loss: 1028.8310546875\nINFO:root:5: Epoch 2 train loss: 3473.457763671875\nINFO:root:15: Epoch 2 train loss: 1144.1885986328125\nINFO:root:2: Epoch 2 train loss: 249892.953125\nINFO:root:18: Epoch 2 train loss: 295.4798583984375\nINFO:root:3: Epoch 2 train loss: 194804.890625\nINFO:root:16: Epoch 2 train loss: 273176.46875\nINFO:root:14: Epoch 2 train loss: 3779.452880859375\nINFO:root:20: Epoch 2 train loss: 250307.90625\nINFO:root:9: Epoch 2 train loss: 4658.36328125\nINFO:root:17: Epoch 2 train loss: 325768.09375\nINFO:root:12: Epoch 2 train loss: 2289.1513671875\nINFO:root:13: Epoch 2 train loss: 312731.46875\nINFO:root:21: Epoch 2 train loss: 7591.15625\nINFO:root:8: Epoch 2 train loss: 263618.53125\nINFO:root:0: Epoch 2 train loss: 2762.52587890625\nINFO:root:1: Epoch 2 train loss: 228180.40625\nINFO:root:0: Epoch 2 validation loss: 338499783.5877608\nINFO:root:6: Epoch 3 train loss: 950.7744750976562\nINFO:root:7: Epoch 3 train loss: 235148.015625\nINFO:root:19: Epoch 3 train loss: 195684.625\nINFO:root:17: Epoch 3 train loss: 1675.8582763671875\nINFO:root:18: Epoch 3 train loss: 1337.3079833984375\nINFO:root:16: Epoch 3 train loss: 476203.09375\nINFO:root:15: Epoch 3 train loss: 88362.1328125\nINFO:root:14: Epoch 3 train loss: 3468.04443359375\nINFO:root:9: Epoch 3 train loss: 252035.9375\nINFO:root:21: Epoch 3 train loss: 4462.009765625\nINFO:root:13: Epoch 3 train loss: 257840.765625\nINFO:root:10: Epoch 3 train loss: 251015.609375\nINFO:root:20: Epoch 3 train loss: 377.1955871582031\nINFO:root:4: Epoch 3 train loss: 1845.84423828125\nINFO:root:12: Epoch 3 train loss: 779.4564819335938\nINFO:root:11: Epoch 3 train loss: 28005.94921875\nINFO:root:8: Epoch 3 train loss: 1706.35302734375\nINFO:root:2: Epoch 3 train loss: 28379.029296875\nINFO:root:3: Epoch 3 train loss: 258003.53125\nINFO:root:1: Epoch 3 train loss: 782.5317993164062\nINFO:root:0: Epoch 3 train loss: 434028.09375\nINFO:root:5: Epoch 3 train loss: 5466.83203125\nINFO:root:0: Epoch 3 validation loss: 338499667.6926437\nINFO:root:19: Epoch 4 train loss: 840.9243774414062\nINFO:root:17: Epoch 4 train loss: 5354.3837890625\nINFO:root:3: Epoch 4 train loss: 27907.09375\nINFO:root:5: Epoch 4 train loss: 205250.15625\nINFO:root:4: Epoch 4 train loss: 1699.076904296875\nINFO:root:16: Epoch 4 train loss: 4288.43310546875\nINFO:root:21: Epoch 4 train loss: 1385.1966552734375\nINFO:root:20: Epoch 4 train loss: 215266.75\nINFO:root:1: Epoch 4 train loss: 7917.51220703125\nINFO:root:0: Epoch 4 train loss: 857.8760986328125\nINFO:root:15: Epoch 4 train loss: 6645.80712890625\nINFO:root:14: Epoch 4 train loss: 1239.1767578125\nINFO:root:6: Epoch 4 train loss: 29062.986328125\nINFO:root:18: Epoch 4 train loss: 83661.578125\nINFO:root:7: Epoch 4 train loss: 192612.421875\nINFO:root:2: Epoch 4 train loss: 87.74102783203125\nINFO:root:10: Epoch 4 train loss: 3064.2744140625\nINFO:root:11: Epoch 4 train loss: 199389.96875\nINFO:root:13: Epoch 4 train loss: 1148.602294921875\nINFO:root:9: Epoch 4 train loss: 311292.5\nINFO:root:8: Epoch 4 train loss: 3937.432373046875\nINFO:root:12: Epoch 4 train loss: 467481.0\nINFO:root:0: Epoch 4 validation loss: 338499586.7704461\nINFO:root:2: Epoch 5 train loss: 485.56024169921875\nINFO:root:11: Epoch 5 train loss: 2055.423828125\nINFO:root:3: Epoch 5 train loss: 27478.591796875\nINFO:root:10: Epoch 5 train loss: 737.843994140625\nINFO:root:7: Epoch 5 train loss: 2214.14404296875\nINFO:root:1: Epoch 5 train loss: 1378.489501953125\nINFO:root:21: Epoch 5 train loss: 3976.78466796875\nINFO:root:19: Epoch 5 train loss: 3289.989990234375\nINFO:root:6: Epoch 5 train loss: 1738.0145263671875\nINFO:root:16: Epoch 5 train loss: 9867.9755859375\nINFO:root:13: Epoch 5 train loss: 3792.33349609375\nINFO:root:15: Epoch 5 train loss: 12304.3037109375\nINFO:root:8: Epoch 5 train loss: 83396.7734375\nINFO:root:18: Epoch 5 train loss: 532.6101684570312\nINFO:root:4: Epoch 5 train loss: 905.9815063476562\nINFO:root:17: Epoch 5 train loss: 917.407958984375\nINFO:root:20: Epoch 5 train loss: 1456.3990478515625\nINFO:root:5: Epoch 5 train loss: 1858.44677734375\nINFO:root:14: Epoch 5 train loss: 86399.9296875\nINFO:root:9: Epoch 5 train loss: 8781.0380859375\nINFO:root:12: Epoch 5 train loss: 396.9422302246094\nINFO:root:0: Epoch 5 train loss: 2972.748779296875\nINFO:root:0: Epoch 5 validation loss: 338499470.29344237\n", "seconds": 15.24559998512268, "batch_size": 256, "nodes": 11, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n23 Start Epoch 0\n23: 1 batches\n1 Start Epoch 0\n1: 1 batches\n2 Start Epoch 0\n2: 1 batches\n4 Start Epoch 0\n4: 1 batches\n8 Start Epoch 0\n15 Start Epoch 0\n7 Start Epoch 0\n16 Start Epoch 0\n8: 1 batches\n7: 1 batches\n3 Start Epoch 0\n16: 1 batches\n15: 1 batches\n3: 1 batches\n20 Start Epoch 0\n20: 1 batches\n12 Start Epoch 0\n12: 1 batches\n6 Start Epoch 0\n5 Start Epoch 0\n19 Start Epoch 0\n17 Start Epoch 0\n5: 1 batches\n19: 1 batches\n17: 1 batches\n9 Start Epoch 0\n6: 1 batches\n9: 1 batches\n18 Start Epoch 0\n10 Start Epoch 0\n11 Start Epoch 0\n18: 1 batches\n11: 1 batches\n10: 1 batches\n13 Start Epoch 0\n14 Start Epoch 0\n13: 1 batches\n14: 1 batches\n21 Start Epoch 0\n22 Start Epoch 0\n21: 1 batches\n22: 1 batches\n6 Start Epoch 1\n7 Start Epoch 1\n7: 1 batches\n6: 1 batches\n3 Start Epoch 1\n2 Start Epoch 1\n3: 1 batches\n2: 1 batches\n5 Start Epoch 1\n1 Start Epoch 1\n11 Start Epoch 1\n1: 1 batches\n8 Start Epoch 1\n5: 1 batches\n11: 1 batches\n9 Start Epoch 1\n10 Start Epoch 1\n10: 1 batches\n8: 1 batches\n9: 1 batches\n4 Start Epoch 1\n4: 1 batches\n19 Start Epoch 1\n19: 1 batches\n18 Start Epoch 1\n18: 1 batches\n13 Start Epoch 1\n13: 1 batches\n14 Start Epoch 1\n17 Start Epoch 1\n15 Start Epoch 1\n16 Start Epoch 1\n14: 1 batches\n21 Start Epoch 1\n15: 1 batches\n20 Start Epoch 1\n16: 1 batches\n21: 1 batches\n17: 1 batches\n20: 1 batches\n23 Start Epoch 1\n22 Start Epoch 1\n23: 1 batches\n22: 1 batches\n12 Start Epoch 1\n12: 1 batches\n0 Start Epoch 1\n0: 1 batches\n7 Start Epoch 2\n7: 1 batches\n6 Start Epoch 2\n3 Start Epoch 2\n6: 1 batches\n3: 1 batches\n19 Start Epoch 2\n19: 1 batches\n2 Start Epoch 2\n18 Start Epoch 2\n18: 1 batches\n2: 1 batches\n1 Start Epoch 2\n1: 1 batches\n11 Start Epoch 2\n11: 1 batches\n8 Start Epoch 2\n20 Start Epoch 2\n4 Start Epoch 2\n17 Start Epoch 2\n13 Start Epoch 2\n23 Start Epoch 2\n9 Start Epoch 2\n15 Start Epoch 2\n22 Start Epoch 2\n8: 1 batches\n14 Start Epoch 2\n21 Start Epoch 2\n4: 1 batches\n16 Start Epoch 2\n12 Start Epoch 2\n5 Start Epoch 2\n16: 1 batches\n12: 1 batches\n22: 1 batches\n9: 1 batches\n14: 1 batches\n21: 1 batches\n15: 1 batches\n20: 1 batches\n5: 1 batches\n17: 1 batches\n10 Start Epoch 2\n13: 1 batches\n23: 1 batches\n10: 1 batches\n0 Start Epoch 2\n0: 1 batches\n19 Start Epoch 3\n7 Start Epoch 3\n18 Start Epoch 3\n14 Start Epoch 3\n7: 1 batches\n5 Start Epoch 3\n2 Start Epoch 3\n17 Start Epoch 3\n15 Start Epoch 3\n21 Start Epoch 3\n5: 1 batches\n3 Start Epoch 3\n17: 1 batches\n11 Start Epoch 3\n13 Start Epoch 3\n23 Start Epoch 3\n9 Start Epoch 3\n3: 1 batches\n11: 1 batches\n13: 1 batches\n22 Start Epoch 3\n8 Start Epoch 3\n14: 1 batches\n20 Start Epoch 3\n19: 1 batches\n8: 1 batches\n15: 1 batches\n21: 1 batches\n18: 1 batches\n2: 1 batches\n16 Start Epoch 3\n10 Start Epoch 3\n12 Start Epoch 3\n23: 1 batches\n16: 1 batches\n10: 1 batches\n12: 1 batches\n22: 1 batches\n9: 1 batches\n20: 1 batches\n4 Start Epoch 3\n4: 1 batches\n1 Start Epoch 3\n1: 1 batches\n6 Start Epoch 3\n6: 1 batches\n0 Start Epoch 3\n0: 1 batches\n19 Start Epoch 4\n15 Start Epoch 4\n19: 1 batches\n14 Start Epoch 4\n18 Start Epoch 4\n3 Start Epoch 4\n15: 1 batches\n7 Start Epoch 4\n14: 1 batches\n6 Start Epoch 4\n18: 1 batches\n3: 1 batches\n6: 1 batches\n7: 1 batches\n2 Start Epoch 4\n12 Start Epoch 4\n22 Start Epoch 4\n9 Start Epoch 4\n20 Start Epoch 4\n2: 1 batches\n16 Start Epoch 4\n11 Start Epoch 4\n21 Start Epoch 4\n16: 1 batches\n11: 1 batches\n13 Start Epoch 4\n23 Start Epoch 4\n8 Start Epoch 4\n8: 1 batches\n20: 1 batches\n17 Start Epoch 4\n10 Start Epoch 4\n13: 1 batches\n22: 1 batches\n21: 1 batches\n17: 1 batches\n10: 1 batches\n12: 1 batches\n23: 1 batches\n9: 1 batches\n1 Start Epoch 4\n1: 1 batches\n5 Start Epoch 4\n4 Start Epoch 4\n5: 1 batches\n4: 1 batches\n0 Start Epoch 4\n0: 1 batches\n7 Start Epoch 5\n6 Start Epoch 5\n10 Start Epoch 5\n8 Start Epoch 5\n10: 1 batches\n13 Start Epoch 5\n9 Start Epoch 5\n11 Start Epoch 5\n12 Start Epoch 5\n8: 1 batches\n14 Start Epoch 5\n13: 1 batches\n9: 1 batches\n15 Start Epoch 5\n14: 1 batches\n12: 1 batches\n15: 1 batches\n11: 1 batches\n6: 1 batches\n7: 1 batches\n22 Start Epoch 5\n21 Start Epoch 5\n4 Start Epoch 5\n19 Start Epoch 5\n2 Start Epoch 5\n17 Start Epoch 5\n23 Start Epoch 5\n20 Start Epoch 5\n5 Start Epoch 5\n19: 1 batches\n3 Start Epoch 5\n16 Start Epoch 5\n16: 1 batches\n22: 1 batches\n20: 1 batches\n4: 1 batches\n18 Start Epoch 5\n3: 1 batches\n17: 1 batches\n21: 1 batches\n5: 1 batches\n18: 1 batches\n2: 1 batches\n23: 1 batches\n1 Start Epoch 5\n1: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:6: Epoch 0 train loss: 2182.143798828125\nINFO:root:7: Epoch 0 train loss: 269605.21875\nINFO:root:2: Epoch 0 train loss: 4517.28857421875\nINFO:root:3: Epoch 0 train loss: 3478.460205078125\nINFO:root:8: Epoch 0 train loss: 1350.379150390625\nINFO:root:10: Epoch 0 train loss: 789.0491333007812\nINFO:root:5: Epoch 0 train loss: 738459.125\nINFO:root:11: Epoch 0 train loss: 261444.0625\nINFO:root:9: Epoch 0 train loss: 229408.1875\nINFO:root:1: Epoch 0 train loss: 1638.6639404296875\nINFO:root:0: Epoch 0 train loss: 2340.21533203125\nINFO:root:4: Epoch 0 train loss: 2428.309814453125\nINFO:root:19: Epoch 0 train loss: 2247.64501953125\nINFO:root:18: Epoch 0 train loss: 1474.946533203125\nINFO:root:13: Epoch 0 train loss: 515817.75\nINFO:root:14: Epoch 0 train loss: 212050.3125\nINFO:root:16: Epoch 0 train loss: 1815.514892578125\nINFO:root:15: Epoch 0 train loss: 1695.730224609375\nINFO:root:17: Epoch 0 train loss: 868.8223876953125\nINFO:root:20: Epoch 0 train loss: 1467.8585205078125\nINFO:root:21: Epoch 0 train loss: 8093.14208984375\nINFO:root:23: Epoch 0 train loss: 8197.1650390625\nINFO:root:22: Epoch 0 train loss: 1180.9757080078125\nINFO:root:12: Epoch 0 train loss: 284732.03125\nINFO:root:0: Epoch 0 validation loss: 567490.958055807\nINFO:root:7: Epoch 1 train loss: 12107.1171875\nINFO:root:6: Epoch 1 train loss: 88063.046875\nINFO:root:3: Epoch 1 train loss: 1840.6798095703125\nINFO:root:18: Epoch 1 train loss: 587.9136962890625\nINFO:root:2: Epoch 1 train loss: 4486.349609375\nINFO:root:19: Epoch 1 train loss: 1087.82177734375\nINFO:root:1: Epoch 1 train loss: 2316.587158203125\nINFO:root:0: Epoch 1 train loss: 255129.671875\nINFO:root:8: Epoch 1 train loss: 427.6742248535156\nINFO:root:21: Epoch 1 train loss: 298.6367492675781\nINFO:root:4: Epoch 1 train loss: 1277.6082763671875\nINFO:root:16: Epoch 1 train loss: 311219.125\nINFO:root:12: Epoch 1 train loss: 6430.0615234375\nINFO:root:23: Epoch 1 train loss: 1859.1866455078125\nINFO:root:9: Epoch 1 train loss: 225751.40625\nINFO:root:15: Epoch 1 train loss: 985.9882202148438\nINFO:root:20: Epoch 1 train loss: 823.2479248046875\nINFO:root:5: Epoch 1 train loss: 11548.5458984375\nINFO:root:17: Epoch 1 train loss: 7578.81005859375\nINFO:root:11: Epoch 1 train loss: 272563.65625\nINFO:root:13: Epoch 1 train loss: 2080.550537109375\nINFO:root:22: Epoch 1 train loss: 1187.4322509765625\nINFO:root:14: Epoch 1 train loss: 313265.875\nINFO:root:10: Epoch 1 train loss: 341.5282897949219\nINFO:root:0: Epoch 1 validation loss: 567482.6416543658\nINFO:root:2: Epoch 2 train loss: 211909.515625\nINFO:root:15: Epoch 2 train loss: 249026.984375\nINFO:root:7: Epoch 2 train loss: 309570.71875\nINFO:root:10: Epoch 2 train loss: 4257.3193359375\nINFO:root:12: Epoch 2 train loss: 4098.35888671875\nINFO:root:23: Epoch 2 train loss: 3678.869140625\nINFO:root:9: Epoch 2 train loss: 212482.4375\nINFO:root:14: Epoch 2 train loss: 270395.03125\nINFO:root:21: Epoch 2 train loss: 221513.515625\nINFO:root:5: Epoch 2 train loss: 283.63616943359375\nINFO:root:3: Epoch 2 train loss: 2059.81787109375\nINFO:root:17: Epoch 2 train loss: 2391.47802734375\nINFO:root:11: Epoch 2 train loss: 310320.3125\nINFO:root:13: Epoch 2 train loss: 684.0545043945312\nINFO:root:22: Epoch 2 train loss: 312357.71875\nINFO:root:8: Epoch 2 train loss: 1205.3988037109375\nINFO:root:20: Epoch 2 train loss: 350.8009948730469\nINFO:root:19: Epoch 2 train loss: 267758.375\nINFO:root:18: Epoch 2 train loss: 2110.597900390625\nINFO:root:16: Epoch 2 train loss: 1396.766845703125\nINFO:root:4: Epoch 2 train loss: 269055.40625\nINFO:root:1: Epoch 2 train loss: 317459.09375\nINFO:root:0: Epoch 2 train loss: 268070.0625\nINFO:root:6: Epoch 2 train loss: 2544.259521484375\nINFO:root:0: Epoch 2 validation loss: 567474.5380405962\nINFO:root:14: Epoch 3 train loss: 560.7369384765625\nINFO:root:19: Epoch 3 train loss: 309806.34375\nINFO:root:15: Epoch 3 train loss: 32703.923828125\nINFO:root:6: Epoch 3 train loss: 108.98443603515625\nINFO:root:7: Epoch 3 train loss: 4779.63525390625\nINFO:root:3: Epoch 3 train loss: 1326.963134765625\nINFO:root:18: Epoch 3 train loss: 525537.9375\nINFO:root:17: Epoch 3 train loss: 1062.886962890625\nINFO:root:11: Epoch 3 train loss: 10273.2177734375\nINFO:root:12: Epoch 3 train loss: 1669.6317138671875\nINFO:root:22: Epoch 3 train loss: 5119.60498046875\nINFO:root:8: Epoch 3 train loss: 1442.93212890625\nINFO:root:21: Epoch 3 train loss: 1977.2958984375\nINFO:root:2: Epoch 3 train loss: 729.2627563476562\nINFO:root:9: Epoch 3 train loss: 611.4229125976562\nINFO:root:20: Epoch 3 train loss: 2583.92919921875\nINFO:root:16: Epoch 3 train loss: 2139.138916015625\nINFO:root:10: Epoch 3 train loss: 5233.08251953125\nINFO:root:13: Epoch 3 train loss: 313174.6875\nINFO:root:23: Epoch 3 train loss: 3314.322509765625\nINFO:root:5: Epoch 3 train loss: 1208.5758056640625\nINFO:root:1: Epoch 3 train loss: 127.23216247558594\nINFO:root:0: Epoch 3 train loss: 2966.239013671875\nINFO:root:4: Epoch 3 train loss: 226521.65625\nINFO:root:0: Epoch 3 validation loss: 567466.174994759\nINFO:root:7: Epoch 4 train loss: 210156.84375\nINFO:root:6: Epoch 4 train loss: 2551.02099609375\nINFO:root:8: Epoch 4 train loss: 1221.2791748046875\nINFO:root:10: Epoch 4 train loss: 253.04437255859375\nINFO:root:9: Epoch 4 train loss: 11428.1005859375\nINFO:root:11: Epoch 4 train loss: 2595.78955078125\nINFO:root:13: Epoch 4 train loss: 88156.3671875\nINFO:root:12: Epoch 4 train loss: 267754.65625\nINFO:root:14: Epoch 4 train loss: 724.1198120117188\nINFO:root:15: Epoch 4 train loss: 310667.59375\nINFO:root:19: Epoch 4 train loss: 1790.3834228515625\nINFO:root:2: Epoch 4 train loss: 258170.859375\nINFO:root:16: Epoch 4 train loss: 11217.0791015625\nINFO:root:23: Epoch 4 train loss: 479602.4375\nINFO:root:20: Epoch 4 train loss: 224761.46875\nINFO:root:5: Epoch 4 train loss: 259543.03125\nINFO:root:4: Epoch 4 train loss: 6238.99072265625\nINFO:root:18: Epoch 4 train loss: 31788.109375\nINFO:root:3: Epoch 4 train loss: 2092.902099609375\nINFO:root:17: Epoch 4 train loss: 2016.9967041015625\nINFO:root:22: Epoch 4 train loss: 7889.361328125\nINFO:root:21: Epoch 4 train loss: 529.0538940429688\nINFO:root:0: Epoch 4 train loss: 1637.5877685546875\nINFO:root:1: Epoch 4 train loss: 229230.21875\nINFO:root:0: Epoch 4 validation loss: 567457.6215201801\nINFO:root:23: Epoch 5 train loss: 8719.99609375\nINFO:root:15: Epoch 5 train loss: 1265.7833251953125\nINFO:root:14: Epoch 5 train loss: 752.3746948242188\nINFO:root:22: Epoch 5 train loss: 5555.13134765625\nINFO:root:16: Epoch 5 train loss: 2312.201416015625\nINFO:root:17: Epoch 5 train loss: 2051.0625\nINFO:root:21: Epoch 5 train loss: 3780.777587890625\nINFO:root:20: Epoch 5 train loss: 7955.47314453125\nINFO:root:1: Epoch 5 train loss: 260372.53125\nINFO:root:0: Epoch 5 train loss: 6553.49609375\nINFO:root:12: Epoch 5 train loss: 254559.015625\nINFO:root:8: Epoch 5 train loss: 1631.6414794921875\nINFO:root:13: Epoch 5 train loss: 11936.3388671875\nINFO:root:9: Epoch 5 train loss: 248769.734375\nINFO:root:7: Epoch 5 train loss: 2823.789306640625\nINFO:root:6: Epoch 5 train loss: 269649.65625\nINFO:root:11: Epoch 5 train loss: 254436.328125\nINFO:root:10: Epoch 5 train loss: 309212.28125\nINFO:root:3: Epoch 5 train loss: 4328.09814453125\nINFO:root:2: Epoch 5 train loss: 736.9200439453125\nINFO:root:19: Epoch 5 train loss: 694.2127685546875\nINFO:root:4: Epoch 5 train loss: 939.07470703125\nINFO:root:18: Epoch 5 train loss: 223125.515625\nINFO:root:5: Epoch 5 train loss: 6674.23193359375\nINFO:root:0: Epoch 5 validation loss: 567448.8744429653\n", "seconds": 15.626100063323975, "batch_size": 256, "nodes": 12, "processes_per_node": 2, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.15,192.168.2.15 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "1 Start Epoch 0\n0 Start Epoch 0\n0: 4 batches\n2 Start Epoch 0\n2: 4 batches\n1: 4 batches\n1 Start Epoch 1\n1: 4 batches\n2 Start Epoch 1\n2: 4 batches\n0 Start Epoch 1\n0: 4 batches\n2 Start Epoch 2\n2: 4 batches\n1 Start Epoch 2\n1: 4 batches\n0 Start Epoch 2\n0: 4 batches\n1 Start Epoch 3\n1: 4 batches\n2 Start Epoch 3\n2: 4 batches\n0 Start Epoch 3\n0: 4 batches\n1 Start Epoch 4\n1: 4 batches\n2 Start Epoch 4\n2: 4 batches\n0 Start Epoch 4\n0: 4 batches\n1 Start Epoch 5\n2 Start Epoch 5\n1: 4 batches\n2: 4 batches\n0 Start Epoch 5\n0: 4 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 82871.86694335938\nINFO:root:1: Epoch 0 train loss: 42814.33367919922\nINFO:root:2: Epoch 0 train loss: 140763.06188964844\nINFO:root:0: Epoch 0 validation loss: 16903.647026983912\nINFO:root:2: Epoch 1 train loss: 117735.93957519531\nINFO:root:1: Epoch 1 train loss: 57964.990966796875\nINFO:root:0: Epoch 1 train loss: 106900.60499572754\nINFO:root:0: Epoch 1 validation loss: 16893.618795125567\nINFO:root:1: Epoch 2 train loss: 99752.76154327393\nINFO:root:0: Epoch 2 train loss: 71049.0171508789\nINFO:root:2: Epoch 2 train loss: 79774.45486450195\nINFO:root:0: Epoch 2 validation loss: 16882.833534849327\nINFO:root:0: Epoch 3 train loss: 63759.232192993164\nINFO:root:1: Epoch 3 train loss: 47596.921142578125\nINFO:root:2: Epoch 3 train loss: 107477.77990722656\nINFO:root:0: Epoch 3 validation loss: 16870.724304524283\nINFO:root:0: Epoch 4 train loss: 3873.8394470214844\nINFO:root:1: Epoch 4 train loss: 13157.622314453125\nINFO:root:2: Epoch 4 train loss: 161438.8009033203\nINFO:root:0: Epoch 4 validation loss: 16856.400911288143\nINFO:root:1: Epoch 5 train loss: 66178.22500610352\nINFO:root:2: Epoch 5 train loss: 39242.378845214844\nINFO:root:0: Epoch 5 train loss: 66104.25012207031\nINFO:root:0: Epoch 5 validation loss: 16839.012082832898\n", "seconds": 62.260292053222656, "batch_size": 256, "nodes": 1, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.15,192.168.2.2,192.168.2.15,192.168.2.2 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n3 Start Epoch 0\n4 Start Epoch 0\n3: 2 batches\n4: 2 batches\n5 Start Epoch 0\n5: 2 batches\n1 Start Epoch 0\n1: 2 batches\n2 Start Epoch 0\n2: 2 batches\n2 Start Epoch 1\n1 Start Epoch 1\n1: 2 batches\n2: 2 batches\n5 Start Epoch 1\n5: 2 batches\n3 Start Epoch 1\n4 Start Epoch 1\n3: 2 batches\n4: 2 batches\n0 Start Epoch 1\n0: 2 batches\n3 Start Epoch 2\n3: 2 batches\n2 Start Epoch 2\n2: 2 batches\n1 Start Epoch 2\n1: 2 batches\n5 Start Epoch 2\n5: 2 batches\n4 Start Epoch 2\n4: 2 batches\n0 Start Epoch 2\n0: 2 batches\n2 Start Epoch 3\n2: 2 batches\n1 Start Epoch 3\n1: 2 batches\n5 Start Epoch 3\n5: 2 batches\n3 Start Epoch 3\n3: 2 batches\n4 Start Epoch 3\n4: 2 batches\n0 Start Epoch 3\n0: 2 batches\n5 Start Epoch 4\n5: 2 batches\n4 Start Epoch 4\n4: 2 batches\n3 Start Epoch 4\n3: 2 batches\n1 Start Epoch 4\n1: 2 batches\n2 Start Epoch 4\n2: 2 batches\n0 Start Epoch 4\n0: 2 batches\n2 Start Epoch 5\n2: 2 batches\n3 Start Epoch 5\n5 Start Epoch 5\n3: 2 batches\n4 Start Epoch 5\n5: 2 batches\n4: 2 batches\n1 Start Epoch 5\n1: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 78580.44653320312\nINFO:root:2: Epoch 0 train loss: 71567.05670166016\nINFO:root:1: Epoch 0 train loss: 2087.865234375\nINFO:root:5: Epoch 0 train loss: 212613.5\nINFO:root:3: Epoch 0 train loss: 140698.99993896484\nINFO:root:4: Epoch 0 train loss: 53833.60119628906\nINFO:root:0: Epoch 0 validation loss: 63658.772415485684\nINFO:root:3: Epoch 1 train loss: 1963.7882995605469\nINFO:root:2: Epoch 1 train loss: 213667.8359375\nINFO:root:1: Epoch 1 train loss: 154495.02734375\nINFO:root:0: Epoch 1 train loss: 146727.09240722656\nINFO:root:5: Epoch 1 train loss: 135292.69470214844\nINFO:root:4: Epoch 1 train loss: 168077.39672851562\nINFO:root:0: Epoch 1 validation loss: 63652.69249166233\nINFO:root:2: Epoch 2 train loss: 75626.7056274414\nINFO:root:1: Epoch 2 train loss: 73980.63327026367\nINFO:root:0: Epoch 2 train loss: 2604.4033203125\nINFO:root:5: Epoch 2 train loss: 3387.1025390625\nINFO:root:3: Epoch 2 train loss: 205043.87475585938\nINFO:root:4: Epoch 2 train loss: 75300.421875\nINFO:root:0: Epoch 2 validation loss: 63646.73522824282\nINFO:root:5: Epoch 3 train loss: 3323.668212890625\nINFO:root:4: Epoch 3 train loss: 64032.08728027344\nINFO:root:3: Epoch 3 train loss: 61254.406005859375\nINFO:root:0: Epoch 3 train loss: 120611.10888671875\nINFO:root:1: Epoch 3 train loss: 22493.11700439453\nINFO:root:2: Epoch 3 train loss: 36716.9326171875\nINFO:root:0: Epoch 3 validation loss: 63640.62116451273\nINFO:root:0: Epoch 4 train loss: 79262.99267578125\nINFO:root:2: Epoch 4 train loss: 84472.25830078125\nINFO:root:5: Epoch 4 train loss: 67309.64514160156\nINFO:root:3: Epoch 4 train loss: 201261.9296875\nINFO:root:4: Epoch 4 train loss: 139254.953125\nINFO:root:1: Epoch 4 train loss: 84115.68359375\nINFO:root:0: Epoch 4 validation loss: 63634.40247556375\nINFO:root:1: Epoch 5 train loss: 217701.71655273438\nINFO:root:2: Epoch 5 train loss: 132904.42578125\nINFO:root:0: Epoch 5 train loss: 3253.2725219726562\nINFO:root:4: Epoch 5 train loss: 10196.131652832031\nINFO:root:5: Epoch 5 train loss: 90516.759765625\nINFO:root:3: Epoch 5 train loss: 70900.87182617188\nINFO:root:0: Epoch 5 validation loss: 63628.02221664056\n", "seconds": 32.794137716293335, "batch_size": 256, "nodes": 2, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.15,192.168.2.2,192.168.2.3 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 2 batches\n2: 2 batches\n6 Start Epoch 0\n7 Start Epoch 0\n6: 2 batches\n8 Start Epoch 0\n7: 2 batches\n5 Start Epoch 0\n4 Start Epoch 0\n4: 2 batches\n5: 2 batches\n8: 2 batches\n3 Start Epoch 0\n3: 2 batches\n8 Start Epoch 1\n8: 2 batches\n7 Start Epoch 1\n7: 2 batches\n6 Start Epoch 1\n6: 2 batches\n5 Start Epoch 1\n5: 2 batches\n1 Start Epoch 1\n1: 2 batches\n2 Start Epoch 1\n2: 2 batches\n4 Start Epoch 1\n3 Start Epoch 1\n4: 2 batches\n3: 2 batches\n0 Start Epoch 1\n0: 2 batches\n2 Start Epoch 2\n2: 2 batches\n1 Start Epoch 2\n1: 2 batches\n8 Start Epoch 2\n8: 2 batches\n7 Start Epoch 2\n7: 2 batches\n6 Start Epoch 2\n6: 2 batches\n5 Start Epoch 2\n5: 2 batches\n3 Start Epoch 2\n4 Start Epoch 2\n3: 2 batches\n4: 2 batches\n0 Start Epoch 2\n0: 2 batches\n7 Start Epoch 3\n7: 2 batches\n2 Start Epoch 3\n2: 2 batches\n1 Start Epoch 3\n1: 2 batches\n8 Start Epoch 3\n8: 2 batches\n3 Start Epoch 3\n5 Start Epoch 3\n6 Start Epoch 3\n6: 2 batches\n3: 2 batches\n5: 2 batches\n4 Start Epoch 3\n4: 2 batches\n0 Start Epoch 3\n0: 2 batches\n8 Start Epoch 4\n8: 2 batches\n7 Start Epoch 4\n7: 2 batches\n6 Start Epoch 4\n6: 2 batches\n5 Start Epoch 4\n4 Start Epoch 4\n5: 2 batches\n4: 2 batches\n3 Start Epoch 4\n3: 2 batches\n2 Start Epoch 4\n2: 2 batches\n1 Start Epoch 4\n1: 2 batches\n0 Start Epoch 4\n0: 2 batches\n8 Start Epoch 5\n8: 2 batches\n7 Start Epoch 5\n7: 2 batches\n2 Start Epoch 5\n1 Start Epoch 5\n1: 2 batches\n4 Start Epoch 5\n3 Start Epoch 5\n5 Start Epoch 5\n4: 2 batches\n5: 2 batches\n3: 2 batches\n2: 2 batches\n6 Start Epoch 5\n6: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:8: Epoch 0 train loss: 4525.690002441406\nINFO:root:0: Epoch 0 train loss: 62213.830322265625\nINFO:root:7: Epoch 0 train loss: 4808.85888671875\nINFO:root:6: Epoch 0 train loss: 3167.2664184570312\nINFO:root:5: Epoch 0 train loss: 136817.76065063477\nINFO:root:1: Epoch 0 train loss: 2404.6238403320312\nINFO:root:2: Epoch 0 train loss: 134243.27124023438\nINFO:root:3: Epoch 0 train loss: 209993.279296875\nINFO:root:4: Epoch 0 train loss: 226954.17126464844\nINFO:root:0: Epoch 0 validation loss: 189864.31226403118\nINFO:root:2: Epoch 1 train loss: 89557.89945983887\nINFO:root:1: Epoch 1 train loss: 1078.9107971191406\nINFO:root:0: Epoch 1 train loss: 3201.297821044922\nINFO:root:8: Epoch 1 train loss: 8019.898254394531\nINFO:root:7: Epoch 1 train loss: 4563.81787109375\nINFO:root:6: Epoch 1 train loss: 2625.5372467041016\nINFO:root:5: Epoch 1 train loss: 3127.815689086914\nINFO:root:3: Epoch 1 train loss: 2194.7468814849854\nINFO:root:4: Epoch 1 train loss: 115834.39754295349\nINFO:root:0: Epoch 1 validation loss: 189849.42830144777\nINFO:root:7: Epoch 2 train loss: 65660.4755859375\nINFO:root:1: Epoch 2 train loss: 277896.14453125\nINFO:root:0: Epoch 2 train loss: 3048.2286376953125\nINFO:root:2: Epoch 2 train loss: 987.4180297851562\nINFO:root:5: Epoch 2 train loss: 68298.8466796875\nINFO:root:8: Epoch 2 train loss: 4103.321044921875\nINFO:root:3: Epoch 2 train loss: 66052.73828125\nINFO:root:6: Epoch 2 train loss: 1386.8365478515625\nINFO:root:4: Epoch 2 train loss: 8875.36181640625\nINFO:root:0: Epoch 2 validation loss: 189834.64815021466\nINFO:root:8: Epoch 3 train loss: 68793.1031036377\nINFO:root:7: Epoch 3 train loss: 2605.1217041015625\nINFO:root:0: Epoch 3 train loss: 8504.738220214844\nINFO:root:6: Epoch 3 train loss: 67971.6123046875\nINFO:root:5: Epoch 3 train loss: 67850.92456054688\nINFO:root:3: Epoch 3 train loss: 1748.3762817382812\nINFO:root:4: Epoch 3 train loss: 52670.60935974121\nINFO:root:1: Epoch 3 train loss: 98179.32308959961\nINFO:root:2: Epoch 3 train loss: 114730.55313873291\nINFO:root:0: Epoch 3 validation loss: 189819.6628473665\nINFO:root:8: Epoch 4 train loss: 1047.0671081542969\nINFO:root:7: Epoch 4 train loss: 21679.036895751953\nINFO:root:0: Epoch 4 train loss: 68997.74982452393\nINFO:root:2: Epoch 4 train loss: 177682.2080078125\nINFO:root:1: Epoch 4 train loss: 55625.240631103516\nINFO:root:4: Epoch 4 train loss: 66734.38598632812\nINFO:root:5: Epoch 4 train loss: 225437.78833007812\nINFO:root:3: Epoch 4 train loss: 2668.3719482421875\nINFO:root:6: Epoch 4 train loss: 2854.6951904296875\nINFO:root:0: Epoch 4 validation loss: 189804.5394538167\nINFO:root:6: Epoch 5 train loss: 8543.913879394531\nINFO:root:3: Epoch 5 train loss: 77389.28771972656\nINFO:root:4: Epoch 5 train loss: 136134.708984375\nINFO:root:5: Epoch 5 train loss: 7341.9739990234375\nINFO:root:7: Epoch 5 train loss: 70919.80053710938\nINFO:root:8: Epoch 5 train loss: 263272.1484375\nINFO:root:1: Epoch 5 train loss: 225031.81158447266\nINFO:root:2: Epoch 5 train loss: 66214.86071777344\nINFO:root:0: Epoch 5 train loss: 294573.3671875\nINFO:root:0: Epoch 5 validation loss: 189789.04015993417\n", "seconds": 31.882233142852783, "batch_size": 256, "nodes": 3, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n2 Start Epoch 0\n2: 1 batches\n3 Start Epoch 0\n4 Start Epoch 0\n7 Start Epoch 0\n8 Start Epoch 0\n7: 1 batches\n8: 1 batches\n4: 1 batches\n3: 1 batches\n1 Start Epoch 0\n1: 1 batches\n11 Start Epoch 0\n11: 1 batches\n6 Start Epoch 0\n9 Start Epoch 0\n5 Start Epoch 0\n10 Start Epoch 0\n6: 1 batches\n5: 1 batches\n9: 1 batches\n10: 1 batches\n8 Start Epoch 1\n7 Start Epoch 1\n7: 1 batches\n6 Start Epoch 1\n6: 1 batches\n10 Start Epoch 1\n9 Start Epoch 1\n11 Start Epoch 1\n9: 1 batches\n8: 1 batches\n10: 1 batches\n11: 1 batches\n1 Start Epoch 1\n1: 1 batches\n2 Start Epoch 1\n2: 1 batches\n3 Start Epoch 1\n3: 1 batches\n4 Start Epoch 1\n4: 1 batches\n5 Start Epoch 1\n5: 1 batches\n0 Start Epoch 1\n0: 1 batches\n11 Start Epoch 2\n3 Start Epoch 2\n4 Start Epoch 2\n11: 1 batches\n3: 1 batches\n4: 1 batches\n8 Start Epoch 2\n9 Start Epoch 2\n7 Start Epoch 2\n7: 1 batches\n10 Start Epoch 2\n6 Start Epoch 2\n6: 1 batches\n10: 1 batches\n9: 1 batches\n8: 1 batches\n2 Start Epoch 2\n2: 1 batches\n5 Start Epoch 2\n5: 1 batches\n1 Start Epoch 2\n1: 1 batches\n0 Start Epoch 2\n0: 1 batches\n11 Start Epoch 3\n11: 1 batches\n3 Start Epoch 3\n3: 1 batches\n2 Start Epoch 3\n7 Start Epoch 3\n6 Start Epoch 3\n7: 1 batches\n6: 1 batches\n8 Start Epoch 3\n8: 1 batches\n1 Start Epoch 3\n2: 1 batches\n4 Start Epoch 3\n5 Start Epoch 3\n4: 1 batches\n5: 1 batches\n1: 1 batches\n10 Start Epoch 3\n10: 1 batches\n9 Start Epoch 3\n9: 1 batches\n0 Start Epoch 3\n0: 1 batches\n9 Start Epoch 4\n7 Start Epoch 4\n5 Start Epoch 4\n8 Start Epoch 4\n11 Start Epoch 4\n4 Start Epoch 4\n6 Start Epoch 4\n5: 1 batches\n10 Start Epoch 4\n7: 1 batches\n11: 1 batches\n3 Start Epoch 4\n6: 1 batches\n4: 1 batches\n10: 1 batches\n9: 1 batches\n3: 1 batches\n8: 1 batches\n1 Start Epoch 4\n1: 1 batches\n2 Start Epoch 4\n2: 1 batches\n0 Start Epoch 4\n0: 1 batches\n4 Start Epoch 5\n3 Start Epoch 5\n5 Start Epoch 5\n4: 1 batches\n3: 1 batches\n6 Start Epoch 5\n5: 1 batches\n6: 1 batches\n8 Start Epoch 5\n11 Start Epoch 5\n11: 1 batches\n7 Start Epoch 5\n8: 1 batches\n7: 1 batches\n2 Start Epoch 5\n2: 1 batches\n1 Start Epoch 5\n1: 1 batches\n10 Start Epoch 5\n10: 1 batches\n9 Start Epoch 5\n9: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:7: Epoch 0 train loss: 3264.227294921875\nINFO:root:6: Epoch 0 train loss: 142373.828125\nINFO:root:0: Epoch 0 train loss: 141512.421875\nINFO:root:8: Epoch 0 train loss: 271756.78125\nINFO:root:10: Epoch 0 train loss: 1717.1890869140625\nINFO:root:11: Epoch 0 train loss: 270140.75\nINFO:root:9: Epoch 0 train loss: 312092.9375\nINFO:root:1: Epoch 0 train loss: 3152.557373046875\nINFO:root:2: Epoch 0 train loss: 268989.0625\nINFO:root:3: Epoch 0 train loss: 131083.578125\nINFO:root:4: Epoch 0 train loss: 156489.125\nINFO:root:5: Epoch 0 train loss: 3953.2265625\nINFO:root:0: Epoch 0 validation loss: 797360.5833920896\nINFO:root:11: Epoch 1 train loss: 261891.765625\nINFO:root:4: Epoch 1 train loss: 3463.365478515625\nINFO:root:5: Epoch 1 train loss: 2054.75048828125\nINFO:root:3: Epoch 1 train loss: 2211.225341796875\nINFO:root:7: Epoch 1 train loss: 7193.203125\nINFO:root:10: Epoch 1 train loss: 3222.12548828125\nINFO:root:6: Epoch 1 train loss: 126824.6171875\nINFO:root:8: Epoch 1 train loss: 160706.59375\nINFO:root:9: Epoch 1 train loss: 360764.28125\nINFO:root:2: Epoch 1 train loss: 130474.390625\nINFO:root:0: Epoch 1 train loss: 113179.4296875\nINFO:root:1: Epoch 1 train loss: 130324.1875\nINFO:root:0: Epoch 1 validation loss: 797353.7683887107\nINFO:root:11: Epoch 2 train loss: 219300.375\nINFO:root:3: Epoch 2 train loss: 45598.515625\nINFO:root:2: Epoch 2 train loss: 3768.663818359375\nINFO:root:0: Epoch 2 train loss: 156639.90625\nINFO:root:6: Epoch 2 train loss: 2289.424072265625\nINFO:root:7: Epoch 2 train loss: 1631.7852783203125\nINFO:root:8: Epoch 2 train loss: 45251.7265625\nINFO:root:1: Epoch 2 train loss: 2514.906494140625\nINFO:root:4: Epoch 2 train loss: 115043.4765625\nINFO:root:5: Epoch 2 train loss: 7711.46728515625\nINFO:root:9: Epoch 2 train loss: 15476.328125\nINFO:root:10: Epoch 2 train loss: 161861.78125\nINFO:root:0: Epoch 2 validation loss: 797346.7889711225\nINFO:root:8: Epoch 3 train loss: 46570.93359375\nINFO:root:7: Epoch 3 train loss: 18715.87890625\nINFO:root:11: Epoch 3 train loss: 134492.328125\nINFO:root:5: Epoch 3 train loss: 414.54241943359375\nINFO:root:9: Epoch 3 train loss: 50338.8203125\nINFO:root:4: Epoch 3 train loss: 1484.2772216796875\nINFO:root:10: Epoch 3 train loss: 480.67669677734375\nINFO:root:6: Epoch 3 train loss: 3792.827392578125\nINFO:root:3: Epoch 3 train loss: 256174.90625\nINFO:root:2: Epoch 3 train loss: 107990.1328125\nINFO:root:0: Epoch 3 train loss: 291482.28125\nINFO:root:1: Epoch 3 train loss: 371660.96875\nINFO:root:0: Epoch 3 validation loss: 797339.6013634143\nINFO:root:5: Epoch 4 train loss: 1267.4598388671875\nINFO:root:4: Epoch 4 train loss: 1008.8997802734375\nINFO:root:3: Epoch 4 train loss: 107890.125\nINFO:root:6: Epoch 4 train loss: 7147.662109375\nINFO:root:8: Epoch 4 train loss: 47853.41015625\nINFO:root:11: Epoch 4 train loss: 142731.875\nINFO:root:7: Epoch 4 train loss: 3208.71484375\nINFO:root:2: Epoch 4 train loss: 704.5974731445312\nINFO:root:0: Epoch 4 train loss: 17503.423828125\nINFO:root:1: Epoch 4 train loss: 2897.585205078125\nINFO:root:9: Epoch 4 train loss: 142275.015625\nINFO:root:10: Epoch 4 train loss: 179023.40625\nINFO:root:0: Epoch 4 validation loss: 797332.3999180418\nINFO:root:9: Epoch 5 train loss: 2993.33251953125\nINFO:root:0: Epoch 5 train loss: 1744.2353515625\nINFO:root:11: Epoch 5 train loss: 235529.390625\nINFO:root:5: Epoch 5 train loss: 158893.484375\nINFO:root:8: Epoch 5 train loss: 128930.828125\nINFO:root:6: Epoch 5 train loss: 6536.68896484375\nINFO:root:4: Epoch 5 train loss: 158529.453125\nINFO:root:1: Epoch 5 train loss: 5824.21923828125\nINFO:root:2: Epoch 5 train loss: 105775.421875\nINFO:root:7: Epoch 5 train loss: 44568.25390625\nINFO:root:10: Epoch 5 train loss: 143592.953125\nINFO:root:3: Epoch 5 train loss: 131784.03125\nINFO:root:0: Epoch 5 validation loss: 797325.0487735989\n", "seconds": 19.079375982284546, "batch_size": 256, "nodes": 4, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 1 batches\n2: 1 batches\n11 Start Epoch 0\n7 Start Epoch 0\n11: 1 batches\n8 Start Epoch 0\n8: 1 batches\n7: 1 batches\n3 Start Epoch 0\n4 Start Epoch 0\n4: 1 batches\n3: 1 batches\n12 Start Epoch 0\n12: 1 batches\n6 Start Epoch 0\n9 Start Epoch 0\n10 Start Epoch 0\n5 Start Epoch 0\n14 Start Epoch 0\n9: 1 batches\n5: 1 batches\n6: 1 batches\n10: 1 batches\n13 Start Epoch 0\n14: 1 batches\n13: 1 batches\n1 Start Epoch 1\n1: 1 batches\n2 Start Epoch 1\n2: 1 batches\n3 Start Epoch 1\n3: 1 batches\n4 Start Epoch 1\n4: 1 batches\n5 Start Epoch 1\n5: 1 batches\n6 Start Epoch 1\n6: 1 batches\n10 Start Epoch 1\n11 Start Epoch 1\n14 Start Epoch 1\n12 Start Epoch 1\n11: 1 batches\n10: 1 batches\n13 Start Epoch 1\n14: 1 batches\n12: 1 batches\n13: 1 batches\n7 Start Epoch 1\n8 Start Epoch 1\n7: 1 batches\n8: 1 batches\n9 Start Epoch 1\n9: 1 batches\n0 Start Epoch 1\n0: 1 batches\n8 Start Epoch 2\n8: 1 batches\n9 Start Epoch 2\n10 Start Epoch 2\n11 Start Epoch 2\n11: 1 batches\n9: 1 batches\n10: 1 batches\n12 Start Epoch 2\n12: 1 batches\n2 Start Epoch 2\n2: 1 batches\n7 Start Epoch 2\n3 Start Epoch 2\n7: 1 batches\n4 Start Epoch 2\n4: 1 batches\n5 Start Epoch 2\n5: 1 batches\n3: 1 batches\n1 Start Epoch 2\n13 Start Epoch 2\n14 Start Epoch 2\n14: 1 batches\n13: 1 batches\n1: 1 batches\n6 Start Epoch 2\n6: 1 batches\n0 Start Epoch 2\n0: 1 batches\n1 Start Epoch 3\n11 Start Epoch 3\n11: 1 batches\n3 Start Epoch 3\n8 Start Epoch 3\n5 Start Epoch 3\n7 Start Epoch 3\n8: 1 batches\n4 Start Epoch 3\n4: 1 batches\n7: 1 batches\n5: 1 batches\n6 Start Epoch 3\n3: 1 batches\n6: 1 batches\n9 Start Epoch 3\n2 Start Epoch 3\n2: 1 batches\n1: 1 batches\n9: 1 batches\n12 Start Epoch 3\n14 Start Epoch 3\n10 Start Epoch 3\n12: 1 batches\n10: 1 batches\n14: 1 batches\n13 Start Epoch 3\n13: 1 batches\n0 Start Epoch 3\n0: 1 batches\n10 Start Epoch 4\n11 Start Epoch 4\n10: 1 batches\n11: 1 batches\n12 Start Epoch 4\n12: 1 batches\n9 Start Epoch 4\n9: 1 batches\n3 Start Epoch 4\n8 Start Epoch 4\n7 Start Epoch 4\n5 Start Epoch 4\n4 Start Epoch 4\n6 Start Epoch 4\n3: 1 batches\n1 Start Epoch 4\n6: 1 batches\n4: 1 batches\n7: 1 batches\n1: 1 batches\n8: 1 batches\n5: 1 batches\n2 Start Epoch 4\n2: 1 batches\n13 Start Epoch 4\n14 Start Epoch 4\n13: 1 batches\n14: 1 batches\n0 Start Epoch 4\n0: 1 batches\n6 Start Epoch 5\n6: 1 batches\n14 Start Epoch 5\n14: 1 batches\n13 Start Epoch 5\n13: 1 batches\n8 Start Epoch 5\n8: 1 batches\n7 Start Epoch 5\n7: 1 batches\n4 Start Epoch 5\n3 Start Epoch 5\n3: 1 batches\n4: 1 batches\n5 Start Epoch 5\n5: 1 batches\n1 Start Epoch 5\n1: 1 batches\n12 Start Epoch 5\n12: 1 batches\n2 Start Epoch 5\n2: 1 batches\n11 Start Epoch 5\n11: 1 batches\n9 Start Epoch 5\n9: 1 batches\n10 Start Epoch 5\n10: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:1: Epoch 0 train loss: 5628.7197265625\nINFO:root:0: Epoch 0 train loss: 2127.584716796875\nINFO:root:2: Epoch 0 train loss: 11384.6376953125\nINFO:root:3: Epoch 0 train loss: 390880.875\nINFO:root:4: Epoch 0 train loss: 18398.365234375\nINFO:root:5: Epoch 0 train loss: 3368.55517578125\nINFO:root:6: Epoch 0 train loss: 196661.21875\nINFO:root:11: Epoch 0 train loss: 156256.640625\nINFO:root:13: Epoch 0 train loss: 1082.0318603515625\nINFO:root:10: Epoch 0 train loss: 4580.04443359375\nINFO:root:12: Epoch 0 train loss: 132359.046875\nINFO:root:14: Epoch 0 train loss: 219002.578125\nINFO:root:7: Epoch 0 train loss: 2790.1572265625\nINFO:root:8: Epoch 0 train loss: 1251.2271728515625\nINFO:root:9: Epoch 0 train loss: 176637.859375\nINFO:root:0: Epoch 0 validation loss: 5895607.186340839\nINFO:root:8: Epoch 1 train loss: 160167.15625\nINFO:root:10: Epoch 1 train loss: 411.4857482910156\nINFO:root:9: Epoch 1 train loss: 157066.671875\nINFO:root:11: Epoch 1 train loss: 6188.30810546875\nINFO:root:12: Epoch 1 train loss: 226292.421875\nINFO:root:2: Epoch 1 train loss: 157821.03125\nINFO:root:5: Epoch 1 train loss: 1878.88427734375\nINFO:root:6: Epoch 1 train loss: 3701.270751953125\nINFO:root:3: Epoch 1 train loss: 137037.21875\nINFO:root:7: Epoch 1 train loss: 561.16748046875\nINFO:root:4: Epoch 1 train loss: 141412.015625\nINFO:root:0: Epoch 1 train loss: 8460.9755859375\nINFO:root:1: Epoch 1 train loss: 5855.85205078125\nINFO:root:13: Epoch 1 train loss: 4195.36669921875\nINFO:root:14: Epoch 1 train loss: 133332.203125\nINFO:root:0: Epoch 1 validation loss: 5895579.408283431\nINFO:root:1: Epoch 2 train loss: 2961.748046875\nINFO:root:2: Epoch 2 train loss: 190586.53125\nINFO:root:11: Epoch 2 train loss: 135418.21875\nINFO:root:5: Epoch 2 train loss: 176033.375\nINFO:root:6: Epoch 2 train loss: 2248.36376953125\nINFO:root:3: Epoch 2 train loss: 155736.859375\nINFO:root:8: Epoch 2 train loss: 1899.984375\nINFO:root:4: Epoch 2 train loss: 194236.703125\nINFO:root:7: Epoch 2 train loss: 135497.4375\nINFO:root:9: Epoch 2 train loss: 2208.079833984375\nINFO:root:12: Epoch 2 train loss: 171733.640625\nINFO:root:14: Epoch 2 train loss: 218244.15625\nINFO:root:10: Epoch 2 train loss: 162439.328125\nINFO:root:13: Epoch 2 train loss: 64054.96484375\nINFO:root:0: Epoch 2 train loss: 156922.59375\nINFO:root:0: Epoch 2 validation loss: 5895551.618068565\nINFO:root:10: Epoch 3 train loss: 270.7889709472656\nINFO:root:11: Epoch 3 train loss: 2309.346435546875\nINFO:root:12: Epoch 3 train loss: 167399.796875\nINFO:root:9: Epoch 3 train loss: 193592.625\nINFO:root:3: Epoch 3 train loss: 1641.8260498046875\nINFO:root:7: Epoch 3 train loss: 5497.666015625\nINFO:root:4: Epoch 3 train loss: 781.4757080078125\nINFO:root:6: Epoch 3 train loss: 3074.3515625\nINFO:root:5: Epoch 3 train loss: 2616.129150390625\nINFO:root:8: Epoch 3 train loss: 1780.195556640625\nINFO:root:1: Epoch 3 train loss: 133379.78125\nINFO:root:2: Epoch 3 train loss: 1377.2646484375\nINFO:root:0: Epoch 3 train loss: 903.2470092773438\nINFO:root:13: Epoch 3 train loss: 157516.9375\nINFO:root:14: Epoch 3 train loss: 164928.921875\nINFO:root:0: Epoch 3 validation loss: 5895523.831417697\nINFO:root:6: Epoch 4 train loss: 1661.36279296875\nINFO:root:13: Epoch 4 train loss: 170011.265625\nINFO:root:14: Epoch 4 train loss: 2673.14404296875\nINFO:root:7: Epoch 4 train loss: 60827.51171875\nINFO:root:8: Epoch 4 train loss: 158021.953125\nINFO:root:3: Epoch 4 train loss: 55460.27734375\nINFO:root:4: Epoch 4 train loss: 60580.3828125\nINFO:root:5: Epoch 4 train loss: 202632.296875\nINFO:root:1: Epoch 4 train loss: 1337.7042236328125\nINFO:root:0: Epoch 4 train loss: 3846.71142578125\nINFO:root:12: Epoch 4 train loss: 1707.82958984375\nINFO:root:2: Epoch 4 train loss: 2977.959716796875\nINFO:root:9: Epoch 4 train loss: 5253.95556640625\nINFO:root:11: Epoch 4 train loss: 164964.171875\nINFO:root:10: Epoch 4 train loss: 2292.4443359375\nINFO:root:0: Epoch 4 validation loss: 5895495.951230885\nINFO:root:9: Epoch 5 train loss: 169164.15625\nINFO:root:4: Epoch 5 train loss: 140028.53125\nINFO:root:6: Epoch 5 train loss: 1323.838623046875\nINFO:root:5: Epoch 5 train loss: 295245.125\nINFO:root:7: Epoch 5 train loss: 193887.09375\nINFO:root:8: Epoch 5 train loss: 58732.890625\nINFO:root:1: Epoch 5 train loss: 20323.26171875\nINFO:root:2: Epoch 5 train loss: 3867.19970703125\nINFO:root:0: Epoch 5 train loss: 1817.6827392578125\nINFO:root:11: Epoch 5 train loss: 219456.8125\nINFO:root:10: Epoch 5 train loss: 3226.818115234375\nINFO:root:3: Epoch 5 train loss: 1866.203125\nINFO:root:12: Epoch 5 train loss: 158861.390625\nINFO:root:13: Epoch 5 train loss: 338908.59375\nINFO:root:14: Epoch 5 train loss: 4123.5673828125\nINFO:root:0: Epoch 5 validation loss: 5895467.472533528\n", "seconds": 16.983546018600464, "batch_size": 256, "nodes": 5, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 1 batches\n2: 1 batches\n17 Start Epoch 0\n17: 1 batches\n6 Start Epoch 0\n10 Start Epoch 0\n10: 1 batches\n13 Start Epoch 0\n6: 1 batches\n9 Start Epoch 0\n5 Start Epoch 0\n4 Start Epoch 0\n5: 1 batches\n12 Start Epoch 0\n4: 1 batches\n9: 1 batches\n13: 1 batches\n12: 1 batches\n3 Start Epoch 0\n14 Start Epoch 0\n15 Start Epoch 0\n3: 1 batches\n14: 1 batches\n11 Start Epoch 0\n11: 1 batches\n16 Start Epoch 0\n7 Start Epoch 0\n15: 1 batches\n8 Start Epoch 0\n16: 1 batches\n8: 1 batches\n7: 1 batches\n9 Start Epoch 1\n8 Start Epoch 1\n8: 1 batches\n9: 1 batches\n4 Start Epoch 1\n5 Start Epoch 1\n4: 1 batches\n5: 1 batches\n7 Start Epoch 1\n7: 1 batches\n6 Start Epoch 1\n6: 1 batches\n10 Start Epoch 1\n11 Start Epoch 1\n10: 1 batches\n11: 1 batches\n1 Start Epoch 1\n2 Start Epoch 1\n2: 1 batches\n1: 1 batches\n15 Start Epoch 1\n13 Start Epoch 1\n15: 1 batches\n12 Start Epoch 1\n12: 1 batches\n13: 1 batches\n14 Start Epoch 1\n3 Start Epoch 1\n14: 1 batches\n3: 1 batches\n16 Start Epoch 1\n16: 1 batches\n17 Start Epoch 1\n17: 1 batches\n0 Start Epoch 1\n0: 1 batches\n2 Start Epoch 2\n5 Start Epoch 2\n5: 1 batches\n2: 1 batches\n8 Start Epoch 2\n9 Start Epoch 2\n11 Start Epoch 2\n11: 1 batches\n7 Start Epoch 2\n7: 1 batches\n9: 1 batches\n8: 1 batches\n10 Start Epoch 2\n10: 1 batches\n6 Start Epoch 2\n6: 1 batches\n15 Start Epoch 2\n17 Start Epoch 2\n15: 1 batches\n16 Start Epoch 2\n16: 1 batches\n17: 1 batches\n1 Start Epoch 2\n1: 1 batches\n4 Start Epoch 2\n3 Start Epoch 2\n13 Start Epoch 2\n3: 1 batches\n14 Start Epoch 2\n4: 1 batches\n13: 1 batches\n14: 1 batches\n12 Start Epoch 2\n12: 1 batches\n0 Start Epoch 2\n0: 1 batches\n17 Start Epoch 3\n17: 1 batches\n8 Start Epoch 3\n8: 1 batches\n7 Start Epoch 3\n3 Start Epoch 3\n9 Start Epoch 3\n5 Start Epoch 3\n5: 1 batches\n11 Start Epoch 3\n3: 1 batches\n11: 1 batches\n4 Start Epoch 3\n9: 1 batches\n10 Start Epoch 3\n10: 1 batches\n4: 1 batches\n2 Start Epoch 3\n2: 1 batches\n1 Start Epoch 3\n1: 1 batches\n7: 1 batches\n6 Start Epoch 3\n6: 1 batches\n12 Start Epoch 3\n14 Start Epoch 3\n14: 1 batches\n12: 1 batches\n13 Start Epoch 3\n13: 1 batches\n16 Start Epoch 3\n15 Start Epoch 3\n16: 1 batches\n15: 1 batches\n0 Start Epoch 3\n0: 1 batches\n9 Start Epoch 4\n9: 1 batches\n5 Start Epoch 4\n5: 1 batches\n8 Start Epoch 4\n7 Start Epoch 4\n7: 1 batches\n8: 1 batches\n11 Start Epoch 4\n11: 1 batches\n10 Start Epoch 4\n10: 1 batches\n12 Start Epoch 4\n12: 1 batches\n6 Start Epoch 4\n6: 1 batches\n2 Start Epoch 4\n2: 1 batches\n1 Start Epoch 4\n1: 1 batches\n3 Start Epoch 4\n3: 1 batches\n13 Start Epoch 4\n17 Start Epoch 4\n14 Start Epoch 4\n14: 1 batches\n16 Start Epoch 4\n16: 1 batches\n13: 1 batches\n15 Start Epoch 4\n15: 1 batches\n17: 1 batches\n4 Start Epoch 4\n4: 1 batches\n0 Start Epoch 4\n0: 1 batches\n5 Start Epoch 5\n6 Start Epoch 5\n5: 1 batches\n6: 1 batches\n10 Start Epoch 5\n10: 1 batches\n7 Start Epoch 5\n9 Start Epoch 5\n9: 1 batches\n11 Start Epoch 5\n8 Start Epoch 5\n8: 1 batches\n7: 1 batches\n11: 1 batches\n12 Start Epoch 5\n12: 1 batches\n17 Start Epoch 5\n17: 1 batches\n16 Start Epoch 5\n16: 1 batches\n4 Start Epoch 5\n4: 1 batches\n14 Start Epoch 5\n14: 1 batches\n15 Start Epoch 5\n15: 1 batches\n2 Start Epoch 5\n2: 1 batches\n1 Start Epoch 5\n1: 1 batches\n3 Start Epoch 5\n3: 1 batches\n13 Start Epoch 5\n13: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:9: Epoch 0 train loss: 164824.34375\nINFO:root:8: Epoch 0 train loss: 1192.607421875\nINFO:root:5: Epoch 0 train loss: 170788.328125\nINFO:root:4: Epoch 0 train loss: 2860.626220703125\nINFO:root:6: Epoch 0 train loss: 3106.4052734375\nINFO:root:7: Epoch 0 train loss: 235625.109375\nINFO:root:10: Epoch 0 train loss: 2358.6171875\nINFO:root:11: Epoch 0 train loss: 66090.609375\nINFO:root:2: Epoch 0 train loss: 2014.837646484375\nINFO:root:1: Epoch 0 train loss: 195425.15625\nINFO:root:14: Epoch 0 train loss: 213136.609375\nINFO:root:13: Epoch 0 train loss: 9303.568359375\nINFO:root:12: Epoch 0 train loss: 209396.53125\nINFO:root:15: Epoch 0 train loss: 2962.239501953125\nINFO:root:3: Epoch 0 train loss: 160637.65625\nINFO:root:16: Epoch 0 train loss: 1477.7586669921875\nINFO:root:17: Epoch 0 train loss: 23785.890625\nINFO:root:0: Epoch 0 train loss: 187696.96875\nINFO:root:0: Epoch 0 validation loss: 34555.98412040073\nINFO:root:2: Epoch 1 train loss: 535158.3125\nINFO:root:5: Epoch 1 train loss: 2935.098388671875\nINFO:root:7: Epoch 1 train loss: 1344.8359375\nINFO:root:10: Epoch 1 train loss: 383341.75\nINFO:root:6: Epoch 1 train loss: 285.53802490234375\nINFO:root:11: Epoch 1 train loss: 5906.35595703125\nINFO:root:8: Epoch 1 train loss: 891.7223510742188\nINFO:root:9: Epoch 1 train loss: 212172.03125\nINFO:root:17: Epoch 1 train loss: 1086.9437255859375\nINFO:root:15: Epoch 1 train loss: 202.2063446044922\nINFO:root:16: Epoch 1 train loss: 1102.425537109375\nINFO:root:0: Epoch 1 train loss: 1383.922607421875\nINFO:root:1: Epoch 1 train loss: 197386.90625\nINFO:root:4: Epoch 1 train loss: 982.51318359375\nINFO:root:14: Epoch 1 train loss: 2416.9033203125\nINFO:root:3: Epoch 1 train loss: 393684.5\nINFO:root:12: Epoch 1 train loss: 193520.84375\nINFO:root:13: Epoch 1 train loss: 4695.265625\nINFO:root:0: Epoch 1 validation loss: 34553.05995577965\nINFO:root:2: Epoch 2 train loss: 880.2802124023438\nINFO:root:17: Epoch 2 train loss: 1560.2916259765625\nINFO:root:8: Epoch 2 train loss: 1660.2008056640625\nINFO:root:7: Epoch 2 train loss: 234188.609375\nINFO:root:4: Epoch 2 train loss: 162293.53125\nINFO:root:3: Epoch 2 train loss: 3539.9775390625\nINFO:root:10: Epoch 2 train loss: 290094.75\nINFO:root:5: Epoch 2 train loss: 235075.46875\nINFO:root:9: Epoch 2 train loss: 397582.125\nINFO:root:11: Epoch 2 train loss: 222897.765625\nINFO:root:1: Epoch 2 train loss: 69710.34375\nINFO:root:6: Epoch 2 train loss: 2395.230224609375\nINFO:root:14: Epoch 2 train loss: 780.2667846679688\nINFO:root:12: Epoch 2 train loss: 1566.6678466796875\nINFO:root:13: Epoch 2 train loss: 169721.46875\nINFO:root:16: Epoch 2 train loss: 5580.01611328125\nINFO:root:15: Epoch 2 train loss: 3095.396484375\nINFO:root:0: Epoch 2 train loss: 9367.7734375\nINFO:root:0: Epoch 2 validation loss: 34550.09080115436\nINFO:root:9: Epoch 3 train loss: 212181.015625\nINFO:root:5: Epoch 3 train loss: 2301.0205078125\nINFO:root:7: Epoch 3 train loss: 22721.150390625\nINFO:root:8: Epoch 3 train loss: 4532.50244140625\nINFO:root:11: Epoch 3 train loss: 1439.1302490234375\nINFO:root:10: Epoch 3 train loss: 4838.66845703125\nINFO:root:12: Epoch 3 train loss: 187649.625\nINFO:root:6: Epoch 3 train loss: 202827.296875\nINFO:root:1: Epoch 3 train loss: 2847.71923828125\nINFO:root:0: Epoch 3 train loss: 214389.5\nINFO:root:2: Epoch 3 train loss: 173597.15625\nINFO:root:3: Epoch 3 train loss: 188491.234375\nINFO:root:14: Epoch 3 train loss: 2341.305908203125\nINFO:root:15: Epoch 3 train loss: 160075.46875\nINFO:root:16: Epoch 3 train loss: 190087.046875\nINFO:root:13: Epoch 3 train loss: 4069.741943359375\nINFO:root:17: Epoch 3 train loss: 1032.111328125\nINFO:root:4: Epoch 3 train loss: 210553.0625\nINFO:root:0: Epoch 3 validation loss: 34547.13790886644\nINFO:root:6: Epoch 4 train loss: 2095.626220703125\nINFO:root:5: Epoch 4 train loss: 167971.328125\nINFO:root:11: Epoch 4 train loss: 4744.80615234375\nINFO:root:9: Epoch 4 train loss: 1511.6864013671875\nINFO:root:7: Epoch 4 train loss: 203578.25\nINFO:root:10: Epoch 4 train loss: 1721.0322265625\nINFO:root:8: Epoch 4 train loss: 234724.40625\nINFO:root:12: Epoch 4 train loss: 1634.7738037109375\nINFO:root:16: Epoch 4 train loss: 1384.418212890625\nINFO:root:17: Epoch 4 train loss: 7408.87255859375\nINFO:root:4: Epoch 4 train loss: 2287.770751953125\nINFO:root:14: Epoch 4 train loss: 1898.293701171875\nINFO:root:0: Epoch 4 train loss: 22742.837890625\nINFO:root:13: Epoch 4 train loss: 7654.806640625\nINFO:root:15: Epoch 4 train loss: 189445.484375\nINFO:root:3: Epoch 4 train loss: 325027.3125\nINFO:root:1: Epoch 4 train loss: 22687.017578125\nINFO:root:2: Epoch 4 train loss: 215214.40625\nINFO:root:0: Epoch 4 validation loss: 34544.160318607464\nINFO:root:6: Epoch 5 train loss: 1627.4320068359375\nINFO:root:8: Epoch 5 train loss: 1049.2012939453125\nINFO:root:7: Epoch 5 train loss: 67903.0078125\nINFO:root:9: Epoch 5 train loss: 7268.27490234375\nINFO:root:10: Epoch 5 train loss: 202173.0\nINFO:root:11: Epoch 5 train loss: 23224.111328125\nINFO:root:12: Epoch 5 train loss: 196895.203125\nINFO:root:2: Epoch 5 train loss: 194658.53125\nINFO:root:15: Epoch 5 train loss: 188697.203125\nINFO:root:17: Epoch 5 train loss: 3117.709228515625\nINFO:root:16: Epoch 5 train loss: 660.6357421875\nINFO:root:1: Epoch 5 train loss: 4769.53515625\nINFO:root:0: Epoch 5 train loss: 235242.71875\nINFO:root:13: Epoch 5 train loss: 9046.90234375\nINFO:root:14: Epoch 5 train loss: 3172.94482421875\nINFO:root:4: Epoch 5 train loss: 25816.658203125\nINFO:root:5: Epoch 5 train loss: 236003.390625\nINFO:root:3: Epoch 5 train loss: 717.695068359375\nINFO:root:0: Epoch 5 validation loss: 34541.09360131274\n", "seconds": 17.167788982391357, "batch_size": 256, "nodes": 6, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 1 batches\n2: 1 batches\n13 Start Epoch 0\n14 Start Epoch 0\n13: 1 batches\n14: 1 batches\n4 Start Epoch 0\n4: 1 batches\n15 Start Epoch 0\n8 Start Epoch 0\n3 Start Epoch 0\n15: 1 batches\n3: 1 batches\n16 Start Epoch 0\n8: 1 batches\n16: 1 batches\n5 Start Epoch 0\n6 Start Epoch 0\n5: 1 batches\n9 Start Epoch 0\n7 Start Epoch 0\n7: 1 batches\n18 Start Epoch 0\n10 Start Epoch 0\n6: 1 batches\n18: 1 batches\n10: 1 batches\n9: 1 batches\n17 Start Epoch 0\n17: 1 batches\n12 Start Epoch 0\n12: 1 batches\n11 Start Epoch 0\n11: 1 batches\n20 Start Epoch 0\n19 Start Epoch 0\n20: 1 batches\n19: 1 batches\n11 Start Epoch 1\n11: 1 batches\n12 Start Epoch 1\n12: 1 batches\n20 Start Epoch 1\n18 Start Epoch 1\n17 Start Epoch 1\n9 Start Epoch 1\n15 Start Epoch 1\n18: 1 batches\n4 Start Epoch 1\n10 Start Epoch 1\n17: 1 batches\n19 Start Epoch 1\n8 Start Epoch 1\n19: 1 batches\n4: 1 batches\n9: 1 batches\n15: 1 batches\n10: 1 batches\n16 Start Epoch 1\n8: 1 batches\n20: 1 batches\n5 Start Epoch 1\n5: 1 batches\n16: 1 batches\n7 Start Epoch 1\n7: 1 batches\n3 Start Epoch 1\n3: 1 batches\n6 Start Epoch 1\n6: 1 batches\n13 Start Epoch 1\n14 Start Epoch 1\n14: 1 batches\n13: 1 batches\n1 Start Epoch 1\n1: 1 batches\n2 Start Epoch 1\n2: 1 batches\n0 Start Epoch 1\n0: 1 batches\n6 Start Epoch 2\n8 Start Epoch 2\n9 Start Epoch 2\n9: 1 batches\n11 Start Epoch 2\n11: 1 batches\n10 Start Epoch 2\n10: 1 batches\n3 Start Epoch 2\n17 Start Epoch 2\n15 Start Epoch 2\n15: 1 batches\n17: 1 batches\n16 Start Epoch 2\n16: 1 batches\n2 Start Epoch 2\n2: 1 batches\n3: 1 batches\n5 Start Epoch 2\n5: 1 batches\n6: 1 batches\n7 Start Epoch 2\n7: 1 batches\n8: 1 batches\n18 Start Epoch 2\n18: 1 batches\n13 Start Epoch 2\n13: 1 batches\n14 Start Epoch 2\n14: 1 batches\n12 Start Epoch 2\n12: 1 batches\n4 Start Epoch 2\n20 Start Epoch 2\n4: 1 batches\n19 Start Epoch 2\n20: 1 batches\n19: 1 batches\n1 Start Epoch 2\n1: 1 batches\n0 Start Epoch 2\n0: 1 batches\n15 Start Epoch 3\n17 Start Epoch 3\n15: 1 batches\n17: 1 batches\n16 Start Epoch 3\n16: 1 batches\n18 Start Epoch 3\n18: 1 batches\n20 Start Epoch 3\n19 Start Epoch 3\n19: 1 batches\n8 Start Epoch 3\n8: 1 batches\n10 Start Epoch 3\n9 Start Epoch 3\n9: 1 batches\n10: 1 batches\n11 Start Epoch 3\n11: 1 batches\n20: 1 batches\n7 Start Epoch 3\n7: 1 batches\n12 Start Epoch 3\n13 Start Epoch 3\n12: 1 batches\n14 Start Epoch 3\n14: 1 batches\n13: 1 batches\n5 Start Epoch 3\n6 Start Epoch 3\n6: 1 batches\n5: 1 batches\n3 Start Epoch 3\n4 Start Epoch 3\n3: 1 batches\n4: 1 batches\n1 Start Epoch 3\n1: 1 batches\n2 Start Epoch 3\n2: 1 batches\n0 Start Epoch 3\n0: 1 batches\n3 Start Epoch 4\n3: 1 batches\n8 Start Epoch 4\n7 Start Epoch 4\n18 Start Epoch 4\n17 Start Epoch 4\n17: 1 batches\n7: 1 batches\n20 Start Epoch 4\n4 Start Epoch 4\n8: 1 batches\n11 Start Epoch 4\n9 Start Epoch 4\n10 Start Epoch 4\n9: 1 batches\n10: 1 batches\n2 Start Epoch 4\n1 Start Epoch 4\n1: 1 batches\n2: 1 batches\n15 Start Epoch 4\n6 Start Epoch 4\n12 Start Epoch 4\n5 Start Epoch 4\n15: 1 batches\n6: 1 batches\n18: 1 batches\n12: 1 batches\n4: 1 batches\n5: 1 batches\n20: 1 batches\n19 Start Epoch 4\n19: 1 batches\n16 Start Epoch 4\n16: 1 batches\n14 Start Epoch 4\n13 Start Epoch 4\n14: 1 batches\n13: 1 batches\n11: 1 batches\n0 Start Epoch 4\n0: 1 batches\n11 Start Epoch 5\n11: 1 batches\n10 Start Epoch 5\n10: 1 batches\n9 Start Epoch 5\n9: 1 batches\n8 Start Epoch 5\n8: 1 batches\n7 Start Epoch 5\n7: 1 batches\n6 Start Epoch 5\n6: 1 batches\n12 Start Epoch 5\n12: 1 batches\n1 Start Epoch 5\n2 Start Epoch 5\n1: 1 batches\n2: 1 batches\n5 Start Epoch 5\n3 Start Epoch 5\n3: 1 batches\n4 Start Epoch 5\n4: 1 batches\n5: 1 batches\n17 Start Epoch 5\n17: 1 batches\n13 Start Epoch 5\n14 Start Epoch 5\n13: 1 batches\n14: 1 batches\n20 Start Epoch 5\n18 Start Epoch 5\n20: 1 batches\n18: 1 batches\n19 Start Epoch 5\n19: 1 batches\n16 Start Epoch 5\n15 Start Epoch 5\n16: 1 batches\n15: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:11: Epoch 0 train loss: 497075.84375\nINFO:root:12: Epoch 0 train loss: 270864.40625\nINFO:root:19: Epoch 0 train loss: 8401.0517578125\nINFO:root:17: Epoch 0 train loss: 3333.473388671875\nINFO:root:18: Epoch 0 train loss: 1079.5177001953125\nINFO:root:20: Epoch 0 train loss: 788.1049194335938\nINFO:root:16: Epoch 0 train loss: 235088.4375\nINFO:root:9: Epoch 0 train loss: 220317.21875\nINFO:root:15: Epoch 0 train loss: 5671.927734375\nINFO:root:4: Epoch 0 train loss: 1253.3231201171875\nINFO:root:10: Epoch 0 train loss: 217506.59375\nINFO:root:7: Epoch 0 train loss: 973.065673828125\nINFO:root:5: Epoch 0 train loss: 908.361328125\nINFO:root:8: Epoch 0 train loss: 9748.6640625\nINFO:root:3: Epoch 0 train loss: 245993.65625\nINFO:root:6: Epoch 0 train loss: 233800.65625\nINFO:root:14: Epoch 0 train loss: 1959.9068603515625\nINFO:root:13: Epoch 0 train loss: 234944.953125\nINFO:root:1: Epoch 0 train loss: 4204.14501953125\nINFO:root:2: Epoch 0 train loss: 242.94476318359375\nINFO:root:0: Epoch 0 train loss: 25529.009765625\nINFO:root:0: Epoch 0 validation loss: 162791.89607440116\nINFO:root:6: Epoch 1 train loss: 2547.3291015625\nINFO:root:8: Epoch 1 train loss: 1743.3248291015625\nINFO:root:7: Epoch 1 train loss: 1282.0035400390625\nINFO:root:11: Epoch 1 train loss: 228197.8125\nINFO:root:9: Epoch 1 train loss: 2222.482421875\nINFO:root:10: Epoch 1 train loss: 78545.546875\nINFO:root:15: Epoch 1 train loss: 232746.59375\nINFO:root:17: Epoch 1 train loss: 1219.8258056640625\nINFO:root:5: Epoch 1 train loss: 489.349853515625\nINFO:root:3: Epoch 1 train loss: 2544.142333984375\nINFO:root:16: Epoch 1 train loss: 4924.8447265625\nINFO:root:2: Epoch 1 train loss: 1631.563232421875\nINFO:root:18: Epoch 1 train loss: 1313.554443359375\nINFO:root:12: Epoch 1 train loss: 3648.744384765625\nINFO:root:14: Epoch 1 train loss: 741.8380737304688\nINFO:root:13: Epoch 1 train loss: 5151.08642578125\nINFO:root:4: Epoch 1 train loss: 7283.95751953125\nINFO:root:20: Epoch 1 train loss: 270761.71875\nINFO:root:19: Epoch 1 train loss: 26135.044921875\nINFO:root:1: Epoch 1 train loss: 1796.5687255859375\nINFO:root:0: Epoch 1 train loss: 465434.625\nINFO:root:0: Epoch 1 validation loss: 162786.53714511453\nINFO:root:15: Epoch 2 train loss: 229093.390625\nINFO:root:17: Epoch 2 train loss: 1595.8504638671875\nINFO:root:16: Epoch 2 train loss: 702.868408203125\nINFO:root:18: Epoch 2 train loss: 76981.6484375\nINFO:root:20: Epoch 2 train loss: 3147.0859375\nINFO:root:19: Epoch 2 train loss: 1103.6204833984375\nINFO:root:8: Epoch 2 train loss: 470639.84375\nINFO:root:11: Epoch 2 train loss: 4162.2080078125\nINFO:root:9: Epoch 2 train loss: 25792.4140625\nINFO:root:10: Epoch 2 train loss: 1816.94091796875\nINFO:root:0: Epoch 2 train loss: 232916.46875\nINFO:root:14: Epoch 2 train loss: 1727.098388671875\nINFO:root:7: Epoch 2 train loss: 2120.1015625\nINFO:root:13: Epoch 2 train loss: 2217.984619140625\nINFO:root:12: Epoch 2 train loss: 76976.265625\nINFO:root:5: Epoch 2 train loss: 5268.15185546875\nINFO:root:6: Epoch 2 train loss: 27472.923828125\nINFO:root:4: Epoch 2 train loss: 3345.135009765625\nINFO:root:3: Epoch 2 train loss: 7444.9833984375\nINFO:root:1: Epoch 2 train loss: 4995.27197265625\nINFO:root:2: Epoch 2 train loss: 1594.6090087890625\nINFO:root:0: Epoch 2 validation loss: 162781.0861540085\nINFO:root:3: Epoch 3 train loss: 2732.30517578125\nINFO:root:7: Epoch 3 train loss: 30536.869140625\nINFO:root:18: Epoch 3 train loss: 724.7659301757812\nINFO:root:8: Epoch 3 train loss: 199562.765625\nINFO:root:20: Epoch 3 train loss: 4783.26953125\nINFO:root:19: Epoch 3 train loss: 238618.109375\nINFO:root:4: Epoch 3 train loss: 1115.77978515625\nINFO:root:10: Epoch 3 train loss: 470638.5625\nINFO:root:17: Epoch 3 train loss: 2529.666748046875\nINFO:root:11: Epoch 3 train loss: 1139.8690185546875\nINFO:root:9: Epoch 3 train loss: 27989.0625\nINFO:root:1: Epoch 3 train loss: 735.1366577148438\nINFO:root:2: Epoch 3 train loss: 226035.21875\nINFO:root:5: Epoch 3 train loss: 1621.58203125\nINFO:root:12: Epoch 3 train loss: 1398.0333251953125\nINFO:root:15: Epoch 3 train loss: 7917.1416015625\nINFO:root:6: Epoch 3 train loss: 184221.203125\nINFO:root:16: Epoch 3 train loss: 184322.53125\nINFO:root:14: Epoch 3 train loss: 1190.1163330078125\nINFO:root:13: Epoch 3 train loss: 1023.5872802734375\nINFO:root:0: Epoch 3 train loss: 143.56295776367188\nINFO:root:0: Epoch 3 validation loss: 162775.63688349185\nINFO:root:11: Epoch 4 train loss: 27594.205078125\nINFO:root:10: Epoch 4 train loss: 4309.00341796875\nINFO:root:9: Epoch 4 train loss: 1241.683837890625\nINFO:root:8: Epoch 4 train loss: 270613.5\nINFO:root:7: Epoch 4 train loss: 4263.3642578125\nINFO:root:6: Epoch 4 train loss: 186204.6875\nINFO:root:12: Epoch 4 train loss: 250593.921875\nINFO:root:1: Epoch 4 train loss: 7207.12353515625\nINFO:root:2: Epoch 4 train loss: 98.56584930419922\nINFO:root:5: Epoch 4 train loss: 3375.537841796875\nINFO:root:3: Epoch 4 train loss: 218470.40625\nINFO:root:4: Epoch 4 train loss: 2271.9619140625\nINFO:root:17: Epoch 4 train loss: 2458.444091796875\nINFO:root:0: Epoch 4 train loss: 185426.984375\nINFO:root:13: Epoch 4 train loss: 769.4161376953125\nINFO:root:18: Epoch 4 train loss: 270597.1875\nINFO:root:14: Epoch 4 train loss: 279570.625\nINFO:root:20: Epoch 4 train loss: 3927.96337890625\nINFO:root:19: Epoch 4 train loss: 769.62158203125\nINFO:root:15: Epoch 4 train loss: 1206.2669677734375\nINFO:root:16: Epoch 4 train loss: 4814.310546875\nINFO:root:0: Epoch 4 validation loss: 162770.1587406145\nINFO:root:11: Epoch 5 train loss: 1028.68359375\nINFO:root:8: Epoch 5 train loss: 26432.97265625\nINFO:root:10: Epoch 5 train loss: 202642.90625\nINFO:root:7: Epoch 5 train loss: 8216.0361328125\nINFO:root:9: Epoch 5 train loss: 188596.140625\nINFO:root:17: Epoch 5 train loss: 1589.9190673828125\nINFO:root:18: Epoch 5 train loss: 3203.77001953125\nINFO:root:20: Epoch 5 train loss: 373602.90625\nINFO:root:4: Epoch 5 train loss: 3153.672119140625\nINFO:root:5: Epoch 5 train loss: 481.94073486328125\nINFO:root:19: Epoch 5 train loss: 26766.6875\nINFO:root:3: Epoch 5 train loss: 1093.34423828125\nINFO:root:16: Epoch 5 train loss: 195315.390625\nINFO:root:12: Epoch 5 train loss: 5480.41162109375\nINFO:root:6: Epoch 5 train loss: 3865.403564453125\nINFO:root:13: Epoch 5 train loss: 892.042724609375\nINFO:root:2: Epoch 5 train loss: 5721.44091796875\nINFO:root:14: Epoch 5 train loss: 233280.078125\nINFO:root:0: Epoch 5 train loss: 236486.5\nINFO:root:1: Epoch 5 train loss: 542.3157958984375\nINFO:root:15: Epoch 5 train loss: 1561.4552001953125\nINFO:root:0: Epoch 5 validation loss: 162764.6244086523\n", "seconds": 18.524280786514282, "batch_size": 256, "nodes": 7, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n2 Start Epoch 0\n2: 1 batches\n1: 1 batches\n3 Start Epoch 0\n4 Start Epoch 0\n3: 1 batches\n4: 1 batches\n5 Start Epoch 0\n5: 1 batches\n8 Start Epoch 0\n8: 1 batches\n7 Start Epoch 0\n7: 1 batches\n6 Start Epoch 0\n23 Start Epoch 0\n6: 1 batches\n15 Start Epoch 0\n23: 1 batches\n15: 1 batches\n16 Start Epoch 0\n16: 1 batches\n11 Start Epoch 0\n11: 1 batches\n12 Start Epoch 0\n19 Start Epoch 0\n20 Start Epoch 0\n19: 1 batches\n20: 1 batches\n12: 1 batches\n17 Start Epoch 0\n9 Start Epoch 0\n17: 1 batches\n10 Start Epoch 0\n9: 1 batches\n10: 1 batches\n14 Start Epoch 0\n22 Start Epoch 0\n14: 1 batches\n18 Start Epoch 0\n21 Start Epoch 0\n18: 1 batches\n21: 1 batches\n13 Start Epoch 0\n22: 1 batches\n13: 1 batches\n11 Start Epoch 1\n11: 1 batches\n15 Start Epoch 1\n17 Start Epoch 1\n17: 1 batches\n16 Start Epoch 1\n15: 1 batches\n16: 1 batches\n18 Start Epoch 1\n18: 1 batches\n12 Start Epoch 1\n12: 1 batches\n13 Start Epoch 1\n5 Start Epoch 1\n13: 1 batches\n5: 1 batches\n6 Start Epoch 1\n8 Start Epoch 1\n8: 1 batches\n21 Start Epoch 1\n7 Start Epoch 1\n22 Start Epoch 1\n7: 1 batches\n9 Start Epoch 1\n10 Start Epoch 1\n21: 1 batches\n23 Start Epoch 1\n1 Start Epoch 1\n1: 1 batches\n10: 1 batches\n22: 1 batches\n6: 1 batches\n23: 1 batches\n9: 1 batches\n2 Start Epoch 1\n2: 1 batches\n3 Start Epoch 1\n4 Start Epoch 1\n3: 1 batches\n4: 1 batches\n14 Start Epoch 1\n14: 1 batches\n19 Start Epoch 1\n20 Start Epoch 1\n20: 1 batches\n19: 1 batches\n0 Start Epoch 1\n0: 1 batches\n10 Start Epoch 2\n17 Start Epoch 2\n15 Start Epoch 2\n15: 1 batches\n11 Start Epoch 2\n17: 1 batches\n16 Start Epoch 2\n10: 1 batches\n16: 1 batches\n4 Start Epoch 2\n11: 1 batches\n21 Start Epoch 2\n4: 1 batches\n22 Start Epoch 2\n9 Start Epoch 2\n21: 1 batches\n6 Start Epoch 2\n9: 1 batches\n22: 1 batches\n23 Start Epoch 2\n8 Start Epoch 2\n23: 1 batches\n3 Start Epoch 2\n18 Start Epoch 2\n18: 1 batches\n14 Start Epoch 2\n5 Start Epoch 2\n12 Start Epoch 2\n3: 1 batches\n20 Start Epoch 2\n14: 1 batches\n5: 1 batches\n19 Start Epoch 2\n13 Start Epoch 2\n20: 1 batches\n13: 1 batches\n12: 1 batches\n19: 1 batches\n1 Start Epoch 2\n1: 1 batches\n8: 1 batches\n7 Start Epoch 2\n7: 1 batches\n6: 1 batches\n2 Start Epoch 2\n2: 1 batches\n0 Start Epoch 2\n0: 1 batches\n21 Start Epoch 3\n15 Start Epoch 3\n17 Start Epoch 3\n17: 1 batches\n22 Start Epoch 3\n21: 1 batches\n16 Start Epoch 3\n22: 1 batches\n15: 1 batches\n16: 1 batches\n23 Start Epoch 3\n23: 1 batches\n19 Start Epoch 3\n18 Start Epoch 3\n18: 1 batches\n20 Start Epoch 3\n20: 1 batches\n19: 1 batches\n10 Start Epoch 3\n10: 1 batches\n6 Start Epoch 3\n4 Start Epoch 3\n8 Start Epoch 3\n5 Start Epoch 3\n8: 1 batches\n5: 1 batches\n4: 1 batches\n6: 1 batches\n3 Start Epoch 3\n7 Start Epoch 3\n3: 1 batches\n7: 1 batches\n11 Start Epoch 3\n9 Start Epoch 3\n9: 1 batches\n11: 1 batches\n12 Start Epoch 3\n14 Start Epoch 3\n14: 1 batches\n13 Start Epoch 3\n13: 1 batches\n1 Start Epoch 3\n12: 1 batches\n1: 1 batches\n2 Start Epoch 3\n2: 1 batches\n0 Start Epoch 3\n0: 1 batches\n20 Start Epoch 4\n20: 1 batches\n22 Start Epoch 4\n21 Start Epoch 4\n22: 1 batches\n21: 1 batches\n23 Start Epoch 4\n23: 1 batches\n18 Start Epoch 4\n18: 1 batches\n19 Start Epoch 4\n19: 1 batches\n17 Start Epoch 4\n17: 1 batches\n11 Start Epoch 4\n11: 1 batches\n12 Start Epoch 4\n13 Start Epoch 4\n13: 1 batches\n14 Start Epoch 4\n14: 1 batches\n12: 1 batches\n9 Start Epoch 4\n9: 1 batches\n10 Start Epoch 4\n10: 1 batches\n15 Start Epoch 4\n15: 1 batches\n16 Start Epoch 4\n16: 1 batches\n8 Start Epoch 4\n7 Start Epoch 4\n8: 1 batches\n7: 1 batches\n5 Start Epoch 4\n5: 1 batches\n6 Start Epoch 4\n6: 1 batches\n1 Start Epoch 4\n1: 1 batches\n3 Start Epoch 4\n3: 1 batches\n4 Start Epoch 4\n4: 1 batches\n2 Start Epoch 4\n2: 1 batches\n0 Start Epoch 4\n0: 1 batches\n11 Start Epoch 5\n11: 1 batches\n5 Start Epoch 5\n5: 1 batches\n10 Start Epoch 5\n8 Start Epoch 5\n21 Start Epoch 5\n7 Start Epoch 5\n22 Start Epoch 5\n8: 1 batches\n21: 1 batches\n6 Start Epoch 5\n6: 1 batches\n23 Start Epoch 5\n7: 1 batches\n23: 1 batches\n16 Start Epoch 5\n22: 1 batches\n17 Start Epoch 5\n17: 1 batches\n16: 1 batches\n12 Start Epoch 5\n4 Start Epoch 5\n4: 1 batches\n20 Start Epoch 5\n20: 1 batches\n19 Start Epoch 5\n12: 1 batches\n19: 1 batches\n18 Start Epoch 5\n15 Start Epoch 5\n18: 1 batches\n15: 1 batches\n9 Start Epoch 5\n9: 1 batches\n10: 1 batches\n2 Start Epoch 5\n2: 1 batches\n3 Start Epoch 5\n3: 1 batches\n14 Start Epoch 5\n14: 1 batches\n13 Start Epoch 5\n13: 1 batches\n1 Start Epoch 5\n1: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:11: Epoch 0 train loss: 957.0906982421875\nINFO:root:17: Epoch 0 train loss: 4630.6806640625\nINFO:root:15: Epoch 0 train loss: 3471.33935546875\nINFO:root:16: Epoch 0 train loss: 1981.0650634765625\nINFO:root:18: Epoch 0 train loss: 1035.6397705078125\nINFO:root:12: Epoch 0 train loss: 467992.21875\nINFO:root:13: Epoch 0 train loss: 4177.9521484375\nINFO:root:5: Epoch 0 train loss: 3439.503662109375\nINFO:root:6: Epoch 0 train loss: 502306.8125\nINFO:root:7: Epoch 0 train loss: 569879.5\nINFO:root:8: Epoch 0 train loss: 32102.267578125\nINFO:root:21: Epoch 0 train loss: 249781.4375\nINFO:root:22: Epoch 0 train loss: 666.5852661132812\nINFO:root:23: Epoch 0 train loss: 1393.503173828125\nINFO:root:9: Epoch 0 train loss: 3119.652587890625\nINFO:root:10: Epoch 0 train loss: 4726.14208984375\nINFO:root:0: Epoch 0 train loss: 290.72735595703125\nINFO:root:1: Epoch 0 train loss: 1963.251708984375\nINFO:root:2: Epoch 0 train loss: 1025.5516357421875\nINFO:root:3: Epoch 0 train loss: 792.2315063476562\nINFO:root:4: Epoch 0 train loss: 6541.31884765625\nINFO:root:14: Epoch 0 train loss: 3147.86962890625\nINFO:root:19: Epoch 0 train loss: 11920.064453125\nINFO:root:20: Epoch 0 train loss: 6712.47314453125\nINFO:root:0: Epoch 0 validation loss: 109414.77339126912\nINFO:root:17: Epoch 1 train loss: 29876.4140625\nINFO:root:15: Epoch 1 train loss: 292.36187744140625\nINFO:root:16: Epoch 1 train loss: 255.2894744873047\nINFO:root:21: Epoch 1 train loss: 694.5506591796875\nINFO:root:11: Epoch 1 train loss: 8791.658203125\nINFO:root:22: Epoch 1 train loss: 3113.26513671875\nINFO:root:10: Epoch 1 train loss: 7606.35205078125\nINFO:root:23: Epoch 1 train loss: 223002.875\nINFO:root:4: Epoch 1 train loss: 399.9135437011719\nINFO:root:7: Epoch 1 train loss: 8988.6328125\nINFO:root:8: Epoch 1 train loss: 634.47998046875\nINFO:root:9: Epoch 1 train loss: 2219.12353515625\nINFO:root:6: Epoch 1 train loss: 771.7284545898438\nINFO:root:18: Epoch 1 train loss: 3111.694091796875\nINFO:root:13: Epoch 1 train loss: 440.833251953125\nINFO:root:5: Epoch 1 train loss: 510.32904052734375\nINFO:root:14: Epoch 1 train loss: 363.6147766113281\nINFO:root:12: Epoch 1 train loss: 391.27081298828125\nINFO:root:3: Epoch 1 train loss: 1386.503173828125\nINFO:root:20: Epoch 1 train loss: 258595.953125\nINFO:root:19: Epoch 1 train loss: 281816.125\nINFO:root:1: Epoch 1 train loss: 280926.15625\nINFO:root:0: Epoch 1 train loss: 4115.63134765625\nINFO:root:2: Epoch 1 train loss: 433575.25\nINFO:root:0: Epoch 1 validation loss: 109410.74726682395\nINFO:root:21: Epoch 2 train loss: 919.8635864257812\nINFO:root:17: Epoch 2 train loss: 745.7138061523438\nINFO:root:15: Epoch 2 train loss: 4009.675537109375\nINFO:root:22: Epoch 2 train loss: 3461.921630859375\nINFO:root:16: Epoch 2 train loss: 29028.2421875\nINFO:root:23: Epoch 2 train loss: 1913.147216796875\nINFO:root:18: Epoch 2 train loss: 1564.4937744140625\nINFO:root:20: Epoch 2 train loss: 6570.33837890625\nINFO:root:19: Epoch 2 train loss: 2655.741943359375\nINFO:root:10: Epoch 2 train loss: 538.5573120117188\nINFO:root:3: Epoch 2 train loss: 3464.239013671875\nINFO:root:6: Epoch 2 train loss: 778.5118408203125\nINFO:root:4: Epoch 2 train loss: 9790.7685546875\nINFO:root:5: Epoch 2 train loss: 3269.9140625\nINFO:root:8: Epoch 2 train loss: 870.0972900390625\nINFO:root:7: Epoch 2 train loss: 1325.8167724609375\nINFO:root:9: Epoch 2 train loss: 489.9336242675781\nINFO:root:0: Epoch 2 train loss: 95835.0625\nINFO:root:11: Epoch 2 train loss: 9393.8837890625\nINFO:root:14: Epoch 2 train loss: 286546.21875\nINFO:root:12: Epoch 2 train loss: 1044.571044921875\nINFO:root:13: Epoch 2 train loss: 258195.546875\nINFO:root:1: Epoch 2 train loss: 2433.8330078125\nINFO:root:2: Epoch 2 train loss: 7627.82421875\nINFO:root:0: Epoch 2 validation loss: 109406.60114750304\nINFO:root:20: Epoch 3 train loss: 671.6908569335938\nINFO:root:21: Epoch 3 train loss: 6095.89697265625\nINFO:root:22: Epoch 3 train loss: 1435.90673828125\nINFO:root:23: Epoch 3 train loss: 311186.96875\nINFO:root:19: Epoch 3 train loss: 3365.0322265625\nINFO:root:18: Epoch 3 train loss: 4920.87255859375\nINFO:root:17: Epoch 3 train loss: 259.4701843261719\nINFO:root:11: Epoch 3 train loss: 224054.5625\nINFO:root:14: Epoch 3 train loss: 30147.322265625\nINFO:root:12: Epoch 3 train loss: 1083.047607421875\nINFO:root:13: Epoch 3 train loss: 385.3856201171875\nINFO:root:9: Epoch 3 train loss: 444.36065673828125\nINFO:root:0: Epoch 3 train loss: 90148.8515625\nINFO:root:10: Epoch 3 train loss: 30806.486328125\nINFO:root:15: Epoch 3 train loss: 269002.21875\nINFO:root:16: Epoch 3 train loss: 249700.546875\nINFO:root:7: Epoch 3 train loss: 1446.7591552734375\nINFO:root:8: Epoch 3 train loss: 7410.9189453125\nINFO:root:5: Epoch 3 train loss: 1196.5711669921875\nINFO:root:4: Epoch 3 train loss: 974.0460815429688\nINFO:root:6: Epoch 3 train loss: 2514.985107421875\nINFO:root:1: Epoch 3 train loss: 2325.0361328125\nINFO:root:3: Epoch 3 train loss: 225253.84375\nINFO:root:2: Epoch 3 train loss: 709.1986083984375\nINFO:root:0: Epoch 3 validation loss: 109402.45097582032\nINFO:root:11: Epoch 4 train loss: 90436.8828125\nINFO:root:5: Epoch 4 train loss: 533004.75\nINFO:root:7: Epoch 4 train loss: 259686.484375\nINFO:root:9: Epoch 4 train loss: 2537.1416015625\nINFO:root:6: Epoch 4 train loss: 29450.06640625\nINFO:root:10: Epoch 4 train loss: 735.00537109375\nINFO:root:23: Epoch 4 train loss: 1989.7430419921875\nINFO:root:8: Epoch 4 train loss: 260006.78125\nINFO:root:21: Epoch 4 train loss: 35106.6640625\nINFO:root:22: Epoch 4 train loss: 213581.03125\nINFO:root:16: Epoch 4 train loss: 960.2274169921875\nINFO:root:17: Epoch 4 train loss: 223.54702758789062\nINFO:root:12: Epoch 4 train loss: 480.1762390136719\nINFO:root:4: Epoch 4 train loss: 309276.3125\nINFO:root:20: Epoch 4 train loss: 1791.487060546875\nINFO:root:19: Epoch 4 train loss: 1120.6644287109375\nINFO:root:14: Epoch 4 train loss: 5131.9853515625\nINFO:root:18: Epoch 4 train loss: 2939.8994140625\nINFO:root:15: Epoch 4 train loss: 137.41526794433594\nINFO:root:2: Epoch 4 train loss: 722.971435546875\nINFO:root:3: Epoch 4 train loss: 251174.84375\nINFO:root:13: Epoch 4 train loss: 1172.369873046875\nINFO:root:0: Epoch 4 train loss: 3828.095458984375\nINFO:root:1: Epoch 4 train loss: 96221.4296875\nINFO:root:0: Epoch 4 validation loss: 109398.25800133291\nINFO:root:8: Epoch 5 train loss: 216324.90625\nINFO:root:9: Epoch 5 train loss: 484.7655029296875\nINFO:root:5: Epoch 5 train loss: 1572.786865234375\nINFO:root:17: Epoch 5 train loss: 6274.4072265625\nINFO:root:4: Epoch 5 train loss: 2779.004150390625\nINFO:root:10: Epoch 5 train loss: 747.8162231445312\nINFO:root:3: Epoch 5 train loss: 2364.327880859375\nINFO:root:15: Epoch 5 train loss: 249728.78125\nINFO:root:18: Epoch 5 train loss: 2025.0093994140625\nINFO:root:16: Epoch 5 train loss: 1127.9794921875\nINFO:root:12: Epoch 5 train loss: 3430.77001953125\nINFO:root:11: Epoch 5 train loss: 985.6882934570312\nINFO:root:2: Epoch 5 train loss: 568297.5625\nINFO:root:14: Epoch 5 train loss: 471618.53125\nINFO:root:13: Epoch 5 train loss: 4317.97265625\nINFO:root:19: Epoch 5 train loss: 4371.6533203125\nINFO:root:20: Epoch 5 train loss: 830.6525268554688\nINFO:root:6: Epoch 5 train loss: 298563.59375\nINFO:root:7: Epoch 5 train loss: 258410.609375\nINFO:root:22: Epoch 5 train loss: 357.5725402832031\nINFO:root:23: Epoch 5 train loss: 5477.2001953125\nINFO:root:21: Epoch 5 train loss: 4417.81640625\nINFO:root:0: Epoch 5 train loss: 797.7840576171875\nINFO:root:1: Epoch 5 train loss: 29584.505859375\nINFO:root:0: Epoch 5 validation loss: 109394.09188208029\n", "seconds": 19.356560230255127, "batch_size": 256, "nodes": 8, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 1 batches\n2: 1 batches\n3 Start Epoch 0\n4 Start Epoch 0\n4: 1 batches\n3: 1 batches\n11 Start Epoch 0\n11: 1 batches\n23 Start Epoch 0\n12 Start Epoch 0\n16 Start Epoch 0\n23: 1 batches\n12: 1 batches\n19 Start Epoch 0\n16: 1 batches\n24 Start Epoch 0\n20 Start Epoch 0\n19: 1 batches\n20: 1 batches\n24: 1 batches\n15 Start Epoch 0\n15: 1 batches\n7 Start Epoch 0\n8 Start Epoch 0\n8: 1 batches\n5 Start Epoch 0\n7: 1 batches\n5: 1 batches\n6 Start Epoch 0\n6: 1 batches\n9 Start Epoch 0\n10 Start Epoch 0\n10: 1 batches\n22 Start Epoch 0\n13 Start Epoch 0\n21 Start Epoch 0\n14 Start Epoch 0\n22: 1 batches\n13: 1 batches\n14: 1 batches\n21: 1 batches\n25 Start Epoch 0\n26 Start Epoch 0\n18 Start Epoch 0\n26: 1 batches\n17 Start Epoch 0\n25: 1 batches\n17: 1 batches\n18: 1 batches\n9: 1 batches\n22 Start Epoch 1\n25 Start Epoch 1\n21 Start Epoch 1\n26 Start Epoch 1\n22: 1 batches\n26: 1 batches\n23 Start Epoch 1\n25: 1 batches\n23: 1 batches\n24 Start Epoch 1\n21: 1 batches\n24: 1 batches\n14 Start Epoch 1\n18 Start Epoch 1\n13 Start Epoch 1\n13: 1 batches\n14: 1 batches\n20 Start Epoch 1\n11 Start Epoch 1\n12 Start Epoch 1\n18: 1 batches\n11: 1 batches\n17 Start Epoch 1\n17: 1 batches\n12: 1 batches\n20: 1 batches\n19 Start Epoch 1\n19: 1 batches\n1 Start Epoch 1\n1: 1 batches\n2 Start Epoch 1\n2: 1 batches\n15 Start Epoch 1\n15: 1 batches\n16 Start Epoch 1\n16: 1 batches\n7 Start Epoch 1\n6 Start Epoch 1\n6: 1 batches\n7: 1 batches\n3 Start Epoch 1\n3: 1 batches\n8 Start Epoch 1\n4 Start Epoch 1\n4: 1 batches\n8: 1 batches\n5 Start Epoch 1\n5: 1 batches\n9 Start Epoch 1\n9: 1 batches\n10 Start Epoch 1\n10: 1 batches\n0 Start Epoch 1\n0: 1 batches\n26 Start Epoch 2\n26: 1 batches\n22 Start Epoch 2\n22: 1 batches\n23 Start Epoch 2\n23: 1 batches\n11 Start Epoch 2\n11: 1 batches\n17 Start Epoch 2\n21 Start Epoch 2\n16 Start Epoch 2\n21: 1 batches\n5 Start Epoch 2\n17: 1 batches\n3 Start Epoch 2\n16: 1 batches\n3: 1 batches\n5: 1 batches\n15 Start Epoch 2\n4 Start Epoch 2\n4: 1 batches\n15: 1 batches\n14 Start Epoch 2\n12 Start Epoch 2\n20 Start Epoch 2\n12: 1 batches\n14: 1 batches\n18 Start Epoch 2\n20: 1 batches\n19 Start Epoch 2\n19: 1 batches\n18: 1 batches\n8 Start Epoch 2\n8: 1 batches\n6 Start Epoch 2\n6: 1 batches\n7 Start Epoch 2\n7: 1 batches\n10 Start Epoch 2\n10: 1 batches\n9 Start Epoch 2\n9: 1 batches\n13 Start Epoch 2\n13: 1 batches\n2 Start Epoch 2\n1 Start Epoch 2\n2: 1 batches\n1: 1 batches\n24 Start Epoch 2\n24: 1 batches\n25 Start Epoch 2\n25: 1 batches\n0 Start Epoch 2\n0: 1 batches\n22 Start Epoch 3\n5 Start Epoch 3\n4 Start Epoch 3\n4: 1 batches\n5: 1 batches\n26 Start Epoch 3\n26: 1 batches\n2 Start Epoch 3\n2: 1 batches\n16 Start Epoch 3\n16: 1 batches\n17 Start Epoch 3\n17: 1 batches\n19 Start Epoch 3\n19: 1 batches\n11 Start Epoch 3\n1 Start Epoch 3\n23 Start Epoch 3\n23: 1 batches\n6 Start Epoch 3\n6: 1 batches\n22: 1 batches\n20 Start Epoch 3\n20: 1 batches\n11: 1 batches\n1: 1 batches\n3 Start Epoch 3\n10 Start Epoch 3\n7 Start Epoch 3\n10: 1 batches\n24 Start Epoch 3\n25 Start Epoch 3\n7: 1 batches\n25: 1 batches\n14 Start Epoch 3\n9 Start Epoch 3\n24: 1 batches\n13 Start Epoch 3\n8 Start Epoch 3\n9: 1 batches\n13: 1 batches\n8: 1 batches\n12 Start Epoch 3\n12: 1 batches\n14: 1 batches\n3: 1 batches\n21 Start Epoch 3\n15 Start Epoch 3\n15: 1 batches\n21: 1 batches\n18 Start Epoch 3\n18: 1 batches\n0 Start Epoch 3\n0: 1 batches\n8 Start Epoch 4\n11 Start Epoch 4\n8: 1 batches\n11: 1 batches\n22 Start Epoch 4\n17 Start Epoch 4\n23 Start Epoch 4\n18 Start Epoch 4\n15 Start Epoch 4\n22: 1 batches\n19 Start Epoch 4\n16 Start Epoch 4\n23: 1 batches\n18: 1 batches\n17: 1 batches\n20 Start Epoch 4\n15: 1 batches\n16: 1 batches\n14 Start Epoch 4\n10 Start Epoch 4\n26 Start Epoch 4\n14: 1 batches\n9 Start Epoch 4\n10: 1 batches\n26: 1 batches\n9: 1 batches\n20: 1 batches\n24 Start Epoch 4\n19: 1 batches\n21 Start Epoch 4\n21: 1 batches\n24: 1 batches\n13 Start Epoch 4\n13: 1 batches\n12 Start Epoch 4\n12: 1 batches\n25 Start Epoch 4\n25: 1 batches\n5 Start Epoch 4\n4 Start Epoch 4\n3 Start Epoch 4\n5: 1 batches\n4: 1 batches\n3: 1 batches\n2 Start Epoch 4\n2: 1 batches\n7 Start Epoch 4\n7: 1 batches\n6 Start Epoch 4\n6: 1 batches\n1 Start Epoch 4\n1: 1 batches\n0 Start Epoch 4\n0: 1 batches\n17 Start Epoch 5\n17: 1 batches\n21 Start Epoch 5\n21: 1 batches\n14 Start Epoch 5\n14: 1 batches\n18 Start Epoch 5\n18: 1 batches\n20 Start Epoch 5\n20: 1 batches\n19 Start Epoch 5\n19: 1 batches\n22 Start Epoch 5\n22: 1 batches\n11 Start Epoch 5\n11: 1 batches\n7 Start Epoch 5\n10 Start Epoch 5\n8 Start Epoch 5\n10: 1 batches\n6 Start Epoch 5\n6: 1 batches\n7: 1 batches\n8: 1 batches\n2 Start Epoch 5\n24 Start Epoch 5\n24: 1 batches\n12 Start Epoch 5\n12: 1 batches\n2: 1 batches\n13 Start Epoch 5\n13: 1 batches\n5 Start Epoch 5\n5: 1 batches\n16 Start Epoch 5\n16: 1 batches\n15 Start Epoch 5\n15: 1 batches\n1 Start Epoch 5\n1: 1 batches\n9 Start Epoch 5\n9: 1 batches\n26 Start Epoch 5\n26: 1 batches\n25 Start Epoch 5\n25: 1 batches\n23 Start Epoch 5\n3 Start Epoch 5\n3: 1 batches\n23: 1 batches\n4 Start Epoch 5\n4: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:25: Epoch 0 train loss: 1177.7862548828125\nINFO:root:23: Epoch 0 train loss: 137.1509246826172\nINFO:root:22: Epoch 0 train loss: 301290.4375\nINFO:root:26: Epoch 0 train loss: 875.9933471679688\nINFO:root:24: Epoch 0 train loss: 348560.75\nINFO:root:21: Epoch 0 train loss: 315290.375\nINFO:root:12: Epoch 0 train loss: 3975.053466796875\nINFO:root:14: Epoch 0 train loss: 8161.71728515625\nINFO:root:13: Epoch 0 train loss: 250938.34375\nINFO:root:18: Epoch 0 train loss: 3889.281005859375\nINFO:root:11: Epoch 0 train loss: 291173.84375\nINFO:root:20: Epoch 0 train loss: 2048.88818359375\nINFO:root:17: Epoch 0 train loss: 6121.63671875\nINFO:root:19: Epoch 0 train loss: 5671.4716796875\nINFO:root:1: Epoch 0 train loss: 6145.888671875\nINFO:root:2: Epoch 0 train loss: 350583.78125\nINFO:root:16: Epoch 0 train loss: 738.0775146484375\nINFO:root:15: Epoch 0 train loss: 2283.87451171875\nINFO:root:6: Epoch 0 train loss: 4386.0654296875\nINFO:root:7: Epoch 0 train loss: 807.2598876953125\nINFO:root:0: Epoch 0 train loss: 10922.8359375\nINFO:root:3: Epoch 0 train loss: 252778.375\nINFO:root:8: Epoch 0 train loss: 258636.765625\nINFO:root:4: Epoch 0 train loss: 34463.0\nINFO:root:5: Epoch 0 train loss: 341.5025939941406\nINFO:root:9: Epoch 0 train loss: 132.19081115722656\nINFO:root:10: Epoch 0 train loss: 6572.3134765625\nINFO:root:0: Epoch 0 validation loss: 24289.629569591503\nINFO:root:26: Epoch 1 train loss: 155.26889038085938\nINFO:root:23: Epoch 1 train loss: 821.9468994140625\nINFO:root:22: Epoch 1 train loss: 237418.546875\nINFO:root:0: Epoch 1 train loss: 2163.590087890625\nINFO:root:11: Epoch 1 train loss: 4615.10546875\nINFO:root:17: Epoch 1 train loss: 1838.37841796875\nINFO:root:5: Epoch 1 train loss: 2503.9130859375\nINFO:root:16: Epoch 1 train loss: 174.0381622314453\nINFO:root:21: Epoch 1 train loss: 351348.28125\nINFO:root:3: Epoch 1 train loss: 315889.90625\nINFO:root:4: Epoch 1 train loss: 252475.953125\nINFO:root:15: Epoch 1 train loss: 720.1670532226562\nINFO:root:12: Epoch 1 train loss: 2464.233154296875\nINFO:root:19: Epoch 1 train loss: 2279.39794921875\nINFO:root:14: Epoch 1 train loss: 281524.3125\nINFO:root:18: Epoch 1 train loss: 10008.4814453125\nINFO:root:20: Epoch 1 train loss: 2805.32666015625\nINFO:root:7: Epoch 1 train loss: 297353.03125\nINFO:root:8: Epoch 1 train loss: 194.5331268310547\nINFO:root:6: Epoch 1 train loss: 4497.79541015625\nINFO:root:9: Epoch 1 train loss: 11919.2900390625\nINFO:root:10: Epoch 1 train loss: 357248.375\nINFO:root:13: Epoch 1 train loss: 6110.59033203125\nINFO:root:2: Epoch 1 train loss: 2964.793212890625\nINFO:root:1: Epoch 1 train loss: 3625.25048828125\nINFO:root:24: Epoch 1 train loss: 100858.71875\nINFO:root:25: Epoch 1 train loss: 6377.8251953125\nINFO:root:0: Epoch 1 validation loss: 24287.613986778008\nINFO:root:23: Epoch 2 train loss: 9635.9248046875\nINFO:root:4: Epoch 2 train loss: 303524.46875\nINFO:root:22: Epoch 2 train loss: 99584.890625\nINFO:root:5: Epoch 2 train loss: 6304.119140625\nINFO:root:26: Epoch 2 train loss: 315596.96875\nINFO:root:2: Epoch 2 train loss: 705.2027587890625\nINFO:root:17: Epoch 2 train loss: 561772.5625\nINFO:root:16: Epoch 2 train loss: 1554.607421875\nINFO:root:1: Epoch 2 train loss: 2570.619140625\nINFO:root:6: Epoch 2 train loss: 579.14013671875\nINFO:root:11: Epoch 2 train loss: 2435.141845703125\nINFO:root:20: Epoch 2 train loss: 3405.957275390625\nINFO:root:19: Epoch 2 train loss: 1503.1053466796875\nINFO:root:0: Epoch 2 train loss: 5807.8330078125\nINFO:root:3: Epoch 2 train loss: 1104.540283203125\nINFO:root:10: Epoch 2 train loss: 613.7872924804688\nINFO:root:24: Epoch 2 train loss: 661.3941040039062\nINFO:root:7: Epoch 2 train loss: 316230.4375\nINFO:root:25: Epoch 2 train loss: 6933.521484375\nINFO:root:12: Epoch 2 train loss: 2485.884033203125\nINFO:root:14: Epoch 2 train loss: 291300.46875\nINFO:root:13: Epoch 2 train loss: 3169.20556640625\nINFO:root:9: Epoch 2 train loss: 534.5039672851562\nINFO:root:8: Epoch 2 train loss: 349232.3125\nINFO:root:21: Epoch 2 train loss: 3127.255615234375\nINFO:root:15: Epoch 2 train loss: 146.19630432128906\nINFO:root:18: Epoch 2 train loss: 1380.366455078125\nINFO:root:0: Epoch 2 validation loss: 24285.6043327857\nINFO:root:8: Epoch 3 train loss: 12150.849609375\nINFO:root:11: Epoch 3 train loss: 305.4494934082031\nINFO:root:15: Epoch 3 train loss: 719.6419067382812\nINFO:root:23: Epoch 3 train loss: 319418.9375\nINFO:root:18: Epoch 3 train loss: 2466.456787109375\nINFO:root:17: Epoch 3 train loss: 594205.5\nINFO:root:22: Epoch 3 train loss: 926.2734985351562\nINFO:root:19: Epoch 3 train loss: 34451.671875\nINFO:root:16: Epoch 3 train loss: 317123.28125\nINFO:root:20: Epoch 3 train loss: 168.445556640625\nINFO:root:10: Epoch 3 train loss: 1090.0498046875\nINFO:root:9: Epoch 3 train loss: 103564.8671875\nINFO:root:14: Epoch 3 train loss: 2517.795166015625\nINFO:root:26: Epoch 3 train loss: 353824.09375\nINFO:root:24: Epoch 3 train loss: 821.645751953125\nINFO:root:21: Epoch 3 train loss: 6158.1748046875\nINFO:root:13: Epoch 3 train loss: 289398.84375\nINFO:root:12: Epoch 3 train loss: 1716.5201416015625\nINFO:root:25: Epoch 3 train loss: 708.6212768554688\nINFO:root:4: Epoch 3 train loss: 291341.21875\nINFO:root:3: Epoch 3 train loss: 1636.2529296875\nINFO:root:5: Epoch 3 train loss: 237624.359375\nINFO:root:2: Epoch 3 train loss: 52.86265563964844\nINFO:root:7: Epoch 3 train loss: 251320.984375\nINFO:root:6: Epoch 3 train loss: 3905.68603515625\nINFO:root:1: Epoch 3 train loss: 488.3526306152344\nINFO:root:0: Epoch 3 train loss: 348937.40625\nINFO:root:0: Epoch 3 validation loss: 24283.622052215298\nINFO:root:17: Epoch 4 train loss: 4099.14501953125\nINFO:root:21: Epoch 4 train loss: 101964.453125\nINFO:root:14: Epoch 4 train loss: 1189.3543701171875\nINFO:root:18: Epoch 4 train loss: 13274.7958984375\nINFO:root:20: Epoch 4 train loss: 9653.390625\nINFO:root:19: Epoch 4 train loss: 3251.0732421875\nINFO:root:22: Epoch 4 train loss: 1654.3843994140625\nINFO:root:11: Epoch 4 train loss: 7959.7216796875\nINFO:root:7: Epoch 4 train loss: 7315.67431640625\nINFO:root:10: Epoch 4 train loss: 2991.10693359375\nINFO:root:6: Epoch 4 train loss: 913.936767578125\nINFO:root:8: Epoch 4 train loss: 6543.34716796875\nINFO:root:24: Epoch 4 train loss: 237751.140625\nINFO:root:2: Epoch 4 train loss: 153.836181640625\nINFO:root:13: Epoch 4 train loss: 1824.99658203125\nINFO:root:12: Epoch 4 train loss: 1292.29248046875\nINFO:root:0: Epoch 4 train loss: 347805.09375\nINFO:root:1: Epoch 4 train loss: 584042.375\nINFO:root:5: Epoch 4 train loss: 352930.65625\nINFO:root:16: Epoch 4 train loss: 5833.9677734375\nINFO:root:15: Epoch 4 train loss: 1387.6805419921875\nINFO:root:9: Epoch 4 train loss: 1380.1796875\nINFO:root:25: Epoch 4 train loss: 318448.625\nINFO:root:26: Epoch 4 train loss: 236281.09375\nINFO:root:23: Epoch 4 train loss: 1092.5828857421875\nINFO:root:4: Epoch 4 train loss: 2763.364990234375\nINFO:root:3: Epoch 4 train loss: 281835.375\nINFO:root:0: Epoch 4 validation loss: 24281.606468856535\nINFO:root:26: Epoch 5 train loss: 2780.64013671875\nINFO:root:7: Epoch 5 train loss: 1481.7593994140625\nINFO:root:3: Epoch 5 train loss: 2588.3798828125\nINFO:root:6: Epoch 5 train loss: 4188.6474609375\nINFO:root:10: Epoch 5 train loss: 295.345703125\nINFO:root:8: Epoch 5 train loss: 753.0482177734375\nINFO:root:11: Epoch 5 train loss: 3621.01025390625\nINFO:root:5: Epoch 5 train loss: 3690.935791015625\nINFO:root:4: Epoch 5 train loss: 6879.77490234375\nINFO:root:9: Epoch 5 train loss: 3972.283447265625\nINFO:root:2: Epoch 5 train loss: 3853.07421875\nINFO:root:14: Epoch 5 train loss: 217.02777099609375\nINFO:root:20: Epoch 5 train loss: 2128.686767578125\nINFO:root:15: Epoch 5 train loss: 3541.11865234375\nINFO:root:17: Epoch 5 train loss: 664.9644775390625\nINFO:root:13: Epoch 5 train loss: 1203.4212646484375\nINFO:root:12: Epoch 5 train loss: 2491.167724609375\nINFO:root:16: Epoch 5 train loss: 4204.8427734375\nINFO:root:23: Epoch 5 train loss: 1752.251708984375\nINFO:root:24: Epoch 5 train loss: 551621.0\nINFO:root:25: Epoch 5 train loss: 3078.645751953125\nINFO:root:22: Epoch 5 train loss: 1253.6246337890625\nINFO:root:21: Epoch 5 train loss: 1062.544677734375\nINFO:root:19: Epoch 5 train loss: 884.190185546875\nINFO:root:18: Epoch 5 train loss: 100448.6171875\nINFO:root:1: Epoch 5 train loss: 666.0638427734375\nINFO:root:0: Epoch 5 train loss: 2561.1279296875\nINFO:root:0: Epoch 5 validation loss: 24279.55787816286\n", "seconds": 19.609227895736694, "batch_size": 256, "nodes": 9, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n2 Start Epoch 0\n2: 1 batches\n3 Start Epoch 0\n4 Start Epoch 0\n3: 1 batches\n4: 1 batches\n1 Start Epoch 0\n8 Start Epoch 0\n16 Start Epoch 0\n16: 1 batches\n24 Start Epoch 0\n7 Start Epoch 0\n24: 1 batches\n8: 1 batches\n7: 1 batches\n23 Start Epoch 0\n29 Start Epoch 0\n29: 1 batches\n23: 1 batches\n15 Start Epoch 0\n15: 1 batches\n27 Start Epoch 0\n28 Start Epoch 0\n27: 1 batches\n28: 1 batches\n12 Start Epoch 0\n11 Start Epoch 0\n11: 1 batches\n1: 1 batches\n12: 1 batches\n19 Start Epoch 0\n20 Start Epoch 0\n19: 1 batches\n20: 1 batches\n6 Start Epoch 0\n6: 1 batches\n5 Start Epoch 0\n5: 1 batches\n18 Start Epoch 0\n17 Start Epoch 0\n18: 1 batches\n17: 1 batches\n26 Start Epoch 0\n9 Start Epoch 0\n25 Start Epoch 0\n10 Start Epoch 0\n25: 1 batches\n9: 1 batches\n26: 1 batches\n10: 1 batches\n21 Start Epoch 0\n22 Start Epoch 0\n21: 1 batches\n22: 1 batches\n13 Start Epoch 0\n14 Start Epoch 0\n13: 1 batches\n14: 1 batches\n28 Start Epoch 1\n28: 1 batches\n29 Start Epoch 1\n29: 1 batches\n7 Start Epoch 1\n19 Start Epoch 1\n8 Start Epoch 1\n9 Start Epoch 1\n18 Start Epoch 1\n7: 1 batches\n3 Start Epoch 1\n10 Start Epoch 1\n20 Start Epoch 1\n8: 1 batches\n5 Start Epoch 1\n9: 1 batches\n11 Start Epoch 1\n19: 1 batches\n5: 1 batches\n18: 1 batches\n3: 1 batches\n11: 1 batches\n20: 1 batches\n4 Start Epoch 1\n10: 1 batches\n4: 1 batches\n26 Start Epoch 1\n6 Start Epoch 1\n14 Start Epoch 1\n2 Start Epoch 1\n2: 1 batches\n6: 1 batches\n22 Start Epoch 1\n14: 1 batches\n25 Start Epoch 1\n17 Start Epoch 1\n15 Start Epoch 1\n12 Start Epoch 1\n25: 1 batches\n21 Start Epoch 1\n21: 1 batches\n16 Start Epoch 1\n12: 1 batches\n17: 1 batches\n23 Start Epoch 1\n22: 1 batches\n16: 1 batches\n13 Start Epoch 1\n13: 1 batches\n23: 1 batches\n15: 1 batches\n24 Start Epoch 1\n24: 1 batches\n26: 1 batches\n1 Start Epoch 1\n1: 1 batches\n27 Start Epoch 1\n27: 1 batches\n0 Start Epoch 1\n0: 1 batches\n29 Start Epoch 2\n29: 1 batches\n28 Start Epoch 2\n28: 1 batches\n27 Start Epoch 2\n27: 1 batches\n26 Start Epoch 2\n26: 1 batches\n25 Start Epoch 2\n23 Start Epoch 2\n23: 1 batches\n11 Start Epoch 2\n11: 1 batches\n24 Start Epoch 2\n24: 1 batches\n3 Start Epoch 2\n10 Start Epoch 2\n10: 1 batches\n5 Start Epoch 2\n17 Start Epoch 2\n25: 1 batches\n16 Start Epoch 2\n5: 1 batches\n3: 1 batches\n15 Start Epoch 2\n4 Start Epoch 2\n17: 1 batches\n16: 1 batches\n4: 1 batches\n9 Start Epoch 2\n20 Start Epoch 2\n9: 1 batches\n1 Start Epoch 2\n1: 1 batches\n20: 1 batches\n12 Start Epoch 2\n13 Start Epoch 2\n12: 1 batches\n13: 1 batches\n7 Start Epoch 2\n7: 1 batches\n14 Start Epoch 2\n14: 1 batches\n22 Start Epoch 2\n21 Start Epoch 2\n21: 1 batches\n22: 1 batches\n18 Start Epoch 2\n19 Start Epoch 2\n19: 1 batches\n18: 1 batches\n6 Start Epoch 2\n6: 1 batches\n8 Start Epoch 2\n8: 1 batches\n15: 1 batches\n2 Start Epoch 2\n2: 1 batches\n0 Start Epoch 2\n0: 1 batches\n9 Start Epoch 3\n9: 1 batches\n11 Start Epoch 3\n23 Start Epoch 3\n23: 1 batches\n11: 1 batches\n27 Start Epoch 3\n26 Start Epoch 3\n24 Start Epoch 3\n7 Start Epoch 3\n28 Start Epoch 3\n24: 1 batches\n27: 1 batches\n7: 1 batches\n28: 1 batches\n17 Start Epoch 3\n25 Start Epoch 3\n13 Start Epoch 3\n19 Start Epoch 3\n25: 1 batches\n29 Start Epoch 3\n17: 1 batches\n8 Start Epoch 3\n3 Start Epoch 3\n29: 1 batches\n12 Start Epoch 3\n18 Start Epoch 3\n26: 1 batches\n18: 1 batches\n8: 1 batches\n5 Start Epoch 3\n10 Start Epoch 3\n3: 1 batches\n10: 1 batches\n12: 1 batches\n19: 1 batches\n13: 1 batches\n5: 1 batches\n4 Start Epoch 3\n14 Start Epoch 3\n4: 1 batches\n14: 1 batches\n1 Start Epoch 3\n1: 1 batches\n2 Start Epoch 3\n2: 1 batches\n21 Start Epoch 3\n20 Start Epoch 3\n6 Start Epoch 3\n21: 1 batches\n15 Start Epoch 3\n20: 1 batches\n6: 1 batches\n16 Start Epoch 3\n22 Start Epoch 3\n16: 1 batches\n22: 1 batches\n15: 1 batches\n0 Start Epoch 3\n0: 1 batches\n2 Start Epoch 4\n2: 1 batches\n8 Start Epoch 4\n9 Start Epoch 4\n11 Start Epoch 4\n9: 1 batches\n11: 1 batches\n10 Start Epoch 4\n4 Start Epoch 4\n10: 1 batches\n8: 1 batches\n6 Start Epoch 4\n4: 1 batches\n6: 1 batches\n3 Start Epoch 4\n27 Start Epoch 4\n17 Start Epoch 4\n17: 1 batches\n28 Start Epoch 4\n3: 1 batches\n7 Start Epoch 4\n28: 1 batches\n7: 1 batches\n27: 1 batches\n29 Start Epoch 4\n16 Start Epoch 4\n29: 1 batches\n15 Start Epoch 4\n15: 1 batches\n16: 1 batches\n18 Start Epoch 4\n26 Start Epoch 4\n18: 1 batches\n26: 1 batches\n12 Start Epoch 4\n13 Start Epoch 4\n12: 1 batches\n13: 1 batches\n14 Start Epoch 4\n1 Start Epoch 4\n1: 1 batches\n14: 1 batches\n5 Start Epoch 4\n5: 1 batches\n20 Start Epoch 4\n23 Start Epoch 4\n19 Start Epoch 4\n22 Start Epoch 4\n20: 1 batches\n23: 1 batches\n19: 1 batches\n22: 1 batches\n21 Start Epoch 4\n21: 1 batches\n24 Start Epoch 4\n24: 1 batches\n25 Start Epoch 4\n25: 1 batches\n0 Start Epoch 4\n0: 1 batches\n5 Start Epoch 5\n5: 1 batches\n11 Start Epoch 5\n28 Start Epoch 5\n9 Start Epoch 5\n29 Start Epoch 5\n29: 1 batches\n9: 1 batches\n28: 1 batches\n10 Start Epoch 5\n4 Start Epoch 5\n2 Start Epoch 5\n2: 1 batches\n1 Start Epoch 5\n1: 1 batches\n18 Start Epoch 5\n26 Start Epoch 5\n26: 1 batches\n3 Start Epoch 5\n10: 1 batches\n18: 1 batches\n17 Start Epoch 5\n4: 1 batches\n11: 1 batches\n13 Start Epoch 5\n25 Start Epoch 5\n25: 1 batches\n8 Start Epoch 5\n3: 1 batches\n15 Start Epoch 5\n17: 1 batches\n14 Start Epoch 5\n6 Start Epoch 5\n8: 1 batches\n15: 1 batches\n12 Start Epoch 5\n12: 1 batches\n16 Start Epoch 5\n14: 1 batches\n6: 1 batches\n16: 1 batches\n13: 1 batches\n19 Start Epoch 5\n7 Start Epoch 5\n7: 1 batches\n19: 1 batches\n24 Start Epoch 5\n24: 1 batches\n22 Start Epoch 5\n20 Start Epoch 5\n23 Start Epoch 5\n20: 1 batches\n23: 1 batches\n22: 1 batches\n21 Start Epoch 5\n21: 1 batches\n27 Start Epoch 5\n27: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:29: Epoch 0 train loss: 2296.55078125\nINFO:root:28: Epoch 0 train loss: 3443.043212890625\nINFO:root:8: Epoch 0 train loss: 1335.798583984375\nINFO:root:11: Epoch 0 train loss: 4639.66015625\nINFO:root:20: Epoch 0 train loss: 4236.79296875\nINFO:root:4: Epoch 0 train loss: 3115.7294921875\nINFO:root:10: Epoch 0 train loss: 1743.460205078125\nINFO:root:19: Epoch 0 train loss: 339468.875\nINFO:root:7: Epoch 0 train loss: 285417.59375\nINFO:root:9: Epoch 0 train loss: 750.1300659179688\nINFO:root:18: Epoch 0 train loss: 1584.450439453125\nINFO:root:5: Epoch 0 train loss: 373.59136962890625\nINFO:root:3: Epoch 0 train loss: 649.7692260742188\nINFO:root:22: Epoch 0 train loss: 5606.98046875\nINFO:root:15: Epoch 0 train loss: 3232.976318359375\nINFO:root:14: Epoch 0 train loss: 6704.146484375\nINFO:root:26: Epoch 0 train loss: 5831.65087890625\nINFO:root:6: Epoch 0 train loss: 2420.4248046875\nINFO:root:23: Epoch 0 train loss: 1281.08203125\nINFO:root:16: Epoch 0 train loss: 735.333984375\nINFO:root:2: Epoch 0 train loss: 279646.15625\nINFO:root:25: Epoch 0 train loss: 662.141357421875\nINFO:root:17: Epoch 0 train loss: 2708.55078125\nINFO:root:21: Epoch 0 train loss: 1679.87548828125\nINFO:root:12: Epoch 0 train loss: 7412.49853515625\nINFO:root:13: Epoch 0 train loss: 1835.5357666015625\nINFO:root:0: Epoch 0 train loss: 1779.2197265625\nINFO:root:24: Epoch 0 train loss: 13794.8759765625\nINFO:root:1: Epoch 0 train loss: 318463.5625\nINFO:root:27: Epoch 0 train loss: 38366.078125\nINFO:root:0: Epoch 0 validation loss: 4742303.450304212\nINFO:root:29: Epoch 1 train loss: 1079.5216064453125\nINFO:root:28: Epoch 1 train loss: 1137.3641357421875\nINFO:root:27: Epoch 1 train loss: 356526.65625\nINFO:root:26: Epoch 1 train loss: 1553.6146240234375\nINFO:root:0: Epoch 1 train loss: 2990.4091796875\nINFO:root:11: Epoch 1 train loss: 324729.46875\nINFO:root:23: Epoch 1 train loss: 2687.1474609375\nINFO:root:3: Epoch 1 train loss: 110045.953125\nINFO:root:24: Epoch 1 train loss: 6834.5361328125\nINFO:root:4: Epoch 1 train loss: 461.5625305175781\nINFO:root:10: Epoch 1 train loss: 1000.4172973632812\nINFO:root:16: Epoch 1 train loss: 334997.0625\nINFO:root:25: Epoch 1 train loss: 12722.76171875\nINFO:root:5: Epoch 1 train loss: 296.3785400390625\nINFO:root:17: Epoch 1 train loss: 2176.974365234375\nINFO:root:15: Epoch 1 train loss: 2032.40185546875\nINFO:root:20: Epoch 1 train loss: 3715.89453125\nINFO:root:9: Epoch 1 train loss: 4298.34716796875\nINFO:root:12: Epoch 1 train loss: 323319.5\nINFO:root:1: Epoch 1 train loss: 6483.34521484375\nINFO:root:13: Epoch 1 train loss: 440.2439880371094\nINFO:root:14: Epoch 1 train loss: 73.61013793945312\nINFO:root:21: Epoch 1 train loss: 552.4572143554688\nINFO:root:22: Epoch 1 train loss: 2965.1162109375\nINFO:root:18: Epoch 1 train loss: 324276.25\nINFO:root:19: Epoch 1 train loss: 37219.18359375\nINFO:root:7: Epoch 1 train loss: 267905.3125\nINFO:root:6: Epoch 1 train loss: 2660.345947265625\nINFO:root:8: Epoch 1 train loss: 264797.5625\nINFO:root:2: Epoch 1 train loss: 4764.0302734375\nINFO:root:0: Epoch 1 validation loss: 4742274.955289865\nINFO:root:9: Epoch 2 train loss: 312289.28125\nINFO:root:27: Epoch 2 train loss: 4480.0703125\nINFO:root:23: Epoch 2 train loss: 284379.90625\nINFO:root:25: Epoch 2 train loss: 6052.3583984375\nINFO:root:11: Epoch 2 train loss: 2347.006591796875\nINFO:root:26: Epoch 2 train loss: 1995.877685546875\nINFO:root:29: Epoch 2 train loss: 2857.216796875\nINFO:root:24: Epoch 2 train loss: 2135.480712890625\nINFO:root:28: Epoch 2 train loss: 263702.875\nINFO:root:13: Epoch 2 train loss: 10461.8388671875\nINFO:root:18: Epoch 2 train loss: 327824.90625\nINFO:root:7: Epoch 2 train loss: 1095.77783203125\nINFO:root:3: Epoch 2 train loss: 1053.1778564453125\nINFO:root:17: Epoch 2 train loss: 387068.125\nINFO:root:4: Epoch 2 train loss: 2818.801513671875\nINFO:root:12: Epoch 2 train loss: 1260.9290771484375\nINFO:root:19: Epoch 2 train loss: 3441.612060546875\nINFO:root:8: Epoch 2 train loss: 282916.71875\nINFO:root:5: Epoch 2 train loss: 1778.0047607421875\nINFO:root:10: Epoch 2 train loss: 4048.16162109375\nINFO:root:14: Epoch 2 train loss: 324834.125\nINFO:root:1: Epoch 2 train loss: 695.8300170898438\nINFO:root:0: Epoch 2 train loss: 244.6163787841797\nINFO:root:2: Epoch 2 train loss: 318.8879089355469\nINFO:root:6: Epoch 2 train loss: 215.94345092773438\nINFO:root:21: Epoch 2 train loss: 36617.8359375\nINFO:root:16: Epoch 2 train loss: 282686.1875\nINFO:root:20: Epoch 2 train loss: 344.9257507324219\nINFO:root:15: Epoch 2 train loss: 1378.2607421875\nINFO:root:22: Epoch 2 train loss: 713.9925537109375\nINFO:root:0: Epoch 2 validation loss: 4742246.880104114\nINFO:root:2: Epoch 3 train loss: 279590.3125\nINFO:root:10: Epoch 3 train loss: 351000.0\nINFO:root:9: Epoch 3 train loss: 1765.3541259765625\nINFO:root:11: Epoch 3 train loss: 319403.34375\nINFO:root:8: Epoch 3 train loss: 443.58648681640625\nINFO:root:4: Epoch 3 train loss: 846.5664672851562\nINFO:root:28: Epoch 3 train loss: 2536.80224609375\nINFO:root:27: Epoch 3 train loss: 292.93310546875\nINFO:root:6: Epoch 3 train loss: 312748.65625\nINFO:root:3: Epoch 3 train loss: 241.7797088623047\nINFO:root:29: Epoch 3 train loss: 3665.3740234375\nINFO:root:16: Epoch 3 train loss: 249.85035705566406\nINFO:root:7: Epoch 3 train loss: 1153.7860107421875\nINFO:root:15: Epoch 3 train loss: 1967.16015625\nINFO:root:17: Epoch 3 train loss: 2956.491455078125\nINFO:root:18: Epoch 3 train loss: 349.6881408691406\nINFO:root:26: Epoch 3 train loss: 314839.125\nINFO:root:13: Epoch 3 train loss: 353662.53125\nINFO:root:12: Epoch 3 train loss: 938.7969360351562\nINFO:root:14: Epoch 3 train loss: 567.2787475585938\nINFO:root:1: Epoch 3 train loss: 5526.33642578125\nINFO:root:5: Epoch 3 train loss: 3746.142333984375\nINFO:root:0: Epoch 3 train loss: 833.7205810546875\nINFO:root:19: Epoch 3 train loss: 551.6305541992188\nINFO:root:21: Epoch 3 train loss: 475.7986145019531\nINFO:root:20: Epoch 3 train loss: 366.6050720214844\nINFO:root:23: Epoch 3 train loss: 262565.96875\nINFO:root:22: Epoch 3 train loss: 1297.2744140625\nINFO:root:24: Epoch 3 train loss: 1059.49609375\nINFO:root:25: Epoch 3 train loss: 3658.82666015625\nINFO:root:0: Epoch 3 validation loss: 4742218.736911208\nINFO:root:9: Epoch 4 train loss: 2910.602294921875\nINFO:root:5: Epoch 4 train loss: 312325.6875\nINFO:root:11: Epoch 4 train loss: 1458.553955078125\nINFO:root:28: Epoch 4 train loss: 2257.47802734375\nINFO:root:10: Epoch 4 train loss: 4161.27880859375\nINFO:root:29: Epoch 4 train loss: 2840.633544921875\nINFO:root:15: Epoch 4 train loss: 324797.6875\nINFO:root:2: Epoch 4 train loss: 8477.927734375\nINFO:root:1: Epoch 4 train loss: 644.0505981445312\nINFO:root:18: Epoch 4 train loss: 1708.61083984375\nINFO:root:4: Epoch 4 train loss: 2590.493408203125\nINFO:root:17: Epoch 4 train loss: 5920.14208984375\nINFO:root:13: Epoch 4 train loss: 335691.71875\nINFO:root:6: Epoch 4 train loss: 2417.541259765625\nINFO:root:16: Epoch 4 train loss: 75.84953308105469\nINFO:root:14: Epoch 4 train loss: 12488.3994140625\nINFO:root:25: Epoch 4 train loss: 265631.75\nINFO:root:7: Epoch 4 train loss: 2571.936279296875\nINFO:root:3: Epoch 4 train loss: 5508.59326171875\nINFO:root:12: Epoch 4 train loss: 1715.2525634765625\nINFO:root:26: Epoch 4 train loss: 336287.125\nINFO:root:8: Epoch 4 train loss: 218.05618286132812\nINFO:root:19: Epoch 4 train loss: 3039.75537109375\nINFO:root:21: Epoch 4 train loss: 1779.324462890625\nINFO:root:24: Epoch 4 train loss: 4325.29443359375\nINFO:root:23: Epoch 4 train loss: 2335.918212890625\nINFO:root:22: Epoch 4 train loss: 313388.875\nINFO:root:20: Epoch 4 train loss: 1936.8668212890625\nINFO:root:0: Epoch 4 train loss: 2576.0576171875\nINFO:root:27: Epoch 4 train loss: 36591.25390625\nINFO:root:0: Epoch 4 validation loss: 4742190.7221190715\nINFO:root:29: Epoch 5 train loss: 4105.96923828125\nINFO:root:26: Epoch 5 train loss: 1528.23486328125\nINFO:root:5: Epoch 5 train loss: 3188.77587890625\nINFO:root:25: Epoch 5 train loss: 237.6298065185547\nINFO:root:4: Epoch 5 train loss: 323451.0625\nINFO:root:10: Epoch 5 train loss: 431.0108642578125\nINFO:root:24: Epoch 5 train loss: 5139.5693359375\nINFO:root:11: Epoch 5 train loss: 335393.6875\nINFO:root:28: Epoch 5 train loss: 351522.46875\nINFO:root:27: Epoch 5 train loss: 312433.90625\nINFO:root:1: Epoch 5 train loss: 278843.96875\nINFO:root:2: Epoch 5 train loss: 2155.755859375\nINFO:root:22: Epoch 5 train loss: 177.67449951171875\nINFO:root:16: Epoch 5 train loss: 345399.125\nINFO:root:14: Epoch 5 train loss: 392739.34375\nINFO:root:19: Epoch 5 train loss: 38893.1015625\nINFO:root:6: Epoch 5 train loss: 2397.28076171875\nINFO:root:17: Epoch 5 train loss: 850.4644165039062\nINFO:root:21: Epoch 5 train loss: 284863.875\nINFO:root:18: Epoch 5 train loss: 6221.70556640625\nINFO:root:7: Epoch 5 train loss: 3949.32666015625\nINFO:root:3: Epoch 5 train loss: 3886.636962890625\nINFO:root:15: Epoch 5 train loss: 1457.7498779296875\nINFO:root:8: Epoch 5 train loss: 9217.0263671875\nINFO:root:23: Epoch 5 train loss: 5604.1318359375\nINFO:root:9: Epoch 5 train loss: 720697.0\nINFO:root:20: Epoch 5 train loss: 1015.7933349609375\nINFO:root:13: Epoch 5 train loss: 1923.8592529296875\nINFO:root:12: Epoch 5 train loss: 2365.158203125\nINFO:root:0: Epoch 5 train loss: 2840.878173828125\nINFO:root:0: Epoch 5 validation loss: 4742162.373949317\n", "seconds": 19.22291398048401, "batch_size": 256, "nodes": 10, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n2 Start Epoch 0\n1 Start Epoch 0\n1: 1 batches\n2: 1 batches\n24 Start Epoch 0\n24: 1 batches\n23 Start Epoch 0\n23: 1 batches\n15 Start Epoch 0\n3 Start Epoch 0\n8 Start Epoch 0\n16 Start Epoch 0\n4 Start Epoch 0\n32 Start Epoch 0\n7 Start Epoch 0\n15: 1 batches\n4: 1 batches\n32: 1 batches\n8: 1 batches\n16: 1 batches\n3: 1 batches\n31 Start Epoch 0\n31: 1 batches\n7: 1 batches\n27 Start Epoch 0\n28 Start Epoch 0\n27: 1 batches\n28: 1 batches\n12 Start Epoch 0\n12: 1 batches\n20 Start Epoch 0\n19 Start Epoch 0\n11 Start Epoch 0\n20: 1 batches\n19: 1 batches\n11: 1 batches\n5 Start Epoch 0\n5: 1 batches\n6 Start Epoch 0\n6: 1 batches\n29 Start Epoch 0\n29: 1 batches\n9 Start Epoch 0\n10 Start Epoch 0\n30 Start Epoch 0\n30: 1 batches\n9: 1 batches\n10: 1 batches\n13 Start Epoch 0\n14 Start Epoch 0\n13: 1 batches\n14: 1 batches\n17 Start Epoch 0\n17: 1 batches\n18 Start Epoch 0\n18: 1 batches\n21 Start Epoch 0\n22 Start Epoch 0\n22: 1 batches\n21: 1 batches\n25 Start Epoch 0\n26 Start Epoch 0\n25: 1 batches\n26: 1 batches\n29 Start Epoch 1\n29: 1 batches\n32 Start Epoch 1\n30 Start Epoch 1\n30: 1 batches\n32: 1 batches\n31 Start Epoch 1\n31: 1 batches\n11 Start Epoch 1\n3 Start Epoch 1\n11: 1 batches\n3: 1 batches\n4 Start Epoch 1\n4: 1 batches\n10 Start Epoch 1\n9 Start Epoch 1\n9: 1 batches\n10: 1 batches\n22 Start Epoch 1\n21 Start Epoch 1\n23 Start Epoch 1\n8 Start Epoch 1\n22: 1 batches\n8: 1 batches\n21: 1 batches\n23: 1 batches\n12 Start Epoch 1\n13 Start Epoch 1\n13: 1 batches\n14 Start Epoch 1\n14: 1 batches\n12: 1 batches\n16 Start Epoch 1\n16: 1 batches\n24 Start Epoch 1\n7 Start Epoch 1\n17 Start Epoch 1\n17: 1 batches\n18 Start Epoch 1\n7: 1 batches\n27 Start Epoch 1\n26 Start Epoch 1\n28 Start Epoch 1\n26: 1 batches\n20 Start Epoch 1\n24: 1 batches\n20: 1 batches\n15 Start Epoch 1\n27: 1 batches\n28: 1 batches\n19 Start Epoch 1\n15: 1 batches\n19: 1 batches\n18: 1 batches\n2 Start Epoch 1\n2: 1 batches\n1 Start Epoch 1\n1: 1 batches\n5 Start Epoch 1\n5: 1 batches\n25 Start Epoch 1\n25: 1 batches\n6 Start Epoch 1\n6: 1 batches\n0 Start Epoch 1\n0: 1 batches\n5 Start Epoch 2\n5: 1 batches\n8 Start Epoch 2\n7 Start Epoch 2\n6 Start Epoch 2\n7: 1 batches\n6: 1 batches\n8: 1 batches\n12 Start Epoch 2\n12: 1 batches\n32 Start Epoch 2\n32: 1 batches\n31 Start Epoch 2\n31: 1 batches\n11 Start Epoch 2\n4 Start Epoch 2\n11: 1 batches\n3 Start Epoch 2\n29 Start Epoch 2\n3: 1 batches\n9 Start Epoch 2\n29: 1 batches\n4: 1 batches\n9: 1 batches\n25 Start Epoch 2\n26 Start Epoch 2\n26: 1 batches\n22 Start Epoch 2\n23 Start Epoch 2\n17 Start Epoch 2\n22: 1 batches\n16 Start Epoch 2\n25: 1 batches\n21 Start Epoch 2\n17: 1 batches\n21: 1 batches\n15 Start Epoch 2\n23: 1 batches\n2 Start Epoch 2\n2: 1 batches\n30 Start Epoch 2\n30: 1 batches\n24 Start Epoch 2\n24: 1 batches\n28 Start Epoch 2\n13 Start Epoch 2\n14 Start Epoch 2\n27 Start Epoch 2\n20 Start Epoch 2\n28: 1 batches\n18 Start Epoch 2\n13: 1 batches\n27: 1 batches\n20: 1 batches\n14: 1 batches\n15: 1 batches\n19 Start Epoch 2\n16: 1 batches\n19: 1 batches\n18: 1 batches\n1 Start Epoch 2\n1: 1 batches\n10 Start Epoch 2\n10: 1 batches\n0 Start Epoch 2\n0: 1 batches\n10 Start Epoch 3\n27 Start Epoch 3\n22 Start Epoch 3\n23 Start Epoch 3\n10: 1 batches\n28 Start Epoch 3\n11 Start Epoch 3\n28: 1 batches\n23: 1 batches\n29 Start Epoch 3\n11: 1 batches\n32 Start Epoch 3\n32: 1 batches\n6 Start Epoch 3\n6: 1 batches\n22: 1 batches\n21 Start Epoch 3\n29: 1 batches\n14 Start Epoch 3\n21: 1 batches\n27: 1 batches\n26 Start Epoch 3\n14: 1 batches\n17 Start Epoch 3\n12 Start Epoch 3\n7 Start Epoch 3\n19 Start Epoch 3\n12: 1 batches\n8 Start Epoch 3\n18 Start Epoch 3\n8: 1 batches\n16 Start Epoch 3\n20 Start Epoch 3\n7: 1 batches\n17: 1 batches\n15 Start Epoch 3\n20: 1 batches\n18: 1 batches\n15: 1 batches\n16: 1 batches\n24 Start Epoch 3\n19: 1 batches\n24: 1 batches\n25 Start Epoch 3\n13 Start Epoch 3\n9 Start Epoch 3\n31 Start Epoch 3\n26: 1 batches\n13: 1 batches\n9: 1 batches\n25: 1 batches\n30 Start Epoch 3\n30: 1 batches\n31: 1 batches\n1 Start Epoch 3\n2 Start Epoch 3\n1: 1 batches\n2: 1 batches\n5 Start Epoch 3\n5: 1 batches\n4 Start Epoch 3\n4: 1 batches\n3 Start Epoch 3\n3: 1 batches\n0 Start Epoch 3\n0: 1 batches\n29 Start Epoch 4\n26 Start Epoch 4\n29: 1 batches\n26: 1 batches\n30 Start Epoch 4\n32 Start Epoch 4\n31 Start Epoch 4\n32: 1 batches\n31: 1 batches\n30: 1 batches\n28 Start Epoch 4\n28: 1 batches\n27 Start Epoch 4\n27: 1 batches\n17 Start Epoch 4\n23 Start Epoch 4\n23: 1 batches\n22 Start Epoch 4\n22: 1 batches\n21 Start Epoch 4\n21: 1 batches\n17: 1 batches\n24 Start Epoch 4\n24: 1 batches\n4 Start Epoch 4\n9 Start Epoch 4\n25 Start Epoch 4\n19 Start Epoch 4\n5 Start Epoch 4\n10 Start Epoch 4\n18 Start Epoch 4\n3 Start Epoch 4\n3: 1 batches\n10: 1 batches\n25: 1 batches\n18: 1 batches\n5: 1 batches\n11 Start Epoch 4\n11: 1 batches\n20 Start Epoch 4\n4: 1 batches\n9: 1 batches\n20: 1 batches\n19: 1 batches\n14 Start Epoch 4\n14: 1 batches\n7 Start Epoch 4\n7: 1 batches\n2 Start Epoch 4\n2: 1 batches\n1 Start Epoch 4\n1: 1 batches\n13 Start Epoch 4\n13: 1 batches\n6 Start Epoch 4\n16 Start Epoch 4\n16: 1 batches\n15 Start Epoch 4\n15: 1 batches\n12 Start Epoch 4\n8 Start Epoch 4\n12: 1 batches\n8: 1 batches\n6: 1 batches\n0 Start Epoch 4\n0: 1 batches\n25 Start Epoch 5\n26 Start Epoch 5\n29 Start Epoch 5\n22 Start Epoch 5\n16 Start Epoch 5\n27 Start Epoch 5\n26: 1 batches\n22: 1 batches\n17 Start Epoch 5\n11 Start Epoch 5\n9 Start Epoch 5\n29: 1 batches\n21 Start Epoch 5\n17: 1 batches\n5 Start Epoch 5\n21: 1 batches\n15 Start Epoch 5\n4 Start Epoch 5\n10 Start Epoch 5\n28 Start Epoch 5\n5: 1 batches\n11: 1 batches\n28: 1 batches\n15: 1 batches\n4: 1 batches\n10: 1 batches\n32 Start Epoch 5\n27: 1 batches\n24 Start Epoch 5\n14 Start Epoch 5\n14: 1 batches\n16: 1 batches\n6 Start Epoch 5\n3 Start Epoch 5\n9: 1 batches\n32: 1 batches\n24: 1 batches\n18 Start Epoch 5\n8 Start Epoch 5\n8: 1 batches\n3: 1 batches\n20 Start Epoch 5\n6: 1 batches\n7 Start Epoch 5\n19 Start Epoch 5\n19: 1 batches\n18: 1 batches\n20: 1 batches\n2 Start Epoch 5\n7: 1 batches\n2: 1 batches\n25: 1 batches\n31 Start Epoch 5\n1 Start Epoch 5\n1: 1 batches\n23 Start Epoch 5\n31: 1 batches\n13 Start Epoch 5\n23: 1 batches\n13: 1 batches\n12 Start Epoch 5\n30 Start Epoch 5\n12: 1 batches\n30: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:29: Epoch 0 train loss: 752159.375\nINFO:root:32: Epoch 0 train loss: 14310.8427734375\nINFO:root:30: Epoch 0 train loss: 289317.34375\nINFO:root:31: Epoch 0 train loss: 41095.97265625\nINFO:root:3: Epoch 0 train loss: 4620.51611328125\nINFO:root:11: Epoch 0 train loss: 5426.00927734375\nINFO:root:4: Epoch 0 train loss: 3161.72705078125\nINFO:root:10: Epoch 0 train loss: 755.6725463867188\nINFO:root:9: Epoch 0 train loss: 2142.136474609375\nINFO:root:0: Epoch 0 train loss: 1113.3526611328125\nINFO:root:21: Epoch 0 train loss: 39955.15625\nINFO:root:22: Epoch 0 train loss: 3029.505615234375\nINFO:root:23: Epoch 0 train loss: 1487.97216796875\nINFO:root:8: Epoch 0 train loss: 362281.03125\nINFO:root:13: Epoch 0 train loss: 4196.6064453125\nINFO:root:12: Epoch 0 train loss: 1921.5469970703125\nINFO:root:14: Epoch 0 train loss: 6436.16162109375\nINFO:root:24: Epoch 0 train loss: 358741.28125\nINFO:root:18: Epoch 0 train loss: 390813.5625\nINFO:root:20: Epoch 0 train loss: 202.9886932373047\nINFO:root:7: Epoch 0 train loss: 381702.84375\nINFO:root:17: Epoch 0 train loss: 656.0817260742188\nINFO:root:28: Epoch 0 train loss: 2382.701904296875\nINFO:root:26: Epoch 0 train loss: 403.4989929199219\nINFO:root:19: Epoch 0 train loss: 3888.62646484375\nINFO:root:27: Epoch 0 train loss: 3847.281005859375\nINFO:root:16: Epoch 0 train loss: 4603.21337890625\nINFO:root:15: Epoch 0 train loss: 120223.859375\nINFO:root:2: Epoch 0 train loss: 427786.21875\nINFO:root:1: Epoch 0 train loss: 1816.8095703125\nINFO:root:25: Epoch 0 train loss: 355.7079772949219\nINFO:root:5: Epoch 0 train loss: 2497.61669921875\nINFO:root:6: Epoch 0 train loss: 9938.369140625\nINFO:root:0: Epoch 0 validation loss: 530710.8172651578\nINFO:root:5: Epoch 1 train loss: 586.28173828125\nINFO:root:6: Epoch 1 train loss: 214.19500732421875\nINFO:root:8: Epoch 1 train loss: 4312.11572265625\nINFO:root:7: Epoch 1 train loss: 629.4315185546875\nINFO:root:12: Epoch 1 train loss: 407.0047302246094\nINFO:root:31: Epoch 1 train loss: 8592.43359375\nINFO:root:32: Epoch 1 train loss: 362.9409484863281\nINFO:root:3: Epoch 1 train loss: 123995.296875\nINFO:root:11: Epoch 1 train loss: 527.6180419921875\nINFO:root:4: Epoch 1 train loss: 682.9067993164062\nINFO:root:29: Epoch 1 train loss: 308015.4375\nINFO:root:9: Epoch 1 train loss: 3047.59765625\nINFO:root:25: Epoch 1 train loss: 3393.177734375\nINFO:root:26: Epoch 1 train loss: 1673.378173828125\nINFO:root:23: Epoch 1 train loss: 4622.61474609375\nINFO:root:22: Epoch 1 train loss: 1964.150634765625\nINFO:root:16: Epoch 1 train loss: 313868.125\nINFO:root:15: Epoch 1 train loss: 274.47454833984375\nINFO:root:17: Epoch 1 train loss: 124250.0234375\nINFO:root:21: Epoch 1 train loss: 431877.03125\nINFO:root:2: Epoch 1 train loss: 2140.62060546875\nINFO:root:0: Epoch 1 train loss: 356644.9375\nINFO:root:30: Epoch 1 train loss: 4688.4365234375\nINFO:root:24: Epoch 1 train loss: 1086.5833740234375\nINFO:root:28: Epoch 1 train loss: 8986.7255859375\nINFO:root:20: Epoch 1 train loss: 360.1574401855469\nINFO:root:14: Epoch 1 train loss: 362774.71875\nINFO:root:19: Epoch 1 train loss: 2121.442626953125\nINFO:root:13: Epoch 1 train loss: 342255.125\nINFO:root:27: Epoch 1 train loss: 8478.232421875\nINFO:root:18: Epoch 1 train loss: 4544.6806640625\nINFO:root:1: Epoch 1 train loss: 357079.5625\nINFO:root:10: Epoch 1 train loss: 348.7508544921875\nINFO:root:0: Epoch 1 validation loss: 530701.2004597745\nINFO:root:28: Epoch 2 train loss: 1597.275634765625\nINFO:root:22: Epoch 2 train loss: 3433.134765625\nINFO:root:11: Epoch 2 train loss: 145.52566528320312\nINFO:root:29: Epoch 2 train loss: 4277.29736328125\nINFO:root:10: Epoch 2 train loss: 2739.947998046875\nINFO:root:27: Epoch 2 train loss: 6998.70751953125\nINFO:root:23: Epoch 2 train loss: 121174.1328125\nINFO:root:32: Epoch 2 train loss: 3144.843017578125\nINFO:root:6: Epoch 2 train loss: 289291.875\nINFO:root:14: Epoch 2 train loss: 138.21437072753906\nINFO:root:21: Epoch 2 train loss: 5788.388671875\nINFO:root:12: Epoch 2 train loss: 343610.375\nINFO:root:26: Epoch 2 train loss: 433533.59375\nINFO:root:20: Epoch 2 train loss: 3329.4638671875\nINFO:root:8: Epoch 2 train loss: 6975.98681640625\nINFO:root:15: Epoch 2 train loss: 12263.599609375\nINFO:root:19: Epoch 2 train loss: 212.85305786132812\nINFO:root:7: Epoch 2 train loss: 428524.125\nINFO:root:17: Epoch 2 train loss: 10692.708984375\nINFO:root:18: Epoch 2 train loss: 1103.454833984375\nINFO:root:16: Epoch 2 train loss: 355822.1875\nINFO:root:24: Epoch 2 train loss: 2067.612060546875\nINFO:root:0: Epoch 2 train loss: 1597.530029296875\nINFO:root:25: Epoch 2 train loss: 12050.7763671875\nINFO:root:13: Epoch 2 train loss: 4027.457275390625\nINFO:root:9: Epoch 2 train loss: 369732.34375\nINFO:root:31: Epoch 2 train loss: 14747.5849609375\nINFO:root:30: Epoch 2 train loss: 377.4759521484375\nINFO:root:1: Epoch 2 train loss: 991.5770263671875\nINFO:root:2: Epoch 2 train loss: 2249.964599609375\nINFO:root:5: Epoch 2 train loss: 354765.09375\nINFO:root:4: Epoch 2 train loss: 2131.898681640625\nINFO:root:3: Epoch 2 train loss: 1558.125732421875\nINFO:root:0: Epoch 2 validation loss: 530691.5657308337\nINFO:root:26: Epoch 3 train loss: 5273.58837890625\nINFO:root:29: Epoch 3 train loss: 3494.35107421875\nINFO:root:32: Epoch 3 train loss: 221.87315368652344\nINFO:root:30: Epoch 3 train loss: 26.149343490600586\nINFO:root:31: Epoch 3 train loss: 367420.34375\nINFO:root:28: Epoch 3 train loss: 1036.2568359375\nINFO:root:27: Epoch 3 train loss: 385758.96875\nINFO:root:17: Epoch 3 train loss: 4463.509765625\nINFO:root:22: Epoch 3 train loss: 478.9073791503906\nINFO:root:23: Epoch 3 train loss: 387932.65625\nINFO:root:21: Epoch 3 train loss: 2725.5224609375\nINFO:root:0: Epoch 3 train loss: 1256.54443359375\nINFO:root:16: Epoch 3 train loss: 4602.15087890625\nINFO:root:4: Epoch 3 train loss: 342719.09375\nINFO:root:10: Epoch 3 train loss: 14602.2763671875\nINFO:root:24: Epoch 3 train loss: 290094.0\nINFO:root:19: Epoch 3 train loss: 1341.70654296875\nINFO:root:5: Epoch 3 train loss: 5139.1123046875\nINFO:root:11: Epoch 3 train loss: 5729.3828125\nINFO:root:18: Epoch 3 train loss: 1281.44677734375\nINFO:root:20: Epoch 3 train loss: 9620.2275390625\nINFO:root:3: Epoch 3 train loss: 842.0321044921875\nINFO:root:9: Epoch 3 train loss: 1132.452392578125\nINFO:root:25: Epoch 3 train loss: 604.5478515625\nINFO:root:14: Epoch 3 train loss: 3985.091552734375\nINFO:root:7: Epoch 3 train loss: 358242.78125\nINFO:root:1: Epoch 3 train loss: 1930.142333984375\nINFO:root:2: Epoch 3 train loss: 961.2686767578125\nINFO:root:6: Epoch 3 train loss: 514.55517578125\nINFO:root:15: Epoch 3 train loss: 941.392333984375\nINFO:root:13: Epoch 3 train loss: 49342.29296875\nINFO:root:8: Epoch 3 train loss: 1273.8450927734375\nINFO:root:12: Epoch 3 train loss: 749.2676391601562\nINFO:root:0: Epoch 3 validation loss: 530681.953284815\nINFO:root:25: Epoch 4 train loss: 2441.56298828125\nINFO:root:9: Epoch 4 train loss: 7410.78759765625\nINFO:root:28: Epoch 4 train loss: 3138.8212890625\nINFO:root:26: Epoch 4 train loss: 3335.5166015625\nINFO:root:16: Epoch 4 train loss: 205.92083740234375\nINFO:root:21: Epoch 4 train loss: 995.2607421875\nINFO:root:15: Epoch 4 train loss: 7203.86181640625\nINFO:root:27: Epoch 4 train loss: 403814.125\nINFO:root:29: Epoch 4 train loss: 739866.25\nINFO:root:22: Epoch 4 train loss: 41725.94921875\nINFO:root:17: Epoch 4 train loss: 2246.693359375\nINFO:root:4: Epoch 4 train loss: 299.89764404296875\nINFO:root:10: Epoch 4 train loss: 3241.956298828125\nINFO:root:5: Epoch 4 train loss: 52119.921875\nINFO:root:11: Epoch 4 train loss: 208.871826171875\nINFO:root:3: Epoch 4 train loss: 7339.34326171875\nINFO:root:0: Epoch 4 train loss: 251.36692810058594\nINFO:root:32: Epoch 4 train loss: 48685.58984375\nINFO:root:24: Epoch 4 train loss: 381784.3125\nINFO:root:18: Epoch 4 train loss: 343171.4375\nINFO:root:14: Epoch 4 train loss: 268.42388916015625\nINFO:root:8: Epoch 4 train loss: 1189.1221923828125\nINFO:root:20: Epoch 4 train loss: 312411.78125\nINFO:root:6: Epoch 4 train loss: 139.9405975341797\nINFO:root:19: Epoch 4 train loss: 1339.9168701171875\nINFO:root:7: Epoch 4 train loss: 427.0860290527344\nINFO:root:2: Epoch 4 train loss: 478.0517883300781\nINFO:root:31: Epoch 4 train loss: 541.60595703125\nINFO:root:13: Epoch 4 train loss: 485.673095703125\nINFO:root:23: Epoch 4 train loss: 425861.46875\nINFO:root:1: Epoch 4 train loss: 1409.3778076171875\nINFO:root:12: Epoch 4 train loss: 314492.09375\nINFO:root:30: Epoch 4 train loss: 385501.4375\nINFO:root:0: Epoch 4 validation loss: 530672.3035339208\nINFO:root:11: Epoch 5 train loss: 1193.9605712890625\nINFO:root:29: Epoch 5 train loss: 40522.19921875\nINFO:root:27: Epoch 5 train loss: 357448.78125\nINFO:root:28: Epoch 5 train loss: 390446.8125\nINFO:root:10: Epoch 5 train loss: 2499.715087890625\nINFO:root:9: Epoch 5 train loss: 40163.6796875\nINFO:root:21: Epoch 5 train loss: 1002.223876953125\nINFO:root:23: Epoch 5 train loss: 1094.444580078125\nINFO:root:22: Epoch 5 train loss: 355361.65625\nINFO:root:7: Epoch 5 train loss: 292646.9375\nINFO:root:8: Epoch 5 train loss: 387511.375\nINFO:root:26: Epoch 5 train loss: 1843.005859375\nINFO:root:12: Epoch 5 train loss: 1117.1993408203125\nINFO:root:14: Epoch 5 train loss: 4136.4072265625\nINFO:root:13: Epoch 5 train loss: 9233.1396484375\nINFO:root:18: Epoch 5 train loss: 5826.326171875\nINFO:root:15: Epoch 5 train loss: 4082.760498046875\nINFO:root:17: Epoch 5 train loss: 771970.5625\nINFO:root:16: Epoch 5 train loss: 306865.34375\nINFO:root:6: Epoch 5 train loss: 14855.0029296875\nINFO:root:19: Epoch 5 train loss: 427263.4375\nINFO:root:25: Epoch 5 train loss: 1714.06591796875\nINFO:root:24: Epoch 5 train loss: 2342.902587890625\nINFO:root:20: Epoch 5 train loss: 8689.8974609375\nINFO:root:4: Epoch 5 train loss: 425784.09375\nINFO:root:5: Epoch 5 train loss: 11005.107421875\nINFO:root:3: Epoch 5 train loss: 1070.4195556640625\nINFO:root:0: Epoch 5 train loss: 789.3521728515625\nINFO:root:30: Epoch 5 train loss: 427280.3125\nINFO:root:32: Epoch 5 train loss: 308816.8125\nINFO:root:31: Epoch 5 train loss: 307776.8125\nINFO:root:1: Epoch 5 train loss: 2416.6533203125\nINFO:root:2: Epoch 5 train loss: 3496.318115234375\nINFO:root:0: Epoch 5 validation loss: 530662.7749961101\n", "seconds": 19.441699266433716, "batch_size": 256, "nodes": 11, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n2 Start Epoch 0\n2: 1 batches\n1: 1 batches\n3 Start Epoch 0\n4 Start Epoch 0\n4: 1 batches\n3: 1 batches\n23 Start Epoch 0\n23: 1 batches\n24 Start Epoch 0\n31 Start Epoch 0\n24: 1 batches\n32 Start Epoch 0\n16 Start Epoch 0\n5 Start Epoch 0\n5: 1 batches\n7 Start Epoch 0\n31: 1 batches\n15 Start Epoch 0\n8 Start Epoch 0\n32: 1 batches\n16: 1 batches\n15: 1 batches\n6 Start Epoch 0\n8: 1 batches\n6: 1 batches\n7: 1 batches\n28 Start Epoch 0\n28: 1 batches\n27 Start Epoch 0\n27: 1 batches\n11 Start Epoch 0\n11: 1 batches\n35 Start Epoch 0\n35: 1 batches\n12 Start Epoch 0\n20 Start Epoch 0\n12: 1 batches\n20: 1 batches\n19 Start Epoch 0\n19: 1 batches\n9 Start Epoch 0\n10 Start Epoch 0\n9: 1 batches\n18 Start Epoch 0\n25 Start Epoch 0\n26 Start Epoch 0\n18: 1 batches\n26: 1 batches\n10: 1 batches\n25: 1 batches\n17 Start Epoch 0\n34 Start Epoch 0\n33 Start Epoch 0\n34: 1 batches\n33: 1 batches\n17: 1 batches\n29 Start Epoch 0\n29: 1 batches\n21 Start Epoch 0\n30 Start Epoch 0\n22 Start Epoch 0\n30: 1 batches\n14 Start Epoch 0\n13 Start Epoch 0\n14: 1 batches\n13: 1 batches\n21: 1 batches\n22: 1 batches\n10 Start Epoch 1\n16 Start Epoch 1\n11 Start Epoch 1\n15 Start Epoch 1\n11: 1 batches\n16: 1 batches\n10: 1 batches\n15: 1 batches\n17 Start Epoch 1\n17: 1 batches\n29 Start Epoch 1\n18 Start Epoch 1\n23 Start Epoch 1\n8 Start Epoch 1\n26 Start Epoch 1\n9 Start Epoch 1\n8: 1 batches\n31 Start Epoch 1\n26: 1 batches\n9: 1 batches\n29: 1 batches\n18: 1 batches\n14 Start Epoch 1\n14: 1 batches\n33 Start Epoch 1\n33: 1 batches\n31: 1 batches\n4 Start Epoch 1\n32 Start Epoch 1\n28 Start Epoch 1\n13 Start Epoch 1\n13: 1 batches\n5 Start Epoch 1\n34 Start Epoch 1\n21 Start Epoch 1\n32: 1 batches\n24 Start Epoch 1\n28: 1 batches\n19 Start Epoch 1\n20 Start Epoch 1\n5: 1 batches\n34: 1 batches\n21: 1 batches\n25 Start Epoch 1\n4: 1 batches\n35 Start Epoch 1\n23: 1 batches\n24: 1 batches\n27 Start Epoch 1\n19: 1 batches\n22 Start Epoch 1\n25: 1 batches\n27: 1 batches\n20: 1 batches\n3 Start Epoch 1\n35: 1 batches\n22: 1 batches\n3: 1 batches\n12 Start Epoch 1\n12: 1 batches\n7 Start Epoch 1\n6 Start Epoch 1\n7: 1 batches\n6: 1 batches\n2 Start Epoch 1\n2: 1 batches\n1 Start Epoch 1\n1: 1 batches\n30 Start Epoch 1\n30: 1 batches\n0 Start Epoch 1\n0: 1 batches\n28 Start Epoch 2\n29 Start Epoch 2\n35 Start Epoch 2\n29: 1 batches\n28: 1 batches\n35: 1 batches\n27 Start Epoch 2\n27: 1 batches\n32 Start Epoch 2\n31 Start Epoch 2\n32: 1 batches\n30 Start Epoch 2\n30: 1 batches\n31: 1 batches\n6 Start Epoch 2\n17 Start Epoch 2\n14 Start Epoch 2\n33 Start Epoch 2\n6: 1 batches\n10 Start Epoch 2\n14: 1 batches\n3 Start Epoch 2\n34 Start Epoch 2\n33: 1 batches\n11 Start Epoch 2\n5 Start Epoch 2\n4 Start Epoch 2\n34: 1 batches\n26 Start Epoch 2\n9 Start Epoch 2\n5: 1 batches\n25 Start Epoch 2\n9: 1 batches\n24 Start Epoch 2\n11: 1 batches\n3: 1 batches\n26: 1 batches\n10: 1 batches\n4: 1 batches\n24: 1 batches\n25: 1 batches\n12 Start Epoch 2\n7 Start Epoch 2\n7: 1 batches\n13 Start Epoch 2\n12: 1 batches\n13: 1 batches\n2 Start Epoch 2\n2: 1 batches\n1 Start Epoch 2\n1: 1 batches\n8 Start Epoch 2\n8: 1 batches\n16 Start Epoch 2\n20 Start Epoch 2\n15 Start Epoch 2\n19 Start Epoch 2\n21 Start Epoch 2\n18 Start Epoch 2\n23 Start Epoch 2\n16: 1 batches\n21: 1 batches\n15: 1 batches\n19: 1 batches\n18: 1 batches\n22 Start Epoch 2\n17: 1 batches\n20: 1 batches\n22: 1 batches\n23: 1 batches\n0 Start Epoch 2\n0: 1 batches\n26 Start Epoch 3\n26: 1 batches\n29 Start Epoch 3\n28 Start Epoch 3\n21 Start Epoch 3\n11 Start Epoch 3\n27 Start Epoch 3\n27: 1 batches\n23 Start Epoch 3\n21: 1 batches\n11: 1 batches\n29: 1 batches\n22 Start Epoch 3\n28: 1 batches\n22: 1 batches\n30 Start Epoch 3\n17 Start Epoch 3\n20 Start Epoch 3\n23: 1 batches\n8 Start Epoch 3\n8: 1 batches\n30: 1 batches\n17: 1 batches\n20: 1 batches\n13 Start Epoch 3\n33 Start Epoch 3\n14 Start Epoch 3\n15 Start Epoch 3\n15: 1 batches\n31 Start Epoch 3\n25 Start Epoch 3\n10 Start Epoch 3\n18 Start Epoch 3\n14: 1 batches\n24 Start Epoch 3\n9 Start Epoch 3\n18: 1 batches\n13: 1 batches\n9: 1 batches\n16 Start Epoch 3\n16: 1 batches\n31: 1 batches\n25: 1 batches\n32 Start Epoch 3\n24: 1 batches\n10: 1 batches\n19 Start Epoch 3\n32: 1 batches\n19: 1 batches\n34 Start Epoch 3\n34: 1 batches\n35 Start Epoch 3\n33: 1 batches\n35: 1 batches\n12 Start Epoch 3\n12: 1 batches\n4 Start Epoch 3\n5 Start Epoch 3\n4: 1 batches\n5: 1 batches\n1 Start Epoch 3\n2 Start Epoch 3\n6 Start Epoch 3\n7 Start Epoch 3\n6: 1 batches\n7: 1 batches\n1: 1 batches\n2: 1 batches\n3 Start Epoch 3\n3: 1 batches\n0 Start Epoch 3\n0: 1 batches\n29 Start Epoch 4\n28 Start Epoch 4\n29: 1 batches\n28: 1 batches\n34 Start Epoch 4\n31 Start Epoch 4\n35 Start Epoch 4\n31: 1 batches\n35: 1 batches\n34: 1 batches\n32 Start Epoch 4\n30 Start Epoch 4\n30: 1 batches\n23 Start Epoch 4\n32: 1 batches\n23: 1 batches\n33 Start Epoch 4\n33: 1 batches\n22 Start Epoch 4\n22: 1 batches\n20 Start Epoch 4\n19 Start Epoch 4\n24 Start Epoch 4\n20: 1 batches\n25 Start Epoch 4\n25: 1 batches\n19: 1 batches\n26 Start Epoch 4\n26: 1 batches\n24: 1 batches\n21 Start Epoch 4\n21: 1 batches\n27 Start Epoch 4\n27: 1 batches\n1 Start Epoch 4\n1: 1 batches\n6 Start Epoch 4\n11 Start Epoch 4\n6: 1 batches\n17 Start Epoch 4\n14 Start Epoch 4\n9 Start Epoch 4\n16 Start Epoch 4\n13 Start Epoch 4\n5 Start Epoch 4\n5: 1 batches\n14: 1 batches\n3 Start Epoch 4\n9: 1 batches\n17: 1 batches\n4 Start Epoch 4\n4: 1 batches\n16: 1 batches\n13: 1 batches\n3: 1 batches\n10 Start Epoch 4\n11: 1 batches\n15 Start Epoch 4\n10: 1 batches\n15: 1 batches\n18 Start Epoch 4\n12 Start Epoch 4\n18: 1 batches\n12: 1 batches\n8 Start Epoch 4\n8: 1 batches\n7 Start Epoch 4\n7: 1 batches\n2 Start Epoch 4\n2: 1 batches\n0 Start Epoch 4\n0: 1 batches\n9 Start Epoch 5\n9: 1 batches\n11 Start Epoch 5\n11: 1 batches\n10 Start Epoch 5\n10: 1 batches\n8 Start Epoch 5\n8: 1 batches\n7 Start Epoch 5\n7: 1 batches\n6 Start Epoch 5\n6: 1 batches\n35 Start Epoch 5\n34 Start Epoch 5\n35: 1 batches\n12 Start Epoch 5\n12: 1 batches\n29 Start Epoch 5\n28 Start Epoch 5\n27 Start Epoch 5\n29: 1 batches\n28: 1 batches\n27: 1 batches\n34: 1 batches\n23 Start Epoch 5\n23: 1 batches\n32 Start Epoch 5\n31 Start Epoch 5\n31: 1 batches\n32: 1 batches\n30 Start Epoch 5\n21 Start Epoch 5\n30: 1 batches\n21: 1 batches\n33 Start Epoch 5\n1 Start Epoch 5\n1: 1 batches\n33: 1 batches\n22 Start Epoch 5\n15 Start Epoch 5\n13 Start Epoch 5\n22: 1 batches\n24 Start Epoch 5\n15: 1 batches\n18 Start Epoch 5\n20 Start Epoch 5\n14 Start Epoch 5\n4 Start Epoch 5\n25 Start Epoch 5\n24: 1 batches\n20: 1 batches\n13: 1 batches\n5 Start Epoch 5\n17 Start Epoch 5\n18: 1 batches\n14: 1 batches\n3 Start Epoch 5\n3: 1 batches\n25: 1 batches\n17: 1 batches\n4: 1 batches\n16 Start Epoch 5\n19 Start Epoch 5\n5: 1 batches\n26 Start Epoch 5\n26: 1 batches\n16: 1 batches\n19: 1 batches\n2 Start Epoch 5\n2: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:15: Epoch 0 train loss: 882373.1875\nINFO:root:10: Epoch 0 train loss: 1313.6636962890625\nINFO:root:16: Epoch 0 train loss: 1966.9847412109375\nINFO:root:11: Epoch 0 train loss: 1886.18359375\nINFO:root:17: Epoch 0 train loss: 1280.886962890625\nINFO:root:29: Epoch 0 train loss: 130802.0625\nINFO:root:18: Epoch 0 train loss: 1817.208251953125\nINFO:root:13: Epoch 0 train loss: 4587.67578125\nINFO:root:23: Epoch 0 train loss: 8689.900390625\nINFO:root:8: Epoch 0 train loss: 789.75830078125\nINFO:root:31: Epoch 0 train loss: 913.7223510742188\nINFO:root:26: Epoch 0 train loss: 5644.943359375\nINFO:root:9: Epoch 0 train loss: 463311.9375\nINFO:root:14: Epoch 0 train loss: 1898.23583984375\nINFO:root:32: Epoch 0 train loss: 1359.25\nINFO:root:4: Epoch 0 train loss: 700.5701904296875\nINFO:root:33: Epoch 0 train loss: 417392.375\nINFO:root:5: Epoch 0 train loss: 1804.3232421875\nINFO:root:21: Epoch 0 train loss: 977.6621704101562\nINFO:root:24: Epoch 0 train loss: 1816.1947021484375\nINFO:root:28: Epoch 0 train loss: 8419.1796875\nINFO:root:19: Epoch 0 train loss: 2640.01513671875\nINFO:root:34: Epoch 0 train loss: 2304.621826171875\nINFO:root:22: Epoch 0 train loss: 1162.4693603515625\nINFO:root:25: Epoch 0 train loss: 148.40773010253906\nINFO:root:20: Epoch 0 train loss: 316697.6875\nINFO:root:27: Epoch 0 train loss: 3665.125732421875\nINFO:root:3: Epoch 0 train loss: 271.24041748046875\nINFO:root:35: Epoch 0 train loss: 1733.10107421875\nINFO:root:12: Epoch 0 train loss: 3508.252197265625\nINFO:root:6: Epoch 0 train loss: 3099.84912109375\nINFO:root:7: Epoch 0 train loss: 315237.84375\nINFO:root:0: Epoch 0 train loss: 480.15045166015625\nINFO:root:1: Epoch 0 train loss: 2280.195068359375\nINFO:root:2: Epoch 0 train loss: 387.5387878417969\nINFO:root:30: Epoch 0 train loss: 1329.2552490234375\nINFO:root:0: Epoch 0 validation loss: 43490.5692449003\nINFO:root:28: Epoch 1 train loss: 759.8285522460938\nINFO:root:27: Epoch 1 train loss: 5187.431640625\nINFO:root:29: Epoch 1 train loss: 422254.75\nINFO:root:35: Epoch 1 train loss: 2336.803955078125\nINFO:root:32: Epoch 1 train loss: 385628.71875\nINFO:root:30: Epoch 1 train loss: 43224.1640625\nINFO:root:31: Epoch 1 train loss: 4135.99169921875\nINFO:root:17: Epoch 1 train loss: 2830.564453125\nINFO:root:3: Epoch 1 train loss: 13403.01171875\nINFO:root:34: Epoch 1 train loss: 1298.848876953125\nINFO:root:6: Epoch 1 train loss: 462216.375\nINFO:root:9: Epoch 1 train loss: 4320.4775390625\nINFO:root:5: Epoch 1 train loss: 403951.96875\nINFO:root:33: Epoch 1 train loss: 17963.771484375\nINFO:root:11: Epoch 1 train loss: 44469.34765625\nINFO:root:14: Epoch 1 train loss: 4038.5126953125\nINFO:root:4: Epoch 1 train loss: 5278.693359375\nINFO:root:25: Epoch 1 train loss: 192.23287963867188\nINFO:root:10: Epoch 1 train loss: 372027.5625\nINFO:root:24: Epoch 1 train loss: 3432.9873046875\nINFO:root:26: Epoch 1 train loss: 1805.860107421875\nINFO:root:12: Epoch 1 train loss: 819.938720703125\nINFO:root:7: Epoch 1 train loss: 423487.0\nINFO:root:13: Epoch 1 train loss: 1310.649658203125\nINFO:root:2: Epoch 1 train loss: 878.89892578125\nINFO:root:0: Epoch 1 train loss: 10513.470703125\nINFO:root:1: Epoch 1 train loss: 3412.960205078125\nINFO:root:20: Epoch 1 train loss: 63.37607192993164\nINFO:root:8: Epoch 1 train loss: 1889.2908935546875\nINFO:root:16: Epoch 1 train loss: 546.9071655273438\nINFO:root:19: Epoch 1 train loss: 713.87939453125\nINFO:root:23: Epoch 1 train loss: 297.43426513671875\nINFO:root:21: Epoch 1 train loss: 3338.8779296875\nINFO:root:18: Epoch 1 train loss: 1487.1256103515625\nINFO:root:15: Epoch 1 train loss: 3309.09716796875\nINFO:root:22: Epoch 1 train loss: 1705.5555419921875\nINFO:root:0: Epoch 1 validation loss: 43487.17596430989\nINFO:root:26: Epoch 2 train loss: 5346.49072265625\nINFO:root:28: Epoch 2 train loss: 150.74400329589844\nINFO:root:29: Epoch 2 train loss: 2434.77978515625\nINFO:root:27: Epoch 2 train loss: 16768.37890625\nINFO:root:23: Epoch 2 train loss: 898.7798461914062\nINFO:root:21: Epoch 2 train loss: 420589.96875\nINFO:root:22: Epoch 2 train loss: 2003.4888916015625\nINFO:root:11: Epoch 2 train loss: 1677.076416015625\nINFO:root:20: Epoch 2 train loss: 8016.97265625\nINFO:root:14: Epoch 2 train loss: 9596.6640625\nINFO:root:8: Epoch 2 train loss: 2927.0390625\nINFO:root:30: Epoch 2 train loss: 1562.0650634765625\nINFO:root:17: Epoch 2 train loss: 2192.42529296875\nINFO:root:13: Epoch 2 train loss: 9878.1279296875\nINFO:root:33: Epoch 2 train loss: 546.471923828125\nINFO:root:25: Epoch 2 train loss: 894.4515380859375\nINFO:root:9: Epoch 2 train loss: 4462.50927734375\nINFO:root:18: Epoch 2 train loss: 8593.9130859375\nINFO:root:31: Epoch 2 train loss: 385270.15625\nINFO:root:24: Epoch 2 train loss: 228.56280517578125\nINFO:root:10: Epoch 2 train loss: 633.7925415039062\nINFO:root:16: Epoch 2 train loss: 5394.494140625\nINFO:root:32: Epoch 2 train loss: 3030.8759765625\nINFO:root:15: Epoch 2 train loss: 399372.03125\nINFO:root:19: Epoch 2 train loss: 1139.114013671875\nINFO:root:12: Epoch 2 train loss: 18047.12890625\nINFO:root:34: Epoch 2 train loss: 8374.0361328125\nINFO:root:35: Epoch 2 train loss: 44353.90625\nINFO:root:4: Epoch 2 train loss: 1533.96337890625\nINFO:root:3: Epoch 2 train loss: 649.1038208007812\nINFO:root:5: Epoch 2 train loss: 9068.44921875\nINFO:root:0: Epoch 2 train loss: 3117.583251953125\nINFO:root:2: Epoch 2 train loss: 604.9857788085938\nINFO:root:1: Epoch 2 train loss: 8853.7392578125\nINFO:root:6: Epoch 2 train loss: 697.0330810546875\nINFO:root:7: Epoch 2 train loss: 889331.5625\nINFO:root:0: Epoch 2 validation loss: 43483.732421846675\nINFO:root:28: Epoch 3 train loss: 3081.41748046875\nINFO:root:29: Epoch 3 train loss: 1047.6927490234375\nINFO:root:35: Epoch 3 train loss: 585.8692016601562\nINFO:root:31: Epoch 3 train loss: 1612.7750244140625\nINFO:root:34: Epoch 3 train loss: 13970.5419921875\nINFO:root:30: Epoch 3 train loss: 3284.776611328125\nINFO:root:32: Epoch 3 train loss: 3683.432861328125\nINFO:root:23: Epoch 3 train loss: 374009.3125\nINFO:root:0: Epoch 3 train loss: 42.75216293334961\nINFO:root:33: Epoch 3 train loss: 8943.744140625\nINFO:root:22: Epoch 3 train loss: 1986.9375\nINFO:root:26: Epoch 3 train loss: 313760.15625\nINFO:root:20: Epoch 3 train loss: 5454.90234375\nINFO:root:19: Epoch 3 train loss: 45672.4453125\nINFO:root:25: Epoch 3 train loss: 9813.146484375\nINFO:root:24: Epoch 3 train loss: 1092.64453125\nINFO:root:21: Epoch 3 train loss: 7260.79443359375\nINFO:root:27: Epoch 3 train loss: 133387.6875\nINFO:root:1: Epoch 3 train loss: 703.2449340820312\nINFO:root:5: Epoch 3 train loss: 3734.060302734375\nINFO:root:17: Epoch 3 train loss: 1425.4984130859375\nINFO:root:13: Epoch 3 train loss: 3982.861083984375\nINFO:root:6: Epoch 3 train loss: 1758.09619140625\nINFO:root:11: Epoch 3 train loss: 1126.1436767578125\nINFO:root:16: Epoch 3 train loss: 287.9774475097656\nINFO:root:14: Epoch 3 train loss: 1350.2701416015625\nINFO:root:4: Epoch 3 train loss: 146.82598876953125\nINFO:root:3: Epoch 3 train loss: 563.112060546875\nINFO:root:9: Epoch 3 train loss: 6742.21484375\nINFO:root:10: Epoch 3 train loss: 1264.7958984375\nINFO:root:15: Epoch 3 train loss: 26.888391494750977\nINFO:root:18: Epoch 3 train loss: 577.8577270507812\nINFO:root:12: Epoch 3 train loss: 3605.52001953125\nINFO:root:8: Epoch 3 train loss: 131512.546875\nINFO:root:7: Epoch 3 train loss: 605.8394775390625\nINFO:root:2: Epoch 3 train loss: 316120.625\nINFO:root:0: Epoch 3 validation loss: 43480.26655313761\nINFO:root:9: Epoch 4 train loss: 737.969970703125\nINFO:root:11: Epoch 4 train loss: 333549.625\nINFO:root:10: Epoch 4 train loss: 332963.5625\nINFO:root:8: Epoch 4 train loss: 534.79931640625\nINFO:root:7: Epoch 4 train loss: 1757.7008056640625\nINFO:root:6: Epoch 4 train loss: 1967.84716796875\nINFO:root:34: Epoch 4 train loss: 156.5467071533203\nINFO:root:35: Epoch 4 train loss: 1125.4232177734375\nINFO:root:29: Epoch 4 train loss: 3734.53759765625\nINFO:root:12: Epoch 4 train loss: 1263.7728271484375\nINFO:root:28: Epoch 4 train loss: 748.559326171875\nINFO:root:27: Epoch 4 train loss: 1484.90234375\nINFO:root:0: Epoch 4 train loss: 1753.259765625\nINFO:root:23: Epoch 4 train loss: 9067.9931640625\nINFO:root:31: Epoch 4 train loss: 428456.96875\nINFO:root:30: Epoch 4 train loss: 3469.98486328125\nINFO:root:32: Epoch 4 train loss: 4580.544921875\nINFO:root:21: Epoch 4 train loss: 131114.828125\nINFO:root:33: Epoch 4 train loss: 5669.201171875\nINFO:root:1: Epoch 4 train loss: 419550.9375\nINFO:root:15: Epoch 4 train loss: 238.64907836914062\nINFO:root:20: Epoch 4 train loss: 9258.9365234375\nINFO:root:13: Epoch 4 train loss: 2529.76708984375\nINFO:root:3: Epoch 4 train loss: 400625.40625\nINFO:root:25: Epoch 4 train loss: 3561.308837890625\nINFO:root:5: Epoch 4 train loss: 1264.3001708984375\nINFO:root:22: Epoch 4 train loss: 4357.49609375\nINFO:root:24: Epoch 4 train loss: 2751.77197265625\nINFO:root:18: Epoch 4 train loss: 382237.0\nINFO:root:14: Epoch 4 train loss: 465994.15625\nINFO:root:4: Epoch 4 train loss: 1776.92578125\nINFO:root:17: Epoch 4 train loss: 5334.47265625\nINFO:root:16: Epoch 4 train loss: 464806.9375\nINFO:root:19: Epoch 4 train loss: 2417.564453125\nINFO:root:26: Epoch 4 train loss: 3075.689453125\nINFO:root:2: Epoch 4 train loss: 1153.87109375\nINFO:root:0: Epoch 4 validation loss: 43476.74534035946\nINFO:root:29: Epoch 5 train loss: 469216.78125\nINFO:root:3: Epoch 5 train loss: 127.71942901611328\nINFO:root:33: Epoch 5 train loss: 43644.984375\nINFO:root:31: Epoch 5 train loss: 371066.6875\nINFO:root:25: Epoch 5 train loss: 43198.6328125\nINFO:root:9: Epoch 5 train loss: 1059.435302734375\nINFO:root:13: Epoch 5 train loss: 711.3224487304688\nINFO:root:4: Epoch 5 train loss: 269.6313781738281\nINFO:root:30: Epoch 5 train loss: 4183.86767578125\nINFO:root:26: Epoch 5 train loss: 20500.298828125\nINFO:root:11: Epoch 5 train loss: 314634.96875\nINFO:root:16: Epoch 5 train loss: 10805.4033203125\nINFO:root:28: Epoch 5 train loss: 6839.5166015625\nINFO:root:19: Epoch 5 train loss: 3273.127685546875\nINFO:root:5: Epoch 5 train loss: 1528.645263671875\nINFO:root:32: Epoch 5 train loss: 4251.27783203125\nINFO:root:10: Epoch 5 train loss: 371401.15625\nINFO:root:17: Epoch 5 train loss: 5699.154296875\nINFO:root:27: Epoch 5 train loss: 765.7022705078125\nINFO:root:18: Epoch 5 train loss: 419345.875\nINFO:root:12: Epoch 5 train loss: 5000.09228515625\nINFO:root:15: Epoch 5 train loss: 2869.7939453125\nINFO:root:20: Epoch 5 train loss: 43614.32421875\nINFO:root:14: Epoch 5 train loss: 1077.626953125\nINFO:root:0: Epoch 5 train loss: 774.6675415039062\nINFO:root:1: Epoch 5 train loss: 313200.0625\nINFO:root:7: Epoch 5 train loss: 3810.172119140625\nINFO:root:34: Epoch 5 train loss: 1154.110107421875\nINFO:root:22: Epoch 5 train loss: 391.96856689453125\nINFO:root:21: Epoch 5 train loss: 1112.3028564453125\nINFO:root:8: Epoch 5 train loss: 2008.0732421875\nINFO:root:35: Epoch 5 train loss: 8551.3076171875\nINFO:root:6: Epoch 5 train loss: 125.40850067138672\nINFO:root:23: Epoch 5 train loss: 166.19801330566406\nINFO:root:2: Epoch 5 train loss: 247.7986602783203\nINFO:root:24: Epoch 5 train loss: 2314.466796875\nINFO:root:0: Epoch 5 validation loss: 43473.16770932528\n", "seconds": 19.513149738311768, "batch_size": 256, "nodes": 12, "processes_per_node": 3, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.15,192.168.2.15,192.168.2.15 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n2 Start Epoch 0\n3 Start Epoch 0\n2: 3 batches\n3: 3 batches\n1 Start Epoch 0\n0: 3 batches\n1: 3 batches\n1 Start Epoch 1\n1: 3 batches\n2 Start Epoch 1\n2: 3 batches\n3 Start Epoch 1\n3: 3 batches\n0 Start Epoch 1\n0: 3 batches\n1 Start Epoch 2\n1: 3 batches\n2 Start Epoch 2\n3 Start Epoch 2\n2: 3 batches\n3: 3 batches\n0 Start Epoch 2\n0: 3 batches\n3 Start Epoch 3\n1 Start Epoch 3\n1: 3 batches\n2 Start Epoch 3\n2: 3 batches\n3: 3 batches\n0 Start Epoch 3\n0: 3 batches\n1 Start Epoch 4\n2 Start Epoch 4\n2: 3 batches\n3 Start Epoch 4\n3: 3 batches\n1: 3 batches\n0 Start Epoch 4\n0: 3 batches\n3 Start Epoch 5\n3: 3 batches\n1 Start Epoch 5\n2 Start Epoch 5\n1: 3 batches\n2: 3 batches\n0 Start Epoch 5\n0: 3 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:1: Epoch 0 train loss: 56927.40612792969\nINFO:root:2: Epoch 0 train loss: 188427.4170328776\nINFO:root:0: Epoch 0 train loss: 92183.81884765625\nINFO:root:3: Epoch 0 train loss: 47839.644775390625\nINFO:root:0: Epoch 0 validation loss: 9856.11663036252\nINFO:root:0: Epoch 1 train loss: 143039.63541666666\nINFO:root:1: Epoch 1 train loss: 18402.438151041668\nINFO:root:3: Epoch 1 train loss: 43720.208984375\nINFO:root:2: Epoch 1 train loss: 2972.33935546875\nINFO:root:0: Epoch 1 validation loss: 9849.161686152276\nINFO:root:1: Epoch 2 train loss: 45832.23429361979\nINFO:root:2: Epoch 2 train loss: 52939.56953938802\nINFO:root:0: Epoch 2 train loss: 50858.37312825521\nINFO:root:3: Epoch 2 train loss: 42894.09814453125\nINFO:root:0: Epoch 2 validation loss: 9842.142311729443\nINFO:root:1: Epoch 3 train loss: 118524.81510416667\nINFO:root:2: Epoch 3 train loss: 84047.21232096355\nINFO:root:3: Epoch 3 train loss: 46087.54923502604\nINFO:root:0: Epoch 3 train loss: 51452.06213378906\nINFO:root:0: Epoch 3 validation loss: 9834.774828755071\nINFO:root:0: Epoch 4 train loss: 76918.84798177083\nINFO:root:3: Epoch 4 train loss: 53158.47275797526\nINFO:root:2: Epoch 4 train loss: 100113.7655436198\nINFO:root:1: Epoch 4 train loss: 2012.1415405273438\nINFO:root:0: Epoch 4 validation loss: 9826.840585156118\nINFO:root:1: Epoch 5 train loss: 127810.06087239583\nINFO:root:0: Epoch 5 train loss: 136647.88509114584\nINFO:root:3: Epoch 5 train loss: 54230.856119791664\nINFO:root:2: Epoch 5 train loss: 95291.2889811198\nINFO:root:0: Epoch 5 validation loss: 9818.131478899768\n", "seconds": 64.45156240463257, "batch_size": 256, "nodes": 1, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.15,192.168.2.2,192.168.2.15,192.168.2.2,192.168.2.15,192.168.2.2 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 2 batches\n7 Start Epoch 0\n7: 2 batches\n5 Start Epoch 0\n4 Start Epoch 0\n5: 2 batches\n6 Start Epoch 0\n6: 2 batches\n4: 2 batches\n1 Start Epoch 0\n1: 2 batches\n2 Start Epoch 0\n2: 2 batches\n3 Start Epoch 0\n3: 2 batches\n1 Start Epoch 1\n1: 2 batches\n2 Start Epoch 1\n3 Start Epoch 1\n2: 2 batches\n3: 2 batches\n7 Start Epoch 1\n7: 2 batches\n6 Start Epoch 1\n6: 2 batches\n5 Start Epoch 1\n5: 2 batches\n4 Start Epoch 1\n4: 2 batches\n0 Start Epoch 1\n0: 2 batches\n5 Start Epoch 2\n5: 2 batches\n4 Start Epoch 2\n4: 2 batches\n2 Start Epoch 2\n1 Start Epoch 2\n1: 2 batches\n3 Start Epoch 2\n3: 2 batches\n2: 2 batches\n6 Start Epoch 2\n6: 2 batches\n7 Start Epoch 2\n7: 2 batches\n0 Start Epoch 2\n0: 2 batches\n3 Start Epoch 3\n2 Start Epoch 3\n3: 2 batches\n2: 2 batches\n4 Start Epoch 3\n4: 2 batches\n5 Start Epoch 3\n5: 2 batches\n1 Start Epoch 3\n1: 2 batches\n7 Start Epoch 3\n6 Start Epoch 3\n6: 2 batches\n7: 2 batches\n0 Start Epoch 3\n0: 2 batches\n5 Start Epoch 4\n5: 2 batches\n3 Start Epoch 4\n3: 2 batches\n4 Start Epoch 4\n4: 2 batches\n2 Start Epoch 4\n2: 2 batches\n1 Start Epoch 4\n1: 2 batches\n7 Start Epoch 4\n7: 2 batches\n6 Start Epoch 4\n6: 2 batches\n0 Start Epoch 4\n0: 2 batches\n1 Start Epoch 5\n1: 2 batches\n2 Start Epoch 5\n2: 2 batches\n4 Start Epoch 5\n5 Start Epoch 5\n7 Start Epoch 5\n7: 2 batches\n4: 2 batches\n5: 2 batches\n6 Start Epoch 5\n6: 2 batches\n3 Start Epoch 5\n3: 2 batches\n0 Start Epoch 5\n0: 2 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 50622.916015625\nINFO:root:1: Epoch 0 train loss: 69240.9560546875\nINFO:root:2: Epoch 0 train loss: 1344.440185546875\nINFO:root:3: Epoch 0 train loss: 57587.185302734375\nINFO:root:7: Epoch 0 train loss: 6526.1790771484375\nINFO:root:6: Epoch 0 train loss: 3431.1488647460938\nINFO:root:5: Epoch 0 train loss: 305863.421875\nINFO:root:4: Epoch 0 train loss: 24811.5888671875\nINFO:root:0: Epoch 0 validation loss: 493633.37319297047\nINFO:root:5: Epoch 1 train loss: 22381.46160888672\nINFO:root:4: Epoch 1 train loss: 2840.8084106445312\nINFO:root:1: Epoch 1 train loss: 91120.47302246094\nINFO:root:2: Epoch 1 train loss: 76479.21188354492\nINFO:root:3: Epoch 1 train loss: 184604.38122558594\nINFO:root:0: Epoch 1 train loss: 69193.34716796875\nINFO:root:6: Epoch 1 train loss: 5404.3896484375\nINFO:root:7: Epoch 1 train loss: 4942.26318359375\nINFO:root:0: Epoch 1 validation loss: 493615.0143340299\nINFO:root:2: Epoch 2 train loss: 62343.579345703125\nINFO:root:3: Epoch 2 train loss: 232419.640625\nINFO:root:4: Epoch 2 train loss: 135598.05688476562\nINFO:root:5: Epoch 2 train loss: 957.2072296142578\nINFO:root:1: Epoch 2 train loss: 2862.21826171875\nINFO:root:0: Epoch 2 train loss: 5450.929931640625\nINFO:root:6: Epoch 2 train loss: 169208.34002685547\nINFO:root:7: Epoch 2 train loss: 70914.03729248047\nINFO:root:0: Epoch 2 validation loss: 493596.56632298976\nINFO:root:5: Epoch 3 train loss: 55363.338623046875\nINFO:root:3: Epoch 3 train loss: 63047.5185546875\nINFO:root:4: Epoch 3 train loss: 3036.235107421875\nINFO:root:2: Epoch 3 train loss: 1135.1955871582031\nINFO:root:1: Epoch 3 train loss: 19647.984375\nINFO:root:0: Epoch 3 train loss: 64230.258850097656\nINFO:root:7: Epoch 3 train loss: 3744.5235595703125\nINFO:root:6: Epoch 3 train loss: 56670.20324707031\nINFO:root:0: Epoch 3 validation loss: 493577.5763891026\nINFO:root:1: Epoch 4 train loss: 25316.1416015625\nINFO:root:2: Epoch 4 train loss: 65307.667724609375\nINFO:root:5: Epoch 4 train loss: 61920.88330078125\nINFO:root:6: Epoch 4 train loss: 3571.9798278808594\nINFO:root:4: Epoch 4 train loss: 253318.34375\nINFO:root:7: Epoch 4 train loss: 56164.79364013672\nINFO:root:3: Epoch 4 train loss: 68433.49680328369\nINFO:root:0: Epoch 4 train loss: 128977.7509765625\nINFO:root:0: Epoch 4 validation loss: 493557.7325220537\nINFO:root:3: Epoch 5 train loss: 172674.49560546875\nINFO:root:1: Epoch 5 train loss: 3793.066650390625\nINFO:root:2: Epoch 5 train loss: 3498.06591796875\nINFO:root:6: Epoch 5 train loss: 22958.122680664062\nINFO:root:7: Epoch 5 train loss: 77901.58129882812\nINFO:root:4: Epoch 5 train loss: 145078.6640625\nINFO:root:5: Epoch 5 train loss: 178177.71875\nINFO:root:0: Epoch 5 train loss: 146075.13885498047\nINFO:root:0: Epoch 5 validation loss: 493536.85821338\n", "seconds": 42.38749599456787, "batch_size": 256, "nodes": 2, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.15,192.168.2.2,192.168.2.3 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 1 batches\n11 Start Epoch 0\n11: 1 batches\n8 Start Epoch 0\n8: 1 batches\n2: 1 batches\n7 Start Epoch 0\n7: 1 batches\n3 Start Epoch 0\n3: 1 batches\n4 Start Epoch 0\n4: 1 batches\n6 Start Epoch 0\n5 Start Epoch 0\n5: 1 batches\n9 Start Epoch 0\n6: 1 batches\n10 Start Epoch 0\n10: 1 batches\n9: 1 batches\n1 Start Epoch 1\n1: 1 batches\n11 Start Epoch 1\n11: 1 batches\n10 Start Epoch 1\n10: 1 batches\n2 Start Epoch 1\n3 Start Epoch 1\n7 Start Epoch 1\n3: 1 batches\n7: 1 batches\n2: 1 batches\n4 Start Epoch 1\n6 Start Epoch 1\n6: 1 batches\n4: 1 batches\n9 Start Epoch 1\n8 Start Epoch 1\n8: 1 batches\n9: 1 batches\n5 Start Epoch 1\n5: 1 batches\n0 Start Epoch 1\n0: 1 batches\n11 Start Epoch 2\n11: 1 batches\n10 Start Epoch 2\n10: 1 batches\n1 Start Epoch 2\n1: 1 batches\n5 Start Epoch 2\n5: 1 batches\n7 Start Epoch 2\n4 Start Epoch 2\n4: 1 batches\n2 Start Epoch 2\n2: 1 batches\n6 Start Epoch 2\n6: 1 batches\n7: 1 batches\n3 Start Epoch 2\n3: 1 batches\n9 Start Epoch 2\n9: 1 batches\n8 Start Epoch 2\n8: 1 batches\n0 Start Epoch 2\n0: 1 batches\n11 Start Epoch 3\n11: 1 batches\n10 Start Epoch 3\n10: 1 batches\n1 Start Epoch 3\n1: 1 batches\n9 Start Epoch 3\n9: 1 batches\n2 Start Epoch 3\n3 Start Epoch 3\n3: 1 batches\n2: 1 batches\n4 Start Epoch 3\n4: 1 batches\n5 Start Epoch 3\n5: 1 batches\n7 Start Epoch 3\n7: 1 batches\n6 Start Epoch 3\n6: 1 batches\n8 Start Epoch 3\n8: 1 batches\n0 Start Epoch 3\n0: 1 batches\n4 Start Epoch 4\n4: 1 batches\n9 Start Epoch 4\n5 Start Epoch 4\n8 Start Epoch 4\n8: 1 batches\n3 Start Epoch 4\n3: 1 batches\n1 Start Epoch 4\n9: 1 batches\n1: 1 batches\n6 Start Epoch 4\n5: 1 batches\n6: 1 batches\n7 Start Epoch 4\n10 Start Epoch 4\n7: 1 batches\n10: 1 batches\n11 Start Epoch 4\n11: 1 batches\n2 Start Epoch 4\n2: 1 batches\n0 Start Epoch 4\n0: 1 batches\n1 Start Epoch 5\n1: 1 batches\n3 Start Epoch 5\n2 Start Epoch 5\n2: 1 batches\n3: 1 batches\n11 Start Epoch 5\n11: 1 batches\n8 Start Epoch 5\n7 Start Epoch 5\n8: 1 batches\n4 Start Epoch 5\n4: 1 batches\n7: 1 batches\n5 Start Epoch 5\n5: 1 batches\n6 Start Epoch 5\n6: 1 batches\n10 Start Epoch 5\n10: 1 batches\n9 Start Epoch 5\n9: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:0: Epoch 0 train loss: 719.8016967773438\nINFO:root:1: Epoch 0 train loss: 270231.9375\nINFO:root:10: Epoch 0 train loss: 120942.5390625\nINFO:root:11: Epoch 0 train loss: 46151.69140625\nINFO:root:3: Epoch 0 train loss: 45283.62890625\nINFO:root:2: Epoch 0 train loss: 52495.0390625\nINFO:root:7: Epoch 0 train loss: 18328.22265625\nINFO:root:4: Epoch 0 train loss: 8251.0234375\nINFO:root:6: Epoch 0 train loss: 3416.489013671875\nINFO:root:8: Epoch 0 train loss: 157820.96875\nINFO:root:9: Epoch 0 train loss: 934.6552734375\nINFO:root:5: Epoch 0 train loss: 113241.6953125\nINFO:root:0: Epoch 0 validation loss: 193816.63075598457\nINFO:root:0: Epoch 1 train loss: 141713.53125\nINFO:root:11: Epoch 1 train loss: 149312.703125\nINFO:root:10: Epoch 1 train loss: 4753.6845703125\nINFO:root:1: Epoch 1 train loss: 1514.897216796875\nINFO:root:5: Epoch 1 train loss: 130102.7890625\nINFO:root:7: Epoch 1 train loss: 2121.069091796875\nINFO:root:4: Epoch 1 train loss: 1106.72216796875\nINFO:root:2: Epoch 1 train loss: 129652.3203125\nINFO:root:6: Epoch 1 train loss: 1410.8382568359375\nINFO:root:3: Epoch 1 train loss: 143063.140625\nINFO:root:8: Epoch 1 train loss: 11212.3740234375\nINFO:root:9: Epoch 1 train loss: 134677.625\nINFO:root:0: Epoch 1 validation loss: 193811.86553436634\nINFO:root:11: Epoch 2 train loss: 3438.573486328125\nINFO:root:10: Epoch 2 train loss: 107342.8046875\nINFO:root:0: Epoch 2 train loss: 276693.0\nINFO:root:1: Epoch 2 train loss: 46385.18359375\nINFO:root:9: Epoch 2 train loss: 158239.375\nINFO:root:2: Epoch 2 train loss: 3916.0185546875\nINFO:root:3: Epoch 2 train loss: 142626.21875\nINFO:root:5: Epoch 2 train loss: 159920.203125\nINFO:root:4: Epoch 2 train loss: 6497.1484375\nINFO:root:7: Epoch 2 train loss: 1888.8936767578125\nINFO:root:6: Epoch 2 train loss: 136314.375\nINFO:root:8: Epoch 2 train loss: 48559.54296875\nINFO:root:0: Epoch 2 validation loss: 193807.20732433908\nINFO:root:4: Epoch 3 train loss: 128417.09375\nINFO:root:7: Epoch 3 train loss: 169491.15625\nINFO:root:9: Epoch 3 train loss: 2125.233642578125\nINFO:root:0: Epoch 3 train loss: 3379.946533203125\nINFO:root:1: Epoch 3 train loss: 112822.234375\nINFO:root:6: Epoch 3 train loss: 113822.1328125\nINFO:root:5: Epoch 3 train loss: 3804.21435546875\nINFO:root:3: Epoch 3 train loss: 133364.765625\nINFO:root:8: Epoch 3 train loss: 112723.4765625\nINFO:root:10: Epoch 3 train loss: 157310.34375\nINFO:root:2: Epoch 3 train loss: 1186.8919677734375\nINFO:root:11: Epoch 3 train loss: 2806.10546875\nINFO:root:0: Epoch 3 validation loss: 193802.64077547594\nINFO:root:0: Epoch 4 train loss: 140940.859375\nINFO:root:1: Epoch 4 train loss: 276168.78125\nINFO:root:11: Epoch 4 train loss: 125745.171875\nINFO:root:2: Epoch 4 train loss: 1523.840087890625\nINFO:root:3: Epoch 4 train loss: 127209.7890625\nINFO:root:4: Epoch 4 train loss: 7336.27197265625\nINFO:root:8: Epoch 4 train loss: 135579.53125\nINFO:root:5: Epoch 4 train loss: 154424.90625\nINFO:root:7: Epoch 4 train loss: 4456.9296875\nINFO:root:6: Epoch 4 train loss: 18818.392578125\nINFO:root:10: Epoch 4 train loss: 1791.418701171875\nINFO:root:9: Epoch 4 train loss: 1553.427978515625\nINFO:root:0: Epoch 4 validation loss: 193798.1969158509\nINFO:root:0: Epoch 5 train loss: 137506.484375\nINFO:root:11: Epoch 5 train loss: 131210.234375\nINFO:root:7: Epoch 5 train loss: 173156.359375\nINFO:root:4: Epoch 5 train loss: 1300.9744873046875\nINFO:root:2: Epoch 5 train loss: 3710.065673828125\nINFO:root:1: Epoch 5 train loss: 631.1747436523438\nINFO:root:3: Epoch 5 train loss: 113029.1796875\nINFO:root:10: Epoch 5 train loss: 130698.6640625\nINFO:root:9: Epoch 5 train loss: 129693.9765625\nINFO:root:8: Epoch 5 train loss: 677.444091796875\nINFO:root:5: Epoch 5 train loss: 6680.74853515625\nINFO:root:6: Epoch 5 train loss: 135826.953125\nINFO:root:0: Epoch 5 validation loss: 193793.62161580598\n", "seconds": 24.304516077041626, "batch_size": 256, "nodes": 3, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "1 Start Epoch 0\n2 Start Epoch 0\n1: 1 batches\n2: 1 batches\n0 Start Epoch 0\n0: 1 batches\n15 Start Epoch 0\n15: 1 batches\n12 Start Epoch 0\n7 Start Epoch 0\n12: 1 batches\n4 Start Epoch 0\n7: 1 batches\n3 Start Epoch 0\n3: 1 batches\n8 Start Epoch 0\n8: 1 batches\n4: 1 batches\n11 Start Epoch 0\n11: 1 batches\n5 Start Epoch 0\n6 Start Epoch 0\n5: 1 batches\n6: 1 batches\n9 Start Epoch 0\n10 Start Epoch 0\n10: 1 batches\n9: 1 batches\n13 Start Epoch 0\n14 Start Epoch 0\n13: 1 batches\n14: 1 batches\n9 Start Epoch 1\n10 Start Epoch 1\n9: 1 batches\n11 Start Epoch 1\n11: 1 batches\n10: 1 batches\n8 Start Epoch 1\n8: 1 batches\n12 Start Epoch 1\n12: 1 batches\n7 Start Epoch 1\n7: 1 batches\n13 Start Epoch 1\n13: 1 batches\n14 Start Epoch 1\n15 Start Epoch 1\n14: 1 batches\n1 Start Epoch 1\n15: 1 batches\n1: 1 batches\n2 Start Epoch 1\n2: 1 batches\n3 Start Epoch 1\n3: 1 batches\n4 Start Epoch 1\n5 Start Epoch 1\n6 Start Epoch 1\n4: 1 batches\n5: 1 batches\n6: 1 batches\n0 Start Epoch 1\n0: 1 batches\n1 Start Epoch 2\n1: 1 batches\n7 Start Epoch 2\n15 Start Epoch 2\n7: 1 batches\n12 Start Epoch 2\n12: 1 batches\n15: 1 batches\n13 Start Epoch 2\n13: 1 batches\n11 Start Epoch 2\n11: 1 batches\n9 Start Epoch 2\n9: 1 batches\n10 Start Epoch 2\n10: 1 batches\n8 Start Epoch 2\n8: 1 batches\n14 Start Epoch 2\n14: 1 batches\n2 Start Epoch 2\n2: 1 batches\n3 Start Epoch 2\n3: 1 batches\n4 Start Epoch 2\n4: 1 batches\n6 Start Epoch 2\n6: 1 batches\n5 Start Epoch 2\n5: 1 batches\n0 Start Epoch 2\n0: 1 batches\n3 Start Epoch 3\n2 Start Epoch 3\n10 Start Epoch 3\n13 Start Epoch 3\n11 Start Epoch 3\n11: 1 batches\n10: 1 batches\n2: 1 batches\n3: 1 batches\n13: 1 batches\n12 Start Epoch 3\n12: 1 batches\n1 Start Epoch 3\n1: 1 batches\n4 Start Epoch 3\n4: 1 batches\n5 Start Epoch 3\n5: 1 batches\n7 Start Epoch 3\n7: 1 batches\n6 Start Epoch 3\n6: 1 batches\n15 Start Epoch 3\n15: 1 batches\n9 Start Epoch 3\n9: 1 batches\n8 Start Epoch 3\n8: 1 batches\n14 Start Epoch 3\n14: 1 batches\n0 Start Epoch 3\n0: 1 batches\n3 Start Epoch 4\n5 Start Epoch 4\n9 Start Epoch 4\n8 Start Epoch 4\n14 Start Epoch 4\n2 Start Epoch 4\n2: 1 batches\n3: 1 batches\n6 Start Epoch 4\n6: 1 batches\n15 Start Epoch 4\n8: 1 batches\n14: 1 batches\n9: 1 batches\n15: 1 batches\n4 Start Epoch 4\n4: 1 batches\n5: 1 batches\n11 Start Epoch 4\n10 Start Epoch 4\n11: 1 batches\n10: 1 batches\n1 Start Epoch 4\n1: 1 batches\n7 Start Epoch 4\n7: 1 batches\n12 Start Epoch 4\n12: 1 batches\n13 Start Epoch 4\n13: 1 batches\n0 Start Epoch 4\n0: 1 batches\n3 Start Epoch 5\n3: 1 batches\n2 Start Epoch 5\n2: 1 batches\n1 Start Epoch 5\n1: 1 batches\n4 Start Epoch 5\n4: 1 batches\n15 Start Epoch 5\n15: 1 batches\n11 Start Epoch 5\n11: 1 batches\n5 Start Epoch 5\n14 Start Epoch 5\n5: 1 batches\n12 Start Epoch 5\n14: 1 batches\n13 Start Epoch 5\n13: 1 batches\n12: 1 batches\n7 Start Epoch 5\n7: 1 batches\n6 Start Epoch 5\n6: 1 batches\n9 Start Epoch 5\n9: 1 batches\n8 Start Epoch 5\n8: 1 batches\n10 Start Epoch 5\n10: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:9: Epoch 0 train loss: 6332.7958984375\nINFO:root:10: Epoch 0 train loss: 9007.5888671875\nINFO:root:11: Epoch 0 train loss: 230317.09375\nINFO:root:8: Epoch 0 train loss: 8022.3037109375\nINFO:root:12: Epoch 0 train loss: 569.382080078125\nINFO:root:7: Epoch 0 train loss: 173844.5625\nINFO:root:13: Epoch 0 train loss: 4633.02197265625\nINFO:root:15: Epoch 0 train loss: 675.5361938476562\nINFO:root:14: Epoch 0 train loss: 148852.609375\nINFO:root:0: Epoch 0 train loss: 1434.6925048828125\nINFO:root:1: Epoch 0 train loss: 167381.171875\nINFO:root:2: Epoch 0 train loss: 4805.51025390625\nINFO:root:3: Epoch 0 train loss: 59634.78125\nINFO:root:4: Epoch 0 train loss: 1720.2838134765625\nINFO:root:5: Epoch 0 train loss: 224518.15625\nINFO:root:6: Epoch 0 train loss: 365946.625\nINFO:root:0: Epoch 0 validation loss: 70732.38700580873\nINFO:root:1: Epoch 1 train loss: 2220.326904296875\nINFO:root:0: Epoch 1 train loss: 6663.63427734375\nINFO:root:15: Epoch 1 train loss: 5458.59326171875\nINFO:root:7: Epoch 1 train loss: 19622.630859375\nINFO:root:12: Epoch 1 train loss: 1486.475341796875\nINFO:root:13: Epoch 1 train loss: 1475.94970703125\nINFO:root:11: Epoch 1 train loss: 169182.828125\nINFO:root:10: Epoch 1 train loss: 147577.609375\nINFO:root:8: Epoch 1 train loss: 62140.4453125\nINFO:root:9: Epoch 1 train loss: 7111.0927734375\nINFO:root:14: Epoch 1 train loss: 59560.84375\nINFO:root:2: Epoch 1 train loss: 2948.235595703125\nINFO:root:3: Epoch 1 train loss: 227935.15625\nINFO:root:4: Epoch 1 train loss: 58940.4453125\nINFO:root:6: Epoch 1 train loss: 884.7908935546875\nINFO:root:5: Epoch 1 train loss: 322003.78125\nINFO:root:0: Epoch 1 validation loss: 70728.95094039573\nINFO:root:2: Epoch 2 train loss: 64227.71875\nINFO:root:3: Epoch 2 train loss: 4430.96435546875\nINFO:root:11: Epoch 2 train loss: 166251.046875\nINFO:root:13: Epoch 2 train loss: 3255.480224609375\nINFO:root:10: Epoch 2 train loss: 171346.71875\nINFO:root:12: Epoch 2 train loss: 1297.8016357421875\nINFO:root:1: Epoch 2 train loss: 226.89163208007812\nINFO:root:0: Epoch 2 train loss: 2520.629150390625\nINFO:root:4: Epoch 2 train loss: 589.0142822265625\nINFO:root:5: Epoch 2 train loss: 1638.007080078125\nINFO:root:7: Epoch 2 train loss: 752.755126953125\nINFO:root:6: Epoch 2 train loss: 208211.359375\nINFO:root:15: Epoch 2 train loss: 6296.88525390625\nINFO:root:8: Epoch 2 train loss: 511.3479919433594\nINFO:root:14: Epoch 2 train loss: 2848.60888671875\nINFO:root:9: Epoch 2 train loss: 208207.046875\nINFO:root:0: Epoch 2 validation loss: 70725.5652524012\nINFO:root:3: Epoch 3 train loss: 2746.679443359375\nINFO:root:15: Epoch 3 train loss: 824.5803833007812\nINFO:root:14: Epoch 3 train loss: 524347.3125\nINFO:root:6: Epoch 3 train loss: 313497.0625\nINFO:root:5: Epoch 3 train loss: 178080.640625\nINFO:root:9: Epoch 3 train loss: 2689.297607421875\nINFO:root:0: Epoch 3 train loss: 1158.1634521484375\nINFO:root:2: Epoch 3 train loss: 835.8131103515625\nINFO:root:8: Epoch 3 train loss: 196111.15625\nINFO:root:4: Epoch 3 train loss: 2478.89208984375\nINFO:root:11: Epoch 3 train loss: 191669.09375\nINFO:root:10: Epoch 3 train loss: 59330.12890625\nINFO:root:1: Epoch 3 train loss: 58820.203125\nINFO:root:12: Epoch 3 train loss: 798.8932495117188\nINFO:root:7: Epoch 3 train loss: 338847.40625\nINFO:root:13: Epoch 3 train loss: 1662.29052734375\nINFO:root:0: Epoch 3 validation loss: 70722.18365741071\nINFO:root:3: Epoch 4 train loss: 333157.46875\nINFO:root:2: Epoch 4 train loss: 167382.34375\nINFO:root:1: Epoch 4 train loss: 189765.125\nINFO:root:0: Epoch 4 train loss: 3451.532958984375\nINFO:root:4: Epoch 4 train loss: 173433.328125\nINFO:root:15: Epoch 4 train loss: 211234.21875\nINFO:root:11: Epoch 4 train loss: 373317.46875\nINFO:root:13: Epoch 4 train loss: 2833.871337890625\nINFO:root:5: Epoch 4 train loss: 20526.7421875\nINFO:root:14: Epoch 4 train loss: 167501.828125\nINFO:root:12: Epoch 4 train loss: 172598.203125\nINFO:root:7: Epoch 4 train loss: 207254.734375\nINFO:root:6: Epoch 4 train loss: 2239.64892578125\nINFO:root:9: Epoch 4 train loss: 179854.171875\nINFO:root:8: Epoch 4 train loss: 8070.31201171875\nINFO:root:10: Epoch 4 train loss: 59305.91796875\nINFO:root:0: Epoch 4 validation loss: 70718.77952047913\nINFO:root:5: Epoch 5 train loss: 2281.401611328125\nINFO:root:8: Epoch 5 train loss: 754.9910278320312\nINFO:root:9: Epoch 5 train loss: 3300.213134765625\nINFO:root:14: Epoch 5 train loss: 6152.9404296875\nINFO:root:15: Epoch 5 train loss: 5075.73974609375\nINFO:root:7: Epoch 5 train loss: 10346.93359375\nINFO:root:1: Epoch 5 train loss: 1139.37744140625\nINFO:root:0: Epoch 5 train loss: 206853.84375\nINFO:root:13: Epoch 5 train loss: 20199.419921875\nINFO:root:12: Epoch 5 train loss: 3301.031982421875\nINFO:root:10: Epoch 5 train loss: 2091.44970703125\nINFO:root:11: Epoch 5 train loss: 386.08660888671875\nINFO:root:6: Epoch 5 train loss: 1897.3074951171875\nINFO:root:2: Epoch 5 train loss: 245409.328125\nINFO:root:3: Epoch 5 train loss: 192001.78125\nINFO:root:4: Epoch 5 train loss: 166796.75\nINFO:root:0: Epoch 5 validation loss: 70715.30274451138\n", "seconds": 22.24403476715088, "batch_size": 256, "nodes": 4, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n2 Start Epoch 0\n3 Start Epoch 0\n19 Start Epoch 0\n2: 1 batches\n3: 1 batches\n16 Start Epoch 0\n19: 1 batches\n16: 1 batches\n1 Start Epoch 0\n1: 1 batches\n7 Start Epoch 0\n4 Start Epoch 0\n4: 1 batches\n7: 1 batches\n12 Start Epoch 0\n12: 1 batches\n15 Start Epoch 0\n15: 1 batches\n8 Start Epoch 0\n8: 1 batches\n11 Start Epoch 0\n11: 1 batches\n17 Start Epoch 0\n18 Start Epoch 0\n17: 1 batches\n18: 1 batches\n9 Start Epoch 0\n9: 1 batches\n10 Start Epoch 0\n10: 1 batches\n13 Start Epoch 0\n13: 1 batches\n14 Start Epoch 0\n14: 1 batches\n5 Start Epoch 0\n5: 1 batches\n6 Start Epoch 0\n6: 1 batches\n15 Start Epoch 1\n9 Start Epoch 1\n9: 1 batches\n15: 1 batches\n5 Start Epoch 1\n8 Start Epoch 1\n8: 1 batches\n10 Start Epoch 1\n10: 1 batches\n7 Start Epoch 1\n7: 1 batches\n5: 1 batches\n6 Start Epoch 1\n6: 1 batches\n1 Start Epoch 1\n1: 1 batches\n3 Start Epoch 1\n3: 1 batches\n2 Start Epoch 1\n2: 1 batches\n19 Start Epoch 1\n18 Start Epoch 1\n12 Start Epoch 1\n19: 1 batches\n13 Start Epoch 1\n13: 1 batches\n14 Start Epoch 1\n14: 1 batches\n12: 1 batches\n11 Start Epoch 1\n18: 1 batches\n11: 1 batches\n17 Start Epoch 1\n17: 1 batches\n16 Start Epoch 1\n16: 1 batches\n4 Start Epoch 1\n4: 1 batches\n0 Start Epoch 1\n0: 1 batches\n1 Start Epoch 2\n1: 1 batches\n8 Start Epoch 2\n7 Start Epoch 2\n11 Start Epoch 2\n11: 1 batches\n7: 1 batches\n6 Start Epoch 2\n8: 1 batches\n3 Start Epoch 2\n3: 1 batches\n6: 1 batches\n13 Start Epoch 2\n15 Start Epoch 2\n15: 1 batches\n12 Start Epoch 2\n12: 1 batches\n13: 1 batches\n14 Start Epoch 2\n14: 1 batches\n5 Start Epoch 2\n5: 1 batches\n2 Start Epoch 2\n2: 1 batches\n4 Start Epoch 2\n10 Start Epoch 2\n4: 1 batches\n9 Start Epoch 2\n10: 1 batches\n9: 1 batches\n18 Start Epoch 2\n19 Start Epoch 2\n19: 1 batches\n16 Start Epoch 2\n16: 1 batches\n18: 1 batches\n17 Start Epoch 2\n17: 1 batches\n0 Start Epoch 2\n0: 1 batches\n1 Start Epoch 3\n1: 1 batches\n19 Start Epoch 3\n8 Start Epoch 3\n19: 1 batches\n8: 1 batches\n3 Start Epoch 3\n3: 1 batches\n9 Start Epoch 3\n9: 1 batches\n2 Start Epoch 3\n2: 1 batches\n14 Start Epoch 3\n14: 1 batches\n15 Start Epoch 3\n15: 1 batches\n6 Start Epoch 3\n5 Start Epoch 3\n6: 1 batches\n5: 1 batches\n7 Start Epoch 3\n4 Start Epoch 3\n4: 1 batches\n7: 1 batches\n18 Start Epoch 3\n16 Start Epoch 3\n16: 1 batches\n17 Start Epoch 3\n17: 1 batches\n18: 1 batches\n10 Start Epoch 3\n10: 1 batches\n11 Start Epoch 3\n11: 1 batches\n13 Start Epoch 3\n12 Start Epoch 3\n12: 1 batches\n13: 1 batches\n0 Start Epoch 3\n0: 1 batches\n11 Start Epoch 4\n11: 1 batches\n10 Start Epoch 4\n10: 1 batches\n12 Start Epoch 4\n12: 1 batches\n9 Start Epoch 4\n9: 1 batches\n3 Start Epoch 4\n3: 1 batches\n14 Start Epoch 4\n14: 1 batches\n7 Start Epoch 4\n4 Start Epoch 4\n6 Start Epoch 4\n6: 1 batches\n7: 1 batches\n5 Start Epoch 4\n4: 1 batches\n5: 1 batches\n2 Start Epoch 4\n2: 1 batches\n16 Start Epoch 4\n17 Start Epoch 4\n17: 1 batches\n16: 1 batches\n15 Start Epoch 4\n13 Start Epoch 4\n15: 1 batches\n13: 1 batches\n19 Start Epoch 4\n1 Start Epoch 4\n1: 1 batches\n18 Start Epoch 4\n19: 1 batches\n18: 1 batches\n8 Start Epoch 4\n8: 1 batches\n0 Start Epoch 4\n0: 1 batches\n5 Start Epoch 5\n4 Start Epoch 5\n18 Start Epoch 5\n2 Start Epoch 5\n2: 1 batches\n3 Start Epoch 5\n3: 1 batches\n4: 1 batches\n11 Start Epoch 5\n14 Start Epoch 5\n10 Start Epoch 5\n19 Start Epoch 5\n11: 1 batches\n19: 1 batches\n12 Start Epoch 5\n12: 1 batches\n18: 1 batches\n14: 1 batches\n10: 1 batches\n13 Start Epoch 5\n8 Start Epoch 5\n13: 1 batches\n8: 1 batches\n17 Start Epoch 5\n7 Start Epoch 5\n17: 1 batches\n15 Start Epoch 5\n15: 1 batches\n16 Start Epoch 5\n16: 1 batches\n6 Start Epoch 5\n6: 1 batches\n9 Start Epoch 5\n9: 1 batches\n5: 1 batches\n7: 1 batches\n1 Start Epoch 5\n1: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:15: Epoch 0 train loss: 207451.765625\nINFO:root:8: Epoch 0 train loss: 2552.066162109375\nINFO:root:7: Epoch 0 train loss: 8615.9375\nINFO:root:5: Epoch 0 train loss: 1284.8907470703125\nINFO:root:9: Epoch 0 train loss: 262017.1875\nINFO:root:6: Epoch 0 train loss: 181.16529846191406\nINFO:root:10: Epoch 0 train loss: 2589.68212890625\nINFO:root:18: Epoch 0 train loss: 215622.171875\nINFO:root:19: Epoch 0 train loss: 8424.056640625\nINFO:root:0: Epoch 0 train loss: 2095.091064453125\nINFO:root:2: Epoch 0 train loss: 186522.09375\nINFO:root:1: Epoch 0 train loss: 5461.86865234375\nINFO:root:3: Epoch 0 train loss: 209867.15625\nINFO:root:12: Epoch 0 train loss: 431241.21875\nINFO:root:13: Epoch 0 train loss: 341.2975158691406\nINFO:root:11: Epoch 0 train loss: 807.4639892578125\nINFO:root:14: Epoch 0 train loss: 26005.505859375\nINFO:root:17: Epoch 0 train loss: 2063.4462890625\nINFO:root:16: Epoch 0 train loss: 281.5057067871094\nINFO:root:4: Epoch 0 train loss: 2474.7373046875\nINFO:root:0: Epoch 0 validation loss: 218856.72853087974\nINFO:root:8: Epoch 1 train loss: 77715.4296875\nINFO:root:7: Epoch 1 train loss: 1086.8480224609375\nINFO:root:1: Epoch 1 train loss: 260981.90625\nINFO:root:11: Epoch 1 train loss: 525.054931640625\nINFO:root:6: Epoch 1 train loss: 240560.296875\nINFO:root:15: Epoch 1 train loss: 456825.9375\nINFO:root:12: Epoch 1 train loss: 10206.771484375\nINFO:root:2: Epoch 1 train loss: 4274.6767578125\nINFO:root:13: Epoch 1 train loss: 74284.40625\nINFO:root:3: Epoch 1 train loss: 176179.109375\nINFO:root:14: Epoch 1 train loss: 1258.2413330078125\nINFO:root:5: Epoch 1 train loss: 216186.921875\nINFO:root:0: Epoch 1 train loss: 5173.84814453125\nINFO:root:4: Epoch 1 train loss: 3900.294921875\nINFO:root:10: Epoch 1 train loss: 210237.265625\nINFO:root:9: Epoch 1 train loss: 4412.994140625\nINFO:root:18: Epoch 1 train loss: 617.4506225585938\nINFO:root:19: Epoch 1 train loss: 912.3212890625\nINFO:root:16: Epoch 1 train loss: 176967.46875\nINFO:root:17: Epoch 1 train loss: 2352.787353515625\nINFO:root:0: Epoch 1 validation loss: 218850.405696808\nINFO:root:1: Epoch 2 train loss: 2778.805908203125\nINFO:root:2: Epoch 2 train loss: 4020.174560546875\nINFO:root:8: Epoch 2 train loss: 207438.515625\nINFO:root:19: Epoch 2 train loss: 3891.46142578125\nINFO:root:9: Epoch 2 train loss: 5417.74365234375\nINFO:root:3: Epoch 2 train loss: 2365.876953125\nINFO:root:14: Epoch 2 train loss: 498682.3125\nINFO:root:0: Epoch 2 train loss: 217298.796875\nINFO:root:15: Epoch 2 train loss: 2005.6524658203125\nINFO:root:6: Epoch 2 train loss: 210455.5\nINFO:root:5: Epoch 2 train loss: 138.1944580078125\nINFO:root:7: Epoch 2 train loss: 192153.234375\nINFO:root:4: Epoch 2 train loss: 179957.984375\nINFO:root:18: Epoch 2 train loss: 3488.99853515625\nINFO:root:16: Epoch 2 train loss: 187219.46875\nINFO:root:17: Epoch 2 train loss: 657.4434814453125\nINFO:root:10: Epoch 2 train loss: 583.8515014648438\nINFO:root:11: Epoch 2 train loss: 1177.1629638671875\nINFO:root:13: Epoch 2 train loss: 210416.125\nINFO:root:12: Epoch 2 train loss: 1575.83251953125\nINFO:root:0: Epoch 2 validation loss: 218844.16988038842\nINFO:root:10: Epoch 3 train loss: 24464.029296875\nINFO:root:11: Epoch 3 train loss: 233230.65625\nINFO:root:12: Epoch 3 train loss: 6304.4326171875\nINFO:root:9: Epoch 3 train loss: 199457.09375\nINFO:root:3: Epoch 3 train loss: 568742.3125\nINFO:root:14: Epoch 3 train loss: 1857.0614013671875\nINFO:root:4: Epoch 3 train loss: 225525.53125\nINFO:root:5: Epoch 3 train loss: 928.890625\nINFO:root:6: Epoch 3 train loss: 9322.0283203125\nINFO:root:7: Epoch 3 train loss: 2948.26171875\nINFO:root:17: Epoch 3 train loss: 727.946533203125\nINFO:root:16: Epoch 3 train loss: 784.469970703125\nINFO:root:2: Epoch 3 train loss: 2110.644287109375\nINFO:root:8: Epoch 3 train loss: 2619.531005859375\nINFO:root:13: Epoch 3 train loss: 437745.15625\nINFO:root:15: Epoch 3 train loss: 214363.765625\nINFO:root:19: Epoch 3 train loss: 75678.34375\nINFO:root:18: Epoch 3 train loss: 1815.7056884765625\nINFO:root:0: Epoch 3 train loss: 2693.359375\nINFO:root:1: Epoch 3 train loss: 3720.37744140625\nINFO:root:0: Epoch 3 validation loss: 218837.8308425072\nINFO:root:4: Epoch 4 train loss: 236341.28125\nINFO:root:5: Epoch 4 train loss: 1133.7830810546875\nINFO:root:11: Epoch 4 train loss: 234969.203125\nINFO:root:14: Epoch 4 train loss: 7859.43115234375\nINFO:root:8: Epoch 4 train loss: 2479.951416015625\nINFO:root:12: Epoch 4 train loss: 2699.6748046875\nINFO:root:10: Epoch 4 train loss: 176090.40625\nINFO:root:0: Epoch 4 train loss: 6274.08154296875\nINFO:root:3: Epoch 4 train loss: 186706.53125\nINFO:root:2: Epoch 4 train loss: 24673.263671875\nINFO:root:18: Epoch 4 train loss: 2555.050537109375\nINFO:root:19: Epoch 4 train loss: 6408.185546875\nINFO:root:13: Epoch 4 train loss: 215366.484375\nINFO:root:6: Epoch 4 train loss: 523.9517822265625\nINFO:root:7: Epoch 4 train loss: 207793.0\nINFO:root:17: Epoch 4 train loss: 532.7717895507812\nINFO:root:15: Epoch 4 train loss: 195.4373779296875\nINFO:root:16: Epoch 4 train loss: 261646.53125\nINFO:root:9: Epoch 4 train loss: 1530.4644775390625\nINFO:root:1: Epoch 4 train loss: 1383.9139404296875\nINFO:root:0: Epoch 4 validation loss: 218831.53043818337\nINFO:root:6: Epoch 5 train loss: 305574.34375\nINFO:root:7: Epoch 5 train loss: 216432.40625\nINFO:root:17: Epoch 5 train loss: 4921.2705078125\nINFO:root:9: Epoch 5 train loss: 2178.11083984375\nINFO:root:18: Epoch 5 train loss: 261098.953125\nINFO:root:14: Epoch 5 train loss: 235203.171875\nINFO:root:12: Epoch 5 train loss: 175177.0625\nINFO:root:11: Epoch 5 train loss: 185915.953125\nINFO:root:19: Epoch 5 train loss: 234101.09375\nINFO:root:15: Epoch 5 train loss: 908.8558349609375\nINFO:root:8: Epoch 5 train loss: 199446.390625\nINFO:root:16: Epoch 5 train loss: 259708.890625\nINFO:root:13: Epoch 5 train loss: 2938.447265625\nINFO:root:10: Epoch 5 train loss: 3054.2568359375\nINFO:root:3: Epoch 5 train loss: 334561.71875\nINFO:root:2: Epoch 5 train loss: 223674.765625\nINFO:root:0: Epoch 5 train loss: 481538.0\nINFO:root:1: Epoch 5 train loss: 241503.8125\nINFO:root:5: Epoch 5 train loss: 2924.77880859375\nINFO:root:4: Epoch 5 train loss: 3051.274658203125\nINFO:root:0: Epoch 5 validation loss: 218825.23965610695\n", "seconds": 21.991819143295288, "batch_size": 256, "nodes": 5, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n2 Start Epoch 0\n1: 1 batches\n2: 1 batches\n23 Start Epoch 0\n23: 1 batches\n3 Start Epoch 0\n3: 1 batches\n8 Start Epoch 0\n20 Start Epoch 0\n8: 1 batches\n20: 1 batches\n4 Start Epoch 0\n12 Start Epoch 0\n11 Start Epoch 0\n7 Start Epoch 0\n4: 1 batches\n12: 1 batches\n16 Start Epoch 0\n11: 1 batches\n19 Start Epoch 0\n7: 1 batches\n15 Start Epoch 0\n15: 1 batches\n19: 1 batches\n16: 1 batches\n17 Start Epoch 0\n9 Start Epoch 0\n5 Start Epoch 0\n13 Start Epoch 0\n9: 1 batches\n6 Start Epoch 0\n14 Start Epoch 0\n18 Start Epoch 0\n21 Start Epoch 0\n5: 1 batches\n13: 1 batches\n18: 1 batches\n22 Start Epoch 0\n10 Start Epoch 0\n17: 1 batches\n21: 1 batches\n10: 1 batches\n6: 1 batches\n14: 1 batches\n22: 1 batches\n9 Start Epoch 1\n8 Start Epoch 1\n9: 1 batches\n8: 1 batches\n6 Start Epoch 1\n7 Start Epoch 1\n15 Start Epoch 1\n1 Start Epoch 1\n2 Start Epoch 1\n1: 1 batches\n2: 1 batches\n14 Start Epoch 1\n7: 1 batches\n6: 1 batches\n14: 1 batches\n3 Start Epoch 1\n3: 1 batches\n15: 1 batches\n16 Start Epoch 1\n18 Start Epoch 1\n22 Start Epoch 1\n4 Start Epoch 1\n4: 1 batches\n18: 1 batches\n20 Start Epoch 1\n19 Start Epoch 1\n21 Start Epoch 1\n21: 1 batches\n19: 1 batches\n20: 1 batches\n5 Start Epoch 1\n16: 1 batches\n23 Start Epoch 1\n5: 1 batches\n23: 1 batches\n17 Start Epoch 1\n22: 1 batches\n17: 1 batches\n12 Start Epoch 1\n13 Start Epoch 1\n12: 1 batches\n13: 1 batches\n10 Start Epoch 1\n11 Start Epoch 1\n10: 1 batches\n11: 1 batches\n0 Start Epoch 1\n0: 1 batches\n1 Start Epoch 2\n1: 1 batches\n19 Start Epoch 2\n19: 1 batches\n22 Start Epoch 2\n21 Start Epoch 2\n20 Start Epoch 2\n22: 1 batches\n21: 1 batches\n23 Start Epoch 2\n23: 1 batches\n2 Start Epoch 2\n3 Start Epoch 2\n3: 1 batches\n14 Start Epoch 2\n14: 1 batches\n16 Start Epoch 2\n12 Start Epoch 2\n18 Start Epoch 2\n18: 1 batches\n20: 1 batches\n12: 1 batches\n13 Start Epoch 2\n11 Start Epoch 2\n11: 1 batches\n10 Start Epoch 2\n10: 1 batches\n15 Start Epoch 2\n13: 1 batches\n9 Start Epoch 2\n8 Start Epoch 2\n9: 1 batches\n8: 1 batches\n17 Start Epoch 2\n17: 1 batches\n16: 1 batches\n15: 1 batches\n2: 1 batches\n5 Start Epoch 2\n5: 1 batches\n6 Start Epoch 2\n6: 1 batches\n4 Start Epoch 2\n4: 1 batches\n7 Start Epoch 2\n7: 1 batches\n0 Start Epoch 2\n0: 1 batches\n3 Start Epoch 3\n3: 1 batches\n23 Start Epoch 3\n23: 1 batches\n22 Start Epoch 3\n22: 1 batches\n19 Start Epoch 3\n19: 1 batches\n1 Start Epoch 3\n1: 1 batches\n2 Start Epoch 3\n2: 1 batches\n15 Start Epoch 3\n8 Start Epoch 3\n5 Start Epoch 3\n8: 1 batches\n4 Start Epoch 3\n15: 1 batches\n21 Start Epoch 3\n21: 1 batches\n14 Start Epoch 3\n14: 1 batches\n16 Start Epoch 3\n18 Start Epoch 3\n13 Start Epoch 3\n13: 1 batches\n16: 1 batches\n17 Start Epoch 3\n7 Start Epoch 3\n7: 1 batches\n18: 1 batches\n4: 1 batches\n6 Start Epoch 3\n6: 1 batches\n5: 1 batches\n17: 1 batches\n9 Start Epoch 3\n20 Start Epoch 3\n10 Start Epoch 3\n10: 1 batches\n12 Start Epoch 3\n12: 1 batches\n20: 1 batches\n9: 1 batches\n11 Start Epoch 3\n11: 1 batches\n0 Start Epoch 3\n0: 1 batches\n23 Start Epoch 4\n22 Start Epoch 4\n23: 1 batches\n22: 1 batches\n19 Start Epoch 4\n19: 1 batches\n20 Start Epoch 4\n20: 1 batches\n21 Start Epoch 4\n21: 1 batches\n18 Start Epoch 4\n18: 1 batches\n1 Start Epoch 4\n1: 1 batches\n17 Start Epoch 4\n17: 1 batches\n12 Start Epoch 4\n15 Start Epoch 4\n15: 1 batches\n12: 1 batches\n4 Start Epoch 4\n4: 1 batches\n7 Start Epoch 4\n7: 1 batches\n2 Start Epoch 4\n2: 1 batches\n5 Start Epoch 4\n5: 1 batches\n13 Start Epoch 4\n10 Start Epoch 4\n13: 1 batches\n14 Start Epoch 4\n9 Start Epoch 4\n6 Start Epoch 4\n9: 1 batches\n6: 1 batches\n14: 1 batches\n10: 1 batches\n11 Start Epoch 4\n11: 1 batches\n3 Start Epoch 4\n3: 1 batches\n8 Start Epoch 4\n8: 1 batches\n16 Start Epoch 4\n16: 1 batches\n0 Start Epoch 4\n0: 1 batches\n23 Start Epoch 5\n23: 1 batches\n1 Start Epoch 5\n1: 1 batches\n22 Start Epoch 5\n22: 1 batches\n3 Start Epoch 5\n3: 1 batches\n2 Start Epoch 5\n2: 1 batches\n13 Start Epoch 5\n13: 1 batches\n7 Start Epoch 5\n12 Start Epoch 5\n6 Start Epoch 5\n5 Start Epoch 5\n10 Start Epoch 5\n7: 1 batches\n11 Start Epoch 5\n6: 1 batches\n9 Start Epoch 5\n9: 1 batches\n5: 1 batches\n11: 1 batches\n10: 1 batches\n8 Start Epoch 5\n12: 1 batches\n8: 1 batches\n14 Start Epoch 5\n14: 1 batches\n20 Start Epoch 5\n4 Start Epoch 5\n4: 1 batches\n21 Start Epoch 5\n20: 1 batches\n21: 1 batches\n19 Start Epoch 5\n16 Start Epoch 5\n19: 1 batches\n16: 1 batches\n17 Start Epoch 5\n17: 1 batches\n18 Start Epoch 5\n18: 1 batches\n15 Start Epoch 5\n15: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:9: Epoch 0 train loss: 267390.9375\nINFO:root:8: Epoch 0 train loss: 742.0592041015625\nINFO:root:7: Epoch 0 train loss: 6693.6884765625\nINFO:root:6: Epoch 0 train loss: 915.4237670898438\nINFO:root:15: Epoch 0 train loss: 272321.25\nINFO:root:14: Epoch 0 train loss: 29103.14453125\nINFO:root:1: Epoch 0 train loss: 277.36114501953125\nINFO:root:2: Epoch 0 train loss: 7839.8251953125\nINFO:root:16: Epoch 0 train loss: 761.5043334960938\nINFO:root:20: Epoch 0 train loss: 96531.3515625\nINFO:root:19: Epoch 0 train loss: 1704.1121826171875\nINFO:root:22: Epoch 0 train loss: 209868.984375\nINFO:root:3: Epoch 0 train loss: 2121.928955078125\nINFO:root:18: Epoch 0 train loss: 90332.6484375\nINFO:root:21: Epoch 0 train loss: 2509.30712890625\nINFO:root:4: Epoch 0 train loss: 1793.911865234375\nINFO:root:23: Epoch 0 train loss: 1839.4027099609375\nINFO:root:5: Epoch 0 train loss: 367.38226318359375\nINFO:root:17: Epoch 0 train loss: 30815.78515625\nINFO:root:12: Epoch 0 train loss: 398.1459045410156\nINFO:root:13: Epoch 0 train loss: 1655.0823974609375\nINFO:root:10: Epoch 0 train loss: 29581.51953125\nINFO:root:11: Epoch 0 train loss: 1053.9766845703125\nINFO:root:0: Epoch 0 train loss: 408.85003662109375\nINFO:root:0: Epoch 0 validation loss: 159559.81117339703\nINFO:root:1: Epoch 1 train loss: 267634.125\nINFO:root:0: Epoch 1 train loss: 7161.10400390625\nINFO:root:19: Epoch 1 train loss: 2954.154541015625\nINFO:root:22: Epoch 1 train loss: 15177.6396484375\nINFO:root:21: Epoch 1 train loss: 7664.3701171875\nINFO:root:23: Epoch 1 train loss: 2323.4189453125\nINFO:root:20: Epoch 1 train loss: 8825.349609375\nINFO:root:2: Epoch 1 train loss: 458534.96875\nINFO:root:3: Epoch 1 train loss: 373.589111328125\nINFO:root:14: Epoch 1 train loss: 248531.140625\nINFO:root:17: Epoch 1 train loss: 6146.37646484375\nINFO:root:16: Epoch 1 train loss: 262114.65625\nINFO:root:18: Epoch 1 train loss: 222467.375\nINFO:root:12: Epoch 1 train loss: 515897.8125\nINFO:root:10: Epoch 1 train loss: 1336.65234375\nINFO:root:13: Epoch 1 train loss: 1876.9271240234375\nINFO:root:11: Epoch 1 train loss: 310807.625\nINFO:root:15: Epoch 1 train loss: 257011.328125\nINFO:root:9: Epoch 1 train loss: 254207.265625\nINFO:root:8: Epoch 1 train loss: 1629.8692626953125\nINFO:root:7: Epoch 1 train loss: 978.590576171875\nINFO:root:4: Epoch 1 train loss: 30705.26953125\nINFO:root:6: Epoch 1 train loss: 259418.65625\nINFO:root:5: Epoch 1 train loss: 5151.443359375\nINFO:root:0: Epoch 1 validation loss: 159553.93228737163\nINFO:root:3: Epoch 2 train loss: 251452.9375\nINFO:root:23: Epoch 2 train loss: 310616.6875\nINFO:root:22: Epoch 2 train loss: 611.3104858398438\nINFO:root:19: Epoch 2 train loss: 921.16015625\nINFO:root:8: Epoch 2 train loss: 286251.9375\nINFO:root:5: Epoch 2 train loss: 3329.91943359375\nINFO:root:2: Epoch 2 train loss: 4399.35400390625\nINFO:root:1: Epoch 2 train loss: 2318.428955078125\nINFO:root:15: Epoch 2 train loss: 311530.46875\nINFO:root:6: Epoch 2 train loss: 29092.580078125\nINFO:root:4: Epoch 2 train loss: 2623.1650390625\nINFO:root:0: Epoch 2 train loss: 3081.07373046875\nINFO:root:21: Epoch 2 train loss: 216.96566772460938\nINFO:root:17: Epoch 2 train loss: 1885.554443359375\nINFO:root:16: Epoch 2 train loss: 2573.37255859375\nINFO:root:14: Epoch 2 train loss: 50.09873580932617\nINFO:root:18: Epoch 2 train loss: 285506.5625\nINFO:root:13: Epoch 2 train loss: 4549.177734375\nINFO:root:7: Epoch 2 train loss: 2098.296630859375\nINFO:root:9: Epoch 2 train loss: 280939.6875\nINFO:root:12: Epoch 2 train loss: 266750.9375\nINFO:root:20: Epoch 2 train loss: 2084.80224609375\nINFO:root:10: Epoch 2 train loss: 228.3088836669922\nINFO:root:11: Epoch 2 train loss: 1692.4478759765625\nINFO:root:0: Epoch 2 validation loss: 159548.0670183369\nINFO:root:23: Epoch 3 train loss: 9066.21875\nINFO:root:22: Epoch 3 train loss: 5793.25830078125\nINFO:root:19: Epoch 3 train loss: 91.05776977539062\nINFO:root:21: Epoch 3 train loss: 1163.539794921875\nINFO:root:20: Epoch 3 train loss: 400559.0625\nINFO:root:18: Epoch 3 train loss: 223615.5\nINFO:root:0: Epoch 3 train loss: 424.3094177246094\nINFO:root:1: Epoch 3 train loss: 1729.419189453125\nINFO:root:17: Epoch 3 train loss: 453.67572021484375\nINFO:root:12: Epoch 3 train loss: 280910.375\nINFO:root:15: Epoch 3 train loss: 1446.624267578125\nINFO:root:7: Epoch 3 train loss: 2437.720947265625\nINFO:root:4: Epoch 3 train loss: 1516.6378173828125\nINFO:root:5: Epoch 3 train loss: 992.2968139648438\nINFO:root:2: Epoch 3 train loss: 2211.5048828125\nINFO:root:14: Epoch 3 train loss: 88460.109375\nINFO:root:10: Epoch 3 train loss: 98141.53125\nINFO:root:9: Epoch 3 train loss: 3179.683837890625\nINFO:root:13: Epoch 3 train loss: 1831.94873046875\nINFO:root:11: Epoch 3 train loss: 5163.61474609375\nINFO:root:6: Epoch 3 train loss: 295420.9375\nINFO:root:3: Epoch 3 train loss: 463.6368713378906\nINFO:root:8: Epoch 3 train loss: 2196.562744140625\nINFO:root:16: Epoch 3 train loss: 466288.625\nINFO:root:0: Epoch 3 validation loss: 159542.05667841487\nINFO:root:23: Epoch 4 train loss: 1145.2969970703125\nINFO:root:1: Epoch 4 train loss: 6192.79443359375\nINFO:root:0: Epoch 4 train loss: 7557.96484375\nINFO:root:22: Epoch 4 train loss: 4830.99462890625\nINFO:root:2: Epoch 4 train loss: 311112.09375\nINFO:root:3: Epoch 4 train loss: 33469.3046875\nINFO:root:5: Epoch 4 train loss: 2256.965087890625\nINFO:root:12: Epoch 4 train loss: 2072.9912109375\nINFO:root:6: Epoch 4 train loss: 10169.1669921875\nINFO:root:13: Epoch 4 train loss: 1254.9697265625\nINFO:root:7: Epoch 4 train loss: 438.80963134765625\nINFO:root:11: Epoch 4 train loss: 559.0057983398438\nINFO:root:9: Epoch 4 train loss: 223769.46875\nINFO:root:4: Epoch 4 train loss: 222931.359375\nINFO:root:10: Epoch 4 train loss: 2310.02587890625\nINFO:root:8: Epoch 4 train loss: 30079.29296875\nINFO:root:14: Epoch 4 train loss: 211270.96875\nINFO:root:21: Epoch 4 train loss: 2156.309326171875\nINFO:root:20: Epoch 4 train loss: 763.4159545898438\nINFO:root:16: Epoch 4 train loss: 314366.59375\nINFO:root:19: Epoch 4 train loss: 4779.34326171875\nINFO:root:17: Epoch 4 train loss: 3944.353759765625\nINFO:root:18: Epoch 4 train loss: 4775.91650390625\nINFO:root:15: Epoch 4 train loss: 3142.5439453125\nINFO:root:0: Epoch 4 validation loss: 159535.95260097316\nINFO:root:23: Epoch 5 train loss: 5123.2509765625\nINFO:root:3: Epoch 5 train loss: 309760.78125\nINFO:root:0: Epoch 5 train loss: 91299.75\nINFO:root:7: Epoch 5 train loss: 281567.40625\nINFO:root:15: Epoch 5 train loss: 3985.8515625\nINFO:root:11: Epoch 5 train loss: 222437.921875\nINFO:root:13: Epoch 5 train loss: 2283.23193359375\nINFO:root:9: Epoch 5 train loss: 260613.0625\nINFO:root:10: Epoch 5 train loss: 257577.984375\nINFO:root:12: Epoch 5 train loss: 1936.0045166015625\nINFO:root:4: Epoch 5 train loss: 2367.21142578125\nINFO:root:5: Epoch 5 train loss: 1593.3026123046875\nINFO:root:6: Epoch 5 train loss: 471.84100341796875\nINFO:root:16: Epoch 5 train loss: 1442.7144775390625\nINFO:root:17: Epoch 5 train loss: 4058.818359375\nINFO:root:1: Epoch 5 train loss: 569284.4375\nINFO:root:2: Epoch 5 train loss: 5509.16552734375\nINFO:root:21: Epoch 5 train loss: 267426.03125\nINFO:root:20: Epoch 5 train loss: 3373.01123046875\nINFO:root:22: Epoch 5 train loss: 1072.8575439453125\nINFO:root:14: Epoch 5 train loss: 5730.27099609375\nINFO:root:8: Epoch 5 train loss: 4396.9775390625\nINFO:root:19: Epoch 5 train loss: 4472.53515625\nINFO:root:18: Epoch 5 train loss: 282.22039794921875\nINFO:root:0: Epoch 5 validation loss: 159529.70702973034\n", "seconds": 22.263003826141357, "batch_size": 256, "nodes": 6, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n27 Start Epoch 0\n2 Start Epoch 0\n2: 1 batches\n27: 1 batches\n1 Start Epoch 0\n1: 1 batches\n3 Start Epoch 0\n3: 1 batches\n4 Start Epoch 0\n4: 1 batches\n8 Start Epoch 0\n16 Start Epoch 0\n16: 1 batches\n23 Start Epoch 0\n24 Start Epoch 0\n7 Start Epoch 0\n12 Start Epoch 0\n7: 1 batches\n8: 1 batches\n15 Start Epoch 0\n24: 1 batches\n23: 1 batches\n11 Start Epoch 0\n15: 1 batches\n12: 1 batches\n20 Start Epoch 0\n20: 1 batches\n11: 1 batches\n19 Start Epoch 0\n19: 1 batches\n5 Start Epoch 0\n6 Start Epoch 0\n21 Start Epoch 0\n6: 1 batches\n22 Start Epoch 0\n21: 1 batches\n5: 1 batches\n22: 1 batches\n13 Start Epoch 0\n14 Start Epoch 0\n13: 1 batches\n14: 1 batches\n9 Start Epoch 0\n10 Start Epoch 0\n17 Start Epoch 0\n10: 1 batches\n18 Start Epoch 0\n9: 1 batches\n17: 1 batches\n18: 1 batches\n25 Start Epoch 0\n25: 1 batches\n26 Start Epoch 0\n26: 1 batches\n7 Start Epoch 1\n7: 1 batches\n10 Start Epoch 1\n10: 1 batches\n14 Start Epoch 1\n11 Start Epoch 1\n13 Start Epoch 1\n11: 1 batches\n13: 1 batches\n14: 1 batches\n15 Start Epoch 1\n15: 1 batches\n12 Start Epoch 1\n12: 1 batches\n8 Start Epoch 1\n8: 1 batches\n9 Start Epoch 1\n22 Start Epoch 1\n9: 1 batches\n17 Start Epoch 1\n17: 1 batches\n22: 1 batches\n23 Start Epoch 1\n23: 1 batches\n16 Start Epoch 1\n16: 1 batches\n26 Start Epoch 1\n26: 1 batches\n27 Start Epoch 1\n27: 1 batches\n18 Start Epoch 1\n18: 1 batches\n19 Start Epoch 1\n19: 1 batches\n20 Start Epoch 1\n1 Start Epoch 1\n21 Start Epoch 1\n21: 1 batches\n20: 1 batches\n24 Start Epoch 1\n25 Start Epoch 1\n25: 1 batches\n24: 1 batches\n6 Start Epoch 1\n6: 1 batches\n5 Start Epoch 1\n5: 1 batches\n1: 1 batches\n2 Start Epoch 1\n2: 1 batches\n3 Start Epoch 1\n3: 1 batches\n4 Start Epoch 1\n4: 1 batches\n0 Start Epoch 1\n0: 1 batches\n11 Start Epoch 2\n11: 1 batches\n12 Start Epoch 2\n13 Start Epoch 2\n14 Start Epoch 2\n13: 1 batches\n14: 1 batches\n15 Start Epoch 2\n12: 1 batches\n15: 1 batches\n16 Start Epoch 2\n16: 1 batches\n23 Start Epoch 2\n24 Start Epoch 2\n27 Start Epoch 2\n25 Start Epoch 2\n27: 1 batches\n23: 1 batches\n25: 1 batches\n6 Start Epoch 2\n4 Start Epoch 2\n26 Start Epoch 2\n7 Start Epoch 2\n20 Start Epoch 2\n26: 1 batches\n20: 1 batches\n10 Start Epoch 2\n9 Start Epoch 2\n10: 1 batches\n9: 1 batches\n24: 1 batches\n21 Start Epoch 2\n19 Start Epoch 2\n22 Start Epoch 2\n18 Start Epoch 2\n18: 1 batches\n22: 1 batches\n21: 1 batches\n17 Start Epoch 2\n17: 1 batches\n19: 1 batches\n2 Start Epoch 2\n3 Start Epoch 2\n2: 1 batches\n3: 1 batches\n8 Start Epoch 2\n8: 1 batches\n1 Start Epoch 2\n1: 1 batches\n7: 1 batches\n6: 1 batches\n5 Start Epoch 2\n5: 1 batches\n4: 1 batches\n0 Start Epoch 2\n0: 1 batches\n26 Start Epoch 3\n27 Start Epoch 3\n27: 1 batches\n26: 1 batches\n25 Start Epoch 3\n25: 1 batches\n23 Start Epoch 3\n23: 1 batches\n24 Start Epoch 3\n24: 1 batches\n22 Start Epoch 3\n22: 1 batches\n14 Start Epoch 3\n14: 1 batches\n7 Start Epoch 3\n15 Start Epoch 3\n4 Start Epoch 3\n15: 1 batches\n6 Start Epoch 3\n7: 1 batches\n6: 1 batches\n5 Start Epoch 3\n5: 1 batches\n17 Start Epoch 3\n18 Start Epoch 3\n19 Start Epoch 3\n17: 1 batches\n18: 1 batches\n19: 1 batches\n10 Start Epoch 3\n11 Start Epoch 3\n10: 1 batches\n11: 1 batches\n8 Start Epoch 3\n8: 1 batches\n16 Start Epoch 3\n16: 1 batches\n2 Start Epoch 3\n2: 1 batches\n9 Start Epoch 3\n21 Start Epoch 3\n21: 1 batches\n20 Start Epoch 3\n20: 1 batches\n1 Start Epoch 3\n3 Start Epoch 3\n3: 1 batches\n1: 1 batches\n9: 1 batches\n13 Start Epoch 3\n13: 1 batches\n12 Start Epoch 3\n12: 1 batches\n4: 1 batches\n0 Start Epoch 3\n0: 1 batches\n26 Start Epoch 4\n27 Start Epoch 4\n25 Start Epoch 4\n27: 1 batches\n25: 1 batches\n24 Start Epoch 4\n24: 1 batches\n26: 1 batches\n22 Start Epoch 4\n22: 1 batches\n21 Start Epoch 4\n21: 1 batches\n20 Start Epoch 4\n20: 1 batches\n23 Start Epoch 4\n23: 1 batches\n6 Start Epoch 4\n7 Start Epoch 4\n7: 1 batches\n12 Start Epoch 4\n13 Start Epoch 4\n5 Start Epoch 4\n5: 1 batches\n14 Start Epoch 4\n12: 1 batches\n13: 1 batches\n14: 1 batches\n15 Start Epoch 4\n15: 1 batches\n2 Start Epoch 4\n2: 1 batches\n3 Start Epoch 4\n3: 1 batches\n9 Start Epoch 4\n9: 1 batches\n8 Start Epoch 4\n8: 1 batches\n18 Start Epoch 4\n17 Start Epoch 4\n17: 1 batches\n18: 1 batches\n11 Start Epoch 4\n11: 1 batches\n10 Start Epoch 4\n10: 1 batches\n19 Start Epoch 4\n6: 1 batches\n19: 1 batches\n16 Start Epoch 4\n16: 1 batches\n4 Start Epoch 4\n4: 1 batches\n1 Start Epoch 4\n1: 1 batches\n0 Start Epoch 4\n0: 1 batches\n25 Start Epoch 5\n25: 1 batches\n24 Start Epoch 5\n24: 1 batches\n22 Start Epoch 5\n22: 1 batches\n23 Start Epoch 5\n23: 1 batches\n7 Start Epoch 5\n15 Start Epoch 5\n26 Start Epoch 5\n7: 1 batches\n8 Start Epoch 5\n15: 1 batches\n27 Start Epoch 5\n8: 1 batches\n27: 1 batches\n6 Start Epoch 5\n11 Start Epoch 5\n18 Start Epoch 5\n26: 1 batches\n11: 1 batches\n18: 1 batches\n10 Start Epoch 5\n16 Start Epoch 5\n19 Start Epoch 5\n9 Start Epoch 5\n10: 1 batches\n19: 1 batches\n9: 1 batches\n2 Start Epoch 5\n2: 1 batches\n16: 1 batches\n4 Start Epoch 5\n6: 1 batches\n14 Start Epoch 5\n20 Start Epoch 5\n20: 1 batches\n14: 1 batches\n17 Start Epoch 5\n21 Start Epoch 5\n21: 1 batches\n17: 1 batches\n5 Start Epoch 5\n5: 1 batches\n4: 1 batches\n13 Start Epoch 5\n13: 1 batches\n12 Start Epoch 5\n12: 1 batches\n3 Start Epoch 5\n3: 1 batches\n1 Start Epoch 5\n1: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:7: Epoch 0 train loss: 1271.6427001953125\nINFO:root:11: Epoch 0 train loss: 303144.0625\nINFO:root:14: Epoch 0 train loss: 10288.1357421875\nINFO:root:10: Epoch 0 train loss: 5824.9208984375\nINFO:root:13: Epoch 0 train loss: 362313.84375\nINFO:root:15: Epoch 0 train loss: 6975.02294921875\nINFO:root:12: Epoch 0 train loss: 1320.1048583984375\nINFO:root:8: Epoch 0 train loss: 105698.1796875\nINFO:root:22: Epoch 0 train loss: 323.68963623046875\nINFO:root:9: Epoch 0 train loss: 5971.705078125\nINFO:root:23: Epoch 0 train loss: 1215.5655517578125\nINFO:root:17: Epoch 0 train loss: 10285.3798828125\nINFO:root:16: Epoch 0 train loss: 1495.3985595703125\nINFO:root:26: Epoch 0 train loss: 34514.43359375\nINFO:root:0: Epoch 0 train loss: 4447.63427734375\nINFO:root:27: Epoch 0 train loss: 103757.7265625\nINFO:root:18: Epoch 0 train loss: 102471.9140625\nINFO:root:19: Epoch 0 train loss: 1808.879150390625\nINFO:root:20: Epoch 0 train loss: 2968.259521484375\nINFO:root:21: Epoch 0 train loss: 4094.552734375\nINFO:root:1: Epoch 0 train loss: 770.7335205078125\nINFO:root:25: Epoch 0 train loss: 262590.4375\nINFO:root:24: Epoch 0 train loss: 2060.7900390625\nINFO:root:6: Epoch 0 train loss: 102807.8046875\nINFO:root:5: Epoch 0 train loss: 6620.09716796875\nINFO:root:2: Epoch 0 train loss: 3150.396484375\nINFO:root:3: Epoch 0 train loss: 504.2275695800781\nINFO:root:4: Epoch 0 train loss: 4240.8115234375\nINFO:root:0: Epoch 0 validation loss: 207076.93198964448\nINFO:root:11: Epoch 1 train loss: 197.0247802734375\nINFO:root:12: Epoch 1 train loss: 2146.782470703125\nINFO:root:15: Epoch 1 train loss: 306163.59375\nINFO:root:14: Epoch 1 train loss: 114.3927001953125\nINFO:root:13: Epoch 1 train loss: 367870.90625\nINFO:root:16: Epoch 1 train loss: 57.00640869140625\nINFO:root:23: Epoch 1 train loss: 388.6370849609375\nINFO:root:25: Epoch 1 train loss: 326826.5\nINFO:root:24: Epoch 1 train loss: 6049.12255859375\nINFO:root:27: Epoch 1 train loss: 1690.338134765625\nINFO:root:26: Epoch 1 train loss: 2948.0302734375\nINFO:root:7: Epoch 1 train loss: 262477.9375\nINFO:root:4: Epoch 1 train loss: 816.4573364257812\nINFO:root:6: Epoch 1 train loss: 3464.852294921875\nINFO:root:5: Epoch 1 train loss: 5134.3076171875\nINFO:root:20: Epoch 1 train loss: 1331.8282470703125\nINFO:root:10: Epoch 1 train loss: 1397.8580322265625\nINFO:root:9: Epoch 1 train loss: 316.7936706542969\nINFO:root:0: Epoch 1 train loss: 583241.6875\nINFO:root:18: Epoch 1 train loss: 708.3984985351562\nINFO:root:21: Epoch 1 train loss: 116.24889373779297\nINFO:root:19: Epoch 1 train loss: 2303.856689453125\nINFO:root:17: Epoch 1 train loss: 2637.923828125\nINFO:root:22: Epoch 1 train loss: 249.91165161132812\nINFO:root:2: Epoch 1 train loss: 868.2864379882812\nINFO:root:1: Epoch 1 train loss: 237.0056915283203\nINFO:root:3: Epoch 1 train loss: 1726.4466552734375\nINFO:root:8: Epoch 1 train loss: 302719.09375\nINFO:root:0: Epoch 1 validation loss: 207071.78643448802\nINFO:root:27: Epoch 2 train loss: 1953.219970703125\nINFO:root:26: Epoch 2 train loss: 108258.8203125\nINFO:root:25: Epoch 2 train loss: 6378.68701171875\nINFO:root:0: Epoch 2 train loss: 314452.0625\nINFO:root:23: Epoch 2 train loss: 3305.520263671875\nINFO:root:24: Epoch 2 train loss: 103805.1328125\nINFO:root:22: Epoch 2 train loss: 69.76798248291016\nINFO:root:7: Epoch 2 train loss: 2502.56005859375\nINFO:root:15: Epoch 2 train loss: 2669.037353515625\nINFO:root:4: Epoch 2 train loss: 1777.47802734375\nINFO:root:14: Epoch 2 train loss: 362558.6875\nINFO:root:5: Epoch 2 train loss: 2692.6552734375\nINFO:root:6: Epoch 2 train loss: 466.3525695800781\nINFO:root:17: Epoch 2 train loss: 2333.588623046875\nINFO:root:18: Epoch 2 train loss: 2427.896728515625\nINFO:root:19: Epoch 2 train loss: 1877.4163818359375\nINFO:root:10: Epoch 2 train loss: 2271.342041015625\nINFO:root:11: Epoch 2 train loss: 2594.21875\nINFO:root:8: Epoch 2 train loss: 2976.570556640625\nINFO:root:16: Epoch 2 train loss: 364278.71875\nINFO:root:2: Epoch 2 train loss: 1625.4945068359375\nINFO:root:3: Epoch 2 train loss: 1418.1546630859375\nINFO:root:1: Epoch 2 train loss: 314813.59375\nINFO:root:9: Epoch 2 train loss: 1767.267822265625\nINFO:root:21: Epoch 2 train loss: 333136.5625\nINFO:root:20: Epoch 2 train loss: 4289.47021484375\nINFO:root:13: Epoch 2 train loss: 2125.19775390625\nINFO:root:12: Epoch 2 train loss: 629.7852783203125\nINFO:root:0: Epoch 2 validation loss: 207066.6073971454\nINFO:root:27: Epoch 3 train loss: 1365.1927490234375\nINFO:root:26: Epoch 3 train loss: 4003.975830078125\nINFO:root:25: Epoch 3 train loss: 303485.65625\nINFO:root:24: Epoch 3 train loss: 429354.0\nINFO:root:22: Epoch 3 train loss: 6680.0068359375\nINFO:root:21: Epoch 3 train loss: 1046.4249267578125\nINFO:root:20: Epoch 3 train loss: 282.13726806640625\nINFO:root:0: Epoch 3 train loss: 3673.68310546875\nINFO:root:23: Epoch 3 train loss: 1105.0328369140625\nINFO:root:7: Epoch 3 train loss: 114554.4609375\nINFO:root:14: Epoch 3 train loss: 6576.59130859375\nINFO:root:5: Epoch 3 train loss: 4850.6865234375\nINFO:root:6: Epoch 3 train loss: 3246.741455078125\nINFO:root:12: Epoch 3 train loss: 102831.0\nINFO:root:15: Epoch 3 train loss: 1358.4781494140625\nINFO:root:13: Epoch 3 train loss: 2342.32958984375\nINFO:root:3: Epoch 3 train loss: 1219.8734130859375\nINFO:root:2: Epoch 3 train loss: 1048.52099609375\nINFO:root:18: Epoch 3 train loss: 105694.8671875\nINFO:root:10: Epoch 3 train loss: 6225.0830078125\nINFO:root:17: Epoch 3 train loss: 419.4082336425781\nINFO:root:8: Epoch 3 train loss: 1218.166015625\nINFO:root:9: Epoch 3 train loss: 978.3624877929688\nINFO:root:11: Epoch 3 train loss: 4295.71923828125\nINFO:root:19: Epoch 3 train loss: 970.7012939453125\nINFO:root:16: Epoch 3 train loss: 4802.46337890625\nINFO:root:1: Epoch 3 train loss: 529.3456420898438\nINFO:root:4: Epoch 3 train loss: 2194.848876953125\nINFO:root:0: Epoch 3 validation loss: 207061.30026460488\nINFO:root:25: Epoch 4 train loss: 2554.02099609375\nINFO:root:24: Epoch 4 train loss: 1025.700439453125\nINFO:root:23: Epoch 4 train loss: 363955.28125\nINFO:root:22: Epoch 4 train loss: 327698.0625\nINFO:root:27: Epoch 4 train loss: 423.97747802734375\nINFO:root:7: Epoch 4 train loss: 9109.9013671875\nINFO:root:11: Epoch 4 train loss: 290532.65625\nINFO:root:15: Epoch 4 train loss: 362.1524963378906\nINFO:root:26: Epoch 4 train loss: 293466.15625\nINFO:root:8: Epoch 4 train loss: 328959.65625\nINFO:root:18: Epoch 4 train loss: 110297.140625\nINFO:root:6: Epoch 4 train loss: 862.0277709960938\nINFO:root:16: Epoch 4 train loss: 2861.28076171875\nINFO:root:4: Epoch 4 train loss: 10733.638671875\nINFO:root:10: Epoch 4 train loss: 947.4982299804688\nINFO:root:19: Epoch 4 train loss: 245144.484375\nINFO:root:9: Epoch 4 train loss: 260124.984375\nINFO:root:2: Epoch 4 train loss: 3073.185791015625\nINFO:root:0: Epoch 4 train loss: 453.153076171875\nINFO:root:14: Epoch 4 train loss: 6005.75537109375\nINFO:root:20: Epoch 4 train loss: 1027.7060546875\nINFO:root:17: Epoch 4 train loss: 6121.9970703125\nINFO:root:5: Epoch 4 train loss: 2297.1572265625\nINFO:root:21: Epoch 4 train loss: 1222.4989013671875\nINFO:root:3: Epoch 4 train loss: 361516.0625\nINFO:root:12: Epoch 4 train loss: 2141.977294921875\nINFO:root:13: Epoch 4 train loss: 4480.94482421875\nINFO:root:1: Epoch 4 train loss: 2556.31005859375\nINFO:root:0: Epoch 4 validation loss: 207056.0881913649\nINFO:root:20: Epoch 5 train loss: 1974.6390380859375\nINFO:root:21: Epoch 5 train loss: 2987.873046875\nINFO:root:15: Epoch 5 train loss: 250685.484375\nINFO:root:11: Epoch 5 train loss: 1311.555419921875\nINFO:root:22: Epoch 5 train loss: 3418.795654296875\nINFO:root:23: Epoch 5 train loss: 176.6979522705078\nINFO:root:5: Epoch 5 train loss: 3089.12646484375\nINFO:root:6: Epoch 5 train loss: 465208.53125\nINFO:root:7: Epoch 5 train loss: 397514.90625\nINFO:root:0: Epoch 5 train loss: 245702.296875\nINFO:root:25: Epoch 5 train loss: 313209.65625\nINFO:root:1: Epoch 5 train loss: 10619.9794921875\nINFO:root:4: Epoch 5 train loss: 3780.9365234375\nINFO:root:19: Epoch 5 train loss: 529.7708129882812\nINFO:root:24: Epoch 5 train loss: 2270.977783203125\nINFO:root:18: Epoch 5 train loss: 1734.829833984375\nINFO:root:27: Epoch 5 train loss: 2863.28173828125\nINFO:root:3: Epoch 5 train loss: 1443.251708984375\nINFO:root:12: Epoch 5 train loss: 368299.09375\nINFO:root:16: Epoch 5 train loss: 260429.578125\nINFO:root:17: Epoch 5 train loss: 361335.0625\nINFO:root:14: Epoch 5 train loss: 34407.82421875\nINFO:root:13: Epoch 5 train loss: 589.454345703125\nINFO:root:26: Epoch 5 train loss: 10076.6171875\nINFO:root:9: Epoch 5 train loss: 2504.687255859375\nINFO:root:8: Epoch 5 train loss: 262748.40625\nINFO:root:10: Epoch 5 train loss: 312473.5\nINFO:root:2: Epoch 5 train loss: 261053.15625\nINFO:root:0: Epoch 5 validation loss: 207050.95111105844\n", "seconds": 23.25565814971924, "batch_size": 256, "nodes": 7, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n1: 1 batches\n4 Start Epoch 0\n4: 1 batches\n31 Start Epoch 0\n31: 1 batches\n5 Start Epoch 0\n6 Start Epoch 0\n6: 1 batches\n5: 1 batches\n3 Start Epoch 0\n3: 1 batches\n9 Start Epoch 0\n10 Start Epoch 0\n17 Start Epoch 0\n18 Start Epoch 0\n18: 1 batches\n9: 1 batches\n17: 1 batches\n10: 1 batches\n8 Start Epoch 0\n7 Start Epoch 0\n2 Start Epoch 0\n7: 1 batches\n2: 1 batches\n15 Start Epoch 0\n15: 1 batches\n16 Start Epoch 0\n16: 1 batches\n12 Start Epoch 0\n19 Start Epoch 0\n12: 1 batches\n19: 1 batches\n13 Start Epoch 0\n14 Start Epoch 0\n23 Start Epoch 0\n14: 1 batches\n29 Start Epoch 0\n29: 1 batches\n13: 1 batches\n8: 1 batches\n30 Start Epoch 0\n30: 1 batches\n23: 1 batches\n24 Start Epoch 0\n24: 1 batches\n20 Start Epoch 0\n11 Start Epoch 0\n11: 1 batches\n25 Start Epoch 0\n25: 1 batches\n20: 1 batches\n26 Start Epoch 0\n26: 1 batches\n21 Start Epoch 0\n21: 1 batches\n27 Start Epoch 0\n22 Start Epoch 0\n27: 1 batches\n22: 1 batches\n28 Start Epoch 0\n28: 1 batches\n31 Start Epoch 1\n31: 1 batches\n1 Start Epoch 1\n1: 1 batches\n6 Start Epoch 1\n14 Start Epoch 1\n15 Start Epoch 1\n15: 1 batches\n21 Start Epoch 1\n16 Start Epoch 1\n6: 1 batches\n8 Start Epoch 1\n29 Start Epoch 1\n13 Start Epoch 1\n13: 1 batches\n20 Start Epoch 1\n7 Start Epoch 1\n2 Start Epoch 1\n28 Start Epoch 1\n2: 1 batches\n14: 1 batches\n22 Start Epoch 1\n10 Start Epoch 1\n10: 1 batches\n28: 1 batches\n21: 1 batches\n17 Start Epoch 1\n5 Start Epoch 1\n9 Start Epoch 1\n9: 1 batches\n12 Start Epoch 1\n20: 1 batches\n17: 1 batches\n7: 1 batches\n11 Start Epoch 1\n25 Start Epoch 1\n29: 1 batches\n12: 1 batches\n23 Start Epoch 1\n16: 1 batches\n5: 1 batches\n11: 1 batches\n27 Start Epoch 1\n26 Start Epoch 1\n26: 1 batches\n3 Start Epoch 1\n3: 1 batches\n30 Start Epoch 1\n23: 1 batches\n8: 1 batches\n4 Start Epoch 1\n25: 1 batches\n30: 1 batches\n22: 1 batches\n19 Start Epoch 1\n24 Start Epoch 1\n19: 1 batches\n4: 1 batches\n24: 1 batches\n27: 1 batches\n18 Start Epoch 1\n18: 1 batches\n0 Start Epoch 1\n0: 1 batches\n1 Start Epoch 2\n1: 1 batches\n14 Start Epoch 2\n5 Start Epoch 2\n25 Start Epoch 2\n28 Start Epoch 2\n15 Start Epoch 2\n2 Start Epoch 2\n8 Start Epoch 2\n27 Start Epoch 2\n2: 1 batches\n29 Start Epoch 2\n14: 1 batches\n20 Start Epoch 2\n6 Start Epoch 2\n10 Start Epoch 2\n10: 1 batches\n26 Start Epoch 2\n28: 1 batches\n15: 1 batches\n21 Start Epoch 2\n22 Start Epoch 2\n6: 1 batches\n9 Start Epoch 2\n9: 1 batches\n25: 1 batches\n29: 1 batches\n11 Start Epoch 2\n26: 1 batches\n31 Start Epoch 2\n20: 1 batches\n5: 1 batches\n31: 1 batches\n21: 1 batches\n16 Start Epoch 2\n7 Start Epoch 2\n8: 1 batches\n23 Start Epoch 2\n17 Start Epoch 2\n7: 1 batches\n11: 1 batches\n24 Start Epoch 2\n13 Start Epoch 2\n13: 1 batches\n23: 1 batches\n17: 1 batches\n4 Start Epoch 2\n24: 1 batches\n30 Start Epoch 2\n4: 1 batches\n27: 1 batches\n30: 1 batches\n22: 1 batches\n18 Start Epoch 2\n19 Start Epoch 2\n19: 1 batches\n18: 1 batches\n16: 1 batches\n12 Start Epoch 2\n12: 1 batches\n3 Start Epoch 2\n3: 1 batches\n0 Start Epoch 2\n0: 1 batches\n15 Start Epoch 3\n10 Start Epoch 3\n14 Start Epoch 3\n15: 1 batches\n9 Start Epoch 3\n14: 1 batches\n9: 1 batches\n28 Start Epoch 3\n10: 1 batches\n8 Start Epoch 3\n7 Start Epoch 3\n7: 1 batches\n13 Start Epoch 3\n13: 1 batches\n17 Start Epoch 3\n16 Start Epoch 3\n17: 1 batches\n1 Start Epoch 3\n16: 1 batches\n5 Start Epoch 3\n23 Start Epoch 3\n23: 1 batches\n25 Start Epoch 3\n4 Start Epoch 3\n25: 1 batches\n26 Start Epoch 3\n6 Start Epoch 3\n6: 1 batches\n26: 1 batches\n5: 1 batches\n31 Start Epoch 3\n31: 1 batches\n4: 1 batches\n24 Start Epoch 3\n28: 1 batches\n30 Start Epoch 3\n30: 1 batches\n24: 1 batches\n29 Start Epoch 3\n29: 1 batches\n2 Start Epoch 3\n2: 1 batches\n27 Start Epoch 3\n27: 1 batches\n3 Start Epoch 3\n19 Start Epoch 3\n19: 1 batches\n18 Start Epoch 3\n18: 1 batches\n1: 1 batches\n3: 1 batches\n11 Start Epoch 3\n8: 1 batches\n11: 1 batches\n12 Start Epoch 3\n12: 1 batches\n20 Start Epoch 3\n20: 1 batches\n22 Start Epoch 3\n22: 1 batches\n21 Start Epoch 3\n21: 1 batches\n0 Start Epoch 3\n0: 1 batches\n7 Start Epoch 4\n4 Start Epoch 4\n4: 1 batches\n14 Start Epoch 4\n15 Start Epoch 4\n13 Start Epoch 4\n7: 1 batches\n14: 1 batches\n31 Start Epoch 4\n31: 1 batches\n13: 1 batches\n15: 1 batches\n9 Start Epoch 4\n8 Start Epoch 4\n10 Start Epoch 4\n9: 1 batches\n10: 1 batches\n11 Start Epoch 4\n11: 1 batches\n8: 1 batches\n30 Start Epoch 4\n16 Start Epoch 4\n29 Start Epoch 4\n17 Start Epoch 4\n30: 1 batches\n17: 1 batches\n29: 1 batches\n16: 1 batches\n3 Start Epoch 4\n3: 1 batches\n26 Start Epoch 4\n27 Start Epoch 4\n27: 1 batches\n23 Start Epoch 4\n20 Start Epoch 4\n20: 1 batches\n22 Start Epoch 4\n21 Start Epoch 4\n21: 1 batches\n23: 1 batches\n22: 1 batches\n25 Start Epoch 4\n24 Start Epoch 4\n24: 1 batches\n25: 1 batches\n19 Start Epoch 4\n18 Start Epoch 4\n19: 1 batches\n18: 1 batches\n2 Start Epoch 4\n2: 1 batches\n12 Start Epoch 4\n12: 1 batches\n28 Start Epoch 4\n28: 1 batches\n26: 1 batches\n6 Start Epoch 4\n6: 1 batches\n1 Start Epoch 4\n1: 1 batches\n5 Start Epoch 4\n5: 1 batches\n0 Start Epoch 4\n0: 1 batches\n24 Start Epoch 5\n29 Start Epoch 5\n24: 1 batches\n28 Start Epoch 5\n28: 1 batches\n29: 1 batches\n26 Start Epoch 5\n26: 1 batches\n25 Start Epoch 5\n27 Start Epoch 5\n25: 1 batches\n27: 1 batches\n31 Start Epoch 5\n31: 1 batches\n30 Start Epoch 5\n30: 1 batches\n15 Start Epoch 5\n14 Start Epoch 5\n14: 1 batches\n15: 1 batches\n21 Start Epoch 5\n20 Start Epoch 5\n22 Start Epoch 5\n20: 1 batches\n22: 1 batches\n21: 1 batches\n18 Start Epoch 5\n17 Start Epoch 5\n17: 1 batches\n18: 1 batches\n19 Start Epoch 5\n23 Start Epoch 5\n19: 1 batches\n23: 1 batches\n16 Start Epoch 5\n16: 1 batches\n7 Start Epoch 5\n7: 1 batches\n10 Start Epoch 5\n8 Start Epoch 5\n9 Start Epoch 5\n10: 1 batches\n8: 1 batches\n9: 1 batches\n2 Start Epoch 5\n2: 1 batches\n12 Start Epoch 5\n13 Start Epoch 5\n13: 1 batches\n12: 1 batches\n1 Start Epoch 5\n1: 1 batches\n5 Start Epoch 5\n4 Start Epoch 5\n3 Start Epoch 5\n3: 1 batches\n4: 1 batches\n5: 1 batches\n6 Start Epoch 5\n6: 1 batches\n11 Start Epoch 5\n11: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:31: Epoch 0 train loss: 374828.71875\nINFO:root:14: Epoch 0 train loss: 378771.625\nINFO:root:23: Epoch 0 train loss: 1892.512451171875\nINFO:root:13: Epoch 0 train loss: 3776.790283203125\nINFO:root:20: Epoch 0 train loss: 1199.6978759765625\nINFO:root:6: Epoch 0 train loss: 1835.190673828125\nINFO:root:8: Epoch 0 train loss: 882.2140502929688\nINFO:root:21: Epoch 0 train loss: 1550.26123046875\nINFO:root:7: Epoch 0 train loss: 4828.29248046875\nINFO:root:9: Epoch 0 train loss: 1940.05859375\nINFO:root:15: Epoch 0 train loss: 281762.84375\nINFO:root:0: Epoch 0 train loss: 4418.61474609375\nINFO:root:1: Epoch 0 train loss: 96.34281921386719\nINFO:root:10: Epoch 0 train loss: 717.83154296875\nINFO:root:29: Epoch 0 train loss: 12870.943359375\nINFO:root:22: Epoch 0 train loss: 1936.03466796875\nINFO:root:26: Epoch 0 train loss: 3363.59130859375\nINFO:root:28: Epoch 0 train loss: 1284.4974365234375\nINFO:root:11: Epoch 0 train loss: 925.5465087890625\nINFO:root:27: Epoch 0 train loss: 5164.64697265625\nINFO:root:16: Epoch 0 train loss: 3274.352783203125\nINFO:root:2: Epoch 0 train loss: 2660.337646484375\nINFO:root:17: Epoch 0 train loss: 297058.65625\nINFO:root:5: Epoch 0 train loss: 3664.439453125\nINFO:root:24: Epoch 0 train loss: 15748.8916015625\nINFO:root:25: Epoch 0 train loss: 41859.796875\nINFO:root:12: Epoch 0 train loss: 4589.400390625\nINFO:root:30: Epoch 0 train loss: 1406.900390625\nINFO:root:3: Epoch 0 train loss: 743981.9375\nINFO:root:19: Epoch 0 train loss: 1555.8563232421875\nINFO:root:4: Epoch 0 train loss: 1437.2490234375\nINFO:root:18: Epoch 0 train loss: 1294.75146484375\nINFO:root:0: Epoch 0 validation loss: 779780.3004136069\nINFO:root:9: Epoch 1 train loss: 1000.1519775390625\nINFO:root:25: Epoch 1 train loss: 463.59527587890625\nINFO:root:29: Epoch 1 train loss: 3834.853271484375\nINFO:root:15: Epoch 1 train loss: 1664.8695068359375\nINFO:root:0: Epoch 1 train loss: 283648.125\nINFO:root:1: Epoch 1 train loss: 4066.098388671875\nINFO:root:23: Epoch 1 train loss: 2038.6544189453125\nINFO:root:7: Epoch 1 train loss: 386.6081848144531\nINFO:root:6: Epoch 1 train loss: 1178.2117919921875\nINFO:root:10: Epoch 1 train loss: 1032.177734375\nINFO:root:27: Epoch 1 train loss: 829.237548828125\nINFO:root:31: Epoch 1 train loss: 1827.56298828125\nINFO:root:14: Epoch 1 train loss: 6434.0712890625\nINFO:root:22: Epoch 1 train loss: 120711.0625\nINFO:root:11: Epoch 1 train loss: 479.7638244628906\nINFO:root:26: Epoch 1 train loss: 329.68017578125\nINFO:root:28: Epoch 1 train loss: 789.6707763671875\nINFO:root:20: Epoch 1 train loss: 3707.465087890625\nINFO:root:8: Epoch 1 train loss: 2831.35546875\nINFO:root:21: Epoch 1 train loss: 4020.13818359375\nINFO:root:4: Epoch 1 train loss: 2814.660888671875\nINFO:root:2: Epoch 1 train loss: 1412.044189453125\nINFO:root:5: Epoch 1 train loss: 803.572265625\nINFO:root:17: Epoch 1 train loss: 55346.7109375\nINFO:root:18: Epoch 1 train loss: 760.8489379882812\nINFO:root:13: Epoch 1 train loss: 1127.448974609375\nINFO:root:16: Epoch 1 train loss: 989.2890014648438\nINFO:root:12: Epoch 1 train loss: 1206.6844482421875\nINFO:root:24: Epoch 1 train loss: 2581.202880859375\nINFO:root:30: Epoch 1 train loss: 120656.9453125\nINFO:root:19: Epoch 1 train loss: 3588.135498046875\nINFO:root:3: Epoch 1 train loss: 344226.9375\nINFO:root:0: Epoch 1 validation loss: 779772.1566210854\nINFO:root:15: Epoch 2 train loss: 279960.0\nINFO:root:14: Epoch 2 train loss: 8046.79638671875\nINFO:root:10: Epoch 2 train loss: 748.3999633789062\nINFO:root:31: Epoch 2 train loss: 493.38043212890625\nINFO:root:9: Epoch 2 train loss: 9106.9326171875\nINFO:root:28: Epoch 2 train loss: 2021.11474609375\nINFO:root:8: Epoch 2 train loss: 2787.0869140625\nINFO:root:11: Epoch 2 train loss: 6221.29638671875\nINFO:root:13: Epoch 2 train loss: 1759.592529296875\nINFO:root:7: Epoch 2 train loss: 965.0048828125\nINFO:root:12: Epoch 2 train loss: 415019.96875\nINFO:root:17: Epoch 2 train loss: 885.2506103515625\nINFO:root:16: Epoch 2 train loss: 2562.986328125\nINFO:root:1: Epoch 2 train loss: 7533.6337890625\nINFO:root:23: Epoch 2 train loss: 907.5908813476562\nINFO:root:25: Epoch 2 train loss: 2040.8482666015625\nINFO:root:4: Epoch 2 train loss: 1042.7261962890625\nINFO:root:5: Epoch 2 train loss: 413411.96875\nINFO:root:26: Epoch 2 train loss: 3623.3154296875\nINFO:root:6: Epoch 2 train loss: 525.1257934570312\nINFO:root:24: Epoch 2 train loss: 339802.53125\nINFO:root:30: Epoch 2 train loss: 1686.2271728515625\nINFO:root:29: Epoch 2 train loss: 2439.904296875\nINFO:root:2: Epoch 2 train loss: 373463.3125\nINFO:root:27: Epoch 2 train loss: 7320.56201171875\nINFO:root:0: Epoch 2 train loss: 133.87353515625\nINFO:root:3: Epoch 2 train loss: 121423.6328125\nINFO:root:18: Epoch 2 train loss: 2070.718994140625\nINFO:root:19: Epoch 2 train loss: 11542.7822265625\nINFO:root:22: Epoch 2 train loss: 367220.34375\nINFO:root:20: Epoch 2 train loss: 10779.85546875\nINFO:root:21: Epoch 2 train loss: 297407.125\nINFO:root:0: Epoch 2 validation loss: 779764.1009969092\nINFO:root:7: Epoch 3 train loss: 6203.6357421875\nINFO:root:13: Epoch 3 train loss: 12648.0029296875\nINFO:root:4: Epoch 3 train loss: 5444.47216796875\nINFO:root:11: Epoch 3 train loss: 3840.899169921875\nINFO:root:15: Epoch 3 train loss: 1604.2159423828125\nINFO:root:14: Epoch 3 train loss: 365.66217041015625\nINFO:root:12: Epoch 3 train loss: 7900.25146484375\nINFO:root:10: Epoch 3 train loss: 279921.6875\nINFO:root:8: Epoch 3 train loss: 8190.92529296875\nINFO:root:9: Epoch 3 train loss: 282021.78125\nINFO:root:31: Epoch 3 train loss: 415060.71875\nINFO:root:30: Epoch 3 train loss: 1675.6802978515625\nINFO:root:17: Epoch 3 train loss: 556.150146484375\nINFO:root:29: Epoch 3 train loss: 2101.838134765625\nINFO:root:16: Epoch 3 train loss: 5578.91650390625\nINFO:root:3: Epoch 3 train loss: 2414.766845703125\nINFO:root:2: Epoch 3 train loss: 1022.0616455078125\nINFO:root:23: Epoch 3 train loss: 182.81932067871094\nINFO:root:21: Epoch 3 train loss: 425419.78125\nINFO:root:27: Epoch 3 train loss: 2556.984130859375\nINFO:root:22: Epoch 3 train loss: 355868.8125\nINFO:root:20: Epoch 3 train loss: 6790.89794921875\nINFO:root:26: Epoch 3 train loss: 923.1814575195312\nINFO:root:25: Epoch 3 train loss: 11986.4541015625\nINFO:root:24: Epoch 3 train loss: 299494.5625\nINFO:root:18: Epoch 3 train loss: 357120.875\nINFO:root:19: Epoch 3 train loss: 265.2437744140625\nINFO:root:0: Epoch 3 train loss: 3310.17578125\nINFO:root:28: Epoch 3 train loss: 666.4620971679688\nINFO:root:6: Epoch 3 train loss: 428.5840759277344\nINFO:root:1: Epoch 3 train loss: 2941.797607421875\nINFO:root:5: Epoch 3 train loss: 1704.19873046875\nINFO:root:0: Epoch 3 validation loss: 779756.0524356896\nINFO:root:24: Epoch 4 train loss: 1770.0718994140625\nINFO:root:28: Epoch 4 train loss: 7934.62646484375\nINFO:root:29: Epoch 4 train loss: 1586.217041015625\nINFO:root:26: Epoch 4 train loss: 436.0378723144531\nINFO:root:27: Epoch 4 train loss: 1726.59716796875\nINFO:root:25: Epoch 4 train loss: 339581.125\nINFO:root:31: Epoch 4 train loss: 2456.72314453125\nINFO:root:30: Epoch 4 train loss: 6733.96435546875\nINFO:root:15: Epoch 4 train loss: 5838.251953125\nINFO:root:14: Epoch 4 train loss: 3031.303466796875\nINFO:root:23: Epoch 4 train loss: 3089.3408203125\nINFO:root:20: Epoch 4 train loss: 1021.11474609375\nINFO:root:21: Epoch 4 train loss: 345599.0\nINFO:root:22: Epoch 4 train loss: 685.076171875\nINFO:root:17: Epoch 4 train loss: 9957.001953125\nINFO:root:18: Epoch 4 train loss: 5704.2470703125\nINFO:root:19: Epoch 4 train loss: 704.314697265625\nINFO:root:16: Epoch 4 train loss: 8258.2275390625\nINFO:root:0: Epoch 4 train loss: 651877.3125\nINFO:root:7: Epoch 4 train loss: 917.949951171875\nINFO:root:9: Epoch 4 train loss: 2129.9482421875\nINFO:root:11: Epoch 4 train loss: 4471.3974609375\nINFO:root:10: Epoch 4 train loss: 7632.578125\nINFO:root:8: Epoch 4 train loss: 3083.19384765625\nINFO:root:2: Epoch 4 train loss: 2346.421142578125\nINFO:root:1: Epoch 4 train loss: 123345.234375\nINFO:root:13: Epoch 4 train loss: 4356.97314453125\nINFO:root:12: Epoch 4 train loss: 685.3604125976562\nINFO:root:6: Epoch 4 train loss: 345288.40625\nINFO:root:5: Epoch 4 train loss: 328.36346435546875\nINFO:root:4: Epoch 4 train loss: 887.8071899414062\nINFO:root:3: Epoch 4 train loss: 356192.03125\nINFO:root:0: Epoch 4 validation loss: 779747.9028746532\nINFO:root:3: Epoch 5 train loss: 2352.080810546875\nINFO:root:7: Epoch 5 train loss: 6391.63720703125\nINFO:root:9: Epoch 5 train loss: 2378.27783203125\nINFO:root:31: Epoch 5 train loss: 400.7469787597656\nINFO:root:15: Epoch 5 train loss: 3111.60791015625\nINFO:root:11: Epoch 5 train loss: 383.71337890625\nINFO:root:14: Epoch 5 train loss: 1491.39501953125\nINFO:root:10: Epoch 5 train loss: 651859.625\nINFO:root:8: Epoch 5 train loss: 1981.9464111328125\nINFO:root:12: Epoch 5 train loss: 555.09423828125\nINFO:root:23: Epoch 5 train loss: 72.10979461669922\nINFO:root:17: Epoch 5 train loss: 2618.448486328125\nINFO:root:4: Epoch 5 train loss: 2478.934326171875\nINFO:root:6: Epoch 5 train loss: 338.77178955078125\nINFO:root:27: Epoch 5 train loss: 1736.1329345703125\nINFO:root:13: Epoch 5 train loss: 788.6573486328125\nINFO:root:22: Epoch 5 train loss: 765.5300903320312\nINFO:root:18: Epoch 5 train loss: 12069.658203125\nINFO:root:21: Epoch 5 train loss: 9133.8603515625\nINFO:root:16: Epoch 5 train loss: 85.21041107177734\nINFO:root:5: Epoch 5 train loss: 154.43798828125\nINFO:root:24: Epoch 5 train loss: 390272.78125\nINFO:root:19: Epoch 5 train loss: 281362.34375\nINFO:root:25: Epoch 5 train loss: 667.5213623046875\nINFO:root:30: Epoch 5 train loss: 3410.24853515625\nINFO:root:29: Epoch 5 train loss: 2758.177490234375\nINFO:root:28: Epoch 5 train loss: 518.1241455078125\nINFO:root:20: Epoch 5 train loss: 2797.60009765625\nINFO:root:26: Epoch 5 train loss: 1468.71826171875\nINFO:root:1: Epoch 5 train loss: 6484.09521484375\nINFO:root:2: Epoch 5 train loss: 4400.50048828125\nINFO:root:0: Epoch 5 train loss: 332306.1875\nINFO:root:0: Epoch 5 validation loss: 779739.6695346327\n", "seconds": 23.52194619178772, "batch_size": 256, "nodes": 8, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n2 Start Epoch 0\n2: 1 batches\n1: 1 batches\n5 Start Epoch 0\n6 Start Epoch 0\n6: 1 batches\n5: 1 batches\n4 Start Epoch 0\n4: 1 batches\n31 Start Epoch 0\n23 Start Epoch 0\n15 Start Epoch 0\n31: 1 batches\n15: 1 batches\n16 Start Epoch 0\n7 Start Epoch 0\n8 Start Epoch 0\n33 Start Epoch 0\n33: 1 batches\n23: 1 batches\n24 Start Epoch 0\n7: 1 batches\n8: 1 batches\n16: 1 batches\n24: 1 batches\n34 Start Epoch 0\n34: 1 batches\n17 Start Epoch 0\n9 Start Epoch 0\n26 Start Epoch 0\n9: 1 batches\n32 Start Epoch 0\n32: 1 batches\n17: 1 batches\n26: 1 batches\n10 Start Epoch 0\n25 Start Epoch 0\n10: 1 batches\n25: 1 batches\n35 Start Epoch 0\n35: 1 batches\n18 Start Epoch 0\n18: 1 batches\n3 Start Epoch 0\n3: 1 batches\n28 Start Epoch 0\n11 Start Epoch 0\n28: 1 batches\n19 Start Epoch 0\n27 Start Epoch 0\n27: 1 batches\n11: 1 batches\n12 Start Epoch 0\n19: 1 batches\n12: 1 batches\n13 Start Epoch 0\n30 Start Epoch 0\n14 Start Epoch 0\n13: 1 batches\n29 Start Epoch 0\n29: 1 batches\n14: 1 batches\n30: 1 batches\n20 Start Epoch 0\n20: 1 batches\n21 Start Epoch 0\n22 Start Epoch 0\n21: 1 batches\n22: 1 batches\n14 Start Epoch 1\n15 Start Epoch 1\n15: 1 batches\n13 Start Epoch 1\n13: 1 batches\n14: 1 batches\n35 Start Epoch 1\n35: 1 batches\n34 Start Epoch 1\n33 Start Epoch 1\n34: 1 batches\n33: 1 batches\n30 Start Epoch 1\n29 Start Epoch 1\n9 Start Epoch 1\n28 Start Epoch 1\n9: 1 batches\n29: 1 batches\n32 Start Epoch 1\n30: 1 batches\n32: 1 batches\n12 Start Epoch 1\n12: 1 batches\n31 Start Epoch 1\n31: 1 batches\n28: 1 batches\n11 Start Epoch 1\n11: 1 batches\n8 Start Epoch 1\n8: 1 batches\n10 Start Epoch 1\n17 Start Epoch 1\n10: 1 batches\n17: 1 batches\n20 Start Epoch 1\n20: 1 batches\n16 Start Epoch 1\n7 Start Epoch 1\n7: 1 batches\n16: 1 batches\n22 Start Epoch 1\n21 Start Epoch 1\n22: 1 batches\n26 Start Epoch 1\n24 Start Epoch 1\n23 Start Epoch 1\n25 Start Epoch 1\n23: 1 batches\n26: 1 batches\n24: 1 batches\n27 Start Epoch 1\n27: 1 batches\n21: 1 batches\n25: 1 batches\n19 Start Epoch 1\n19: 1 batches\n18 Start Epoch 1\n18: 1 batches\n1 Start Epoch 1\n1: 1 batches\n2 Start Epoch 1\n2: 1 batches\n3 Start Epoch 1\n3: 1 batches\n6 Start Epoch 1\n6: 1 batches\n4 Start Epoch 1\n4: 1 batches\n5 Start Epoch 1\n5: 1 batches\n0 Start Epoch 1\n0: 1 batches\n7 Start Epoch 2\n7: 1 batches\n31 Start Epoch 2\n31: 1 batches\n15 Start Epoch 2\n28 Start Epoch 2\n28: 1 batches\n14 Start Epoch 2\n15: 1 batches\n12 Start Epoch 2\n12: 1 batches\n16 Start Epoch 2\n16: 1 batches\n29 Start Epoch 2\n30 Start Epoch 2\n35 Start Epoch 2\n22 Start Epoch 2\n30: 1 batches\n32 Start Epoch 2\n2 Start Epoch 2\n21 Start Epoch 2\n17 Start Epoch 2\n29: 1 batches\n33 Start Epoch 2\n2: 1 batches\n22: 1 batches\n17: 1 batches\n24 Start Epoch 2\n35: 1 batches\n23 Start Epoch 2\n25 Start Epoch 2\n23: 1 batches\n19 Start Epoch 2\n26 Start Epoch 2\n33: 1 batches\n19: 1 batches\n24: 1 batches\n34 Start Epoch 2\n21: 1 batches\n26: 1 batches\n9 Start Epoch 2\n9: 1 batches\n3 Start Epoch 2\n34: 1 batches\n18 Start Epoch 2\n27 Start Epoch 2\n32: 1 batches\n20 Start Epoch 2\n14: 1 batches\n18: 1 batches\n27: 1 batches\n1 Start Epoch 2\n11 Start Epoch 2\n11: 1 batches\n20: 1 batches\n3: 1 batches\n25: 1 batches\n1: 1 batches\n10 Start Epoch 2\n10: 1 batches\n8 Start Epoch 2\n8: 1 batches\n13 Start Epoch 2\n13: 1 batches\n4 Start Epoch 2\n4: 1 batches\n5 Start Epoch 2\n5: 1 batches\n6 Start Epoch 2\n6: 1 batches\n0 Start Epoch 2\n0: 1 batches\n15 Start Epoch 3\n15: 1 batches\n11 Start Epoch 3\n11: 1 batches\n6 Start Epoch 3\n7 Start Epoch 3\n6: 1 batches\n7: 1 batches\n21 Start Epoch 3\n20 Start Epoch 3\n20: 1 batches\n10 Start Epoch 3\n3 Start Epoch 3\n2 Start Epoch 3\n10: 1 batches\n21: 1 batches\n16 Start Epoch 3\n2: 1 batches\n14 Start Epoch 3\n16: 1 batches\n12 Start Epoch 3\n3: 1 batches\n8 Start Epoch 3\n14: 1 batches\n13 Start Epoch 3\n4 Start Epoch 3\n13: 1 batches\n4: 1 batches\n5 Start Epoch 3\n12: 1 batches\n5: 1 batches\n9 Start Epoch 3\n31 Start Epoch 3\n9: 1 batches\n31: 1 batches\n17 Start Epoch 3\n18 Start Epoch 3\n17: 1 batches\n19 Start Epoch 3\n19: 1 batches\n8: 1 batches\n18: 1 batches\n27 Start Epoch 3\n27: 1 batches\n22 Start Epoch 3\n26 Start Epoch 3\n28 Start Epoch 3\n22: 1 batches\n32 Start Epoch 3\n23 Start Epoch 3\n26: 1 batches\n30 Start Epoch 3\n29 Start Epoch 3\n35 Start Epoch 3\n23: 1 batches\n28: 1 batches\n33 Start Epoch 3\n29: 1 batches\n35: 1 batches\n30: 1 batches\n33: 1 batches\n34 Start Epoch 3\n34: 1 batches\n32: 1 batches\n24 Start Epoch 3\n25 Start Epoch 3\n24: 1 batches\n25: 1 batches\n1 Start Epoch 3\n1: 1 batches\n0 Start Epoch 3\n0: 1 batches\n15 Start Epoch 4\n15: 1 batches\n11 Start Epoch 4\n11: 1 batches\n10 Start Epoch 4\n10: 1 batches\n3 Start Epoch 4\n3: 1 batches\n7 Start Epoch 4\n6 Start Epoch 4\n6: 1 batches\n7: 1 batches\n35 Start Epoch 4\n33 Start Epoch 4\n14 Start Epoch 4\n12 Start Epoch 4\n14: 1 batches\n13 Start Epoch 4\n13: 1 batches\n12: 1 batches\n18 Start Epoch 4\n29 Start Epoch 4\n29: 1 batches\n2 Start Epoch 4\n2: 1 batches\n30 Start Epoch 4\n30: 1 batches\n19 Start Epoch 4\n25 Start Epoch 4\n31 Start Epoch 4\n31: 1 batches\n20 Start Epoch 4\n19: 1 batches\n28 Start Epoch 4\n28: 1 batches\n21 Start Epoch 4\n27 Start Epoch 4\n20: 1 batches\n1 Start Epoch 4\n25: 1 batches\n21: 1 batches\n1: 1 batches\n18: 1 batches\n27: 1 batches\n22 Start Epoch 4\n22: 1 batches\n9 Start Epoch 4\n9: 1 batches\n23 Start Epoch 4\n32 Start Epoch 4\n23: 1 batches\n33: 1 batches\n35: 1 batches\n34 Start Epoch 4\n34: 1 batches\n32: 1 batches\n17 Start Epoch 4\n4 Start Epoch 4\n5 Start Epoch 4\n4: 1 batches\n5: 1 batches\n16 Start Epoch 4\n17: 1 batches\n16: 1 batches\n26 Start Epoch 4\n8 Start Epoch 4\n26: 1 batches\n8: 1 batches\n24 Start Epoch 4\n24: 1 batches\n0 Start Epoch 4\n0: 1 batches\n20 Start Epoch 5\n20: 1 batches\n23 Start Epoch 5\n23: 1 batches\n31 Start Epoch 5\n4 Start Epoch 5\n4: 1 batches\n28 Start Epoch 5\n28: 1 batches\n7 Start Epoch 5\n31: 1 batches\n33 Start Epoch 5\n7: 1 batches\n35 Start Epoch 5\n32 Start Epoch 5\n33: 1 batches\n35: 1 batches\n1 Start Epoch 5\n1: 1 batches\n34 Start Epoch 5\n3 Start Epoch 5\n3: 1 batches\n5 Start Epoch 5\n10 Start Epoch 5\n34: 1 batches\n12 Start Epoch 5\n12: 1 batches\n25 Start Epoch 5\n24 Start Epoch 5\n6 Start Epoch 5\n11 Start Epoch 5\n32: 1 batches\n21 Start Epoch 5\n14 Start Epoch 5\n14: 1 batches\n25: 1 batches\n6: 1 batches\n11: 1 batches\n21: 1 batches\n24: 1 batches\n5: 1 batches\n15 Start Epoch 5\n15: 1 batches\n17 Start Epoch 5\n9 Start Epoch 5\n16 Start Epoch 5\n27 Start Epoch 5\n9: 1 batches\n18 Start Epoch 5\n13 Start Epoch 5\n13: 1 batches\n18: 1 batches\n27: 1 batches\n17: 1 batches\n16: 1 batches\n19 Start Epoch 5\n19: 1 batches\n26 Start Epoch 5\n8 Start Epoch 5\n26: 1 batches\n10: 1 batches\n8: 1 batches\n30 Start Epoch 5\n30: 1 batches\n2 Start Epoch 5\n29 Start Epoch 5\n29: 1 batches\n2: 1 batches\n22 Start Epoch 5\n22: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:13: Epoch 0 train loss: 688.1426391601562\nINFO:root:14: Epoch 0 train loss: 688.4620971679688\nINFO:root:15: Epoch 0 train loss: 974.4439697265625\nINFO:root:35: Epoch 0 train loss: 398526.375\nINFO:root:34: Epoch 0 train loss: 266.1878662109375\nINFO:root:33: Epoch 0 train loss: 1149.8701171875\nINFO:root:30: Epoch 0 train loss: 3348.498046875\nINFO:root:29: Epoch 0 train loss: 313316.90625\nINFO:root:31: Epoch 0 train loss: 45242.484375\nINFO:root:28: Epoch 0 train loss: 1068.0899658203125\nINFO:root:9: Epoch 0 train loss: 910.8031616210938\nINFO:root:32: Epoch 0 train loss: 76.2379150390625\nINFO:root:12: Epoch 0 train loss: 2093.133544921875\nINFO:root:11: Epoch 0 train loss: 9767.8564453125\nINFO:root:8: Epoch 0 train loss: 2735.924072265625\nINFO:root:10: Epoch 0 train loss: 5371.119140625\nINFO:root:17: Epoch 0 train loss: 1605.74072265625\nINFO:root:20: Epoch 0 train loss: 133261.203125\nINFO:root:16: Epoch 0 train loss: 357154.90625\nINFO:root:7: Epoch 0 train loss: 789979.75\nINFO:root:21: Epoch 0 train loss: 542.1583862304688\nINFO:root:24: Epoch 0 train loss: 9808.7900390625\nINFO:root:23: Epoch 0 train loss: 4140.88232421875\nINFO:root:25: Epoch 0 train loss: 1783.9083251953125\nINFO:root:22: Epoch 0 train loss: 1274.8385009765625\nINFO:root:26: Epoch 0 train loss: 262.8307189941406\nINFO:root:27: Epoch 0 train loss: 45881.921875\nINFO:root:19: Epoch 0 train loss: 332140.15625\nINFO:root:18: Epoch 0 train loss: 371547.71875\nINFO:root:0: Epoch 0 train loss: 3308.16796875\nINFO:root:1: Epoch 0 train loss: 13363.1220703125\nINFO:root:2: Epoch 0 train loss: 43212.62109375\nINFO:root:3: Epoch 0 train loss: 3172.173583984375\nINFO:root:6: Epoch 0 train loss: 2502.91943359375\nINFO:root:4: Epoch 0 train loss: 464.9020690917969\nINFO:root:5: Epoch 0 train loss: 2969.983642578125\nINFO:root:0: Epoch 0 validation loss: 39278.237333392695\nINFO:root:7: Epoch 1 train loss: 46591.3203125\nINFO:root:31: Epoch 1 train loss: 3679.513671875\nINFO:root:14: Epoch 1 train loss: 373669.40625\nINFO:root:15: Epoch 1 train loss: 53.00010681152344\nINFO:root:28: Epoch 1 train loss: 195.3348388671875\nINFO:root:12: Epoch 1 train loss: 1310.921875\nINFO:root:9: Epoch 1 train loss: 1405.6240234375\nINFO:root:33: Epoch 1 train loss: 15019.5751953125\nINFO:root:16: Epoch 1 train loss: 699.437255859375\nINFO:root:30: Epoch 1 train loss: 6290.376953125\nINFO:root:34: Epoch 1 train loss: 110.84632873535156\nINFO:root:22: Epoch 1 train loss: 7564.1123046875\nINFO:root:0: Epoch 1 train loss: 734.5017700195312\nINFO:root:29: Epoch 1 train loss: 3149.339599609375\nINFO:root:35: Epoch 1 train loss: 538.2197875976562\nINFO:root:23: Epoch 1 train loss: 2330.131591796875\nINFO:root:27: Epoch 1 train loss: 14736.439453125\nINFO:root:24: Epoch 1 train loss: 534.455078125\nINFO:root:32: Epoch 1 train loss: 549.1546630859375\nINFO:root:21: Epoch 1 train loss: 1582.190673828125\nINFO:root:25: Epoch 1 train loss: 3618.569580078125\nINFO:root:17: Epoch 1 train loss: 3408.08837890625\nINFO:root:26: Epoch 1 train loss: 320891.21875\nINFO:root:2: Epoch 1 train loss: 7641.00927734375\nINFO:root:19: Epoch 1 train loss: 3550.099365234375\nINFO:root:20: Epoch 1 train loss: 204.6084747314453\nINFO:root:18: Epoch 1 train loss: 7367.37890625\nINFO:root:3: Epoch 1 train loss: 203.93719482421875\nINFO:root:11: Epoch 1 train loss: 323925.65625\nINFO:root:1: Epoch 1 train loss: 473.31243896484375\nINFO:root:8: Epoch 1 train loss: 196.91891479492188\nINFO:root:10: Epoch 1 train loss: 4778.70458984375\nINFO:root:13: Epoch 1 train loss: 386902.5625\nINFO:root:4: Epoch 1 train loss: 6353.24267578125\nINFO:root:6: Epoch 1 train loss: 18996.1875\nINFO:root:5: Epoch 1 train loss: 506748.90625\nINFO:root:0: Epoch 1 validation loss: 39274.421804431084\nINFO:root:15: Epoch 2 train loss: 132434.515625\nINFO:root:11: Epoch 2 train loss: 2342.563720703125\nINFO:root:7: Epoch 2 train loss: 2897.6748046875\nINFO:root:6: Epoch 2 train loss: 12975.1103515625\nINFO:root:20: Epoch 2 train loss: 3109.816162109375\nINFO:root:21: Epoch 2 train loss: 466614.21875\nINFO:root:10: Epoch 2 train loss: 313368.25\nINFO:root:14: Epoch 2 train loss: 4072.199462890625\nINFO:root:13: Epoch 2 train loss: 414707.75\nINFO:root:2: Epoch 2 train loss: 401783.84375\nINFO:root:3: Epoch 2 train loss: 689.4661865234375\nINFO:root:16: Epoch 2 train loss: 190.9764404296875\nINFO:root:12: Epoch 2 train loss: 474.35009765625\nINFO:root:8: Epoch 2 train loss: 3665.1943359375\nINFO:root:5: Epoch 2 train loss: 2579.837646484375\nINFO:root:4: Epoch 2 train loss: 4742.6015625\nINFO:root:9: Epoch 2 train loss: 2227.119384765625\nINFO:root:31: Epoch 2 train loss: 114.00114440917969\nINFO:root:19: Epoch 2 train loss: 389753.5625\nINFO:root:17: Epoch 2 train loss: 3344.895751953125\nINFO:root:18: Epoch 2 train loss: 864.9597778320312\nINFO:root:1: Epoch 2 train loss: 4209.0869140625\nINFO:root:27: Epoch 2 train loss: 4091.644287109375\nINFO:root:29: Epoch 2 train loss: 647.1526489257812\nINFO:root:35: Epoch 2 train loss: 319718.34375\nINFO:root:23: Epoch 2 train loss: 417826.90625\nINFO:root:28: Epoch 2 train loss: 2315.9140625\nINFO:root:32: Epoch 2 train loss: 1817.784423828125\nINFO:root:22: Epoch 2 train loss: 8011.009765625\nINFO:root:26: Epoch 2 train loss: 332119.71875\nINFO:root:30: Epoch 2 train loss: 3057.3994140625\nINFO:root:33: Epoch 2 train loss: 1705.552734375\nINFO:root:34: Epoch 2 train loss: 318061.125\nINFO:root:24: Epoch 2 train loss: 725.3507080078125\nINFO:root:25: Epoch 2 train loss: 2903.23779296875\nINFO:root:0: Epoch 2 train loss: 414192.46875\nINFO:root:0: Epoch 2 validation loss: 39270.75423123612\nINFO:root:15: Epoch 3 train loss: 3650.004638671875\nINFO:root:10: Epoch 3 train loss: 2278.386962890625\nINFO:root:11: Epoch 3 train loss: 250.12461853027344\nINFO:root:3: Epoch 3 train loss: 4194.82568359375\nINFO:root:6: Epoch 3 train loss: 372653.0\nINFO:root:7: Epoch 3 train loss: 2495.71923828125\nINFO:root:33: Epoch 3 train loss: 10671.2138671875\nINFO:root:34: Epoch 3 train loss: 1127.756103515625\nINFO:root:35: Epoch 3 train loss: 914.42919921875\nINFO:root:32: Epoch 3 train loss: 486.201904296875\nINFO:root:12: Epoch 3 train loss: 201.59523010253906\nINFO:root:14: Epoch 3 train loss: 1373.776123046875\nINFO:root:13: Epoch 3 train loss: 2960.31787109375\nINFO:root:18: Epoch 3 train loss: 43909.0078125\nINFO:root:28: Epoch 3 train loss: 316390.34375\nINFO:root:0: Epoch 3 train loss: 417327.40625\nINFO:root:2: Epoch 3 train loss: 7639.77099609375\nINFO:root:21: Epoch 3 train loss: 7080.36962890625\nINFO:root:19: Epoch 3 train loss: 1255.3258056640625\nINFO:root:25: Epoch 3 train loss: 133154.40625\nINFO:root:31: Epoch 3 train loss: 2010.16796875\nINFO:root:27: Epoch 3 train loss: 5151.78955078125\nINFO:root:30: Epoch 3 train loss: 461746.9375\nINFO:root:20: Epoch 3 train loss: 371073.5\nINFO:root:29: Epoch 3 train loss: 365566.125\nINFO:root:1: Epoch 3 train loss: 1408.8997802734375\nINFO:root:22: Epoch 3 train loss: 235.281982421875\nINFO:root:9: Epoch 3 train loss: 1170.73095703125\nINFO:root:23: Epoch 3 train loss: 4515.49267578125\nINFO:root:17: Epoch 3 train loss: 236.8683624267578\nINFO:root:4: Epoch 3 train loss: 12431.345703125\nINFO:root:5: Epoch 3 train loss: 8478.9189453125\nINFO:root:16: Epoch 3 train loss: 225.75624084472656\nINFO:root:26: Epoch 3 train loss: 464499.46875\nINFO:root:8: Epoch 3 train loss: 388114.46875\nINFO:root:24: Epoch 3 train loss: 354.1639709472656\nINFO:root:0: Epoch 3 validation loss: 39267.118339582055\nINFO:root:20: Epoch 4 train loss: 1458.037109375\nINFO:root:23: Epoch 4 train loss: 377.7995910644531\nINFO:root:7: Epoch 4 train loss: 1330.7432861328125\nINFO:root:31: Epoch 4 train loss: 1215.7860107421875\nINFO:root:32: Epoch 4 train loss: 2516.81298828125\nINFO:root:35: Epoch 4 train loss: 1842.856689453125\nINFO:root:4: Epoch 4 train loss: 152.49560546875\nINFO:root:28: Epoch 4 train loss: 45083.125\nINFO:root:33: Epoch 4 train loss: 708.0753784179688\nINFO:root:34: Epoch 4 train loss: 3830.62548828125\nINFO:root:25: Epoch 4 train loss: 421069.4375\nINFO:root:5: Epoch 4 train loss: 170.9195556640625\nINFO:root:10: Epoch 4 train loss: 7433.79345703125\nINFO:root:1: Epoch 4 train loss: 502.89385986328125\nINFO:root:0: Epoch 4 train loss: 372993.0625\nINFO:root:3: Epoch 4 train loss: 6304.0390625\nINFO:root:24: Epoch 4 train loss: 467.77056884765625\nINFO:root:6: Epoch 4 train loss: 7360.9140625\nINFO:root:11: Epoch 4 train loss: 2497.402587890625\nINFO:root:21: Epoch 4 train loss: 132.91748046875\nINFO:root:17: Epoch 4 train loss: 417513.6875\nINFO:root:16: Epoch 4 train loss: 4844.09130859375\nINFO:root:15: Epoch 4 train loss: 320080.15625\nINFO:root:18: Epoch 4 train loss: 1159.000732421875\nINFO:root:9: Epoch 4 train loss: 2031.10205078125\nINFO:root:27: Epoch 4 train loss: 2654.326904296875\nINFO:root:12: Epoch 4 train loss: 2043.3795166015625\nINFO:root:13: Epoch 4 train loss: 2491.22509765625\nINFO:root:14: Epoch 4 train loss: 696.6276245117188\nINFO:root:19: Epoch 4 train loss: 190.9171905517578\nINFO:root:26: Epoch 4 train loss: 333599.625\nINFO:root:8: Epoch 4 train loss: 3042.60498046875\nINFO:root:2: Epoch 4 train loss: 332068.40625\nINFO:root:30: Epoch 4 train loss: 372.136474609375\nINFO:root:29: Epoch 4 train loss: 387576.75\nINFO:root:22: Epoch 4 train loss: 1138.7430419921875\nINFO:root:0: Epoch 4 validation loss: 39263.52997677533\nINFO:root:15: Epoch 5 train loss: 402147.1875\nINFO:root:7: Epoch 5 train loss: 2795.969970703125\nINFO:root:34: Epoch 5 train loss: 1652.7620849609375\nINFO:root:35: Epoch 5 train loss: 274.2651672363281\nINFO:root:33: Epoch 5 train loss: 1682.162841796875\nINFO:root:32: Epoch 5 train loss: 1966.9913330078125\nINFO:root:11: Epoch 5 train loss: 386490.6875\nINFO:root:10: Epoch 5 train loss: 1114.3052978515625\nINFO:root:16: Epoch 5 train loss: 2186.5517578125\nINFO:root:3: Epoch 5 train loss: 1569.7340087890625\nINFO:root:17: Epoch 5 train loss: 418959.0\nINFO:root:26: Epoch 5 train loss: 5467.33642578125\nINFO:root:27: Epoch 5 train loss: 890.9376220703125\nINFO:root:25: Epoch 5 train loss: 1220.9200439453125\nINFO:root:24: Epoch 5 train loss: 4885.41064453125\nINFO:root:19: Epoch 5 train loss: 2735.931396484375\nINFO:root:2: Epoch 5 train loss: 4894.79150390625\nINFO:root:18: Epoch 5 train loss: 1001.986328125\nINFO:root:12: Epoch 5 train loss: 7431.95703125\nINFO:root:13: Epoch 5 train loss: 44502.11328125\nINFO:root:14: Epoch 5 train loss: 2017.9322509765625\nINFO:root:28: Epoch 5 train loss: 1060.4049072265625\nINFO:root:23: Epoch 5 train loss: 27.466796875\nINFO:root:31: Epoch 5 train loss: 2234.2451171875\nINFO:root:20: Epoch 5 train loss: 332692.96875\nINFO:root:22: Epoch 5 train loss: 2411.84765625\nINFO:root:4: Epoch 5 train loss: 43727.79296875\nINFO:root:29: Epoch 5 train loss: 15261.7314453125\nINFO:root:21: Epoch 5 train loss: 2818.525390625\nINFO:root:6: Epoch 5 train loss: 1672.5096435546875\nINFO:root:30: Epoch 5 train loss: 7493.125\nINFO:root:5: Epoch 5 train loss: 4708.39892578125\nINFO:root:0: Epoch 5 train loss: 2821.092041015625\nINFO:root:1: Epoch 5 train loss: 87.10569763183594\nINFO:root:9: Epoch 5 train loss: 291.6618347167969\nINFO:root:8: Epoch 5 train loss: 1710.1851806640625\nINFO:root:0: Epoch 5 validation loss: 39259.903885692846\n", "seconds": 23.469019889831543, "batch_size": 256, "nodes": 9, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n2 Start Epoch 0\n2: 1 batches\n1: 1 batches\n39 Start Epoch 0\n39: 1 batches\n4 Start Epoch 0\n4: 1 batches\n3 Start Epoch 0\n3: 1 batches\n28 Start Epoch 0\n12 Start Epoch 0\n28: 1 batches\n12: 1 batches\n11 Start Epoch 0\n27 Start Epoch 0\n11: 1 batches\n19 Start Epoch 0\n19: 1 batches\n7 Start Epoch 0\n7: 1 batches\n8 Start Epoch 0\n16 Start Epoch 0\n8: 1 batches\n27: 1 batches\n35 Start Epoch 0\n35: 1 batches\n16: 1 batches\n24 Start Epoch 0\n15 Start Epoch 0\n32 Start Epoch 0\n32: 1 batches\n24: 1 batches\n15: 1 batches\n36 Start Epoch 0\n36: 1 batches\n20 Start Epoch 0\n20: 1 batches\n5 Start Epoch 0\n23 Start Epoch 0\n23: 1 batches\n6 Start Epoch 0\n6: 1 batches\n5: 1 batches\n33 Start Epoch 0\n34 Start Epoch 0\n33: 1 batches\n34: 1 batches\n31 Start Epoch 0\n10 Start Epoch 0\n25 Start Epoch 0\n26 Start Epoch 0\n17 Start Epoch 0\n10: 1 batches\n25: 1 batches\n18 Start Epoch 0\n26: 1 batches\n17: 1 batches\n9 Start Epoch 0\n18: 1 batches\n9: 1 batches\n13 Start Epoch 0\n14 Start Epoch 0\n14: 1 batches\n31: 1 batches\n21 Start Epoch 0\n29 Start Epoch 0\n22 Start Epoch 0\n29: 1 batches\n21: 1 batches\n22: 1 batches\n13: 1 batches\n30 Start Epoch 0\n30: 1 batches\n37 Start Epoch 0\n38 Start Epoch 0\n38: 1 batches\n37: 1 batches\n37 Start Epoch 1\n38 Start Epoch 1\n39 Start Epoch 1\n39: 1 batches\n38: 1 batches\n37: 1 batches\n1 Start Epoch 1\n1: 1 batches\n31 Start Epoch 1\n4 Start Epoch 1\n6 Start Epoch 1\n14 Start Epoch 1\n34 Start Epoch 1\n31: 1 batches\n14: 1 batches\n34: 1 batches\n4: 1 batches\n15 Start Epoch 1\n35 Start Epoch 1\n29 Start Epoch 1\n2 Start Epoch 1\n29: 1 batches\n6: 1 batches\n15: 1 batches\n35: 1 batches\n13 Start Epoch 1\n33 Start Epoch 1\n30 Start Epoch 1\n7 Start Epoch 1\n13: 1 batches\n30: 1 batches\n5 Start Epoch 1\n12 Start Epoch 1\n36 Start Epoch 1\n36: 1 batches\n5: 1 batches\n26 Start Epoch 1\n7: 1 batches\n25 Start Epoch 1\n19 Start Epoch 1\n21 Start Epoch 1\n17 Start Epoch 1\n23 Start Epoch 1\n27 Start Epoch 1\n21: 1 batches\n25: 1 batches\n16 Start Epoch 1\n16: 1 batches\n22 Start Epoch 1\n8 Start Epoch 1\n8: 1 batches\n26: 1 batches\n17: 1 batches\n33: 1 batches\n18 Start Epoch 1\n22: 1 batches\n10 Start Epoch 1\n10: 1 batches\n27: 1 batches\n11 Start Epoch 1\n28 Start Epoch 1\n18: 1 batches\n23: 1 batches\n28: 1 batches\n19: 1 batches\n9 Start Epoch 1\n24 Start Epoch 1\n32 Start Epoch 1\n20 Start Epoch 1\n9: 1 batches\n24: 1 batches\n32: 1 batches\n20: 1 batches\n11: 1 batches\n2: 1 batches\n3 Start Epoch 1\n12: 1 batches\n3: 1 batches\n0 Start Epoch 1\n0: 1 batches\n13 Start Epoch 2\n14 Start Epoch 2\n12 Start Epoch 2\n12: 1 batches\n14: 1 batches\n15 Start Epoch 2\n13: 1 batches\n15: 1 batches\n39 Start Epoch 2\n39: 1 batches\n38 Start Epoch 2\n38: 1 batches\n30 Start Epoch 2\n37 Start Epoch 2\n30: 1 batches\n37: 1 batches\n31 Start Epoch 2\n7 Start Epoch 2\n7: 1 batches\n31: 1 batches\n16 Start Epoch 2\n8 Start Epoch 2\n16: 1 batches\n9 Start Epoch 2\n8: 1 batches\n9: 1 batches\n6 Start Epoch 2\n21 Start Epoch 2\n20 Start Epoch 2\n4 Start Epoch 2\n34 Start Epoch 2\n20: 1 batches\n10 Start Epoch 2\n2 Start Epoch 2\n2: 1 batches\n1 Start Epoch 2\n1: 1 batches\n3 Start Epoch 2\n3: 1 batches\n5 Start Epoch 2\n34: 1 batches\n10: 1 batches\n36 Start Epoch 2\n36: 1 batches\n21: 1 batches\n33 Start Epoch 2\n29 Start Epoch 2\n17 Start Epoch 2\n5: 1 batches\n33: 1 batches\n19 Start Epoch 2\n19: 1 batches\n11 Start Epoch 2\n6: 1 batches\n28 Start Epoch 2\n23 Start Epoch 2\n11: 1 batches\n4: 1 batches\n28: 1 batches\n22 Start Epoch 2\n27 Start Epoch 2\n24 Start Epoch 2\n32 Start Epoch 2\n29: 1 batches\n18 Start Epoch 2\n18: 1 batches\n22: 1 batches\n23: 1 batches\n25 Start Epoch 2\n32: 1 batches\n17: 1 batches\n35 Start Epoch 2\n25: 1 batches\n27: 1 batches\n35: 1 batches\n26 Start Epoch 2\n26: 1 batches\n24: 1 batches\n0 Start Epoch 2\n0: 1 batches\n3 Start Epoch 3\n2 Start Epoch 3\n2: 1 batches\n3: 1 batches\n38 Start Epoch 3\n4 Start Epoch 3\n7 Start Epoch 3\n39 Start Epoch 3\n7: 1 batches\n38: 1 batches\n34 Start Epoch 3\n34: 1 batches\n31 Start Epoch 3\n31: 1 batches\n23 Start Epoch 3\n23: 1 batches\n39: 1 batches\n5 Start Epoch 3\n5: 1 batches\n4: 1 batches\n6 Start Epoch 3\n6: 1 batches\n8 Start Epoch 3\n8: 1 batches\n16 Start Epoch 3\n16: 1 batches\n9 Start Epoch 3\n9: 1 batches\n25 Start Epoch 3\n28 Start Epoch 3\n25: 1 batches\n29 Start Epoch 3\n29: 1 batches\n19 Start Epoch 3\n10 Start Epoch 3\n27 Start Epoch 3\n14 Start Epoch 3\n28: 1 batches\n19: 1 batches\n27: 1 batches\n14: 1 batches\n30 Start Epoch 3\n11 Start Epoch 3\n10: 1 batches\n15 Start Epoch 3\n30: 1 batches\n18 Start Epoch 3\n11: 1 batches\n26 Start Epoch 3\n15: 1 batches\n18: 1 batches\n26: 1 batches\n13 Start Epoch 3\n17 Start Epoch 3\n17: 1 batches\n13: 1 batches\n20 Start Epoch 3\n21 Start Epoch 3\n20: 1 batches\n21: 1 batches\n22 Start Epoch 3\n22: 1 batches\n35 Start Epoch 3\n35: 1 batches\n24 Start Epoch 3\n24: 1 batches\n1 Start Epoch 3\n37 Start Epoch 3\n37: 1 batches\n1: 1 batches\n12 Start Epoch 3\n33 Start Epoch 3\n33: 1 batches\n32 Start Epoch 3\n32: 1 batches\n36 Start Epoch 3\n36: 1 batches\n12: 1 batches\n0 Start Epoch 3\n0: 1 batches\n39 Start Epoch 4\n38 Start Epoch 4\n38: 1 batches\n39: 1 batches\n2 Start Epoch 4\n2: 1 batches\n4 Start Epoch 4\n4: 1 batches\n35 Start Epoch 4\n35: 1 batches\n5 Start Epoch 4\n5: 1 batches\n23 Start Epoch 4\n14 Start Epoch 4\n14: 1 batches\n21 Start Epoch 4\n20 Start Epoch 4\n15 Start Epoch 4\n13 Start Epoch 4\n12 Start Epoch 4\n13: 1 batches\n6 Start Epoch 4\n26 Start Epoch 4\n31 Start Epoch 4\n32 Start Epoch 4\n31: 1 batches\n19 Start Epoch 4\n6: 1 batches\n25 Start Epoch 4\n17 Start Epoch 4\n7 Start Epoch 4\n26: 1 batches\n34 Start Epoch 4\n30 Start Epoch 4\n32: 1 batches\n30: 1 batches\n18 Start Epoch 4\n18: 1 batches\n7: 1 batches\n19: 1 batches\n24 Start Epoch 4\n34: 1 batches\n24: 1 batches\n33 Start Epoch 4\n33: 1 batches\n16 Start Epoch 4\n16: 1 batches\n25: 1 batches\n17: 1 batches\n1 Start Epoch 4\n1: 1 batches\n3 Start Epoch 4\n3: 1 batches\n12: 1 batches\n15: 1 batches\n21: 1 batches\n22 Start Epoch 4\n22: 1 batches\n10 Start Epoch 4\n23: 1 batches\n8 Start Epoch 4\n20: 1 batches\n8: 1 batches\n10: 1 batches\n9 Start Epoch 4\n9: 1 batches\n11 Start Epoch 4\n11: 1 batches\n29 Start Epoch 4\n28 Start Epoch 4\n29: 1 batches\n28: 1 batches\n37 Start Epoch 4\n37: 1 batches\n36 Start Epoch 4\n36: 1 batches\n27 Start Epoch 4\n27: 1 batches\n0 Start Epoch 4\n0: 1 batches\n7 Start Epoch 5\n7: 1 batches\n39 Start Epoch 5\n38 Start Epoch 5\n39: 1 batches\n31 Start Epoch 5\n31: 1 batches\n34 Start Epoch 5\n38: 1 batches\n34: 1 batches\n35 Start Epoch 5\n36 Start Epoch 5\n36: 1 batches\n35: 1 batches\n8 Start Epoch 5\n2 Start Epoch 5\n2: 1 batches\n3 Start Epoch 5\n3: 1 batches\n8: 1 batches\n15 Start Epoch 5\n33 Start Epoch 5\n23 Start Epoch 5\n27 Start Epoch 5\n14 Start Epoch 5\n33: 1 batches\n1 Start Epoch 5\n37 Start Epoch 5\n1: 1 batches\n37: 1 batches\n17 Start Epoch 5\n23: 1 batches\n27: 1 batches\n14: 1 batches\n9 Start Epoch 5\n6 Start Epoch 5\n15: 1 batches\n32 Start Epoch 5\n30 Start Epoch 5\n30: 1 batches\n17: 1 batches\n9: 1 batches\n5 Start Epoch 5\n26 Start Epoch 5\n32: 1 batches\n28 Start Epoch 5\n28: 1 batches\n11 Start Epoch 5\n5: 1 batches\n26: 1 batches\n29 Start Epoch 5\n19 Start Epoch 5\n21 Start Epoch 5\n29: 1 batches\n20 Start Epoch 5\n11: 1 batches\n6: 1 batches\n13 Start Epoch 5\n13: 1 batches\n12 Start Epoch 5\n12: 1 batches\n19: 1 batches\n21: 1 batches\n4 Start Epoch 5\n20: 1 batches\n10 Start Epoch 5\n4: 1 batches\n24 Start Epoch 5\n18 Start Epoch 5\n25 Start Epoch 5\n16 Start Epoch 5\n10: 1 batches\n18: 1 batches\n22 Start Epoch 5\n22: 1 batches\n25: 1 batches\n16: 1 batches\n24: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:37: Epoch 0 train loss: 1592.9842529296875\nINFO:root:38: Epoch 0 train loss: 144.30853271484375\nINFO:root:39: Epoch 0 train loss: 102.20654296875\nINFO:root:0: Epoch 0 train loss: 312.6368713378906\nINFO:root:1: Epoch 0 train loss: 428301.75\nINFO:root:6: Epoch 0 train loss: 8162.8935546875\nINFO:root:15: Epoch 0 train loss: 48764.3515625\nINFO:root:35: Epoch 0 train loss: 671.80908203125\nINFO:root:31: Epoch 0 train loss: 426844.1875\nINFO:root:34: Epoch 0 train loss: 426777.53125\nINFO:root:14: Epoch 0 train loss: 3394.19091796875\nINFO:root:29: Epoch 0 train loss: 367642.21875\nINFO:root:4: Epoch 0 train loss: 184.51806640625\nINFO:root:2: Epoch 0 train loss: 3056.79296875\nINFO:root:7: Epoch 0 train loss: 5263.78759765625\nINFO:root:13: Epoch 0 train loss: 369.60076904296875\nINFO:root:33: Epoch 0 train loss: 3326.97265625\nINFO:root:30: Epoch 0 train loss: 48848.68359375\nINFO:root:5: Epoch 0 train loss: 11180.029296875\nINFO:root:36: Epoch 0 train loss: 5038.1748046875\nINFO:root:16: Epoch 0 train loss: 4488.1376953125\nINFO:root:26: Epoch 0 train loss: 2106.615234375\nINFO:root:12: Epoch 0 train loss: 181.46192932128906\nINFO:root:17: Epoch 0 train loss: 755.503662109375\nINFO:root:23: Epoch 0 train loss: 3011.92822265625\nINFO:root:27: Epoch 0 train loss: 1509.000244140625\nINFO:root:18: Epoch 0 train loss: 148864.859375\nINFO:root:22: Epoch 0 train loss: 428194.96875\nINFO:root:19: Epoch 0 train loss: 1733.5284423828125\nINFO:root:21: Epoch 0 train loss: 2152.6669921875\nINFO:root:9: Epoch 0 train loss: 51696.1171875\nINFO:root:10: Epoch 0 train loss: 441956.65625\nINFO:root:25: Epoch 0 train loss: 1292.574462890625\nINFO:root:11: Epoch 0 train loss: 644.6627197265625\nINFO:root:8: Epoch 0 train loss: 9183.720703125\nINFO:root:28: Epoch 0 train loss: 159.28807067871094\nINFO:root:24: Epoch 0 train loss: 2639.557373046875\nINFO:root:32: Epoch 0 train loss: 14.027192115783691\nINFO:root:20: Epoch 0 train loss: 441983.25\nINFO:root:3: Epoch 0 train loss: 2369.454833984375\nINFO:root:0: Epoch 0 validation loss: 859.7197290764625\nINFO:root:12: Epoch 1 train loss: 9065.5087890625\nINFO:root:14: Epoch 1 train loss: 2216.152587890625\nINFO:root:13: Epoch 1 train loss: 448979.09375\nINFO:root:15: Epoch 1 train loss: 839.8758544921875\nINFO:root:39: Epoch 1 train loss: 7269.84326171875\nINFO:root:38: Epoch 1 train loss: 52787.3984375\nINFO:root:30: Epoch 1 train loss: 429771.40625\nINFO:root:31: Epoch 1 train loss: 3760.291748046875\nINFO:root:37: Epoch 1 train loss: 747.6902465820312\nINFO:root:7: Epoch 1 train loss: 121.30623626708984\nINFO:root:8: Epoch 1 train loss: 274.68634033203125\nINFO:root:16: Epoch 1 train loss: 347317.0625\nINFO:root:9: Epoch 1 train loss: 349536.625\nINFO:root:6: Epoch 1 train loss: 2071.678955078125\nINFO:root:21: Epoch 1 train loss: 3507.878662109375\nINFO:root:20: Epoch 1 train loss: 3737.46875\nINFO:root:5: Epoch 1 train loss: 100.81674194335938\nINFO:root:34: Epoch 1 train loss: 48002.7421875\nINFO:root:10: Epoch 1 train loss: 2367.903076171875\nINFO:root:2: Epoch 1 train loss: 565.0230102539062\nINFO:root:1: Epoch 1 train loss: 778591.875\nINFO:root:3: Epoch 1 train loss: 49949.6328125\nINFO:root:0: Epoch 1 train loss: 531.553466796875\nINFO:root:4: Epoch 1 train loss: 4221.1123046875\nINFO:root:24: Epoch 1 train loss: 144474.96875\nINFO:root:33: Epoch 1 train loss: 595.449462890625\nINFO:root:29: Epoch 1 train loss: 4411.15283203125\nINFO:root:18: Epoch 1 train loss: 1385.11865234375\nINFO:root:36: Epoch 1 train loss: 1447.0489501953125\nINFO:root:23: Epoch 1 train loss: 2506.134521484375\nINFO:root:11: Epoch 1 train loss: 410473.53125\nINFO:root:27: Epoch 1 train loss: 55476.51171875\nINFO:root:28: Epoch 1 train loss: 2408.489013671875\nINFO:root:22: Epoch 1 train loss: 1254.3846435546875\nINFO:root:25: Epoch 1 train loss: 375627.875\nINFO:root:35: Epoch 1 train loss: 87.96424102783203\nINFO:root:17: Epoch 1 train loss: 3013.841796875\nINFO:root:26: Epoch 1 train loss: 44.64286422729492\nINFO:root:32: Epoch 1 train loss: 3755.594482421875\nINFO:root:19: Epoch 1 train loss: 355305.75\nINFO:root:0: Epoch 1 validation loss: 859.2766677034895\nINFO:root:2: Epoch 2 train loss: 6883.966796875\nINFO:root:3: Epoch 2 train loss: 1174.2510986328125\nINFO:root:4: Epoch 2 train loss: 72.41248321533203\nINFO:root:5: Epoch 2 train loss: 579.3045043945312\nINFO:root:38: Epoch 2 train loss: 432512.4375\nINFO:root:7: Epoch 2 train loss: 6343.43505859375\nINFO:root:39: Epoch 2 train loss: 1762.386474609375\nINFO:root:34: Epoch 2 train loss: 3919.056640625\nINFO:root:35: Epoch 2 train loss: 262.48876953125\nINFO:root:31: Epoch 2 train loss: 1026.578125\nINFO:root:23: Epoch 2 train loss: 2408.544677734375\nINFO:root:6: Epoch 2 train loss: 95.74079132080078\nINFO:root:8: Epoch 2 train loss: 2154.146240234375\nINFO:root:9: Epoch 2 train loss: 2905.373291015625\nINFO:root:16: Epoch 2 train loss: 1544.8531494140625\nINFO:root:28: Epoch 2 train loss: 3825.4951171875\nINFO:root:25: Epoch 2 train loss: 2949.755615234375\nINFO:root:30: Epoch 2 train loss: 4370.78076171875\nINFO:root:29: Epoch 2 train loss: 465471.25\nINFO:root:14: Epoch 2 train loss: 8410.1962890625\nINFO:root:19: Epoch 2 train loss: 1272.736328125\nINFO:root:11: Epoch 2 train loss: 253.64385986328125\nINFO:root:10: Epoch 2 train loss: 872.288818359375\nINFO:root:27: Epoch 2 train loss: 114.31591033935547\nINFO:root:15: Epoch 2 train loss: 32.176021575927734\nINFO:root:18: Epoch 2 train loss: 431378.65625\nINFO:root:26: Epoch 2 train loss: 403.4534606933594\nINFO:root:13: Epoch 2 train loss: 1474.99560546875\nINFO:root:17: Epoch 2 train loss: 505.79931640625\nINFO:root:21: Epoch 2 train loss: 2437.07275390625\nINFO:root:22: Epoch 2 train loss: 995.9683227539062\nINFO:root:20: Epoch 2 train loss: 416183.3125\nINFO:root:24: Epoch 2 train loss: 9486.0859375\nINFO:root:1: Epoch 2 train loss: 95.43428802490234\nINFO:root:0: Epoch 2 train loss: 147124.6875\nINFO:root:37: Epoch 2 train loss: 1261.561279296875\nINFO:root:12: Epoch 2 train loss: 841.2997436523438\nINFO:root:32: Epoch 2 train loss: 441389.53125\nINFO:root:36: Epoch 2 train loss: 889.8751831054688\nINFO:root:33: Epoch 2 train loss: 2132.20068359375\nINFO:root:0: Epoch 2 validation loss: 858.824808750986\nINFO:root:39: Epoch 3 train loss: 359.8062744140625\nINFO:root:38: Epoch 3 train loss: 2974.727783203125\nINFO:root:2: Epoch 3 train loss: 2723.700927734375\nINFO:root:4: Epoch 3 train loss: 1920.362060546875\nINFO:root:35: Epoch 3 train loss: 1333.4486083984375\nINFO:root:5: Epoch 3 train loss: 426658.625\nINFO:root:14: Epoch 3 train loss: 1628.402099609375\nINFO:root:15: Epoch 3 train loss: 501.9118347167969\nINFO:root:23: Epoch 3 train loss: 3840.375732421875\nINFO:root:20: Epoch 3 train loss: 9987.1103515625\nINFO:root:21: Epoch 3 train loss: 1341.9493408203125\nINFO:root:13: Epoch 3 train loss: 6331.1337890625\nINFO:root:12: Epoch 3 train loss: 1461.7176513671875\nINFO:root:0: Epoch 3 train loss: 1038.185302734375\nINFO:root:6: Epoch 3 train loss: 50.08885955810547\nINFO:root:26: Epoch 3 train loss: 83.19115447998047\nINFO:root:33: Epoch 3 train loss: 8555.05859375\nINFO:root:31: Epoch 3 train loss: 1028.114990234375\nINFO:root:19: Epoch 3 train loss: 8503.0595703125\nINFO:root:34: Epoch 3 train loss: 761.0711059570312\nINFO:root:30: Epoch 3 train loss: 400.43890380859375\nINFO:root:17: Epoch 3 train loss: 3052.64892578125\nINFO:root:7: Epoch 3 train loss: 1715.9630126953125\nINFO:root:25: Epoch 3 train loss: 4221.94482421875\nINFO:root:32: Epoch 3 train loss: 1611.5322265625\nINFO:root:18: Epoch 3 train loss: 119.16885375976562\nINFO:root:24: Epoch 3 train loss: 15441.5068359375\nINFO:root:16: Epoch 3 train loss: 441191.625\nINFO:root:1: Epoch 3 train loss: 445.0664978027344\nINFO:root:3: Epoch 3 train loss: 14814.5517578125\nINFO:root:22: Epoch 3 train loss: 397.0009765625\nINFO:root:10: Epoch 3 train loss: 1525.809326171875\nINFO:root:8: Epoch 3 train loss: 1540.1724853515625\nINFO:root:9: Epoch 3 train loss: 578.828857421875\nINFO:root:11: Epoch 3 train loss: 7022.43408203125\nINFO:root:28: Epoch 3 train loss: 10051.1181640625\nINFO:root:29: Epoch 3 train loss: 1449.93212890625\nINFO:root:36: Epoch 3 train loss: 1276.2374267578125\nINFO:root:37: Epoch 3 train loss: 1668.23828125\nINFO:root:27: Epoch 3 train loss: 4802.96875\nINFO:root:0: Epoch 3 validation loss: 858.3687317210221\nINFO:root:7: Epoch 4 train loss: 3209.16259765625\nINFO:root:39: Epoch 4 train loss: 47906.55859375\nINFO:root:31: Epoch 4 train loss: 369090.25\nINFO:root:35: Epoch 4 train loss: 1111.8087158203125\nINFO:root:34: Epoch 4 train loss: 15964.1953125\nINFO:root:38: Epoch 4 train loss: 1518.34521484375\nINFO:root:36: Epoch 4 train loss: 78.5053482055664\nINFO:root:8: Epoch 4 train loss: 466894.125\nINFO:root:15: Epoch 4 train loss: 2771.7294921875\nINFO:root:33: Epoch 4 train loss: 3684.136962890625\nINFO:root:3: Epoch 4 train loss: 1518.2652587890625\nINFO:root:0: Epoch 4 train loss: 537.7579956054688\nINFO:root:2: Epoch 4 train loss: 1331.0316162109375\nINFO:root:14: Epoch 4 train loss: 3135.3349609375\nINFO:root:23: Epoch 4 train loss: 1318.9676513671875\nINFO:root:6: Epoch 4 train loss: 335.6219482421875\nINFO:root:27: Epoch 4 train loss: 76.97286224365234\nINFO:root:29: Epoch 4 train loss: 447.8996276855469\nINFO:root:37: Epoch 4 train loss: 2371.232421875\nINFO:root:17: Epoch 4 train loss: 659.930908203125\nINFO:root:16: Epoch 4 train loss: 1507.600341796875\nINFO:root:11: Epoch 4 train loss: 263.0046691894531\nINFO:root:4: Epoch 4 train loss: 207.1004180908203\nINFO:root:28: Epoch 4 train loss: 918023.4375\nINFO:root:1: Epoch 4 train loss: 9826.5107421875\nINFO:root:30: Epoch 4 train loss: 796625.9375\nINFO:root:9: Epoch 4 train loss: 4072.11962890625\nINFO:root:5: Epoch 4 train loss: 411646.875\nINFO:root:32: Epoch 4 train loss: 3036.738037109375\nINFO:root:21: Epoch 4 train loss: 417548.9375\nINFO:root:26: Epoch 4 train loss: 462242.25\nINFO:root:19: Epoch 4 train loss: 694.7921752929688\nINFO:root:20: Epoch 4 train loss: 7431.3115234375\nINFO:root:13: Epoch 4 train loss: 1443.0516357421875\nINFO:root:12: Epoch 4 train loss: 436.6134033203125\nINFO:root:18: Epoch 4 train loss: 12542.765625\nINFO:root:25: Epoch 4 train loss: 1861.34765625\nINFO:root:24: Epoch 4 train loss: 511555.90625\nINFO:root:10: Epoch 4 train loss: 3309.2861328125\nINFO:root:22: Epoch 4 train loss: 144418.21875\nINFO:root:0: Epoch 4 validation loss: 857.9146555341983\nINFO:root:14: Epoch 5 train loss: 49367.53515625\nINFO:root:13: Epoch 5 train loss: 913.2213745117188\nINFO:root:15: Epoch 5 train loss: 183.44065856933594\nINFO:root:12: Epoch 5 train loss: 686.8231201171875\nINFO:root:31: Epoch 5 train loss: 4425.6748046875\nINFO:root:11: Epoch 5 train loss: 1984.6595458984375\nINFO:root:10: Epoch 5 train loss: 11365.455078125\nINFO:root:16: Epoch 5 train loss: 7438.6259765625\nINFO:root:26: Epoch 5 train loss: 10572.1416015625\nINFO:root:27: Epoch 5 train loss: 574.4691162109375\nINFO:root:32: Epoch 5 train loss: 1990.8756103515625\nINFO:root:33: Epoch 5 train loss: 222.11221313476562\nINFO:root:35: Epoch 5 train loss: 449132.625\nINFO:root:34: Epoch 5 train loss: 146.67283630371094\nINFO:root:17: Epoch 5 train loss: 18650.2734375\nINFO:root:21: Epoch 5 train loss: 983.9811401367188\nINFO:root:23: Epoch 5 train loss: 821.8378295898438\nINFO:root:20: Epoch 5 train loss: 2888.455810546875\nINFO:root:22: Epoch 5 train loss: 48660.92578125\nINFO:root:30: Epoch 5 train loss: 441438.65625\nINFO:root:28: Epoch 5 train loss: 1179.8402099609375\nINFO:root:36: Epoch 5 train loss: 6408.22216796875\nINFO:root:39: Epoch 5 train loss: 2496.501220703125\nINFO:root:18: Epoch 5 train loss: 263.4030456542969\nINFO:root:37: Epoch 5 train loss: 16075.4287109375\nINFO:root:38: Epoch 5 train loss: 3808.858642578125\nINFO:root:19: Epoch 5 train loss: 350728.25\nINFO:root:24: Epoch 5 train loss: 382.7170715332031\nINFO:root:25: Epoch 5 train loss: 1115.455078125\nINFO:root:29: Epoch 5 train loss: 2535.607177734375\nINFO:root:9: Epoch 5 train loss: 1767.4512939453125\nINFO:root:8: Epoch 5 train loss: 427209.9375\nINFO:root:1: Epoch 5 train loss: 2045.9923095703125\nINFO:root:0: Epoch 5 train loss: 813.121826171875\nINFO:root:7: Epoch 5 train loss: 4856.83837890625\nINFO:root:6: Epoch 5 train loss: 570653.625\nINFO:root:5: Epoch 5 train loss: 1864.736083984375\nINFO:root:4: Epoch 5 train loss: 2108.760009765625\nINFO:root:2: Epoch 5 train loss: 506.545166015625\nINFO:root:3: Epoch 5 train loss: 8382.5146484375\nINFO:root:0: Epoch 5 validation loss: 857.4455911912032\n", "seconds": 23.64018702507019, "batch_size": 256, "nodes": 10, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n1 Start Epoch 0\n1: 1 batches\n2 Start Epoch 0\n2: 1 batches\n4 Start Epoch 0\n4: 1 batches\n3 Start Epoch 0\n3: 1 batches\n43 Start Epoch 0\n43: 1 batches\n11 Start Epoch 0\n27 Start Epoch 0\n11: 1 batches\n27: 1 batches\n8 Start Epoch 0\n36 Start Epoch 0\n8: 1 batches\n36: 1 batches\n35 Start Epoch 0\n20 Start Epoch 0\n20: 1 batches\n35: 1 batches\n6 Start Epoch 0\n19 Start Epoch 0\n32 Start Epoch 0\n5 Start Epoch 0\n16 Start Epoch 0\n32: 1 batches\n6: 1 batches\n19: 1 batches\n16: 1 batches\n5: 1 batches\n28 Start Epoch 0\n28: 1 batches\n7 Start Epoch 0\n7: 1 batches\n31 Start Epoch 0\n31: 1 batches\n15 Start Epoch 0\n15: 1 batches\n12 Start Epoch 0\n12: 1 batches\n24 Start Epoch 0\n24: 1 batches\n23 Start Epoch 0\n17 Start Epoch 0\n40 Start Epoch 0\n18 Start Epoch 0\n23: 1 batches\n39 Start Epoch 0\n40: 1 batches\n10 Start Epoch 0\n17: 1 batches\n33 Start Epoch 0\n18: 1 batches\n34 Start Epoch 0\n39: 1 batches\n9 Start Epoch 0\n10: 1 batches\n33: 1 batches\n9: 1 batches\n34: 1 batches\n13 Start Epoch 0\n29 Start Epoch 0\n30 Start Epoch 0\n14 Start Epoch 0\n21 Start Epoch 0\n29: 1 batches\n13: 1 batches\n41 Start Epoch 0\n25 Start Epoch 0\n42 Start Epoch 0\n25: 1 batches\n22 Start Epoch 0\n30: 1 batches\n14: 1 batches\n41: 1 batches\n26 Start Epoch 0\n21: 1 batches\n42: 1 batches\n26: 1 batches\n22: 1 batches\n37 Start Epoch 0\n38 Start Epoch 0\n38: 1 batches\n37: 1 batches\n6 Start Epoch 1\n13 Start Epoch 1\n5 Start Epoch 1\n14 Start Epoch 1\n6: 1 batches\n12 Start Epoch 1\n5: 1 batches\n13: 1 batches\n14: 1 batches\n30 Start Epoch 1\n30: 1 batches\n7 Start Epoch 1\n7: 1 batches\n15 Start Epoch 1\n31 Start Epoch 1\n31: 1 batches\n15: 1 batches\n37 Start Epoch 1\n4 Start Epoch 1\n12: 1 batches\n38 Start Epoch 1\n36 Start Epoch 1\n4: 1 batches\n37: 1 batches\n39 Start Epoch 1\n38: 1 batches\n39: 1 batches\n36: 1 batches\n27 Start Epoch 1\n42 Start Epoch 1\n27: 1 batches\n16 Start Epoch 1\n17 Start Epoch 1\n23 Start Epoch 1\n43 Start Epoch 1\n17: 1 batches\n22 Start Epoch 1\n32 Start Epoch 1\n43: 1 batches\n10 Start Epoch 1\n10: 1 batches\n42: 1 batches\n11 Start Epoch 1\n11: 1 batches\n16: 1 batches\n22: 1 batches\n33 Start Epoch 1\n23: 1 batches\n33: 1 batches\n18 Start Epoch 1\n32: 1 batches\n18: 1 batches\n19 Start Epoch 1\n34 Start Epoch 1\n19: 1 batches\n35 Start Epoch 1\n35: 1 batches\n34: 1 batches\n8 Start Epoch 1\n8: 1 batches\n9 Start Epoch 1\n9: 1 batches\n40 Start Epoch 1\n21 Start Epoch 1\n41 Start Epoch 1\n1 Start Epoch 1\n1: 1 batches\n41: 1 batches\n20 Start Epoch 1\n21: 1 batches\n40: 1 batches\n25 Start Epoch 1\n20: 1 batches\n24 Start Epoch 1\n24: 1 batches\n25: 1 batches\n26 Start Epoch 1\n26: 1 batches\n3 Start Epoch 1\n2 Start Epoch 1\n3: 1 batches\n2: 1 batches\n28 Start Epoch 1\n28: 1 batches\n29 Start Epoch 1\n29: 1 batches\n0 Start Epoch 1\n0: 1 batches\n39 Start Epoch 2\n39: 1 batches\n37 Start Epoch 2\n38 Start Epoch 2\n37: 1 batches\n38: 1 batches\n41 Start Epoch 2\n42 Start Epoch 2\n43 Start Epoch 2\n43: 1 batches\n41: 1 batches\n40 Start Epoch 2\n40: 1 batches\n42: 1 batches\n35 Start Epoch 2\n35: 1 batches\n36 Start Epoch 2\n36: 1 batches\n34 Start Epoch 2\n34: 1 batches\n1 Start Epoch 2\n15 Start Epoch 2\n15: 1 batches\n17 Start Epoch 2\n17: 1 batches\n26 Start Epoch 2\n1: 1 batches\n26: 1 batches\n23 Start Epoch 2\n19 Start Epoch 2\n22 Start Epoch 2\n25 Start Epoch 2\n19: 1 batches\n25: 1 batches\n18 Start Epoch 2\n21 Start Epoch 2\n18: 1 batches\n20 Start Epoch 2\n21: 1 batches\n20: 1 batches\n22: 1 batches\n23: 1 batches\n16 Start Epoch 2\n16: 1 batches\n30 Start Epoch 2\n30: 1 batches\n7 Start Epoch 2\n31 Start Epoch 2\n31: 1 batches\n7: 1 batches\n10 Start Epoch 2\n28 Start Epoch 2\n28: 1 batches\n8 Start Epoch 2\n29 Start Epoch 2\n29: 1 batches\n11 Start Epoch 2\n10: 1 batches\n8: 1 batches\n9 Start Epoch 2\n9: 1 batches\n11: 1 batches\n3 Start Epoch 2\n3: 1 batches\n12 Start Epoch 2\n12: 1 batches\n2 Start Epoch 2\n2: 1 batches\n6 Start Epoch 2\n6: 1 batches\n5 Start Epoch 2\n5: 1 batches\n4 Start Epoch 2\n4: 1 batches\n27 Start Epoch 2\n24 Start Epoch 2\n24: 1 batches\n27: 1 batches\n32 Start Epoch 2\n33 Start Epoch 2\n32: 1 batches\n33: 1 batches\n14 Start Epoch 2\n14: 1 batches\n13 Start Epoch 2\n13: 1 batches\n0 Start Epoch 2\n0: 1 batches\n7 Start Epoch 3\n34 Start Epoch 3\n34: 1 batches\n35 Start Epoch 3\n3 Start Epoch 3\n35: 1 batches\n8 Start Epoch 3\n8: 1 batches\n37 Start Epoch 3\n9 Start Epoch 3\n7: 1 batches\n38 Start Epoch 3\n42 Start Epoch 3\n6 Start Epoch 3\n6: 1 batches\n38: 1 batches\n41 Start Epoch 3\n37: 1 batches\n9: 1 batches\n40 Start Epoch 3\n41: 1 batches\n30 Start Epoch 3\n31 Start Epoch 3\n4 Start Epoch 3\n40: 1 batches\n43 Start Epoch 3\n24 Start Epoch 3\n31: 1 batches\n5 Start Epoch 3\n43: 1 batches\n42: 1 batches\n25 Start Epoch 3\n5: 1 batches\n4: 1 batches\n3: 1 batches\n25: 1 batches\n24: 1 batches\n30: 1 batches\n13 Start Epoch 3\n14 Start Epoch 3\n12 Start Epoch 3\n39 Start Epoch 3\n13: 1 batches\n14: 1 batches\n15 Start Epoch 3\n26 Start Epoch 3\n26: 1 batches\n18 Start Epoch 3\n18: 1 batches\n19 Start Epoch 3\n19: 1 batches\n21 Start Epoch 3\n22 Start Epoch 3\n36 Start Epoch 3\n11 Start Epoch 3\n23 Start Epoch 3\n10 Start Epoch 3\n21: 1 batches\n10: 1 batches\n22: 1 batches\n23: 1 batches\n28 Start Epoch 3\n15: 1 batches\n39: 1 batches\n11: 1 batches\n27 Start Epoch 3\n20 Start Epoch 3\n28: 1 batches\n12: 1 batches\n27: 1 batches\n20: 1 batches\n29 Start Epoch 3\n29: 1 batches\n16 Start Epoch 3\n16: 1 batches\n32 Start Epoch 3\n32: 1 batches\n17 Start Epoch 3\n17: 1 batches\n36: 1 batches\n33 Start Epoch 3\n33: 1 batches\n2 Start Epoch 3\n2: 1 batches\n1 Start Epoch 3\n1: 1 batches\n0 Start Epoch 3\n0: 1 batches\n7 Start Epoch 4\n7: 1 batches\n6 Start Epoch 4\n3 Start Epoch 4\n3: 1 batches\n6: 1 batches\n15 Start Epoch 4\n15: 1 batches\n19 Start Epoch 4\n29 Start Epoch 4\n11 Start Epoch 4\n5 Start Epoch 4\n11: 1 batches\n19: 1 batches\n21 Start Epoch 4\n43 Start Epoch 4\n21: 1 batches\n35 Start Epoch 4\n5: 1 batches\n41 Start Epoch 4\n16 Start Epoch 4\n20 Start Epoch 4\n35: 1 batches\n41: 1 batches\n16: 1 batches\n20: 1 batches\n43: 1 batches\n40 Start Epoch 4\n40: 1 batches\n18 Start Epoch 4\n18: 1 batches\n9 Start Epoch 4\n8 Start Epoch 4\n9: 1 batches\n8: 1 batches\n33 Start Epoch 4\n42 Start Epoch 4\n33: 1 batches\n31 Start Epoch 4\n31: 1 batches\n42: 1 batches\n23 Start Epoch 4\n28 Start Epoch 4\n28: 1 batches\n10 Start Epoch 4\n22 Start Epoch 4\n34 Start Epoch 4\n34: 1 batches\n22: 1 batches\n10: 1 batches\n26 Start Epoch 4\n32 Start Epoch 4\n29: 1 batches\n25 Start Epoch 4\n23: 1 batches\n25: 1 batches\n26: 1 batches\n30 Start Epoch 4\n32: 1 batches\n17 Start Epoch 4\n17: 1 batches\n27 Start Epoch 4\n37 Start Epoch 4\n37: 1 batches\n36 Start Epoch 4\n36: 1 batches\n38 Start Epoch 4\n38: 1 batches\n24 Start Epoch 4\n24: 1 batches\n27: 1 batches\n4 Start Epoch 4\n4: 1 batches\n14 Start Epoch 4\n14: 1 batches\n39 Start Epoch 4\n39: 1 batches\n30: 1 batches\n13 Start Epoch 4\n13: 1 batches\n2 Start Epoch 4\n2: 1 batches\n1 Start Epoch 4\n1: 1 batches\n12 Start Epoch 4\n12: 1 batches\n0 Start Epoch 4\n0: 1 batches\n15 Start Epoch 5\n7 Start Epoch 5\n15: 1 batches\n7: 1 batches\n6 Start Epoch 5\n6: 1 batches\n31 Start Epoch 5\n5 Start Epoch 5\n42 Start Epoch 5\n9 Start Epoch 5\n9: 1 batches\n20 Start Epoch 5\n20: 1 batches\n31: 1 batches\n21 Start Epoch 5\n21: 1 batches\n13 Start Epoch 5\n37 Start Epoch 5\n42: 1 batches\n8 Start Epoch 5\n8: 1 batches\n4 Start Epoch 5\n14 Start Epoch 5\n43 Start Epoch 5\n5: 1 batches\n14: 1 batches\n39 Start Epoch 5\n43: 1 batches\n11 Start Epoch 5\n11: 1 batches\n30 Start Epoch 5\n4: 1 batches\n13: 1 batches\n36 Start Epoch 5\n17 Start Epoch 5\n33 Start Epoch 5\n19 Start Epoch 5\n34 Start Epoch 5\n29 Start Epoch 5\n12 Start Epoch 5\n37: 1 batches\n10 Start Epoch 5\n27 Start Epoch 5\n36: 1 batches\n10: 1 batches\n26 Start Epoch 5\n26: 1 batches\n1 Start Epoch 5\n1: 1 batches\n17: 1 batches\n30: 1 batches\n12: 1 batches\n29: 1 batches\n38 Start Epoch 5\n25 Start Epoch 5\n25: 1 batches\n19: 1 batches\n18 Start Epoch 5\n33: 1 batches\n28 Start Epoch 5\n38: 1 batches\n27: 1 batches\n28: 1 batches\n39: 1 batches\n18: 1 batches\n34: 1 batches\n35 Start Epoch 5\n32 Start Epoch 5\n35: 1 batches\n32: 1 batches\n3 Start Epoch 5\n3: 1 batches\n41 Start Epoch 5\n40 Start Epoch 5\n40: 1 batches\n41: 1 batches\n16 Start Epoch 5\n16: 1 batches\n2 Start Epoch 5\n2: 1 batches\n24 Start Epoch 5\n24: 1 batches\n23 Start Epoch 5\n23: 1 batches\n22 Start Epoch 5\n22: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:15: Epoch 0 train loss: 816.8896484375\nINFO:root:5: Epoch 0 train loss: 2180.87060546875\nINFO:root:13: Epoch 0 train loss: 841.8311767578125\nINFO:root:7: Epoch 0 train loss: 4494.86865234375\nINFO:root:12: Epoch 0 train loss: 488212.375\nINFO:root:6: Epoch 0 train loss: 1565.8385009765625\nINFO:root:14: Epoch 0 train loss: 382414.96875\nINFO:root:38: Epoch 0 train loss: 569153.75\nINFO:root:37: Epoch 0 train loss: 10748.490234375\nINFO:root:39: Epoch 0 train loss: 154.50112915039062\nINFO:root:31: Epoch 0 train loss: 509.1608581542969\nINFO:root:36: Epoch 0 train loss: 859.1143188476562\nINFO:root:4: Epoch 0 train loss: 1736.3302001953125\nINFO:root:30: Epoch 0 train loss: 34.04499053955078\nINFO:root:0: Epoch 0 train loss: 1490.045166015625\nINFO:root:42: Epoch 0 train loss: 3919.25927734375\nINFO:root:27: Epoch 0 train loss: 216.69073486328125\nINFO:root:17: Epoch 0 train loss: 8097.31884765625\nINFO:root:43: Epoch 0 train loss: 521.9057006835938\nINFO:root:16: Epoch 0 train loss: 376.1751708984375\nINFO:root:22: Epoch 0 train loss: 1081.6767578125\nINFO:root:23: Epoch 0 train loss: 6826.5595703125\nINFO:root:32: Epoch 0 train loss: 962400.8125\nINFO:root:33: Epoch 0 train loss: 159174.890625\nINFO:root:10: Epoch 0 train loss: 373.1898498535156\nINFO:root:18: Epoch 0 train loss: 7410.53662109375\nINFO:root:11: Epoch 0 train loss: 376.1397705078125\nINFO:root:34: Epoch 0 train loss: 7255.4208984375\nINFO:root:19: Epoch 0 train loss: 231.9459686279297\nINFO:root:35: Epoch 0 train loss: 766.64208984375\nINFO:root:8: Epoch 0 train loss: 2880.0654296875\nINFO:root:9: Epoch 0 train loss: 72.51007080078125\nINFO:root:40: Epoch 0 train loss: 54094.66015625\nINFO:root:41: Epoch 0 train loss: 444.741943359375\nINFO:root:21: Epoch 0 train loss: 2447.310791015625\nINFO:root:24: Epoch 0 train loss: 509412.28125\nINFO:root:1: Epoch 0 train loss: 159321.578125\nINFO:root:20: Epoch 0 train loss: 470346.03125\nINFO:root:25: Epoch 0 train loss: 872976.75\nINFO:root:26: Epoch 0 train loss: 721.3692016601562\nINFO:root:3: Epoch 0 train loss: 385567.71875\nINFO:root:2: Epoch 0 train loss: 568545.5\nINFO:root:29: Epoch 0 train loss: 16281.7958984375\nINFO:root:28: Epoch 0 train loss: 2322.882568359375\nINFO:root:0: Epoch 0 validation loss: 11207.694270149837\nINFO:root:39: Epoch 1 train loss: 145.7474365234375\nINFO:root:37: Epoch 1 train loss: 161978.53125\nINFO:root:38: Epoch 1 train loss: 2700.064453125\nINFO:root:41: Epoch 1 train loss: 819.3306274414062\nINFO:root:43: Epoch 1 train loss: 2300.79638671875\nINFO:root:42: Epoch 1 train loss: 163.39906311035156\nINFO:root:40: Epoch 1 train loss: 564550.25\nINFO:root:35: Epoch 1 train loss: 2695.044189453125\nINFO:root:36: Epoch 1 train loss: 4856.810546875\nINFO:root:34: Epoch 1 train loss: 159670.03125\nINFO:root:0: Epoch 1 train loss: 3532.05615234375\nINFO:root:1: Epoch 1 train loss: 2155.614990234375\nINFO:root:17: Epoch 1 train loss: 2334.810546875\nINFO:root:15: Epoch 1 train loss: 329.8863525390625\nINFO:root:26: Epoch 1 train loss: 2790.196533203125\nINFO:root:23: Epoch 1 train loss: 505.5149230957031\nINFO:root:22: Epoch 1 train loss: 1476.337646484375\nINFO:root:19: Epoch 1 train loss: 3383.540771484375\nINFO:root:25: Epoch 1 train loss: 747.9977416992188\nINFO:root:21: Epoch 1 train loss: 3362.137451171875\nINFO:root:18: Epoch 1 train loss: 115.24970245361328\nINFO:root:20: Epoch 1 train loss: 383665.96875\nINFO:root:16: Epoch 1 train loss: 1646.0279541015625\nINFO:root:7: Epoch 1 train loss: 80.00532531738281\nINFO:root:10: Epoch 1 train loss: 1354.5712890625\nINFO:root:11: Epoch 1 train loss: 563954.5\nINFO:root:31: Epoch 1 train loss: 1685.5789794921875\nINFO:root:8: Epoch 1 train loss: 823.9954833984375\nINFO:root:9: Epoch 1 train loss: 138.28448486328125\nINFO:root:30: Epoch 1 train loss: 2486.175537109375\nINFO:root:29: Epoch 1 train loss: 3065.398681640625\nINFO:root:28: Epoch 1 train loss: 3534.322998046875\nINFO:root:3: Epoch 1 train loss: 3189.340087890625\nINFO:root:12: Epoch 1 train loss: 1899.5260009765625\nINFO:root:2: Epoch 1 train loss: 198.55130004882812\nINFO:root:5: Epoch 1 train loss: 4331.98974609375\nINFO:root:6: Epoch 1 train loss: 2161.31884765625\nINFO:root:4: Epoch 1 train loss: 1751.4521484375\nINFO:root:27: Epoch 1 train loss: 160299.796875\nINFO:root:24: Epoch 1 train loss: 4210.93896484375\nINFO:root:33: Epoch 1 train loss: 405391.75\nINFO:root:32: Epoch 1 train loss: 466.10748291015625\nINFO:root:14: Epoch 1 train loss: 13894.5439453125\nINFO:root:13: Epoch 1 train loss: 2011.7939453125\nINFO:root:0: Epoch 1 validation loss: 11206.481185043423\nINFO:root:7: Epoch 2 train loss: 70.982177734375\nINFO:root:6: Epoch 2 train loss: 1192.1513671875\nINFO:root:35: Epoch 2 train loss: 2989.31689453125\nINFO:root:34: Epoch 2 train loss: 1187.7864990234375\nINFO:root:3: Epoch 2 train loss: 1455.825439453125\nINFO:root:8: Epoch 2 train loss: 1204.3468017578125\nINFO:root:37: Epoch 2 train loss: 7334.646484375\nINFO:root:42: Epoch 2 train loss: 1234.41552734375\nINFO:root:41: Epoch 2 train loss: 4855.0224609375\nINFO:root:9: Epoch 2 train loss: 4683.716796875\nINFO:root:38: Epoch 2 train loss: 382506.75\nINFO:root:43: Epoch 2 train loss: 1434.008056640625\nINFO:root:40: Epoch 2 train loss: 6202.38330078125\nINFO:root:30: Epoch 2 train loss: 1130.131103515625\nINFO:root:31: Epoch 2 train loss: 1507.087646484375\nINFO:root:24: Epoch 2 train loss: 1588.442626953125\nINFO:root:5: Epoch 2 train loss: 281.59033203125\nINFO:root:25: Epoch 2 train loss: 4623.7646484375\nINFO:root:4: Epoch 2 train loss: 2045.1278076171875\nINFO:root:12: Epoch 2 train loss: 4007.18896484375\nINFO:root:13: Epoch 2 train loss: 385216.6875\nINFO:root:15: Epoch 2 train loss: 564590.4375\nINFO:root:14: Epoch 2 train loss: 475036.375\nINFO:root:39: Epoch 2 train loss: 6054.63671875\nINFO:root:26: Epoch 2 train loss: 194.38809204101562\nINFO:root:19: Epoch 2 train loss: 2889.355712890625\nINFO:root:18: Epoch 2 train loss: 37.488677978515625\nINFO:root:21: Epoch 2 train loss: 1938.0364990234375\nINFO:root:23: Epoch 2 train loss: 53387.28125\nINFO:root:10: Epoch 2 train loss: 920.4578857421875\nINFO:root:11: Epoch 2 train loss: 4732.396484375\nINFO:root:22: Epoch 2 train loss: 195.39938354492188\nINFO:root:36: Epoch 2 train loss: 9157.87109375\nINFO:root:28: Epoch 2 train loss: 3986.503662109375\nINFO:root:29: Epoch 2 train loss: 5784.53173828125\nINFO:root:27: Epoch 2 train loss: 564001.125\nINFO:root:20: Epoch 2 train loss: 6640.88720703125\nINFO:root:16: Epoch 2 train loss: 408186.71875\nINFO:root:17: Epoch 2 train loss: 307.1219177246094\nINFO:root:32: Epoch 2 train loss: 151.4896240234375\nINFO:root:33: Epoch 2 train loss: 4529.033203125\nINFO:root:1: Epoch 2 train loss: 9432.8779296875\nINFO:root:2: Epoch 2 train loss: 565037.5\nINFO:root:0: Epoch 2 train loss: 568082.125\nINFO:root:0: Epoch 2 validation loss: 11205.260063653233\nINFO:root:7: Epoch 3 train loss: 3087.750244140625\nINFO:root:6: Epoch 3 train loss: 4374.4375\nINFO:root:3: Epoch 3 train loss: 763.0263061523438\nINFO:root:21: Epoch 3 train loss: 161217.640625\nINFO:root:29: Epoch 3 train loss: 5956.3642578125\nINFO:root:41: Epoch 3 train loss: 2861.98974609375\nINFO:root:11: Epoch 3 train loss: 5776.376953125\nINFO:root:19: Epoch 3 train loss: 580.0133666992188\nINFO:root:20: Epoch 3 train loss: 54048.81640625\nINFO:root:5: Epoch 3 train loss: 52955.56640625\nINFO:root:40: Epoch 3 train loss: 2034.8671875\nINFO:root:43: Epoch 3 train loss: 159998.28125\nINFO:root:35: Epoch 3 train loss: 1142.6121826171875\nINFO:root:16: Epoch 3 train loss: 207.09710693359375\nINFO:root:31: Epoch 3 train loss: 164.71485900878906\nINFO:root:9: Epoch 3 train loss: 488234.46875\nINFO:root:18: Epoch 3 train loss: 1365.4952392578125\nINFO:root:8: Epoch 3 train loss: 3591.07421875\nINFO:root:33: Epoch 3 train loss: 563308.375\nINFO:root:42: Epoch 3 train loss: 2111.889892578125\nINFO:root:30: Epoch 3 train loss: 2064.9423828125\nINFO:root:22: Epoch 3 train loss: 32.43364334106445\nINFO:root:28: Epoch 3 train loss: 112.94926452636719\nINFO:root:10: Epoch 3 train loss: 1420.3916015625\nINFO:root:23: Epoch 3 train loss: 2783.95263671875\nINFO:root:34: Epoch 3 train loss: 1536.5230712890625\nINFO:root:25: Epoch 3 train loss: 1419.0643310546875\nINFO:root:26: Epoch 3 train loss: 176.92552185058594\nINFO:root:32: Epoch 3 train loss: 8469.4052734375\nINFO:root:15: Epoch 3 train loss: 1706.40771484375\nINFO:root:17: Epoch 3 train loss: 1428.0665283203125\nINFO:root:27: Epoch 3 train loss: 4421.3046875\nINFO:root:37: Epoch 3 train loss: 2087.791015625\nINFO:root:38: Epoch 3 train loss: 17133.673828125\nINFO:root:36: Epoch 3 train loss: 7416.74365234375\nINFO:root:24: Epoch 3 train loss: 10289.1279296875\nINFO:root:4: Epoch 3 train loss: 563264.875\nINFO:root:14: Epoch 3 train loss: 11365.1416015625\nINFO:root:39: Epoch 3 train loss: 90.91657257080078\nINFO:root:13: Epoch 3 train loss: 4932.05859375\nINFO:root:1: Epoch 3 train loss: 3534.56494140625\nINFO:root:0: Epoch 3 train loss: 4172.984375\nINFO:root:2: Epoch 3 train loss: 1137.4345703125\nINFO:root:12: Epoch 3 train loss: 3520.819091796875\nINFO:root:0: Epoch 3 validation loss: 11204.025287618026\nINFO:root:6: Epoch 4 train loss: 95.19660949707031\nINFO:root:15: Epoch 4 train loss: 354.86865234375\nINFO:root:7: Epoch 4 train loss: 10800.4765625\nINFO:root:20: Epoch 4 train loss: 3919.380126953125\nINFO:root:31: Epoch 4 train loss: 408073.53125\nINFO:root:14: Epoch 4 train loss: 840.8374633789062\nINFO:root:39: Epoch 4 train loss: 7026.73046875\nINFO:root:42: Epoch 4 train loss: 245.53955078125\nINFO:root:9: Epoch 4 train loss: 1492.4666748046875\nINFO:root:4: Epoch 4 train loss: 492.21990966796875\nINFO:root:12: Epoch 4 train loss: 383847.21875\nINFO:root:38: Epoch 4 train loss: 242.8030548095703\nINFO:root:43: Epoch 4 train loss: 71.65253448486328\nINFO:root:8: Epoch 4 train loss: 174.94349670410156\nINFO:root:21: Epoch 4 train loss: 2904.97021484375\nINFO:root:13: Epoch 4 train loss: 341.9850769042969\nINFO:root:37: Epoch 4 train loss: 422.646728515625\nINFO:root:17: Epoch 4 train loss: 69446.6015625\nINFO:root:30: Epoch 4 train loss: 720.2015380859375\nINFO:root:5: Epoch 4 train loss: 60.58101272583008\nINFO:root:29: Epoch 4 train loss: 3268.070556640625\nINFO:root:36: Epoch 4 train loss: 455641.15625\nINFO:root:11: Epoch 4 train loss: 95.70831298828125\nINFO:root:27: Epoch 4 train loss: 469.3575439453125\nINFO:root:18: Epoch 4 train loss: 1952.46826171875\nINFO:root:33: Epoch 4 train loss: 157.11021423339844\nINFO:root:28: Epoch 4 train loss: 3608.71044921875\nINFO:root:25: Epoch 4 train loss: 1406.1551513671875\nINFO:root:19: Epoch 4 train loss: 3004.906982421875\nINFO:root:35: Epoch 4 train loss: 233.7487335205078\nINFO:root:10: Epoch 4 train loss: 922.0634155273438\nINFO:root:26: Epoch 4 train loss: 6865.45849609375\nINFO:root:0: Epoch 4 train loss: 554.6707153320312\nINFO:root:1: Epoch 4 train loss: 160263.46875\nINFO:root:32: Epoch 4 train loss: 158.1434783935547\nINFO:root:34: Epoch 4 train loss: 159471.578125\nINFO:root:3: Epoch 4 train loss: 181.7478485107422\nINFO:root:41: Epoch 4 train loss: 189.89210510253906\nINFO:root:40: Epoch 4 train loss: 1007.0929565429688\nINFO:root:16: Epoch 4 train loss: 1141.456298828125\nINFO:root:2: Epoch 4 train loss: 1128.8148193359375\nINFO:root:24: Epoch 4 train loss: 3276.734619140625\nINFO:root:23: Epoch 4 train loss: 652.1830444335938\nINFO:root:22: Epoch 4 train loss: 455615.65625\nINFO:root:0: Epoch 4 validation loss: 11202.797358616544\nINFO:root:3: Epoch 5 train loss: 179.11512756347656\nINFO:root:14: Epoch 5 train loss: 6242.248046875\nINFO:root:39: Epoch 5 train loss: 486092.625\nINFO:root:10: Epoch 5 train loss: 267.716064453125\nINFO:root:16: Epoch 5 train loss: 1247.033447265625\nINFO:root:23: Epoch 5 train loss: 2582.518310546875\nINFO:root:35: Epoch 5 train loss: 17726.095703125\nINFO:root:31: Epoch 5 train loss: 972.580078125\nINFO:root:15: Epoch 5 train loss: 471469.8125\nINFO:root:38: Epoch 5 train loss: 3847.736083984375\nINFO:root:11: Epoch 5 train loss: 77.85584259033203\nINFO:root:0: Epoch 5 train loss: 94.89271545410156\nINFO:root:17: Epoch 5 train loss: 570991.25\nINFO:root:21: Epoch 5 train loss: 5059.5126953125\nINFO:root:30: Epoch 5 train loss: 87.15482330322266\nINFO:root:7: Epoch 5 train loss: 478.65777587890625\nINFO:root:13: Epoch 5 train loss: 563533.0625\nINFO:root:37: Epoch 5 train loss: 3167.251708984375\nINFO:root:40: Epoch 5 train loss: 148.68702697753906\nINFO:root:25: Epoch 5 train loss: 2541.9169921875\nINFO:root:18: Epoch 5 train loss: 9586.7607421875\nINFO:root:22: Epoch 5 train loss: 3318.78857421875\nINFO:root:33: Epoch 5 train loss: 9283.66796875\nINFO:root:12: Epoch 5 train loss: 3833.938720703125\nINFO:root:36: Epoch 5 train loss: 1098.790771484375\nINFO:root:43: Epoch 5 train loss: 12120.8935546875\nINFO:root:26: Epoch 5 train loss: 771.4993896484375\nINFO:root:20: Epoch 5 train loss: 5706.693359375\nINFO:root:34: Epoch 5 train loss: 1429.107421875\nINFO:root:29: Epoch 5 train loss: 1599.0289306640625\nINFO:root:6: Epoch 5 train loss: 1434.4697265625\nINFO:root:32: Epoch 5 train loss: 2697.06884765625\nINFO:root:28: Epoch 5 train loss: 4227.65625\nINFO:root:1: Epoch 5 train loss: 4791.88671875\nINFO:root:2: Epoch 5 train loss: 292.4369201660156\nINFO:root:19: Epoch 5 train loss: 499.068115234375\nINFO:root:41: Epoch 5 train loss: 162495.9375\nINFO:root:42: Epoch 5 train loss: 952.0140991210938\nINFO:root:24: Epoch 5 train loss: 461347.8125\nINFO:root:4: Epoch 5 train loss: 2745.819580078125\nINFO:root:5: Epoch 5 train loss: 455235.25\nINFO:root:27: Epoch 5 train loss: 1720.938232421875\nINFO:root:9: Epoch 5 train loss: 17052.90625\nINFO:root:8: Epoch 5 train loss: 1671.560791015625\nINFO:root:0: Epoch 5 validation loss: 11201.547165645865\n", "seconds": 23.842493057250977, "batch_size": 256, "nodes": 11, "processes_per_node": 4, "threads_per_process": 1}, {"command": "source ~/susml/jakob_torben/bin/activate && mpirun --host 192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12,192.168.2.15,192.168.2.2,192.168.2.3,192.168.2.4,192.168.2.5,192.168.2.6,192.168.2.7,192.168.2.8,192.168.2.9,192.168.2.10,192.168.2.11,192.168.2.12 bash -c 'source ~/susml/jakob_torben/bin/activate && python ~/susml/jakob_torben/src/corona/main.py --stacked-layer 1 --hidden-units 32 --dropout 0 --batch-size 256 --epochs 6'", "stdout": "0 Start Epoch 0\n0: 1 batches\n47 Start Epoch 0\n1 Start Epoch 0\n1: 1 batches\n47: 1 batches\n2 Start Epoch 0\n2: 1 batches\n3 Start Epoch 0\n3: 1 batches\n4 Start Epoch 0\n4: 1 batches\n6 Start Epoch 0\n6: 1 batches\n5 Start Epoch 0\n5: 1 batches\n8 Start Epoch 0\n39 Start Epoch 0\n8: 1 batches\n39: 1 batches\n16 Start Epoch 0\n16: 1 batches\n32 Start Epoch 0\n31 Start Epoch 0\n7 Start Epoch 0\n32: 1 batches\n31: 1 batches\n7: 1 batches\n23 Start Epoch 0\n13 Start Epoch 0\n13: 1 batches\n24 Start Epoch 0\n40 Start Epoch 0\n23: 1 batches\n38 Start Epoch 0\n14 Start Epoch 0\n14: 1 batches\n24: 1 batches\n40: 1 batches\n37 Start Epoch 0\n37: 1 batches\n15 Start Epoch 0\n15: 1 batches\n38: 1 batches\n12 Start Epoch 0\n12: 1 batches\n36 Start Epoch 0\n36: 1 batches\n27 Start Epoch 0\n43 Start Epoch 0\n11 Start Epoch 0\n44 Start Epoch 0\n28 Start Epoch 0\n27: 1 batches\n43: 1 batches\n11: 1 batches\n44: 1 batches\n22 Start Epoch 0\n28: 1 batches\n35 Start Epoch 0\n21 Start Epoch 0\n17 Start Epoch 0\n9 Start Epoch 0\n33 Start Epoch 0\n46 Start Epoch 0\n22: 1 batches\n30 Start Epoch 0\n18 Start Epoch 0\n21: 1 batches\n18: 1 batches\n9: 1 batches\n35: 1 batches\n46: 1 batches\n34 Start Epoch 0\n30: 1 batches\n19 Start Epoch 0\n10 Start Epoch 0\n34: 1 batches\n45 Start Epoch 0\n20 Start Epoch 0\n29 Start Epoch 0\n19: 1 batches\n10: 1 batches\n33: 1 batches\n45: 1 batches\n20: 1 batches\n29: 1 batches\n17: 1 batches\n25 Start Epoch 0\n41 Start Epoch 0\n26 Start Epoch 0\n42 Start Epoch 0\n26: 1 batches\n41: 1 batches\n25: 1 batches\n42: 1 batches\n39 Start Epoch 1\n15 Start Epoch 1\n43 Start Epoch 1\n39: 1 batches\n15: 1 batches\n1 Start Epoch 1\n1: 1 batches\n3 Start Epoch 1\n3: 1 batches\n43: 1 batches\n6 Start Epoch 1\n45 Start Epoch 1\n23 Start Epoch 1\n38 Start Epoch 1\n4 Start Epoch 1\n5 Start Epoch 1\n46 Start Epoch 1\n38: 1 batches\n12 Start Epoch 1\n21 Start Epoch 1\n36 Start Epoch 1\n13 Start Epoch 1\n30 Start Epoch 1\n16 Start Epoch 1\n24 Start Epoch 1\n6: 1 batches\n10 Start Epoch 1\n35 Start Epoch 1\n33 Start Epoch 1\n47 Start Epoch 1\n21: 1 batches\n36: 1 batches\n14 Start Epoch 1\n28 Start Epoch 1\n18 Start Epoch 1\n25 Start Epoch 1\n4: 1 batches\n9 Start Epoch 1\n22 Start Epoch 1\n14: 1 batches\n31 Start Epoch 1\n17 Start Epoch 1\n27 Start Epoch 1\n7 Start Epoch 1\n8 Start Epoch 1\n8: 1 batches\n32 Start Epoch 1\n46: 1 batches\n18: 1 batches\n24: 1 batches\n7: 1 batches\n9: 1 batches\n35: 1 batches\n47: 1 batches\n22: 1 batches\n37 Start Epoch 1\n12: 1 batches\n28: 1 batches\n5: 1 batches\n11 Start Epoch 1\n32: 1 batches\n45: 1 batches\n37: 1 batches\n13: 1 batches\n30: 1 batches\n16: 1 batches\n27: 1 batches\n20 Start Epoch 1\n29 Start Epoch 1\n19 Start Epoch 1\n26 Start Epoch 1\n42 Start Epoch 1\n11: 1 batches\n34 Start Epoch 1\n10: 1 batches\n34: 1 batches\n44 Start Epoch 1\n23: 1 batches\n29: 1 batches\n19: 1 batches\n26: 1 batches\n42: 1 batches\n31: 1 batches\n17: 1 batches\n25: 1 batches\n33: 1 batches\n44: 1 batches\n20: 1 batches\n40 Start Epoch 1\n41 Start Epoch 1\n41: 1 batches\n40: 1 batches\n2 Start Epoch 1\n2: 1 batches\n0 Start Epoch 1\n0: 1 batches\n39 Start Epoch 2\n39: 1 batches\n41 Start Epoch 2\n41: 1 batches\n47 Start Epoch 2\n47: 1 batches\n45 Start Epoch 2\n43 Start Epoch 2\n45: 1 batches\n43: 1 batches\n44 Start Epoch 2\n44: 1 batches\n46 Start Epoch 2\n40 Start Epoch 2\n46: 1 batches\n42 Start Epoch 2\n42: 1 batches\n40: 1 batches\n1 Start Epoch 2\n1: 1 batches\n4 Start Epoch 2\n14 Start Epoch 2\n14: 1 batches\n6 Start Epoch 2\n6: 1 batches\n5 Start Epoch 2\n4: 1 batches\n7 Start Epoch 2\n7: 1 batches\n5: 1 batches\n3 Start Epoch 2\n3: 1 batches\n31 Start Epoch 2\n31: 1 batches\n18 Start Epoch 2\n37 Start Epoch 2\n18: 1 batches\n35 Start Epoch 2\n20 Start Epoch 2\n38 Start Epoch 2\n19 Start Epoch 2\n27 Start Epoch 2\n8 Start Epoch 2\n19: 1 batches\n24 Start Epoch 2\n9 Start Epoch 2\n32 Start Epoch 2\n21 Start Epoch 2\n38: 1 batches\n25 Start Epoch 2\n10 Start Epoch 2\n33 Start Epoch 2\n23 Start Epoch 2\n37: 1 batches\n9: 1 batches\n35: 1 batches\n20: 1 batches\n36 Start Epoch 2\n16 Start Epoch 2\n27: 1 batches\n24: 1 batches\n8: 1 batches\n32: 1 batches\n21: 1 batches\n36: 1 batches\n17 Start Epoch 2\n26 Start Epoch 2\n11 Start Epoch 2\n34 Start Epoch 2\n22 Start Epoch 2\n11: 1 batches\n34: 1 batches\n22: 1 batches\n16: 1 batches\n26: 1 batches\n33: 1 batches\n23: 1 batches\n17: 1 batches\n25: 1 batches\n10: 1 batches\n2 Start Epoch 2\n2: 1 batches\n13 Start Epoch 2\n13: 1 batches\n28 Start Epoch 2\n12 Start Epoch 2\n12: 1 batches\n28: 1 batches\n15 Start Epoch 2\n15: 1 batches\n30 Start Epoch 2\n30: 1 batches\n29 Start Epoch 2\n29: 1 batches\n0 Start Epoch 2\n0: 1 batches\n6 Start Epoch 3\n36 Start Epoch 3\n7 Start Epoch 3\n39 Start Epoch 3\n38 Start Epoch 3\n38: 1 batches\n36: 1 batches\n39: 1 batches\n37 Start Epoch 3\n37: 1 batches\n7: 1 batches\n47 Start Epoch 3\n47: 1 batches\n31 Start Epoch 3\n41 Start Epoch 3\n42 Start Epoch 3\n31: 1 batches\n41: 1 batches\n15 Start Epoch 3\n15: 1 batches\n21 Start Epoch 3\n42: 1 batches\n23 Start Epoch 3\n21: 1 batches\n19 Start Epoch 3\n16 Start Epoch 3\n20 Start Epoch 3\n23: 1 batches\n16: 1 batches\n33 Start Epoch 3\n19: 1 batches\n27 Start Epoch 3\n32 Start Epoch 3\n20: 1 batches\n25 Start Epoch 3\n35 Start Epoch 3\n24 Start Epoch 3\n8 Start Epoch 3\n35: 1 batches\n24: 1 batches\n10 Start Epoch 3\n32: 1 batches\n27: 1 batches\n4 Start Epoch 3\n9 Start Epoch 3\n34 Start Epoch 3\n34: 1 batches\n26 Start Epoch 3\n4: 1 batches\n9: 1 batches\n26: 1 batches\n43 Start Epoch 3\n8: 1 batches\n33: 1 batches\n25: 1 batches\n5 Start Epoch 3\n11 Start Epoch 3\n5: 1 batches\n11: 1 batches\n43: 1 batches\n10: 1 batches\n40 Start Epoch 3\n40: 1 batches\n1 Start Epoch 3\n1: 1 batches\n2 Start Epoch 3\n2: 1 batches\n3 Start Epoch 3\n3: 1 batches\n6: 1 batches\n30 Start Epoch 3\n17 Start Epoch 3\n30: 1 batches\n18 Start Epoch 3\n17: 1 batches\n45 Start Epoch 3\n44 Start Epoch 3\n18: 1 batches\n44: 1 batches\n46 Start Epoch 3\n46: 1 batches\n45: 1 batches\n28 Start Epoch 3\n28: 1 batches\n22 Start Epoch 3\n14 Start Epoch 3\n14: 1 batches\n13 Start Epoch 3\n13: 1 batches\n29 Start Epoch 3\n22: 1 batches\n12 Start Epoch 3\n12: 1 batches\n29: 1 batches\n0 Start Epoch 3\n0: 1 batches\n6 Start Epoch 4\n6: 1 batches\n7 Start Epoch 4\n7: 1 batches\n39 Start Epoch 4\n31 Start Epoch 4\n36 Start Epoch 4\n31: 1 batches\n39: 1 batches\n5 Start Epoch 4\n5: 1 batches\n38 Start Epoch 4\n38: 1 batches\n36: 1 batches\n35 Start Epoch 4\n33 Start Epoch 4\n32 Start Epoch 4\n35: 1 batches\n32: 1 batches\n34 Start Epoch 4\n34: 1 batches\n4 Start Epoch 4\n33: 1 batches\n8 Start Epoch 4\n9 Start Epoch 4\n8: 1 batches\n9: 1 batches\n4: 1 batches\n3 Start Epoch 4\n3: 1 batches\n1 Start Epoch 4\n1: 1 batches\n2 Start Epoch 4\n2: 1 batches\n43 Start Epoch 4\n47 Start Epoch 4\n47: 1 batches\n25 Start Epoch 4\n10 Start Epoch 4\n14 Start Epoch 4\n29 Start Epoch 4\n14: 1 batches\n29: 1 batches\n16 Start Epoch 4\n27 Start Epoch 4\n40 Start Epoch 4\n11 Start Epoch 4\n15 Start Epoch 4\n30 Start Epoch 4\n18 Start Epoch 4\n43: 1 batches\n10: 1 batches\n46 Start Epoch 4\n40: 1 batches\n11: 1 batches\n45 Start Epoch 4\n23 Start Epoch 4\n15: 1 batches\n30: 1 batches\n19 Start Epoch 4\n26 Start Epoch 4\n45: 1 batches\n20 Start Epoch 4\n13 Start Epoch 4\n13: 1 batches\n26: 1 batches\n16: 1 batches\n27: 1 batches\n46: 1 batches\n21 Start Epoch 4\n28 Start Epoch 4\n20: 1 batches\n28: 1 batches\n17 Start Epoch 4\n25: 1 batches\n42 Start Epoch 4\n23: 1 batches\n12 Start Epoch 4\n12: 1 batches\n19: 1 batches\n41 Start Epoch 4\n44 Start Epoch 4\n22 Start Epoch 4\n18: 1 batches\n24 Start Epoch 4\n42: 1 batches\n44: 1 batches\n24: 1 batches\n41: 1 batches\n22: 1 batches\n17: 1 batches\n21: 1 batches\n37 Start Epoch 4\n37: 1 batches\n0 Start Epoch 4\n0: 1 batches\n43 Start Epoch 5\n15 Start Epoch 5\n43: 1 batches\n15: 1 batches\n8 Start Epoch 5\n8: 1 batches\n45 Start Epoch 5\n14 Start Epoch 5\n13 Start Epoch 5\n35 Start Epoch 5\n44 Start Epoch 5\n33 Start Epoch 5\n44: 1 batches\n45: 1 batches\n14: 1 batches\n32 Start Epoch 5\n13: 1 batches\n35: 1 batches\n34 Start Epoch 5\n12 Start Epoch 5\n32: 1 batches\n12: 1 batches\n11 Start Epoch 5\n34: 1 batches\n33: 1 batches\n27 Start Epoch 5\n29 Start Epoch 5\n27: 1 batches\n10 Start Epoch 5\n21 Start Epoch 5\n21: 1 batches\n28 Start Epoch 5\n17 Start Epoch 5\n10: 1 batches\n29: 1 batches\n19 Start Epoch 5\n28: 1 batches\n18 Start Epoch 5\n17: 1 batches\n18: 1 batches\n19: 1 batches\n16 Start Epoch 5\n26 Start Epoch 5\n9 Start Epoch 5\n36 Start Epoch 5\n36: 1 batches\n22 Start Epoch 5\n39 Start Epoch 5\n39: 1 batches\n31 Start Epoch 5\n16: 1 batches\n26: 1 batches\n11: 1 batches\n22: 1 batches\n31: 1 batches\n40 Start Epoch 5\n25 Start Epoch 5\n41 Start Epoch 5\n38 Start Epoch 5\n38: 1 batches\n30 Start Epoch 5\n25: 1 batches\n41: 1 batches\n20 Start Epoch 5\n23 Start Epoch 5\n42 Start Epoch 5\n9: 1 batches\n24 Start Epoch 5\n42: 1 batches\n23: 1 batches\n24: 1 batches\n40: 1 batches\n46 Start Epoch 5\n20: 1 batches\n37 Start Epoch 5\n37: 1 batches\n46: 1 batches\n47 Start Epoch 5\n47: 1 batches\n7 Start Epoch 5\n7: 1 batches\n1 Start Epoch 5\n1: 1 batches\n30: 1 batches\n3 Start Epoch 5\n3: 1 batches\n4 Start Epoch 5\n4: 1 batches\n6 Start Epoch 5\n6: 1 batches\n2 Start Epoch 5\n2: 1 batches\n5 Start Epoch 5\n5: 1 batches\n0 Start Epoch 5\n0: 1 batches\n", "stderr": "INFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Create trainer\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Create model\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create model\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Create trainer\nINFO:root:Start DataLoader\nINFO:root:Preprocessed data found. Skip preprocessing.\nINFO:root:Create model\nINFO:root:Create trainer\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:Train model...\nINFO:root:5: Epoch 0 train loss: 3493.478271484375\nINFO:root:39: Epoch 0 train loss: 1373.2015380859375\nINFO:root:15: Epoch 0 train loss: 496796.96875\nINFO:root:43: Epoch 0 train loss: 233.9114532470703\nINFO:root:6: Epoch 0 train loss: 2235.869140625\nINFO:root:0: Epoch 0 train loss: 348.88275146484375\nINFO:root:1: Epoch 0 train loss: 25.571998596191406\nINFO:root:3: Epoch 0 train loss: 3155.826416015625\nINFO:root:7: Epoch 0 train loss: 675.9051513671875\nINFO:root:4: Epoch 0 train loss: 2081.317138671875\nINFO:root:8: Epoch 0 train loss: 690734.8125\nINFO:root:32: Epoch 0 train loss: 3258.551513671875\nINFO:root:45: Epoch 0 train loss: 5243.505859375\nINFO:root:21: Epoch 0 train loss: 1497.18896484375\nINFO:root:38: Epoch 0 train loss: 265.296630859375\nINFO:root:13: Epoch 0 train loss: 174879.078125\nINFO:root:28: Epoch 0 train loss: 133.3370361328125\nINFO:root:16: Epoch 0 train loss: 620166.6875\nINFO:root:26: Epoch 0 train loss: 2473.943603515625\nINFO:root:22: Epoch 0 train loss: 838.5629272460938\nINFO:root:36: Epoch 0 train loss: 161.87892150878906\nINFO:root:12: Epoch 0 train loss: 498319.15625\nINFO:root:29: Epoch 0 train loss: 541298.5625\nINFO:root:19: Epoch 0 train loss: 3496.807373046875\nINFO:root:27: Epoch 0 train loss: 132.29444885253906\nINFO:root:9: Epoch 0 train loss: 147.90545654296875\nINFO:root:35: Epoch 0 train loss: 2429.410888671875\nINFO:root:10: Epoch 0 train loss: 560111.5\nINFO:root:34: Epoch 0 train loss: 2452.596923828125\nINFO:root:46: Epoch 0 train loss: 271.15496826171875\nINFO:root:14: Epoch 0 train loss: 2652.2275390625\nINFO:root:30: Epoch 0 train loss: 125.46800994873047\nINFO:root:17: Epoch 0 train loss: 142.43374633789062\nINFO:root:24: Epoch 0 train loss: 2182.021240234375\nINFO:root:31: Epoch 0 train loss: 4023.94580078125\nINFO:root:18: Epoch 0 train loss: 14416.9609375\nINFO:root:25: Epoch 0 train loss: 176296.796875\nINFO:root:11: Epoch 0 train loss: 1921.9395751953125\nINFO:root:33: Epoch 0 train loss: 5641.79052734375\nINFO:root:23: Epoch 0 train loss: 1050.02490234375\nINFO:root:47: Epoch 0 train loss: 94.33521270751953\nINFO:root:37: Epoch 0 train loss: 1127.4981689453125\nINFO:root:20: Epoch 0 train loss: 216.64601135253906\nINFO:root:42: Epoch 0 train loss: 70.38641357421875\nINFO:root:44: Epoch 0 train loss: 2885.467529296875\nINFO:root:41: Epoch 0 train loss: 740.1538696289062\nINFO:root:40: Epoch 0 train loss: 175697.953125\nINFO:root:2: Epoch 0 train loss: 365.7441711425781\nINFO:root:0: Epoch 0 validation loss: 105913.34852330887\nINFO:root:39: Epoch 1 train loss: 1283.3267822265625\nINFO:root:41: Epoch 1 train loss: 94.17293548583984\nINFO:root:47: Epoch 1 train loss: 5498.57861328125\nINFO:root:45: Epoch 1 train loss: 314.2019958496094\nINFO:root:43: Epoch 1 train loss: 233.85633850097656\nINFO:root:44: Epoch 1 train loss: 2812.323486328125\nINFO:root:46: Epoch 1 train loss: 597.0177001953125\nINFO:root:40: Epoch 1 train loss: 356.55670166015625\nINFO:root:0: Epoch 1 train loss: 133.48289489746094\nINFO:root:42: Epoch 1 train loss: 392.94891357421875\nINFO:root:1: Epoch 1 train loss: 206.63710021972656\nINFO:root:6: Epoch 1 train loss: 230.67405700683594\nINFO:root:7: Epoch 1 train loss: 174816.453125\nINFO:root:15: Epoch 1 train loss: 636.3045654296875\nINFO:root:4: Epoch 1 train loss: 232.27593994140625\nINFO:root:5: Epoch 1 train loss: 1822.6951904296875\nINFO:root:14: Epoch 1 train loss: 339.7052307128906\nINFO:root:3: Epoch 1 train loss: 4235.8115234375\nINFO:root:32: Epoch 1 train loss: 1616.107666015625\nINFO:root:23: Epoch 1 train loss: 2985.70654296875\nINFO:root:37: Epoch 1 train loss: 348.98321533203125\nINFO:root:31: Epoch 1 train loss: 19610.3671875\nINFO:root:19: Epoch 1 train loss: 1599.5465087890625\nINFO:root:26: Epoch 1 train loss: 264.329833984375\nINFO:root:11: Epoch 1 train loss: 1092.1436767578125\nINFO:root:33: Epoch 1 train loss: 9230.466796875\nINFO:root:22: Epoch 1 train loss: 1838.704833984375\nINFO:root:36: Epoch 1 train loss: 11471.2607421875\nINFO:root:18: Epoch 1 train loss: 222.3719482421875\nINFO:root:27: Epoch 1 train loss: 190.01693725585938\nINFO:root:8: Epoch 1 train loss: 1419.7850341796875\nINFO:root:38: Epoch 1 train loss: 137.8681640625\nINFO:root:24: Epoch 1 train loss: 445641.875\nINFO:root:9: Epoch 1 train loss: 283.00567626953125\nINFO:root:35: Epoch 1 train loss: 534160.25\nINFO:root:20: Epoch 1 train loss: 5881.3876953125\nINFO:root:10: Epoch 1 train loss: 18449.55078125\nINFO:root:34: Epoch 1 train loss: 14055.7060546875\nINFO:root:21: Epoch 1 train loss: 3489.550048828125\nINFO:root:25: Epoch 1 train loss: 1047.1051025390625\nINFO:root:16: Epoch 1 train loss: 620.11279296875\nINFO:root:17: Epoch 1 train loss: 287.5989074707031\nINFO:root:2: Epoch 1 train loss: 446396.25\nINFO:root:13: Epoch 1 train loss: 643100.375\nINFO:root:28: Epoch 1 train loss: 17404.55859375\nINFO:root:12: Epoch 1 train loss: 621773.9375\nINFO:root:30: Epoch 1 train loss: 255.4412078857422\nINFO:root:29: Epoch 1 train loss: 560839.1875\nINFO:root:0: Epoch 1 validation loss: 105909.94108427387\nINFO:root:36: Epoch 2 train loss: 1786.2972412109375\nINFO:root:6: Epoch 2 train loss: 1692.390380859375\nINFO:root:38: Epoch 2 train loss: 558763.125\nINFO:root:7: Epoch 2 train loss: 2780.003173828125\nINFO:root:39: Epoch 2 train loss: 10112.3828125\nINFO:root:37: Epoch 2 train loss: 516533.09375\nINFO:root:47: Epoch 2 train loss: 678734.6875\nINFO:root:41: Epoch 2 train loss: 420228.15625\nINFO:root:31: Epoch 2 train loss: 562575.125\nINFO:root:42: Epoch 2 train loss: 2845.677490234375\nINFO:root:23: Epoch 2 train loss: 4231.51708984375\nINFO:root:15: Epoch 2 train loss: 1492.9288330078125\nINFO:root:20: Epoch 2 train loss: 19099.21484375\nINFO:root:21: Epoch 2 train loss: 421806.875\nINFO:root:19: Epoch 2 train loss: 111.97547912597656\nINFO:root:34: Epoch 2 train loss: 5315.927734375\nINFO:root:16: Epoch 2 train loss: 400.584228515625\nINFO:root:26: Epoch 2 train loss: 1331.351806640625\nINFO:root:32: Epoch 2 train loss: 18.815963745117188\nINFO:root:27: Epoch 2 train loss: 1185.7117919921875\nINFO:root:33: Epoch 2 train loss: 467.9391784667969\nINFO:root:24: Epoch 2 train loss: 1422.76806640625\nINFO:root:11: Epoch 2 train loss: 2033.4495849609375\nINFO:root:35: Epoch 2 train loss: 2788.606201171875\nINFO:root:25: Epoch 2 train loss: 3222.48095703125\nINFO:root:10: Epoch 2 train loss: 403.8546142578125\nINFO:root:8: Epoch 2 train loss: 618166.0625\nINFO:root:9: Epoch 2 train loss: 968.5010375976562\nINFO:root:4: Epoch 2 train loss: 3383.852294921875\nINFO:root:43: Epoch 2 train loss: 233.2217559814453\nINFO:root:5: Epoch 2 train loss: 10683.9521484375\nINFO:root:40: Epoch 2 train loss: 3247.208740234375\nINFO:root:1: Epoch 2 train loss: 1342.6810302734375\nINFO:root:0: Epoch 2 train loss: 560146.8125\nINFO:root:17: Epoch 2 train loss: 2249.900390625\nINFO:root:3: Epoch 2 train loss: 501967.15625\nINFO:root:2: Epoch 2 train loss: 1664.8702392578125\nINFO:root:45: Epoch 2 train loss: 175377.578125\nINFO:root:30: Epoch 2 train loss: 534523.6875\nINFO:root:18: Epoch 2 train loss: 935603.9375\nINFO:root:44: Epoch 2 train loss: 5402.01025390625\nINFO:root:46: Epoch 2 train loss: 1184.5155029296875\nINFO:root:28: Epoch 2 train loss: 559039.125\nINFO:root:22: Epoch 2 train loss: 419445.78125\nINFO:root:14: Epoch 2 train loss: 2033.5250244140625\nINFO:root:13: Epoch 2 train loss: 559262.875\nINFO:root:29: Epoch 2 train loss: 18876.3359375\nINFO:root:12: Epoch 2 train loss: 561017.9375\nINFO:root:0: Epoch 2 validation loss: 105906.81356463318\nINFO:root:7: Epoch 3 train loss: 3516.786865234375\nINFO:root:6: Epoch 3 train loss: 17747.8359375\nINFO:root:39: Epoch 3 train loss: 619268.0625\nINFO:root:31: Epoch 3 train loss: 1181.26904296875\nINFO:root:5: Epoch 3 train loss: 2046.0599365234375\nINFO:root:36: Epoch 3 train loss: 175926.5\nINFO:root:35: Epoch 3 train loss: 96.22301483154297\nINFO:root:38: Epoch 3 train loss: 4649.32275390625\nINFO:root:34: Epoch 3 train loss: 3115.594482421875\nINFO:root:32: Epoch 3 train loss: 4390.96875\nINFO:root:33: Epoch 3 train loss: 3001.3447265625\nINFO:root:4: Epoch 3 train loss: 1797.9471435546875\nINFO:root:8: Epoch 3 train loss: 2741.947509765625\nINFO:root:9: Epoch 3 train loss: 2349.8017578125\nINFO:root:0: Epoch 3 train loss: 672.359130859375\nINFO:root:3: Epoch 3 train loss: 15773.998046875\nINFO:root:1: Epoch 3 train loss: 376.8685302734375\nINFO:root:11: Epoch 3 train loss: 1530.4031982421875\nINFO:root:47: Epoch 3 train loss: 1715.2105712890625\nINFO:root:14: Epoch 3 train loss: 174814.765625\nINFO:root:29: Epoch 3 train loss: 3540.854248046875\nINFO:root:16: Epoch 3 train loss: 6745.75537109375\nINFO:root:27: Epoch 3 train loss: 433.2392883300781\nINFO:root:43: Epoch 3 train loss: 581.08642578125\nINFO:root:15: Epoch 3 train loss: 157.6683807373047\nINFO:root:2: Epoch 3 train loss: 533601.75\nINFO:root:30: Epoch 3 train loss: 1747.92431640625\nINFO:root:17: Epoch 3 train loss: 499175.3125\nINFO:root:25: Epoch 3 train loss: 60886.875\nINFO:root:10: Epoch 3 train loss: 2532.363037109375\nINFO:root:20: Epoch 3 train loss: 1268.842041015625\nINFO:root:40: Epoch 3 train loss: 3557.60595703125\nINFO:root:45: Epoch 3 train loss: 230.64871215820312\nINFO:root:22: Epoch 3 train loss: 67.56929016113281\nINFO:root:19: Epoch 3 train loss: 19621.333984375\nINFO:root:23: Epoch 3 train loss: 174461.59375\nINFO:root:46: Epoch 3 train loss: 8164.728515625\nINFO:root:26: Epoch 3 train loss: 517084.3125\nINFO:root:21: Epoch 3 train loss: 67.02144622802734\nINFO:root:28: Epoch 3 train loss: 1290.5863037109375\nINFO:root:18: Epoch 3 train loss: 395.5921936035156\nINFO:root:42: Epoch 3 train loss: 2404.863037109375\nINFO:root:41: Epoch 3 train loss: 2501.243896484375\nINFO:root:13: Epoch 3 train loss: 102.7235336303711\nINFO:root:44: Epoch 3 train loss: 421.1695556640625\nINFO:root:12: Epoch 3 train loss: 10786.9873046875\nINFO:root:24: Epoch 3 train loss: 8376.6025390625\nINFO:root:37: Epoch 3 train loss: 543.1842041015625\nINFO:root:0: Epoch 3 validation loss: 105903.63051539255\nINFO:root:15: Epoch 4 train loss: 7362.31005859375\nINFO:root:43: Epoch 4 train loss: 109.67601776123047\nINFO:root:8: Epoch 4 train loss: 755.1411743164062\nINFO:root:33: Epoch 4 train loss: 560442.6875\nINFO:root:45: Epoch 4 train loss: 4000.15185546875\nINFO:root:35: Epoch 4 train loss: 620.89306640625\nINFO:root:44: Epoch 4 train loss: 10033.0556640625\nINFO:root:14: Epoch 4 train loss: 420428.0625\nINFO:root:34: Epoch 4 train loss: 803.0755615234375\nINFO:root:13: Epoch 4 train loss: 6866.42041015625\nINFO:root:32: Epoch 4 train loss: 5695.7431640625\nINFO:root:12: Epoch 4 train loss: 420277.0\nINFO:root:10: Epoch 4 train loss: 390.6500244140625\nINFO:root:29: Epoch 4 train loss: 500.703369140625\nINFO:root:18: Epoch 4 train loss: 168.0406036376953\nINFO:root:27: Epoch 4 train loss: 57872.3828125\nINFO:root:11: Epoch 4 train loss: 1017.3412475585938\nINFO:root:28: Epoch 4 train loss: 559429.875\nINFO:root:17: Epoch 4 train loss: 4433.7783203125\nINFO:root:19: Epoch 4 train loss: 1540.659423828125\nINFO:root:21: Epoch 4 train loss: 724.2230224609375\nINFO:root:9: Epoch 4 train loss: 10260.8642578125\nINFO:root:23: Epoch 4 train loss: 619928.875\nINFO:root:31: Epoch 4 train loss: 4658.619140625\nINFO:root:16: Epoch 4 train loss: 408.2755126953125\nINFO:root:26: Epoch 4 train loss: 4097.4873046875\nINFO:root:42: Epoch 4 train loss: 776.728515625\nINFO:root:40: Epoch 4 train loss: 447039.0\nINFO:root:22: Epoch 4 train loss: 4573.4345703125\nINFO:root:30: Epoch 4 train loss: 628586.0\nINFO:root:41: Epoch 4 train loss: 427886.1875\nINFO:root:36: Epoch 4 train loss: 248.55697631835938\nINFO:root:25: Epoch 4 train loss: 4551.54345703125\nINFO:root:20: Epoch 4 train loss: 4337.50634765625\nINFO:root:0: Epoch 4 train loss: 515901.59375\nINFO:root:39: Epoch 4 train loss: 408.8656005859375\nINFO:root:47: Epoch 4 train loss: 4115.86083984375\nINFO:root:37: Epoch 4 train loss: 849.3116455078125\nINFO:root:24: Epoch 4 train loss: 619839.0625\nINFO:root:46: Epoch 4 train loss: 24.55767250061035\nINFO:root:38: Epoch 4 train loss: 5554.62451171875\nINFO:root:6: Epoch 4 train loss: 6085.79736328125\nINFO:root:7: Epoch 4 train loss: 156.35507202148438\nINFO:root:1: Epoch 4 train loss: 4532.9462890625\nINFO:root:3: Epoch 4 train loss: 10815.8955078125\nINFO:root:4: Epoch 4 train loss: 180.71923828125\nINFO:root:2: Epoch 4 train loss: 130.28836059570312\nINFO:root:5: Epoch 4 train loss: 1625.00537109375\nINFO:root:0: Epoch 4 validation loss: 105900.45149229885\nINFO:root:4: Epoch 5 train loss: 427.4203796386719\nINFO:root:32: Epoch 5 train loss: 559581.75\nINFO:root:39: Epoch 5 train loss: 446480.21875\nINFO:root:15: Epoch 5 train loss: 621967.8125\nINFO:root:6: Epoch 5 train loss: 4833.9814453125\nINFO:root:10: Epoch 5 train loss: 711.0743408203125\nINFO:root:33: Epoch 5 train loss: 558738.4375\nINFO:root:38: Epoch 5 train loss: 4636.44384765625\nINFO:root:12: Epoch 5 train loss: 9912.1640625\nINFO:root:37: Epoch 5 train loss: 4623.19091796875\nINFO:root:14: Epoch 5 train loss: 834.9939575195312\nINFO:root:5: Epoch 5 train loss: 184381.921875\nINFO:root:9: Epoch 5 train loss: 446025.25\nINFO:root:35: Epoch 5 train loss: 1383.4864501953125\nINFO:root:40: Epoch 5 train loss: 1900.64697265625\nINFO:root:11: Epoch 5 train loss: 1125.9576416015625\nINFO:root:1: Epoch 5 train loss: 61.7646484375\nINFO:root:0: Epoch 5 train loss: 322.9781494140625\nINFO:root:34: Epoch 5 train loss: 6787.29052734375\nINFO:root:47: Epoch 5 train loss: 1546.4229736328125\nINFO:root:36: Epoch 5 train loss: 1898.80126953125\nINFO:root:13: Epoch 5 train loss: 3627.29833984375\nINFO:root:16: Epoch 5 train loss: 371.62139892578125\nINFO:root:27: Epoch 5 train loss: 671231.6875\nINFO:root:41: Epoch 5 train loss: 1325.75\nINFO:root:7: Epoch 5 train loss: 446509.65625\nINFO:root:45: Epoch 5 train loss: 4040.194091796875\nINFO:root:21: Epoch 5 train loss: 138.56031799316406\nINFO:root:28: Epoch 5 train loss: 2528.8623046875\nINFO:root:17: Epoch 5 train loss: 69.1825942993164\nINFO:root:26: Epoch 5 train loss: 618872.6875\nINFO:root:19: Epoch 5 train loss: 234.26861572265625\nINFO:root:43: Epoch 5 train loss: 4596.33349609375\nINFO:root:46: Epoch 5 train loss: 1776.681396484375\nINFO:root:22: Epoch 5 train loss: 1920.4056396484375\nINFO:root:30: Epoch 5 train loss: 559930.9375\nINFO:root:42: Epoch 5 train loss: 3851.14599609375\nINFO:root:23: Epoch 5 train loss: 175370.734375\nINFO:root:31: Epoch 5 train loss: 2007.0714111328125\nINFO:root:18: Epoch 5 train loss: 166.97219848632812\nINFO:root:20: Epoch 5 train loss: 446.4451599121094\nINFO:root:8: Epoch 5 train loss: 2026.9495849609375\nINFO:root:44: Epoch 5 train loss: 7599.65966796875\nINFO:root:29: Epoch 5 train loss: 78.87605285644531\nINFO:root:25: Epoch 5 train loss: 558898.0\nINFO:root:24: Epoch 5 train loss: 6373.9931640625\nINFO:root:3: Epoch 5 train loss: 11590.271484375\nINFO:root:2: Epoch 5 train loss: 90.43724060058594\nINFO:root:0: Epoch 5 validation loss: 105897.30361846584\n", "seconds": 11.948535919189453, "batch_size": 256, "nodes": 12, "processes_per_node": 4, "threads_per_process": 1}]}